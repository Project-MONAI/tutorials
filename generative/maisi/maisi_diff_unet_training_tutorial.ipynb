{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import subprocess\n",
    "\n",
    "from monai.data import create_test_image_3d\n",
    "from monai.config import print_config\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simulate-dataset",
   "metadata": {},
   "source": [
    "## Simulate a special dataset\n",
    "\n",
    "It is well known that AI takes time to train. To provide the \"Hello World!\" experience of Auto3D in this notebook, we will simulate a small dataset and run training only for multiple epochs. Due to the nature of AI, the performance shouldn't be highly expected, but the entire pipeline will be completed within minutes!\n",
    "\n",
    "`sim_datalist` provides the information of the simulated datasets. It lists 12 training and 2 testing images and labels. The training data are split into 3 folds. Each fold will use 8 images to train and 4 images to validate. The size of the dimension is defined by the `sim_dim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-datalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_datalist = {\n",
    "    \"training\": [\n",
    "        {\"image\": \"tr_image_001.nii.gz\"},\n",
    "        {\"image\": \"tr_image_002.nii.gz\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "sim_dim = (128, 160, 96)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generate-images-labels",
   "metadata": {},
   "source": [
    "## Generate images and labels\n",
    "\n",
    "Now we can use MONAI `create_test_image_3d` and `nib.Nifti1Image` functions to generate the 3D simulated images under the work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = \"./helloworld_work_dir\"\n",
    "if not os.path.isdir(work_dir):\n",
    "    os.makedirs(work_dir)\n",
    "\n",
    "dataroot_dir = os.path.join(work_dir, \"sim_dataroot\")\n",
    "if not os.path.isdir(dataroot_dir):\n",
    "    os.makedirs(dataroot_dir)\n",
    "\n",
    "datalist_file = os.path.join(work_dir, \"sim_datalist.json\")\n",
    "with open(datalist_file, \"w\") as f:\n",
    "    json.dump(sim_datalist, f)\n",
    "\n",
    "for d in sim_datalist[\"training\"]:\n",
    "    im, _ = create_test_image_3d(\n",
    "        sim_dim[0], sim_dim[1], sim_dim[2], rad_max=10, num_seg_classes=1, random_state=np.random.RandomState(42)\n",
    "    )\n",
    "    image_fpath = os.path.join(dataroot_dir, d[\"image\"])\n",
    "    nib.save(nib.Nifti1Image(im, affine=np.eye(4)), image_fpath)\n",
    "\n",
    "print(\"Generated simulated images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-directories",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directories and configurations\n",
    "env_config_path = \"./configs/environment_maisi_diff_model_train.json\"\n",
    "model_config_path = \"./configs/config_maisi_diff_model_train.json\"\n",
    "\n",
    "# Load environment and model configurations\n",
    "with open(env_config_path, \"r\") as f:\n",
    "    env_config = json.load(f)\n",
    "\n",
    "with open(model_config_path, \"r\") as f:\n",
    "    model_config = json.load(f)\n",
    "\n",
    "env_config_out = copy.deepcopy(env_config)\n",
    "model_config_out = copy.deepcopy(model_config)\n",
    "\n",
    "# Set up directories based on configurations\n",
    "env_config_out[\"data_base_dir\"] = dataroot_dir\n",
    "env_config_out[\"embedding_base_dir\"] = os.path.join(work_dir, env_config_out[\"embedding_base_dir\"])\n",
    "env_config_out[\"json_data_list\"] = datalist_file\n",
    "env_config_out[\"model_dir\"] = os.path.join(work_dir, env_config_out[\"model_dir\"])\n",
    "env_config_out[\"output_dir\"] = os.path.join(work_dir, env_config_out[\"output_dir\"])\n",
    "env_config_out[\"trained_autoencoder_path\"] = None\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(env_config_out[\"embedding_base_dir\"], exist_ok=True)\n",
    "os.makedirs(env_config_out[\"model_dir\"], exist_ok=True)\n",
    "os.makedirs(env_config_out[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "env_config_filepath = os.path.join(work_dir, \"environment_maisi_diff_model_train.json\")\n",
    "with open(env_config_filepath, \"w\") as f:\n",
    "    json.dump(env_config_out, f, sort_keys=True, indent=4)\n",
    "\n",
    "# Update model configuration for demo\n",
    "model_config_out[\"autoencoder_def\"][\"num_splits\"] = 4\n",
    "\n",
    "model_config_filepath = os.path.join(work_dir, \"config_maisi_diff_model_train.json\")\n",
    "with open(model_config_filepath, \"w\") as f:\n",
    "    json.dump(model_config_out, f, sort_keys=True, indent=4)\n",
    "\n",
    "# Print files and folders under work_dir\n",
    "print(os.listdir(work_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-training-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create Training Data\n",
    "print(\"Creating training data...\")\n",
    "\n",
    "# Define the arguments for torchrun\n",
    "num_nodes = 1\n",
    "num_gpus = 2  # Adjust based on the number of GPUs you want to use\n",
    "script = \"scripts/diff_model_create_training_data.py\"  # Replace with your script\n",
    "script_args = [\n",
    "    \"--env_config\", env_config_filepath,\n",
    "    \"--model_config\", model_config_filepath\n",
    "]\n",
    "\n",
    "# Build the torchrun command\n",
    "torchrun_command = [\n",
    "    \"torchrun\",\n",
    "    \"--nproc_per_node\", str(num_gpus),\n",
    "    \"--nnodes\", str(num_nodes),\n",
    "    script\n",
    "] + script_args\n",
    "\n",
    "# Execute the command\n",
    "result = subprocess.run(torchrun_command, capture_output=True, text=True)\n",
    "\n",
    "# Print the output and errors\n",
    "print(\"Output:\\n\", result.stdout)\n",
    "print(\"Errors:\\n\", result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the Model\n",
    "print(\"Training the model...\")\n",
    "diff_model_train(env_config_path, model_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infer-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Infer using the Trained Model\n",
    "print(\"Running inference...\")\n",
    "diff_model_infer(env_config_path, model_config_path, ckpt_filepath, amp)\n",
    "\n",
    "print(\"Completed all steps.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
