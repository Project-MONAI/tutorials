{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b9c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import sys\n",
    "\n",
    "splits = joblib.load('/workspace/Code/tutorials/pathology/hovernet/splits.dat')\n",
    "def prepare_data(data_dir, fold, splits):\n",
    "    images = np.load(os.path.join(data_dir, \"images.npy\"))\n",
    "    labels = np.load(os.path.join(data_dir, \"labels.npy\"))\n",
    "\n",
    "    data = [\n",
    "        {\n",
    "            \"image\": image,\n",
    "            \"image_meta_dict\": {\"original_channel_dim\": -1},\n",
    "            \"label\": label,\n",
    "            \"label_meta_dict\": {\"original_channel_dim\": -1},\n",
    "        }\n",
    "        for image, label in zip(images, labels)\n",
    "    ]\n",
    "    train_data = [data[i] for i in splits[fold]['train']]\n",
    "    valid_data = [data[i] for i in splits[fold]['valid']]\n",
    "    \n",
    "    return train_data, valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b90f63f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from scipy.ndimage import filters, measurements\n",
    "from scipy.ndimage.morphology import (\n",
    "    binary_dilation,\n",
    "    binary_fill_holes,\n",
    "    distance_transform_cdt,\n",
    "    distance_transform_edt,\n",
    ")\n",
    "\n",
    "from skimage.segmentation import watershed\n",
    "\n",
    "import warnings\n",
    "\n",
    "def get_bounding_box(img):\n",
    "    \"\"\"Get bounding box coordinate information.\"\"\"\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "    # due to python indexing, need to add 1 to max\n",
    "    # else accessing will be 1px in the box, not out\n",
    "    rmax += 1\n",
    "    cmax += 1\n",
    "    return [rmin, rmax, cmin, cmax]\n",
    "\n",
    "def remove_small_objects(pred, min_size=64, connectivity=1):\n",
    "    \"\"\"Remove connected components smaller than the specified size.\n",
    "    This function is taken from skimage.morphology.remove_small_objects, but the warning\n",
    "    is removed when a single label is provided. \n",
    "    Args:\n",
    "        pred: input labelled array\n",
    "        min_size: minimum size of instance in output array\n",
    "        connectivity: The connectivity defining the neighborhood of a pixel. \n",
    "    \n",
    "    Returns:\n",
    "        out: output array with instances removed under min_size\n",
    "    \"\"\"\n",
    "    out = pred\n",
    "\n",
    "    if min_size == 0:  # shortcut for efficiency\n",
    "        return out\n",
    "\n",
    "    if out.dtype == bool:\n",
    "        selem = ndimage.generate_binary_structure(pred.ndim, connectivity)\n",
    "        ccs = np.zeros_like(pred, dtype=np.int32)\n",
    "        ndimage.label(pred, selem, output=ccs)\n",
    "    else:\n",
    "        ccs = out\n",
    "\n",
    "    try:\n",
    "        component_sizes = np.bincount(ccs.ravel())\n",
    "    except ValueError:\n",
    "        raise ValueError(\n",
    "            \"Negative value labels are not supported. Try \"\n",
    "            \"relabeling the input with `scipy.ndimage.label` or \"\n",
    "            \"`skimage.morphology.label`.\"\n",
    "        )\n",
    "\n",
    "    too_small = component_sizes < min_size\n",
    "    too_small_mask = too_small[ccs]\n",
    "    out[too_small_mask] = 0\n",
    "\n",
    "    return out\n",
    "\n",
    "def noop(*args, **kargs):\n",
    "    pass\n",
    "\n",
    "\n",
    "warnings.warn = noop\n",
    "\n",
    "\n",
    "####\n",
    "def __proc_np_hv(pred):\n",
    "    \"\"\"Process Nuclei Prediction with XY Coordinate Map.\n",
    "    Args:\n",
    "        pred: prediction output, assuming \n",
    "              channel 0 contain probability map of nuclei\n",
    "              channel 1 containing the regressed X-map\n",
    "              channel 2 containing the regressed Y-map\n",
    "    \"\"\"\n",
    "#     pred = np.array(pred, dtype=np.float32)\n",
    "\n",
    "#     blb_raw = pred[..., 0]\n",
    "#     h_dir_raw = pred[..., 1]\n",
    "#     v_dir_raw = pred[..., 2]\n",
    "\n",
    "#     # processing\n",
    "#     blb = np.array(blb_raw >= 0.5, dtype=np.int32)\n",
    "\n",
    "    blb_raw = pred[HoVerNetBranch.NP.value]\n",
    "    h_dir_raw = pred[HoVerNetBranch.HV.value][0,...]\n",
    "    v_dir_raw = pred[HoVerNetBranch.HV.value][1,...]\n",
    "    blb = Activations(sigmoid=False, softmax=True)(blb_raw)\n",
    "    blb = AsDiscrete(argmax=True)(blb)\n",
    "\n",
    "    blb = blb.detach().cpu()\n",
    "    h_dir_raw = h_dir_raw.detach().cpu().numpy()\n",
    "    v_dir_raw = v_dir_raw.detach().cpu().numpy()\n",
    "    blb = measurements.label(blb)[0]\n",
    "    blb = remove_small_objects(blb, min_size=10)\n",
    "    blb[blb > 0] = 1  # background is 0 already\n",
    "\n",
    "    h_dir = cv2.normalize(\n",
    "        h_dir_raw, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F\n",
    "    )\n",
    "    v_dir = cv2.normalize(\n",
    "        v_dir_raw, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F\n",
    "    )\n",
    "\n",
    "    sobelh = cv2.Sobel(h_dir, cv2.CV_64F, 1, 0, ksize=21)\n",
    "    sobelv = cv2.Sobel(v_dir, cv2.CV_64F, 0, 1, ksize=21)\n",
    "\n",
    "    sobelh = 1 - (\n",
    "        cv2.normalize(\n",
    "            sobelh, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F\n",
    "        )\n",
    "    )\n",
    "    sobelv = 1 - (\n",
    "        cv2.normalize(\n",
    "            sobelv, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F\n",
    "        )\n",
    "    )\n",
    "\n",
    "    overall = np.maximum(sobelh, sobelv)\n",
    "    overall = overall - (1 - blb)\n",
    "    overall[overall < 0] = 0\n",
    "\n",
    "    dist = (1.0 - overall) * blb\n",
    "    ## nuclei values form mountains so inverse to get basins\n",
    "    dist = -cv2.GaussianBlur(dist, (3, 3), 0)\n",
    "\n",
    "    overall = np.array(overall >= 0.8, dtype=np.int32)\n",
    "\n",
    "    marker = blb - overall\n",
    "    marker[marker < 0] = 0\n",
    "    marker = binary_fill_holes(marker).astype(\"uint8\")\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    marker = cv2.morphologyEx(marker, cv2.MORPH_OPEN, kernel)\n",
    "    marker = measurements.label(marker)[0]\n",
    "    marker = remove_small_objects(marker, min_size=10)\n",
    "\n",
    "    proced_pred = watershed(dist, markers=marker, mask=blb)\n",
    "    proced_pred[proced_pred>0] = 1\n",
    "    return proced_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75fad345",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0p = \"/workspace/Code/tutorials/pathology/hovernet/runs/ngc-exp/Oct26_15-14-17_3577198_0/best_metric_model0.pth\"\n",
    "model1p = \"/workspace/Code/tutorials/pathology/hovernet/runs/ngc-exp/Oct26_15-15-55_3577198_1/best_metric_model1.pth\"\n",
    "model2p = \"/workspace/Code/tutorials/pathology/hovernet/runs/ngc-exp/Oct26_15-17-07_3577198_2/best_metric_model2.pth\"\n",
    "\n",
    "model_list = [model0p, model1p, model2p]\n",
    "import sys\n",
    "sys.path.append('/workspace/Code/tutorials/pathology/hovernet/transforms')\n",
    "sys.path.append('/workspace/Code/tutorials/pathology/hovernet/loss')\n",
    "from loss import HoVerNetLoss\n",
    "from transforms import (\n",
    "    GenerateWatershedMaskd,\n",
    "    GenerateInstanceBorderd,\n",
    "    GenerateDistanceMapd,\n",
    "    GenerateWatershedMarkersd,\n",
    "    Watershedd,\n",
    "    GenerateInstanceContour,\n",
    "    GenerateInstanceCentroid,\n",
    "    GenerateInstanceType,\n",
    "    GenerateInstanceCentroid, \n",
    "    GenerateInstanceContour, \n",
    "    GenerateInstanceType,\n",
    ")\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from monai.data import DataLoader, decollate_batch, Dataset, CacheDataset\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import HoVerNet\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    ScaleIntensityRanged,\n",
    "    CastToTyped,\n",
    "    Lambdad,\n",
    "    SplitDimd,\n",
    "    EnsureChannelFirstd,\n",
    "    ComputeHoVerMapsd,\n",
    "    RandFlipd,\n",
    "    RandRotate90d,\n",
    "    RandGaussianSmoothd,\n",
    "    FillHoles,\n",
    "    BoundingRect,\n",
    "    CenterSpatialCropd,\n",
    "    SaveImage,\n",
    "    GaussianSmooth,\n",
    ")\n",
    "\n",
    "from monai.utils import set_determinism, convert_to_tensor\n",
    "from monai.utils.enums import HoVerNetBranch\n",
    "from monai.visualize import plot_2d_or_3d_image\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "            \n",
    "\n",
    "def post_process(output, device, return_binary=True, return_centroids=False, output_classes=None):\n",
    "    post_trans_seg = Compose([\n",
    "        GenerateWatershedMaskd(keys=HoVerNetBranch.NP.value, softmax=True),\n",
    "        GenerateInstanceBorderd(keys='mask', hover_map_key=HoVerNetBranch.HV, kernel_size=3),\n",
    "        GenerateDistanceMapd(keys='mask', border_key='border', smooth_fn=GaussianSmooth()),\n",
    "        GenerateWatershedMarkersd(keys='mask', border_key='border', threshold=0.99, radius=2, postprocess_fn=FillHoles()),\n",
    "        Watershedd(keys='dist', mask_key='mask', markers_key='markers')\n",
    "    ])\n",
    "    if HoVerNetBranch.NC.value in output.keys():\n",
    "        type_pred = Activations(softmax=True)(output[HoVerNetBranch.NC.value])\n",
    "        type_pred = AsDiscrete(argmax=True)(type_pred)\n",
    "\n",
    "    pred_inst_dict = post_trans_seg(output)\n",
    "    pred_inst = pred_inst_dict['dist']\n",
    "\n",
    "    inst_id_list = np.unique(pred_inst)[1:]  # exclude background\n",
    "inst_info\n",
    "    inst_info_dict = None\n",
    "    if return_centroids:\n",
    "        inst_id_list = np.unique(pred_inst)[1:]  # exclude background\n",
    "        inst_info_dict = {}\n",
    "        for inst_id in inst_id_list:\n",
    "            inst_map = pred_inst == inst_id\n",
    "            inst_bbox = BoundingRect()(inst_map)\n",
    "            inst_map = inst_map[:, inst_bbox[0][0]: inst_bbox[0][1], inst_bbox[0][2]: inst_bbox[0][3]]\n",
    "            offset = [inst_bbox[0][2], inst_bbox[0][0]]\n",
    "            inst_contour = GenerateInstanceContour()(inst_map.squeeze(), offset)\n",
    "            inst_centroid = GenerateInstanceCentroid()(inst_map, offset)\n",
    "            if inst_contour is not None:\n",
    "                inst_info_dict[inst_id] = {  # inst_id should start at 1\n",
    "                    \"bounding_box\": inst_bbox,\n",
    "                    \"centroid\": inst_centroid,\n",
    "                    \"contour\": inst_contour,\n",
    "                    \"type_probability\": None,\n",
    "                    \"type\": None,\n",
    "                }\n",
    "\n",
    "    if output_classes is not None:\n",
    "        for inst_id in list(inst_info_dict.keys()):\n",
    "            inst_type, type_prob = GenerateInstanceType()(\n",
    "                bbox=inst_info_dict[inst_id][\"bounding_box\"], type_pred=type_pred, seg_pred=pred_inst, instance_id=inst_id)\n",
    "            inst_info_dict[inst_id][\"type\"] = inst_type\n",
    "            inst_info_dict[inst_id][\"type_probability\"] = type_prob\n",
    "\n",
    "    pred_inst = convert_to_tensor(pred_inst, device=device)\n",
    "    if return_binary:\n",
    "        pred_inst[pred_inst > 0] = 1\n",
    "    return (pred_inst, inst_info_dict, pred_inst_dict)\n",
    "\n",
    "def main(data_dir, fold):\n",
    "\n",
    "    test_transforms = Compose(\n",
    "        [\n",
    "            EnsureChannelFirstd(keys=(\"image\", \"label\"), channel_dim=-1),\n",
    "            SplitDimd(keys=\"label\", output_postfixes=[\"inst\", \"type\"]),\n",
    "            ComputeHoVerMapsd(keys=\"label_inst\"),\n",
    "            CastToTyped(keys=[\"image\", \"label_inst\", \"label_type\", \"hover_label_inst\"], dtype=torch.float32),\n",
    "            Lambdad(keys=\"label\", func=lambda x: x[1: 2, ...] > 0),\n",
    "            AsDiscreted(keys=[\"label\", \"label_type\"], to_onehot=[2, 7]),\n",
    "            CenterSpatialCropd(keys=[\"label\", \"label_inst\", \"label_type\", \"hover_label_inst\"], roi_size=(164,164)),\n",
    "            ScaleIntensityRanged(keys=[\"image\"], a_min=0.0, a_max=255.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "        \n",
    "    post_process_0 = Compose(\n",
    "    [\n",
    "        Activations(sigmoid=False, softmax=True),\n",
    "        \n",
    "    ])\n",
    "    \n",
    "    train_data, valid_data = prepare_data(data_dir, fold, splits)\n",
    "    test_ds = Dataset(data=valid_data, transform=test_transforms)\n",
    "    test_loader = DataLoader(test_ds, batch_size=8, num_workers=4, pin_memory=True)\n",
    "\n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "    device = torch.device(\"cuda:1\")\n",
    "    model = HoVerNet(\n",
    "        mode=\"fast\",\n",
    "        in_channels=3,\n",
    "        out_classes=7,\n",
    "        act=(\"relu\", {\"inplace\": True}),\n",
    "        norm=\"batch\",\n",
    "        dropout_prob=0.2,\n",
    "    ).to(device)\n",
    "\n",
    "#     model.load_state_dict(torch.load(os.path.join(data_dir, \"best_metric_model.pth\")))\n",
    "    model.load_state_dict(torch.load(model_list[fold]))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for test_data in test_loader:\n",
    "            test_inputs, test_label, test_label_type, test_hover_map = (\n",
    "                    test_data[\"image\"].to(device),\n",
    "                    test_data[\"label\"].to(device),\n",
    "                    test_data[\"label_type\"].to(device),\n",
    "                    test_data[\"hover_label_inst\"].to(device),\n",
    "                )\n",
    "\n",
    "            test_outputs = model(test_inputs)\n",
    "#             test_outputs = [torch.tensor(__proc_np_hv(i)).to(device) for i in decollate_batch(test_outputs)]\n",
    "            test_outputs = [AsDiscrete(threshold=0.5)(post_process_0(i[HoVerNetBranch.NP.value])[1:2,...]) for i in decollate_batch(test_outputs)]\n",
    "            test_label = [i for i in decollate_batch(test_label)]\n",
    "    \n",
    "            # compute metric for current iteration\n",
    "            dice_metric(y_pred=test_outputs, y=test_label)\n",
    "\n",
    "        metric = dice_metric.aggregate().item()\n",
    "        # aggregate the final mean dice result\n",
    "        print(\"evaluation metric:\", metric)\n",
    "        # reset the status\n",
    "        dice_metric.reset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d95b441",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation metric: 0.8250155448913574\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/workspace/Data/Lizard/Prepared\"\n",
    "main(data_dir, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2592b8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold0: \n",
    "    evaluation metric: 0.7615175843238831  # 0.6\n",
    "    evaluation metric: 0.8022753596305847  # 0.65\n",
    "    evaluation metric: 0.8130292296409607  # 0.7\n",
    "    evaluation metric: 0.8172582387924194  # 0.75\n",
    "    evaluation metric: 0.8192526698112488  # 0.8\n",
    "    evaluation metric: 0.8202919960021973  # 0.85\n",
    "    evaluation metric: 0.8210670351982117  # 0.9\n",
    "    evaluation metric: 0.8215556144714355  # 0.95\n",
    "    evaluation metric: 0.8216920495033264  # 0.99\n",
    "\n",
    "fold1: \n",
    "    evaluation metric: 0.8130324482917786\n",
    "    \n",
    "fold2:\n",
    "    evaluation metric: 0.8064720630645752"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8250155448913574\n",
    "0.8159043788909912\n",
    "0.8085355758666992\n",
    "\n",
    "0.8163"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
