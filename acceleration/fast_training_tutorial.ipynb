{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Fast training with MONAI features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows a regular PyTorch training program and a MONAI optimized training program, and compared the performance.  \n",
    "Mainly includes:\n",
    "1. AMP (Auto mixed precision).\n",
    "2. CacheDataset for deterministic transforms.\n",
    "3. Move data to GPU and cache, then execute random transforms on GPU.\n",
    "4. multi-threads `ThreadDataLoader` is faster than PyTorch DataLoader in light-weight task.\n",
    "5. Use MONAI `DiceCE` loss instead of regular `Dice` loss.\n",
    "6. Analyzed training curve and tuned algorithm: Use `SGD` optimizer, different network parameters, etc.\n",
    "\n",
    "With a V100 GPU and the target validation `mean dice = 0.94` of the `forground` channel only,  it's more than `100x` speedup compared with the Pytorch regular implementation when achieving the same metric. And every epoch is `20x` faster than regular training.\n",
    "\n",
    "It's modified from the Spleen 3D segmentation tutorial notebook, the Spleen dataset can be downloaded from http://medicaldecathlon.com/.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Project-MONAI/tutorials/blob/main/acceleration/fast_training_tutorial.ipynb)(* please note that the free GPU resource in Colab may be not as powerful as the V100 test results in this notebook: it may not support AMP and the GPU computation of transforms may be not faster than the CPU computation.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To support profiling, the following lines have been commented out. \n",
    "\n",
    "- To verify that you have key packages installed, uncomment the middle section (3 lines).\n",
    "- If you are not interested in profiling (i.e., you will run this as a Jupyter notebook), uncomment the last line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# these are commented out to ensure the converted python script runs smoothly\n",
    "\n",
    "# !python3 -c \"import monai\" || pip install -q \"monai-weekly[nibabel, tqdm]\"\n",
    "# !python3 -c \"import matplotlib\" || pip install -q matplotlib\n",
    "# !python3 -c \"import nvtx\" || pip install -q nvtx\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.9.0\n",
      "Numpy version: 1.22.3\n",
      "Pytorch version: 1.12.0a0+bd13bc6\n",
      "MONAI flags: HAS_EXT = True, USE_COMPILED = False\n",
      "MONAI rev id: af0e0e9f757558d144b655c63afcea3a4e0a06f5\n",
      "MONAI __file__: /opt/monai/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.8\n",
      "Nibabel version: 3.2.2\n",
      "scikit-image version: 0.19.3\n",
      "Pillow version: 9.0.1\n",
      "Tensorboard version: 2.8.0\n",
      "gdown version: 4.4.0\n",
      "TorchVision version: 0.13.0a0\n",
      "tqdm version: 4.64.0\n",
      "lmdb version: 1.3.0\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.3.5\n",
      "einops version: 0.4.1\n",
      "transformers version: 4.19.4\n",
      "mlflow version: 1.26.1\n",
      "pynrrd version: 0.4.3\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import (\n",
    "    CacheDataset,\n",
    "    DataLoader,\n",
    "    ThreadDataLoader,\n",
    "    Dataset,\n",
    "    decollate_batch,\n",
    ")\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.losses import DiceLoss, DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.layers import Act, Norm\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    FgBgToIndicesd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    ToDeviced,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "# for profiling\n",
    "import nvtx\n",
    "from monai.utils.nvtx import Range\n",
    "import contextlib  # to improve code readability (combining training/validation loop with and without profiling)\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data & output directories\n",
    "\n",
    "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.  \n",
    "This allows you to save results and reuse downloads.  \n",
    "If not specified a temporary directory will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root dir is: /tmp/tmpv0msvmnr\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(f\"root dir is: {root_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, outputs will go to `outputs/`. \n",
    "\n",
    "You can run this tutorial twice, once with profiling and once without, and the outputs will not conflict with each other. \n",
    "- When profiling, the output is `outputs/output_base.nsys-rep`, which you can then visualize using the GUI of Nsight systems (a brief guide is provided in the \"Profiling visualization\" section below).\n",
    "- When not profiling, the outputs are `outputs/loss_dice_comparison.png`, `outputs/metric_time_epochs.png`, and `outputs/total_epoch_time_comparison.png`.\n",
    "\n",
    "We set up the tutorial such that figures are only generated when not profiling, but that does not have to be the case. In general, the figures make more sense when training is run for a higher number of epochs (e.g., hundreds), which is usually not the case when profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# outputs\n",
    "\n",
    "out_dir = \"outputs/\"\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section sets up profiling for this tutorial.\n",
    "\n",
    "The number of epochs is automatically set based on whether profiling is being performed, but you can modify as needed.\n",
    "\n",
    "- If you are not interested in profiling, please set `profiling = False` and move on.\n",
    "\n",
    "- If you are profiling:\n",
    "\n",
    "  - Because of the currently supported functionality of Nsight systems (`nsys`), profiling can only be performed from the terminal, and not from within this tutorial. For more information, including installation, refer to the [NVIDIA Nsight Systems page](https://developer.nvidia.com/nsight-systems).\n",
    "  - Perform the following steps:\n",
    "  \n",
    "    1) Make sure `nsys` is installed;\n",
    "    \n",
    "    2) Set `profiling = True`;\n",
    "    \n",
    "    3) Make sure all lines in \"Setup environment\" (first code cell in this tutorial, above) are commented out;\n",
    "    \n",
    "    4) Save this notebook;\n",
    "    \n",
    "    5) Open the terminal and ensure that you are in the directory of this notebook, then run this command:\n",
    "    `jupyter nbconvert fast_training_tutorial.ipynb --to python && nsys profile --output ./outputs/output_base --force-overwrite true --trace-fork-before-exec true python3 fast_training_tutorial.py ; rm fast_training_tutorial.py`\n",
    "    \n",
    "    This command converts the notebook to a Python script locally and runs `nsys`. The output file is `outputs/output_base.nsys-rep`, but you can modify `--output` to specify the desired location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "profiling = False\n",
    "\n",
    "# if profiling = True, it is recommended to set max_epochs = 6 for faster prototyping\n",
    "# to see the trend in training curve and dice results, set max_epochs to be larger (600)\n",
    "# note that before optimization, training can be quite a bit slower\n",
    "max_epochs = 6 if profiling else 600\n",
    "\n",
    "# to improve readability\n",
    "\n",
    "\n",
    "def range_func(x, y): return Range(x)(y) if profiling else y\n",
    "\n",
    "\n",
    "no_profiling = contextlib.nullcontext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset\n",
    "\n",
    "Downloads and extracts the Decathlon Spleen dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task09_Spleen.tar: 1.50GB [01:00, 26.7MB/s]                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-28 03:56:26,901 - INFO - Downloaded: /tmp/tmpv0msvmnr/Task09_Spleen.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-28 03:56:30,190 - INFO - Verified 'Task09_Spleen.tar', md5: 410d4a301da4e5b2f6f86ec3ddba524e.\n",
      "2022-06-28 03:56:30,191 - INFO - Writing into directory: /tmp/tmpv0msvmnr.\n"
     ]
    }
   ],
   "source": [
    "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task09_Spleen.tar\"\n",
    "md5 = \"410d4a301da4e5b2f6f86ec3ddba524e\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"Task09_Spleen.tar\")\n",
    "data_root = os.path.join(root_dir, \"Task09_Spleen\")\n",
    "if not os.path.exists(data_root):\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set MSD Spleen dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_images = sorted(\n",
    "    glob.glob(os.path.join(data_root, \"imagesTr\", \"*.nii.gz\"))\n",
    ")\n",
    "train_labels = sorted(\n",
    "    glob.glob(os.path.join(data_root, \"labelsTr\", \"*.nii.gz\"))\n",
    ")\n",
    "data_dicts = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(train_images, train_labels)\n",
    "]\n",
    "train_files, val_files = data_dicts[:-9], data_dicts[-9:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup transforms for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def transformations(fast=False, device='cuda:0'):\n",
    "    train_transforms = [\n",
    "        range_func(\"LoadImage\", LoadImaged(keys=[\"image\", \"label\"])),\n",
    "        range_func(\"AddChannel\", AddChanneld(keys=[\"image\", \"label\"])),\n",
    "        range_func(\"Orientation\", Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\")),\n",
    "        range_func(\"Spacing\", Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        )),\n",
    "        range_func(\"ScaleIntensityRange\",\n",
    "                   ScaleIntensityRanged(\n",
    "                       keys=[\"image\"],\n",
    "                       a_min=-57,\n",
    "                       a_max=164,\n",
    "                       b_min=0.0,\n",
    "                       b_max=1.0,\n",
    "                       clip=True,\n",
    "                   )),\n",
    "        range_func(\"CropForeground\", CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\")),\n",
    "        # pre-compute foreground and background indexes\n",
    "        # and cache them to accelerate training\n",
    "        range_func(\"Indexing\", FgBgToIndicesd(\n",
    "            keys=\"label\",\n",
    "            fg_postfix=\"_fg\",\n",
    "            bg_postfix=\"_bg\",\n",
    "            image_key=\"image\",\n",
    "        )),\n",
    "        # change to execute transforms with Tensor data\n",
    "        range_func(\"EnsureType\", EnsureTyped(keys=[\"image\", \"label\"])),\n",
    "    ]\n",
    "\n",
    "    if fast:\n",
    "        # move the data to GPU and cache to avoid CPU -> GPU sync in every epoch\n",
    "        train_transforms.append(range_func(\"ToDevice\", ToDeviced(keys=[\"image\", \"label\"], device=device)))\n",
    "\n",
    "    train_transforms.append(\n",
    "        # randomly crop out patch samples from big\n",
    "        # image based on pos / neg ratio\n",
    "        # the image centers of negative samples\n",
    "        # must be in valid image area\n",
    "        range_func(\"RandCrop\", RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            fg_indices_key=\"label_fg\",\n",
    "            bg_indices_key=\"label_bg\",\n",
    "        )),\n",
    "    )\n",
    "\n",
    "    val_transforms = [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-57,\n",
    "            a_max=164,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    "    if fast:\n",
    "        # move the data to GPU and cache to avoid CPU -> GPU sync in every epoch\n",
    "        val_transforms.append(\n",
    "            ToDeviced(keys=[\"image\", \"label\"], device=device)\n",
    "        )\n",
    "\n",
    "    return Compose(train_transforms), Compose(val_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the training progress\n",
    "For a typical PyTorch regular training procedure, use regular `Dataset`, `DataLoader`, `Adam` optimizer and `Dice` loss to train the model.\n",
    "\n",
    "For MONAI fast training progress, we mainly introduce the following features:\n",
    "1. `AMP` (auto mixed precision): AMP is an important feature released in PyTorch v1.6, NVIDIA CUDA 11 added strong support for AMP and significantly improved training speed.\n",
    "2. `CacheDataset`: Dataset with the cache mechanism that can load data and cache deterministic transforms' result during training.\n",
    "3. `ToDeviced` transform: to move data to GPU and cache with `CacheDataset`, then execute random transforms on GPU directly, avoid CPU -> GPU sync in every epoch. Please note that not all the MONAI transforms support GPU operation so far, still working in progress.\n",
    "4. `ThreadDataLoader`: uses multi-threads instead of multi-processing, faster than `DataLoader` in light-weight task as we already cached the results of most computation.\n",
    "5. `DiceCE` loss function: computes Dice loss and Cross Entropy Loss, returns the weighted sum of these two losses.\n",
    "6. Analyzed the training curve and tuned algorithm: Use `SGD` optimizer, different network parameters, etc.\n",
    "\n",
    "(A note on code: to improve readability and support the profiling flag, we used the `with nvtx(...) if profiling else no_profiling` context pattern, where `no_profiling` is a null context from Python's native `contextlib` with no effect on the code. An acknowledgement is provided here[<sup id=\"fn1-back\">1</sup>](#fn1).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def train_process(fast=False):\n",
    "    learning_rate = 2e-4\n",
    "    val_interval = 5  # do validation for every epoch\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        raise RuntimeError('this tutorial is intended for GPU, but no CUDA device is available')\n",
    "\n",
    "    train_trans, val_trans = transformations(fast=fast, device=device)\n",
    "    # set CacheDataset, ThreadDataLoader and DiceCE loss for MONAI fast training\n",
    "    if fast:\n",
    "        # as `RandCropByPosNegLabeld` crops from the cached content and `deepcopy`\n",
    "        # the crop area instead of modifying the cached value, we can set `copy_cache=False`\n",
    "        # to avoid unnecessary deepcopy of cached content in `CacheDataset`\n",
    "        train_ds = CacheDataset(\n",
    "            data=train_files,\n",
    "            transform=train_trans,\n",
    "            cache_rate=1.0,\n",
    "            num_workers=8,\n",
    "            copy_cache=False,\n",
    "        )\n",
    "        val_ds = CacheDataset(\n",
    "            data=val_files, transform=val_trans, cache_rate=1.0, num_workers=5, copy_cache=False\n",
    "        )\n",
    "        # disable multi-workers because `ThreadDataLoader` works with multi-threads\n",
    "        train_loader = ThreadDataLoader(train_ds, num_workers=0, batch_size=4, shuffle=True)\n",
    "        val_loader = ThreadDataLoader(val_ds, num_workers=0, batch_size=1)\n",
    "\n",
    "        loss_function = DiceCELoss(\n",
    "            include_background=False,\n",
    "            to_onehot_y=True,\n",
    "            softmax=True,\n",
    "            squared_pred=True,\n",
    "            batch=True,\n",
    "            smooth_nr=0.00001,\n",
    "            smooth_dr=0.00001,\n",
    "            lambda_dice=0.5,\n",
    "            lambda_ce=0.5,\n",
    "        )\n",
    "        model = UNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=2,\n",
    "            channels=(32, 64, 128, 256, 512),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,\n",
    "            norm=Norm.instance,\n",
    "            kernel_size=3,\n",
    "            up_kernel_size=3,\n",
    "            act=Act.PRELU,\n",
    "            dropout=0.2,\n",
    "            bias=True,\n",
    "            dimensions=None,\n",
    "        ).to(device)\n",
    "    else:\n",
    "        train_ds = Dataset(data=train_files, transform=train_trans)\n",
    "        val_ds = Dataset(data=val_files, transform=val_trans)\n",
    "        # num_worker=4 is the best parameter according to the test\n",
    "        train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4)\n",
    "        val_loader = DataLoader(val_ds, batch_size=1, num_workers=4)\n",
    "        loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "        model = UNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=2,\n",
    "            channels=(16, 32, 64, 128, 256),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,\n",
    "            norm=Norm.BATCH,\n",
    "        ).to(device)\n",
    "\n",
    "    post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=2)])\n",
    "    post_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])\n",
    "\n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "\n",
    "    if fast:\n",
    "        # SGD prefer to much bigger learning rate\n",
    "        optimizer = SGD(\n",
    "            model.parameters(),\n",
    "            lr=learning_rate * 1000,\n",
    "            momentum=0.9,\n",
    "            weight_decay=0.00004,\n",
    "        )\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "    else:\n",
    "        optimizer = Adam(model.parameters(), learning_rate)\n",
    "\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    best_metrics_epochs_and_time = [[], [], []]\n",
    "    epoch_loss_values = []\n",
    "    metric_values = []\n",
    "    epoch_times = []\n",
    "    total_start = time.time()\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "\n",
    "        # profiling: full epoch\n",
    "        with nvtx.annotate(\"epoch\", color=\"red\") if profiling else no_profiling:\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            train_loader_iterator = iter(train_loader)\n",
    "\n",
    "            # using step instead of iterate through train_loader directly to track data loading time\n",
    "            # steps are 1-indexed for printing and calculation purposes\n",
    "            for step in range(1, len(train_loader) + 1):\n",
    "                step_start = time.time()\n",
    "\n",
    "                # profiling: train dataload\n",
    "                with nvtx.annotate(\"dataload\", color=\"red\") if profiling else no_profiling:\n",
    "                    # rng_train_dataload = nvtx.start_range(message=\"dataload\", color=\"red\")\n",
    "                    batch_data = next(train_loader_iterator)\n",
    "                    inputs, labels = (\n",
    "                        batch_data[\"image\"].to(device),\n",
    "                        batch_data[\"label\"].to(device),\n",
    "                    )\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                # set AMP for MONAI training\n",
    "                if fast:\n",
    "                    # profiling: forward\n",
    "                    with nvtx.annotate(\"forward\", color=\"green\") if profiling else no_profiling:\n",
    "                        with torch.cuda.amp.autocast():\n",
    "                            outputs = model(inputs)\n",
    "                            loss = loss_function(outputs, labels)\n",
    "\n",
    "                    # profiling: backward\n",
    "                    with nvtx.annotate(\"backward\", color=\"blue\") if profiling else no_profiling:\n",
    "                        scaler.scale(loss).backward()\n",
    "\n",
    "                    # profiling: update\n",
    "                    with nvtx.annotate(\"update\", color=\"yellow\") if profiling else no_profiling:\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                else:\n",
    "                    # profiling: forward\n",
    "                    with nvtx.annotate(\"forward\", color=\"green\") if profiling else no_profiling:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = loss_function(outputs, labels)\n",
    "\n",
    "                    # profiling: backward\n",
    "                    with nvtx.annotate(\"backward\", color=\"blue\") if profiling else no_profiling:\n",
    "                        loss.backward()\n",
    "\n",
    "                    # profiling: update\n",
    "                    with nvtx.annotate(\"update\", color=\"yellow\") if profiling else no_profiling:\n",
    "                        optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_len = math.ceil(len(train_ds) / train_loader.batch_size)\n",
    "                print(\n",
    "                    f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\"\n",
    "                    f\" step time: {(time.time() - step_start):.4f}\"\n",
    "                )\n",
    "            epoch_loss /= step\n",
    "            epoch_loss_values.append(epoch_loss)\n",
    "            print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "            if (epoch + 1) % val_interval == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_loader_iterator = iter(val_loader)\n",
    "\n",
    "                    for val_step in range(len(val_loader)):\n",
    "                        # profiling: val dataload\n",
    "                        with nvtx.annotate(\"dataload\", color=\"red\") if profiling else no_profiling:\n",
    "                            val_data = next(val_loader_iterator)\n",
    "                            val_inputs, val_labels = (\n",
    "                                val_data[\"image\"].to(device),\n",
    "                                val_data[\"label\"].to(device),\n",
    "                            )\n",
    "\n",
    "                        roi_size = (160, 160, 160)\n",
    "                        sw_batch_size = 4\n",
    "\n",
    "                        # profiling: sliding window\n",
    "                        with nvtx.annotate(\"sliding window\", color=\"green\") if profiling else no_profiling:\n",
    "                            # set AMP for MONAI validation\n",
    "                            if fast:\n",
    "                                with torch.cuda.amp.autocast():\n",
    "                                    val_outputs = sliding_window_inference(\n",
    "                                        val_inputs, roi_size, sw_batch_size, model\n",
    "                                    )\n",
    "                            else:\n",
    "                                val_outputs = sliding_window_inference(\n",
    "                                    val_inputs, roi_size, sw_batch_size, model\n",
    "                                )\n",
    "\n",
    "                        # profiling: decollate batch\n",
    "                        with nvtx.annotate(\"decollate batch\", color=\"blue\") if profiling else no_profiling:\n",
    "                            val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                            val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "\n",
    "                        # profiling: compute metric\n",
    "                        with nvtx.annotate(\"compute metric\", color=\"yellow\") if profiling else no_profiling:\n",
    "                            dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "                    metric = dice_metric.aggregate().item()\n",
    "                    dice_metric.reset()\n",
    "                    metric_values.append(metric)\n",
    "                    if metric > best_metric:\n",
    "                        best_metric = metric\n",
    "                        best_metric_epoch = epoch + 1\n",
    "                        best_metrics_epochs_and_time[0].append(best_metric)\n",
    "                        best_metrics_epochs_and_time[1].append(best_metric_epoch)\n",
    "                        best_metrics_epochs_and_time[2].append(\n",
    "                            time.time() - total_start\n",
    "                        )\n",
    "                        torch.save(model.state_dict(), os.path.join(root_dir, \"best_metric_model.pt\"))\n",
    "                        print(\"saved new best metric model\")\n",
    "                    print(\n",
    "                        f\"current epoch: {epoch + 1} current\"\n",
    "                        f\" mean dice: {metric:.4f}\"\n",
    "                        f\" best mean dice: {best_metric:.4f}\"\n",
    "                        f\" at epoch: {best_metric_epoch}\"\n",
    "                    )\n",
    "\n",
    "        print(\n",
    "            f\"time consuming of epoch {epoch + 1} is:\"\n",
    "            f\" {(time.time() - epoch_start):.4f}\"\n",
    "        )\n",
    "        epoch_times.append(time.time() - epoch_start)\n",
    "\n",
    "    total_time = time.time() - total_start\n",
    "    print(\n",
    "        f\"train completed, best_metric: {best_metric:.4f}\"\n",
    "        f\" at epoch: {best_metric_epoch}\"\n",
    "        f\" total time: {total_time:.4f}\"\n",
    "    )\n",
    "    return (\n",
    "        max_epochs,\n",
    "        epoch_loss_values,\n",
    "        metric_values,\n",
    "        epoch_times,\n",
    "        best_metrics_epochs_and_time,\n",
    "        total_time,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable determinism and execute regular PyTorch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "set_determinism(seed=0)\n",
    "regular_start = time.time()\n",
    "(\n",
    "    epoch_num,\n",
    "    epoch_loss_values,\n",
    "    metric_values,\n",
    "    epoch_times,\n",
    "    best,\n",
    "    train_time,\n",
    ") = train_process(fast=False)\n",
    "total_time = time.time() - regular_start\n",
    "print(\n",
    "    f\"total time of {epoch_num} epochs with regular PyTorch training: {total_time:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable determinism and execute MONAI optimized training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "set_determinism(seed=0)\n",
    "monai_start = time.time()\n",
    "(\n",
    "    epoch_num,\n",
    "    m_epoch_loss_values,\n",
    "    m_metric_values,\n",
    "    m_epoch_times,\n",
    "    m_best,\n",
    "    m_train_time,\n",
    ") = train_process(fast=True)\n",
    "m_total_time = time.time() - monai_start\n",
    "print(\n",
    "    f\"total time of {epoch_num} epochs with MONAI fast training: {m_train_time:.4f},\"\n",
    "    f\" time of preparing cache: {(m_total_time - m_train_time):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████████████| 32/32 [00:33<00:00,  1.04s/it]\n",
      "Loading dataset: 100%|███████████████████████████████████████████████████████████████████████████| 9/9 [00:08<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "set_determinism(seed=0)\n",
    "fast = True\n",
    "\n",
    "learning_rate = 2e-4\n",
    "val_interval = 5  # do validation for every epoch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    raise RuntimeError('this tutorial is intended for GPU, but no CUDA device is available')\n",
    "\n",
    "train_trans, val_trans = transformations(fast=fast, device=device)\n",
    "# set CacheDataset, ThreadDataLoader and DiceCE loss for MONAI fast training\n",
    "\n",
    "# as `RandCropByPosNegLabeld` crops from the cached content and `deepcopy`\n",
    "# the crop area instead of modifying the cached value, we can set `copy_cache=False`\n",
    "# to avoid unnecessary deepcopy of cached content in `CacheDataset`\n",
    "train_ds = CacheDataset(\n",
    "    data=train_files,\n",
    "    transform=train_trans,\n",
    "    cache_rate=1.0,\n",
    "    num_workers=8,\n",
    "    copy_cache=False,\n",
    ")\n",
    "val_ds = CacheDataset(\n",
    "    data=val_files, transform=val_trans, cache_rate=1.0, num_workers=5, copy_cache=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable multi-workers because `ThreadDataLoader` works with multi-threads\n",
    "train_loader = ThreadDataLoader(train_ds, use_thread_workers=False, num_workers=0, batch_size=4, shuffle=True)\n",
    "val_loader = ThreadDataLoader(val_ds, use_thread_workers=False, num_workers=0, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable multi-workers because `ThreadDataLoader` works with multi-threads\n",
    "loss_function = DiceCELoss(\n",
    "    include_background=False,\n",
    "    to_onehot_y=True,\n",
    "    softmax=True,\n",
    "    squared_pred=True,\n",
    "    batch=True,\n",
    "    smooth_nr=0.00001,\n",
    "    smooth_dr=0.00001,\n",
    "    lambda_dice=0.5,\n",
    "    lambda_ce=0.5,\n",
    ")\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(32, 64, 128, 256, 512),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    "    kernel_size=3,\n",
    "    up_kernel_size=3,\n",
    "    act=Act.PRELU,\n",
    "    dropout=0.2,\n",
    "    bias=True,\n",
    "    dimensions=None,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# train_load_per_op = tlpo\n",
    "tlpo_dict, time_dict, metric_dict, loss_dict = {}, {}, {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/600\n",
      "1/8, train_loss: 0.7790 step time: 0.2530\n",
      "2/8, train_loss: 0.6703 step time: 0.1966\n",
      "3/8, train_loss: 0.5067 step time: 0.1951\n",
      "4/8, train_loss: 0.4607 step time: 0.1928\n",
      "5/8, train_loss: 0.4546 step time: 0.1955\n",
      "6/8, train_loss: 0.4509 step time: 0.1940\n",
      "7/8, train_loss: 0.4756 step time: 0.1836\n",
      "8/8, train_loss: 0.4160 step time: 0.1828\n",
      "epoch 1 average loss: 0.5267\n",
      "time consuming of epoch 1 is: 1.5947\n",
      "----------\n",
      "epoch 2/600\n",
      "1/8, train_loss: 0.4516 step time: 0.2394\n",
      "2/8, train_loss: 0.4172 step time: 0.2041\n",
      "3/8, train_loss: 0.6438 step time: 0.1905\n",
      "4/8, train_loss: 0.6094 step time: 0.1995\n",
      "5/8, train_loss: 0.4216 step time: 0.2017\n",
      "6/8, train_loss: 0.5499 step time: 0.2015\n",
      "7/8, train_loss: 0.5725 step time: 0.1833\n",
      "8/8, train_loss: 0.5541 step time: 0.1823\n",
      "epoch 2 average loss: 0.5275\n",
      "time consuming of epoch 2 is: 1.6041\n",
      "----------\n",
      "epoch 3/600\n",
      "1/8, train_loss: 0.6049 step time: 0.2423\n",
      "2/8, train_loss: 0.5896 step time: 0.2031\n",
      "3/8, train_loss: 0.5955 step time: 0.2001\n",
      "4/8, train_loss: 0.5692 step time: 0.2019\n",
      "5/8, train_loss: 0.5608 step time: 0.2036\n",
      "6/8, train_loss: 0.5988 step time: 0.2058\n",
      "7/8, train_loss: 0.5444 step time: 0.1822\n",
      "8/8, train_loss: 0.4742 step time: 0.1823\n",
      "epoch 3 average loss: 0.5672\n",
      "time consuming of epoch 3 is: 1.6230\n",
      "----------\n",
      "epoch 4/600\n",
      "1/8, train_loss: 0.5163 step time: 0.2313\n",
      "2/8, train_loss: 0.4702 step time: 0.1990\n",
      "3/8, train_loss: 0.4418 step time: 0.1977\n",
      "4/8, train_loss: 0.4512 step time: 0.1951\n",
      "5/8, train_loss: 0.4361 step time: 0.1976\n",
      "6/8, train_loss: 0.4215 step time: 0.2001\n",
      "7/8, train_loss: 0.4655 step time: 0.1824\n",
      "8/8, train_loss: 0.4448 step time: 0.1830\n",
      "epoch 4 average loss: 0.4559\n",
      "time consuming of epoch 4 is: 1.5878\n",
      "----------\n",
      "epoch 5/600\n",
      "1/8, train_loss: 0.4356 step time: 0.2428\n",
      "2/8, train_loss: 0.4663 step time: 0.2005\n",
      "3/8, train_loss: 0.4176 step time: 0.2092\n",
      "4/8, train_loss: 0.4016 step time: 0.2069\n",
      "5/8, train_loss: 0.4068 step time: 0.2041\n",
      "6/8, train_loss: 0.4240 step time: 0.2069\n",
      "7/8, train_loss: 0.4158 step time: 0.1844\n",
      "8/8, train_loss: 0.4185 step time: 0.1848\n",
      "epoch 5 average loss: 0.4233\n",
      "saved new best metric model\n",
      "current epoch: 5 current mean dice: 0.0000 best mean dice: 0.0000 at epoch: 5\n",
      "time consuming of epoch 5 is: 2.5513\n",
      "----------\n",
      "epoch 6/600\n",
      "1/8, train_loss: 0.4299 step time: 0.2405\n",
      "2/8, train_loss: 0.3908 step time: 0.1995\n",
      "3/8, train_loss: 0.3484 step time: 0.2000\n",
      "4/8, train_loss: 0.4706 step time: 0.1995\n",
      "5/8, train_loss: 0.4433 step time: 0.1992\n",
      "6/8, train_loss: 0.4395 step time: 0.2049\n",
      "7/8, train_loss: 0.3777 step time: 0.1817\n",
      "8/8, train_loss: 0.3902 step time: 0.1837\n",
      "epoch 6 average loss: 0.4113\n",
      "time consuming of epoch 6 is: 1.6101\n",
      "----------\n",
      "epoch 7/600\n",
      "1/8, train_loss: 0.3943 step time: 0.2373\n",
      "2/8, train_loss: 0.4173 step time: 0.2036\n",
      "3/8, train_loss: 0.3792 step time: 0.2016\n",
      "4/8, train_loss: 0.3475 step time: 0.2058\n",
      "5/8, train_loss: 0.3828 step time: 0.2002\n",
      "6/8, train_loss: 0.4743 step time: 0.2006\n",
      "7/8, train_loss: 0.4055 step time: 0.1847\n",
      "8/8, train_loss: 0.3738 step time: 0.1825\n",
      "epoch 7 average loss: 0.3969\n",
      "time consuming of epoch 7 is: 1.6177\n",
      "----------\n",
      "epoch 8/600\n",
      "1/8, train_loss: 0.4478 step time: 0.2419\n",
      "2/8, train_loss: 0.4176 step time: 0.1984\n",
      "3/8, train_loss: 0.4070 step time: 0.2024\n",
      "4/8, train_loss: 0.3698 step time: 0.2010\n",
      "5/8, train_loss: 0.3812 step time: 0.1977\n",
      "6/8, train_loss: 0.4036 step time: 0.2037\n",
      "7/8, train_loss: 0.3601 step time: 0.1827\n",
      "8/8, train_loss: 0.3408 step time: 0.1827\n",
      "epoch 8 average loss: 0.3910\n",
      "time consuming of epoch 8 is: 1.6120\n",
      "----------\n",
      "epoch 9/600\n",
      "1/8, train_loss: 0.2896 step time: 0.2382\n",
      "2/8, train_loss: 0.2501 step time: 0.2057\n",
      "3/8, train_loss: 0.2276 step time: 0.2064\n",
      "4/8, train_loss: 0.2586 step time: 0.2023\n",
      "5/8, train_loss: 0.1842 step time: 0.2000\n",
      "6/8, train_loss: 0.1824 step time: 0.1993\n",
      "7/8, train_loss: 0.3053 step time: 0.1827\n",
      "8/8, train_loss: 0.1747 step time: 0.1827\n",
      "epoch 9 average loss: 0.2341\n",
      "time consuming of epoch 9 is: 1.6187\n",
      "----------\n",
      "epoch 10/600\n",
      "1/8, train_loss: 0.2341 step time: 0.2366\n",
      "2/8, train_loss: 0.2003 step time: 0.2046\n",
      "3/8, train_loss: 0.1749 step time: 0.1979\n",
      "4/8, train_loss: 0.1433 step time: 0.2013\n",
      "5/8, train_loss: 0.1587 step time: 0.2013\n",
      "6/8, train_loss: 0.1589 step time: 0.2023\n",
      "7/8, train_loss: 0.1875 step time: 0.1852\n",
      "8/8, train_loss: 0.1372 step time: 0.1829\n",
      "epoch 10 average loss: 0.1744\n",
      "saved new best metric model\n",
      "current epoch: 10 current mean dice: 0.1068 best mean dice: 0.1068 at epoch: 10\n",
      "time consuming of epoch 10 is: 2.5124\n",
      "----------\n",
      "epoch 11/600\n",
      "1/8, train_loss: 0.1378 step time: 0.2297\n",
      "2/8, train_loss: 0.2098 step time: 0.1908\n",
      "3/8, train_loss: 0.2831 step time: 0.1925\n",
      "4/8, train_loss: 0.1949 step time: 0.1906\n",
      "5/8, train_loss: 0.1745 step time: 0.1932\n",
      "6/8, train_loss: 0.1226 step time: 0.1943\n",
      "7/8, train_loss: 0.0827 step time: 0.1815\n",
      "8/8, train_loss: 0.1060 step time: 0.1819\n",
      "epoch 11 average loss: 0.1639\n",
      "time consuming of epoch 11 is: 1.5557\n",
      "----------\n",
      "epoch 12/600\n",
      "1/8, train_loss: 0.1774 step time: 0.2400\n",
      "2/8, train_loss: 0.1407 step time: 0.1999\n",
      "3/8, train_loss: 0.1289 step time: 0.2016\n",
      "4/8, train_loss: 0.1057 step time: 0.2020\n",
      "5/8, train_loss: 0.1392 step time: 0.2047\n",
      "6/8, train_loss: 0.1048 step time: 0.1983\n",
      "7/8, train_loss: 0.0981 step time: 0.1821\n",
      "8/8, train_loss: 0.0990 step time: 0.1829\n",
      "epoch 12 average loss: 0.1242\n",
      "time consuming of epoch 12 is: 1.6129\n",
      "----------\n",
      "epoch 13/600\n",
      "1/8, train_loss: 0.1046 step time: 0.2436\n",
      "2/8, train_loss: 0.0908 step time: 0.2041\n",
      "3/8, train_loss: 0.1271 step time: 0.2037\n",
      "4/8, train_loss: 0.0839 step time: 0.2000\n",
      "5/8, train_loss: 0.0979 step time: 0.1989\n",
      "6/8, train_loss: 0.1252 step time: 0.1979\n",
      "7/8, train_loss: 0.0859 step time: 0.1824\n",
      "8/8, train_loss: 0.0649 step time: 0.1820\n",
      "epoch 13 average loss: 0.0975\n",
      "time consuming of epoch 13 is: 1.6140\n",
      "----------\n",
      "epoch 14/600\n",
      "1/8, train_loss: 0.0967 step time: 0.2303\n",
      "2/8, train_loss: 0.1382 step time: 0.1969\n",
      "3/8, train_loss: 0.0975 step time: 0.2004\n",
      "4/8, train_loss: 0.0869 step time: 0.1967\n",
      "5/8, train_loss: 0.0781 step time: 0.2007\n",
      "6/8, train_loss: 0.0707 step time: 0.2008\n",
      "7/8, train_loss: 0.0899 step time: 0.1836\n",
      "8/8, train_loss: 0.1534 step time: 0.1838\n",
      "epoch 14 average loss: 0.1014\n",
      "time consuming of epoch 14 is: 1.5948\n",
      "----------\n",
      "epoch 15/600\n",
      "1/8, train_loss: 0.0912 step time: 0.2400\n",
      "2/8, train_loss: 0.1302 step time: 0.2023\n",
      "3/8, train_loss: 0.1661 step time: 0.2071\n",
      "4/8, train_loss: 0.0708 step time: 0.2010\n",
      "5/8, train_loss: 0.1633 step time: 0.1983\n",
      "6/8, train_loss: 0.1116 step time: 0.2027\n",
      "7/8, train_loss: 0.0953 step time: 0.1827\n",
      "8/8, train_loss: 0.1799 step time: 0.1814\n",
      "epoch 15 average loss: 0.1261\n",
      "saved new best metric model\n",
      "current epoch: 15 current mean dice: 0.8073 best mean dice: 0.8073 at epoch: 15\n",
      "time consuming of epoch 15 is: 2.5141\n",
      "----------\n",
      "epoch 16/600\n",
      "1/8, train_loss: 0.0548 step time: 0.2415\n",
      "2/8, train_loss: 0.0920 step time: 0.2027\n",
      "3/8, train_loss: 0.0603 step time: 0.2005\n",
      "4/8, train_loss: 0.1169 step time: 0.2061\n",
      "5/8, train_loss: 0.0845 step time: 0.2032\n",
      "6/8, train_loss: 0.0729 step time: 0.1997\n",
      "7/8, train_loss: 0.1074 step time: 0.1816\n",
      "8/8, train_loss: 0.0948 step time: 0.1811\n",
      "epoch 16 average loss: 0.0854\n",
      "time consuming of epoch 16 is: 1.6177\n",
      "----------\n",
      "epoch 17/600\n",
      "1/8, train_loss: 0.0736 step time: 0.2401\n",
      "2/8, train_loss: 0.0861 step time: 0.2021\n",
      "3/8, train_loss: 0.0714 step time: 0.1979\n",
      "4/8, train_loss: 0.0665 step time: 0.2010\n",
      "5/8, train_loss: 0.0529 step time: 0.2012\n",
      "6/8, train_loss: 0.0782 step time: 0.1974\n",
      "7/8, train_loss: 0.0718 step time: 0.1813\n",
      "8/8, train_loss: 0.0777 step time: 0.1821\n",
      "epoch 17 average loss: 0.0723\n",
      "time consuming of epoch 17 is: 1.6044\n",
      "----------\n",
      "epoch 18/600\n",
      "1/8, train_loss: 0.0624 step time: 0.2401\n",
      "2/8, train_loss: 0.0586 step time: 0.2019\n",
      "3/8, train_loss: 0.0582 step time: 0.2002\n",
      "4/8, train_loss: 0.0550 step time: 0.2010\n",
      "5/8, train_loss: 0.0804 step time: 0.2000\n",
      "6/8, train_loss: 0.0520 step time: 0.2028\n",
      "7/8, train_loss: 0.1280 step time: 0.1822\n",
      "8/8, train_loss: 0.0832 step time: 0.1824\n",
      "epoch 18 average loss: 0.0722\n",
      "time consuming of epoch 18 is: 1.6122\n",
      "----------\n",
      "epoch 19/600\n",
      "1/8, train_loss: 0.0654 step time: 0.2376\n",
      "2/8, train_loss: 0.0484 step time: 0.2031\n",
      "3/8, train_loss: 0.0586 step time: 0.2019\n",
      "4/8, train_loss: 0.0825 step time: 0.2016\n",
      "5/8, train_loss: 0.0613 step time: 0.1992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/8, train_loss: 0.0792 step time: 0.1981\n",
      "7/8, train_loss: 0.0976 step time: 0.1831\n",
      "8/8, train_loss: 0.1049 step time: 0.1825\n",
      "epoch 19 average loss: 0.0747\n",
      "time consuming of epoch 19 is: 1.6088\n",
      "----------\n",
      "epoch 20/600\n",
      "1/8, train_loss: 0.0475 step time: 0.2454\n",
      "2/8, train_loss: 0.0501 step time: 0.2053\n",
      "3/8, train_loss: 0.1487 step time: 0.2004\n",
      "4/8, train_loss: 0.0799 step time: 0.2018\n",
      "5/8, train_loss: 0.0755 step time: 0.2042\n",
      "6/8, train_loss: 0.0698 step time: 0.1989\n",
      "7/8, train_loss: 0.1062 step time: 0.1849\n",
      "8/8, train_loss: 0.0962 step time: 0.1835\n",
      "epoch 20 average loss: 0.0842\n",
      "current epoch: 20 current mean dice: 0.4622 best mean dice: 0.8073 at epoch: 15\n",
      "time consuming of epoch 20 is: 2.3804\n",
      "----------\n",
      "epoch 21/600\n",
      "1/8, train_loss: 0.0822 step time: 0.2378\n",
      "2/8, train_loss: 0.0768 step time: 0.1999\n",
      "3/8, train_loss: 0.0955 step time: 0.1997\n",
      "4/8, train_loss: 0.1280 step time: 0.1976\n",
      "5/8, train_loss: 0.0909 step time: 0.2006\n",
      "6/8, train_loss: 0.0863 step time: 0.1997\n",
      "7/8, train_loss: 0.0898 step time: 0.1822\n",
      "8/8, train_loss: 0.0465 step time: 0.1830\n",
      "epoch 21 average loss: 0.0870\n",
      "time consuming of epoch 21 is: 1.6015\n",
      "----------\n",
      "epoch 22/600\n",
      "1/8, train_loss: 0.0963 step time: 0.2411\n",
      "2/8, train_loss: 0.0807 step time: 0.2014\n",
      "3/8, train_loss: 0.0771 step time: 0.1998\n",
      "4/8, train_loss: 0.0743 step time: 0.2007\n",
      "5/8, train_loss: 0.0655 step time: 0.2021\n",
      "6/8, train_loss: 0.0555 step time: 0.1985\n",
      "7/8, train_loss: 0.0626 step time: 0.1835\n",
      "8/8, train_loss: 0.1538 step time: 0.1834\n",
      "epoch 22 average loss: 0.0832\n",
      "time consuming of epoch 22 is: 1.6121\n",
      "----------\n",
      "epoch 23/600\n",
      "1/8, train_loss: 0.0610 step time: 0.2389\n",
      "2/8, train_loss: 0.0752 step time: 0.2043\n",
      "3/8, train_loss: 0.0663 step time: 0.1988\n",
      "4/8, train_loss: 0.1190 step time: 0.2011\n",
      "5/8, train_loss: 0.1953 step time: 0.2000\n",
      "6/8, train_loss: 0.1097 step time: 0.2017\n",
      "7/8, train_loss: 0.1115 step time: 0.1842\n",
      "8/8, train_loss: 0.0917 step time: 0.1818\n",
      "epoch 23 average loss: 0.1037\n",
      "time consuming of epoch 23 is: 1.6122\n",
      "----------\n",
      "epoch 24/600\n",
      "1/8, train_loss: 0.0594 step time: 0.2400\n",
      "2/8, train_loss: 0.0888 step time: 0.2024\n",
      "3/8, train_loss: 0.0995 step time: 0.2044\n",
      "4/8, train_loss: 0.1074 step time: 0.2000\n",
      "5/8, train_loss: 0.0455 step time: 0.2010\n",
      "6/8, train_loss: 0.0826 step time: 0.2000\n",
      "7/8, train_loss: 0.1648 step time: 0.1840\n",
      "8/8, train_loss: 0.0631 step time: 0.1820\n",
      "epoch 24 average loss: 0.0889\n",
      "time consuming of epoch 24 is: 1.6151\n",
      "----------\n",
      "epoch 25/600\n",
      "1/8, train_loss: 0.0632 step time: 0.2387\n",
      "2/8, train_loss: 0.0760 step time: 0.2000\n",
      "3/8, train_loss: 0.0905 step time: 0.2014\n",
      "4/8, train_loss: 0.0921 step time: 0.1992\n",
      "5/8, train_loss: 0.1081 step time: 0.2040\n",
      "6/8, train_loss: 0.0840 step time: 0.2043\n",
      "7/8, train_loss: 0.0754 step time: 0.1845\n",
      "8/8, train_loss: 0.0628 step time: 0.1817\n",
      "epoch 25 average loss: 0.0815\n",
      "current epoch: 25 current mean dice: 0.7745 best mean dice: 0.8073 at epoch: 15\n",
      "time consuming of epoch 25 is: 2.3701\n",
      "----------\n",
      "epoch 26/600\n",
      "1/8, train_loss: 0.0655 step time: 0.2370\n",
      "2/8, train_loss: 0.0690 step time: 0.1979\n",
      "3/8, train_loss: 0.0417 step time: 0.1985\n",
      "4/8, train_loss: 0.0498 step time: 0.1978\n",
      "5/8, train_loss: 0.0769 step time: 0.1972\n",
      "6/8, train_loss: 0.0548 step time: 0.1993\n",
      "7/8, train_loss: 0.0543 step time: 0.1822\n",
      "8/8, train_loss: 0.1368 step time: 0.1814\n",
      "epoch 26 average loss: 0.0686\n",
      "time consuming of epoch 26 is: 1.5924\n",
      "----------\n",
      "epoch 27/600\n",
      "1/8, train_loss: 0.0767 step time: 0.2391\n",
      "2/8, train_loss: 0.0867 step time: 0.2016\n",
      "3/8, train_loss: 0.0762 step time: 0.2011\n",
      "4/8, train_loss: 0.0700 step time: 0.1984\n",
      "5/8, train_loss: 0.0429 step time: 0.2007\n",
      "6/8, train_loss: 0.0539 step time: 0.1988\n",
      "7/8, train_loss: 0.0423 step time: 0.1824\n",
      "8/8, train_loss: 0.0691 step time: 0.1822\n",
      "epoch 27 average loss: 0.0647\n",
      "time consuming of epoch 27 is: 1.6060\n",
      "----------\n",
      "epoch 28/600\n",
      "1/8, train_loss: 0.0525 step time: 0.2373\n",
      "2/8, train_loss: 0.0521 step time: 0.1992\n",
      "3/8, train_loss: 0.0420 step time: 0.2026\n",
      "4/8, train_loss: 0.0358 step time: 0.1973\n",
      "5/8, train_loss: 0.0606 step time: 0.1975\n",
      "6/8, train_loss: 0.0533 step time: 0.1947\n",
      "7/8, train_loss: 0.0592 step time: 0.1834\n",
      "8/8, train_loss: 0.0877 step time: 0.1812\n",
      "epoch 28 average loss: 0.0554\n",
      "time consuming of epoch 28 is: 1.5944\n",
      "----------\n",
      "epoch 29/600\n",
      "1/8, train_loss: 0.0589 step time: 0.2377\n",
      "2/8, train_loss: 0.0454 step time: 0.1995\n",
      "3/8, train_loss: 0.0479 step time: 0.2016\n",
      "4/8, train_loss: 0.0416 step time: 0.2032\n",
      "5/8, train_loss: 0.1278 step time: 0.2020\n",
      "6/8, train_loss: 0.0667 step time: 0.1994\n",
      "7/8, train_loss: 0.0497 step time: 0.1839\n",
      "8/8, train_loss: 0.0375 step time: 0.1812\n",
      "epoch 29 average loss: 0.0594\n",
      "time consuming of epoch 29 is: 1.6097\n",
      "----------\n",
      "epoch 30/600\n",
      "1/8, train_loss: 0.0402 step time: 0.2385\n",
      "2/8, train_loss: 0.0489 step time: 0.2082\n",
      "3/8, train_loss: 0.0468 step time: 0.2077\n",
      "4/8, train_loss: 0.0424 step time: 0.2035\n",
      "5/8, train_loss: 0.0543 step time: 0.2033\n",
      "6/8, train_loss: 0.0378 step time: 0.2028\n",
      "7/8, train_loss: 0.0668 step time: 0.1836\n",
      "8/8, train_loss: 0.0534 step time: 0.1831\n",
      "epoch 30 average loss: 0.0488\n",
      "current epoch: 30 current mean dice: 0.7162 best mean dice: 0.8073 at epoch: 15\n",
      "time consuming of epoch 30 is: 2.3897\n",
      "----------\n",
      "epoch 31/600\n",
      "1/8, train_loss: 0.1172 step time: 0.2414\n",
      "2/8, train_loss: 0.0571 step time: 0.1999\n",
      "3/8, train_loss: 0.0870 step time: 0.2009\n",
      "4/8, train_loss: 0.0683 step time: 0.2007\n",
      "5/8, train_loss: 0.0431 step time: 0.2003\n",
      "6/8, train_loss: 0.0494 step time: 0.2025\n",
      "7/8, train_loss: 0.0389 step time: 0.1837\n",
      "8/8, train_loss: 0.0517 step time: 0.1829\n",
      "epoch 31 average loss: 0.0641\n",
      "time consuming of epoch 31 is: 1.6135\n",
      "----------\n",
      "epoch 32/600\n",
      "1/8, train_loss: 0.0706 step time: 0.2514\n",
      "2/8, train_loss: 0.0660 step time: 0.2030\n",
      "3/8, train_loss: 0.0431 step time: 0.2090\n",
      "4/8, train_loss: 0.0481 step time: 0.2000\n",
      "5/8, train_loss: 0.0624 step time: 0.2025\n",
      "6/8, train_loss: 0.0609 step time: 0.1997\n",
      "7/8, train_loss: 0.0382 step time: 0.1824\n",
      "8/8, train_loss: 0.0428 step time: 0.1834\n",
      "epoch 32 average loss: 0.0540\n",
      "time consuming of epoch 32 is: 1.6330\n",
      "----------\n",
      "epoch 33/600\n",
      "1/8, train_loss: 0.0377 step time: 0.2411\n",
      "2/8, train_loss: 0.0332 step time: 0.2001\n",
      "3/8, train_loss: 0.0561 step time: 0.2013\n",
      "4/8, train_loss: 0.0430 step time: 0.1993\n",
      "5/8, train_loss: 0.0441 step time: 0.2028\n",
      "6/8, train_loss: 0.0524 step time: 0.1989\n",
      "7/8, train_loss: 0.0514 step time: 0.1835\n",
      "8/8, train_loss: 0.0519 step time: 0.1827\n",
      "epoch 33 average loss: 0.0462\n",
      "time consuming of epoch 33 is: 1.6111\n",
      "----------\n",
      "epoch 34/600\n",
      "1/8, train_loss: 0.0380 step time: 0.2398\n",
      "2/8, train_loss: 0.1031 step time: 0.2072\n",
      "3/8, train_loss: 0.0676 step time: 0.2000\n",
      "4/8, train_loss: 0.0453 step time: 0.1999\n",
      "5/8, train_loss: 0.0521 step time: 0.2050\n",
      "6/8, train_loss: 0.0896 step time: 0.2000\n",
      "7/8, train_loss: 0.0766 step time: 0.1829\n",
      "8/8, train_loss: 0.0439 step time: 0.1837\n",
      "epoch 34 average loss: 0.0645\n",
      "time consuming of epoch 34 is: 1.6199\n",
      "----------\n",
      "epoch 35/600\n",
      "1/8, train_loss: 0.0895 step time: 0.2381\n",
      "2/8, train_loss: 0.0512 step time: 0.2033\n",
      "3/8, train_loss: 0.0405 step time: 0.2016\n",
      "4/8, train_loss: 0.0405 step time: 0.2042\n",
      "5/8, train_loss: 0.0467 step time: 0.1996\n",
      "6/8, train_loss: 0.0506 step time: 0.2013\n",
      "7/8, train_loss: 0.0427 step time: 0.1849\n",
      "8/8, train_loss: 0.0399 step time: 0.1834\n",
      "epoch 35 average loss: 0.0502\n",
      "current epoch: 35 current mean dice: 0.7242 best mean dice: 0.8073 at epoch: 15\n",
      "time consuming of epoch 35 is: 2.3716\n",
      "----------\n",
      "epoch 36/600\n",
      "1/8, train_loss: 0.0560 step time: 0.2357\n",
      "2/8, train_loss: 0.0432 step time: 0.1971\n",
      "3/8, train_loss: 0.0436 step time: 0.1954\n",
      "4/8, train_loss: 0.0545 step time: 0.2014\n",
      "5/8, train_loss: 0.0697 step time: 0.2019\n",
      "6/8, train_loss: 0.0446 step time: 0.1956\n",
      "7/8, train_loss: 0.0597 step time: 0.1851\n",
      "8/8, train_loss: 0.0428 step time: 0.1840\n",
      "epoch 36 average loss: 0.0517\n",
      "time consuming of epoch 36 is: 1.5976\n",
      "----------\n",
      "epoch 37/600\n",
      "1/8, train_loss: 0.0316 step time: 0.2423\n",
      "2/8, train_loss: 0.0501 step time: 0.2041\n",
      "3/8, train_loss: 0.0435 step time: 0.2053\n",
      "4/8, train_loss: 0.0480 step time: 0.2030\n",
      "5/8, train_loss: 0.0363 step time: 0.1997\n",
      "6/8, train_loss: 0.0384 step time: 0.2010\n",
      "7/8, train_loss: 0.0723 step time: 0.1832\n",
      "8/8, train_loss: 0.0299 step time: 0.1835\n",
      "epoch 37 average loss: 0.0438\n",
      "time consuming of epoch 37 is: 1.6236\n",
      "----------\n",
      "epoch 38/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0431 step time: 0.2425\n",
      "2/8, train_loss: 0.0377 step time: 0.2040\n",
      "3/8, train_loss: 0.0438 step time: 0.2017\n",
      "4/8, train_loss: 0.0319 step time: 0.2023\n",
      "5/8, train_loss: 0.0385 step time: 0.2011\n",
      "6/8, train_loss: 0.0358 step time: 0.2022\n",
      "7/8, train_loss: 0.0425 step time: 0.1815\n",
      "8/8, train_loss: 0.0655 step time: 0.1821\n",
      "epoch 38 average loss: 0.0424\n",
      "time consuming of epoch 38 is: 1.6188\n",
      "----------\n",
      "epoch 39/600\n",
      "1/8, train_loss: 0.0666 step time: 0.2395\n",
      "2/8, train_loss: 0.0346 step time: 0.2030\n",
      "3/8, train_loss: 0.0439 step time: 0.2023\n",
      "4/8, train_loss: 0.0361 step time: 0.2017\n",
      "5/8, train_loss: 0.0435 step time: 0.2019\n",
      "6/8, train_loss: 0.0340 step time: 0.2030\n",
      "7/8, train_loss: 0.0363 step time: 0.1829\n",
      "8/8, train_loss: 0.0435 step time: 0.1842\n",
      "epoch 39 average loss: 0.0423\n",
      "time consuming of epoch 39 is: 1.6201\n",
      "----------\n",
      "epoch 40/600\n",
      "1/8, train_loss: 0.0274 step time: 0.2384\n",
      "2/8, train_loss: 0.0368 step time: 0.1995\n",
      "3/8, train_loss: 0.0813 step time: 0.2066\n",
      "4/8, train_loss: 0.0373 step time: 0.2045\n",
      "5/8, train_loss: 0.0393 step time: 0.2038\n",
      "6/8, train_loss: 0.0530 step time: 0.2024\n",
      "7/8, train_loss: 0.0525 step time: 0.1833\n",
      "8/8, train_loss: 0.0621 step time: 0.1833\n",
      "epoch 40 average loss: 0.0487\n",
      "saved new best metric model\n",
      "current epoch: 40 current mean dice: 0.8915 best mean dice: 0.8915 at epoch: 40\n",
      "time consuming of epoch 40 is: 2.5209\n",
      "----------\n",
      "epoch 41/600\n",
      "1/8, train_loss: 0.0601 step time: 0.2383\n",
      "2/8, train_loss: 0.0598 step time: 0.2024\n",
      "3/8, train_loss: 0.0879 step time: 0.1987\n",
      "4/8, train_loss: 0.0437 step time: 0.1985\n",
      "5/8, train_loss: 0.0527 step time: 0.1992\n",
      "6/8, train_loss: 0.0377 step time: 0.2018\n",
      "7/8, train_loss: 0.0642 step time: 0.1839\n",
      "8/8, train_loss: 0.0353 step time: 0.1842\n",
      "epoch 41 average loss: 0.0552\n",
      "time consuming of epoch 41 is: 1.6081\n",
      "----------\n",
      "epoch 42/600\n",
      "1/8, train_loss: 0.0301 step time: 0.2393\n",
      "2/8, train_loss: 0.0418 step time: 0.2072\n",
      "3/8, train_loss: 0.0329 step time: 0.2040\n",
      "4/8, train_loss: 0.0362 step time: 0.2026\n",
      "5/8, train_loss: 0.0592 step time: 0.2065\n",
      "6/8, train_loss: 0.0358 step time: 0.2028\n",
      "7/8, train_loss: 0.0420 step time: 0.1835\n",
      "8/8, train_loss: 0.0610 step time: 0.1842\n",
      "epoch 42 average loss: 0.0424\n",
      "time consuming of epoch 42 is: 1.6315\n",
      "----------\n",
      "epoch 43/600\n",
      "1/8, train_loss: 0.0413 step time: 0.2451\n",
      "2/8, train_loss: 0.0486 step time: 0.2003\n",
      "3/8, train_loss: 0.0409 step time: 0.2005\n",
      "4/8, train_loss: 0.0409 step time: 0.2003\n",
      "5/8, train_loss: 0.0476 step time: 0.1994\n",
      "6/8, train_loss: 0.0399 step time: 0.1981\n",
      "7/8, train_loss: 0.0605 step time: 0.1829\n",
      "8/8, train_loss: 0.0243 step time: 0.1827\n",
      "epoch 43 average loss: 0.0430\n",
      "time consuming of epoch 43 is: 1.6104\n",
      "----------\n",
      "epoch 44/600\n",
      "1/8, train_loss: 0.0272 step time: 0.2392\n",
      "2/8, train_loss: 0.0820 step time: 0.2038\n",
      "3/8, train_loss: 0.0365 step time: 0.2053\n",
      "4/8, train_loss: 0.0318 step time: 0.2021\n",
      "5/8, train_loss: 0.0326 step time: 0.2000\n",
      "6/8, train_loss: 0.0283 step time: 0.2006\n",
      "7/8, train_loss: 0.0633 step time: 0.1841\n",
      "8/8, train_loss: 0.0341 step time: 0.1829\n",
      "epoch 44 average loss: 0.0420\n",
      "time consuming of epoch 44 is: 1.6198\n",
      "----------\n",
      "epoch 45/600\n",
      "1/8, train_loss: 0.0338 step time: 0.2387\n",
      "2/8, train_loss: 0.0313 step time: 0.2037\n",
      "3/8, train_loss: 0.0444 step time: 0.2015\n",
      "4/8, train_loss: 0.0281 step time: 0.2041\n",
      "5/8, train_loss: 0.0494 step time: 0.2001\n",
      "6/8, train_loss: 0.0380 step time: 0.2037\n",
      "7/8, train_loss: 0.0388 step time: 0.1828\n",
      "8/8, train_loss: 0.0377 step time: 0.1824\n",
      "epoch 45 average loss: 0.0377\n",
      "current epoch: 45 current mean dice: 0.6524 best mean dice: 0.8915 at epoch: 40\n",
      "time consuming of epoch 45 is: 2.3747\n",
      "----------\n",
      "epoch 46/600\n",
      "1/8, train_loss: 0.0376 step time: 0.2275\n",
      "2/8, train_loss: 0.0340 step time: 0.1960\n",
      "3/8, train_loss: 0.0454 step time: 0.2028\n",
      "4/8, train_loss: 0.0471 step time: 0.2011\n",
      "5/8, train_loss: 0.0302 step time: 0.1995\n",
      "6/8, train_loss: 0.0420 step time: 0.2042\n",
      "7/8, train_loss: 0.0418 step time: 0.1848\n",
      "8/8, train_loss: 0.0357 step time: 0.1831\n",
      "epoch 46 average loss: 0.0392\n",
      "time consuming of epoch 46 is: 1.6002\n",
      "----------\n",
      "epoch 47/600\n",
      "1/8, train_loss: 0.0259 step time: 0.2434\n",
      "2/8, train_loss: 0.0281 step time: 0.2050\n",
      "3/8, train_loss: 0.0340 step time: 0.2057\n",
      "4/8, train_loss: 0.0375 step time: 0.2030\n",
      "5/8, train_loss: 0.0326 step time: 0.2033\n",
      "6/8, train_loss: 0.0282 step time: 0.2030\n",
      "7/8, train_loss: 0.0535 step time: 0.1834\n",
      "8/8, train_loss: 0.0349 step time: 0.1832\n",
      "epoch 47 average loss: 0.0343\n",
      "time consuming of epoch 47 is: 1.6317\n",
      "----------\n",
      "epoch 48/600\n",
      "1/8, train_loss: 0.0288 step time: 0.2387\n",
      "2/8, train_loss: 0.0384 step time: 0.2036\n",
      "3/8, train_loss: 0.0410 step time: 0.2003\n",
      "4/8, train_loss: 0.0334 step time: 0.2005\n",
      "5/8, train_loss: 0.0220 step time: 0.2015\n",
      "6/8, train_loss: 0.0297 step time: 0.1976\n",
      "7/8, train_loss: 0.0421 step time: 0.1824\n",
      "8/8, train_loss: 0.0330 step time: 0.1821\n",
      "epoch 48 average loss: 0.0335\n",
      "time consuming of epoch 48 is: 1.6086\n",
      "----------\n",
      "epoch 49/600\n",
      "1/8, train_loss: 0.0302 step time: 0.2358\n",
      "2/8, train_loss: 0.0252 step time: 0.1959\n",
      "3/8, train_loss: 0.0298 step time: 0.1989\n",
      "4/8, train_loss: 0.0331 step time: 0.1972\n",
      "5/8, train_loss: 0.0310 step time: 0.1987\n",
      "6/8, train_loss: 0.0283 step time: 0.1974\n",
      "7/8, train_loss: 0.0250 step time: 0.1814\n",
      "8/8, train_loss: 0.0267 step time: 0.1832\n",
      "epoch 49 average loss: 0.0286\n",
      "time consuming of epoch 49 is: 1.5900\n",
      "----------\n",
      "epoch 50/600\n",
      "1/8, train_loss: 0.0391 step time: 0.2390\n",
      "2/8, train_loss: 0.0263 step time: 0.2045\n",
      "3/8, train_loss: 0.0299 step time: 0.1995\n",
      "4/8, train_loss: 0.0247 step time: 0.1996\n",
      "5/8, train_loss: 0.0314 step time: 0.2004\n",
      "6/8, train_loss: 0.0365 step time: 0.2004\n",
      "7/8, train_loss: 0.0302 step time: 0.1853\n",
      "8/8, train_loss: 0.0277 step time: 0.1830\n",
      "epoch 50 average loss: 0.0307\n",
      "saved new best metric model\n",
      "current epoch: 50 current mean dice: 0.9220 best mean dice: 0.9220 at epoch: 50\n",
      "time consuming of epoch 50 is: 2.5097\n",
      "----------\n",
      "epoch 51/600\n",
      "1/8, train_loss: 0.0372 step time: 0.2400\n",
      "2/8, train_loss: 0.0638 step time: 0.2031\n",
      "3/8, train_loss: 0.0386 step time: 0.1987\n",
      "4/8, train_loss: 0.0312 step time: 0.2064\n",
      "5/8, train_loss: 0.0295 step time: 0.2000\n",
      "6/8, train_loss: 0.0324 step time: 0.2018\n",
      "7/8, train_loss: 0.0322 step time: 0.1846\n",
      "8/8, train_loss: 0.0378 step time: 0.1835\n",
      "epoch 51 average loss: 0.0378\n",
      "time consuming of epoch 51 is: 1.6193\n",
      "----------\n",
      "epoch 52/600\n",
      "1/8, train_loss: 0.0218 step time: 0.2370\n",
      "2/8, train_loss: 0.0315 step time: 0.2018\n",
      "3/8, train_loss: 0.0304 step time: 0.2013\n",
      "4/8, train_loss: 0.0253 step time: 0.2016\n",
      "5/8, train_loss: 0.0328 step time: 0.1988\n",
      "6/8, train_loss: 0.0493 step time: 0.2024\n",
      "7/8, train_loss: 0.0463 step time: 0.1816\n",
      "8/8, train_loss: 0.0267 step time: 0.1818\n",
      "epoch 52 average loss: 0.0330\n",
      "time consuming of epoch 52 is: 1.6076\n",
      "----------\n",
      "epoch 53/600\n",
      "1/8, train_loss: 0.0253 step time: 0.2394\n",
      "2/8, train_loss: 0.0274 step time: 0.1992\n",
      "3/8, train_loss: 0.0353 step time: 0.1998\n",
      "4/8, train_loss: 0.0489 step time: 0.2001\n",
      "5/8, train_loss: 0.0672 step time: 0.1988\n",
      "6/8, train_loss: 0.0246 step time: 0.2015\n",
      "7/8, train_loss: 0.0263 step time: 0.1822\n",
      "8/8, train_loss: 0.0452 step time: 0.1824\n",
      "epoch 53 average loss: 0.0375\n",
      "time consuming of epoch 53 is: 1.6047\n",
      "----------\n",
      "epoch 54/600\n",
      "1/8, train_loss: 0.0280 step time: 0.2382\n",
      "2/8, train_loss: 0.0327 step time: 0.1993\n",
      "3/8, train_loss: 0.0593 step time: 0.2055\n",
      "4/8, train_loss: 0.0292 step time: 0.2045\n",
      "5/8, train_loss: 0.0568 step time: 0.2076\n",
      "6/8, train_loss: 0.0560 step time: 0.2075\n",
      "7/8, train_loss: 0.0317 step time: 0.1846\n",
      "8/8, train_loss: 0.0373 step time: 0.1846\n",
      "epoch 54 average loss: 0.0414\n",
      "time consuming of epoch 54 is: 1.6335\n",
      "----------\n",
      "epoch 55/600\n",
      "1/8, train_loss: 0.0248 step time: 0.2426\n",
      "2/8, train_loss: 0.0329 step time: 0.2069\n",
      "3/8, train_loss: 0.0666 step time: 0.2050\n",
      "4/8, train_loss: 0.0397 step time: 0.2022\n",
      "5/8, train_loss: 0.0418 step time: 0.2038\n",
      "6/8, train_loss: 0.0444 step time: 0.2092\n",
      "7/8, train_loss: 0.0271 step time: 0.1842\n",
      "8/8, train_loss: 0.0554 step time: 0.1847\n",
      "epoch 55 average loss: 0.0416\n",
      "current epoch: 55 current mean dice: 0.8901 best mean dice: 0.9220 at epoch: 50\n",
      "time consuming of epoch 55 is: 2.3989\n",
      "----------\n",
      "epoch 56/600\n",
      "1/8, train_loss: 0.0313 step time: 0.2406\n",
      "2/8, train_loss: 0.0351 step time: 0.2053\n",
      "3/8, train_loss: 0.0358 step time: 0.1965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/8, train_loss: 0.0365 step time: 0.2009\n",
      "5/8, train_loss: 0.0254 step time: 0.1994\n",
      "6/8, train_loss: 0.0350 step time: 0.2013\n",
      "7/8, train_loss: 0.0370 step time: 0.1829\n",
      "8/8, train_loss: 0.0235 step time: 0.1816\n",
      "epoch 56 average loss: 0.0325\n",
      "time consuming of epoch 56 is: 1.6097\n",
      "----------\n",
      "epoch 57/600\n",
      "1/8, train_loss: 0.0229 step time: 0.2405\n",
      "2/8, train_loss: 0.0327 step time: 0.2035\n",
      "3/8, train_loss: 0.0244 step time: 0.2039\n",
      "4/8, train_loss: 0.0518 step time: 0.1986\n",
      "5/8, train_loss: 0.0314 step time: 0.2061\n",
      "6/8, train_loss: 0.0435 step time: 0.2083\n",
      "7/8, train_loss: 0.0366 step time: 0.1827\n",
      "8/8, train_loss: 0.0274 step time: 0.1819\n",
      "epoch 57 average loss: 0.0338\n",
      "time consuming of epoch 57 is: 1.6268\n",
      "----------\n",
      "epoch 58/600\n",
      "1/8, train_loss: 0.0356 step time: 0.2276\n",
      "2/8, train_loss: 0.0292 step time: 0.1940\n",
      "3/8, train_loss: 0.0320 step time: 0.1943\n",
      "4/8, train_loss: 0.0265 step time: 0.1943\n",
      "5/8, train_loss: 0.0452 step time: 0.1968\n",
      "6/8, train_loss: 0.0261 step time: 0.1987\n",
      "7/8, train_loss: 0.0367 step time: 0.1832\n",
      "8/8, train_loss: 0.0297 step time: 0.1819\n",
      "epoch 58 average loss: 0.0326\n",
      "time consuming of epoch 58 is: 1.5724\n",
      "----------\n",
      "epoch 59/600\n",
      "1/8, train_loss: 0.0255 step time: 0.2352\n",
      "2/8, train_loss: 0.0230 step time: 0.2062\n",
      "3/8, train_loss: 0.0256 step time: 0.2052\n",
      "4/8, train_loss: 0.0447 step time: 0.2002\n",
      "5/8, train_loss: 0.0294 step time: 0.2006\n",
      "6/8, train_loss: 0.0405 step time: 0.2005\n",
      "7/8, train_loss: 0.0371 step time: 0.1853\n",
      "8/8, train_loss: 0.0269 step time: 0.1831\n",
      "epoch 59 average loss: 0.0316\n",
      "time consuming of epoch 59 is: 1.6178\n",
      "----------\n",
      "epoch 60/600\n",
      "1/8, train_loss: 0.0290 step time: 0.2415\n",
      "2/8, train_loss: 0.0224 step time: 0.2027\n",
      "3/8, train_loss: 0.0318 step time: 0.1991\n",
      "4/8, train_loss: 0.0256 step time: 0.1991\n",
      "5/8, train_loss: 0.0249 step time: 0.1990\n",
      "6/8, train_loss: 0.0233 step time: 0.2011\n",
      "7/8, train_loss: 0.0243 step time: 0.1820\n",
      "8/8, train_loss: 0.0284 step time: 0.1823\n",
      "epoch 60 average loss: 0.0262\n",
      "current epoch: 60 current mean dice: 0.9218 best mean dice: 0.9220 at epoch: 50\n",
      "time consuming of epoch 60 is: 2.3638\n",
      "----------\n",
      "epoch 61/600\n",
      "1/8, train_loss: 0.0359 step time: 0.2436\n",
      "2/8, train_loss: 0.0250 step time: 0.2013\n",
      "3/8, train_loss: 0.0252 step time: 0.1995\n",
      "4/8, train_loss: 0.0281 step time: 0.2025\n",
      "5/8, train_loss: 0.0393 step time: 0.2016\n",
      "6/8, train_loss: 0.0287 step time: 0.1993\n",
      "7/8, train_loss: 0.0296 step time: 0.1848\n",
      "8/8, train_loss: 0.0406 step time: 0.1820\n",
      "epoch 61 average loss: 0.0315\n",
      "time consuming of epoch 61 is: 1.6158\n",
      "----------\n",
      "epoch 62/600\n",
      "1/8, train_loss: 0.0246 step time: 0.2428\n",
      "2/8, train_loss: 0.0253 step time: 0.2005\n",
      "3/8, train_loss: 0.0321 step time: 0.2016\n",
      "4/8, train_loss: 0.0370 step time: 0.2003\n",
      "5/8, train_loss: 0.0366 step time: 0.1988\n",
      "6/8, train_loss: 0.0301 step time: 0.2019\n",
      "7/8, train_loss: 0.0263 step time: 0.1833\n",
      "8/8, train_loss: 0.0344 step time: 0.1825\n",
      "epoch 62 average loss: 0.0308\n",
      "time consuming of epoch 62 is: 1.6133\n",
      "----------\n",
      "epoch 63/600\n",
      "1/8, train_loss: 0.0234 step time: 0.2413\n",
      "2/8, train_loss: 0.0252 step time: 0.2020\n",
      "3/8, train_loss: 0.0268 step time: 0.1996\n",
      "4/8, train_loss: 0.0362 step time: 0.2016\n",
      "5/8, train_loss: 0.0263 step time: 0.2024\n",
      "6/8, train_loss: 0.0320 step time: 0.1988\n",
      "7/8, train_loss: 0.0242 step time: 0.1821\n",
      "8/8, train_loss: 0.0356 step time: 0.1822\n",
      "epoch 63 average loss: 0.0287\n",
      "time consuming of epoch 63 is: 1.6117\n",
      "----------\n",
      "epoch 64/600\n",
      "1/8, train_loss: 0.0299 step time: 0.2392\n",
      "2/8, train_loss: 0.0377 step time: 0.1989\n",
      "3/8, train_loss: 0.0230 step time: 0.2021\n",
      "4/8, train_loss: 0.0319 step time: 0.1984\n",
      "5/8, train_loss: 0.0272 step time: 0.1994\n",
      "6/8, train_loss: 0.0279 step time: 0.1983\n",
      "7/8, train_loss: 0.0224 step time: 0.1802\n",
      "8/8, train_loss: 0.0370 step time: 0.1824\n",
      "epoch 64 average loss: 0.0296\n",
      "time consuming of epoch 64 is: 1.6004\n",
      "----------\n",
      "epoch 65/600\n",
      "1/8, train_loss: 0.0294 step time: 0.2405\n",
      "2/8, train_loss: 0.0257 step time: 0.2001\n",
      "3/8, train_loss: 0.0462 step time: 0.1992\n",
      "4/8, train_loss: 0.0291 step time: 0.2003\n",
      "5/8, train_loss: 0.0244 step time: 0.2004\n",
      "6/8, train_loss: 0.0289 step time: 0.1999\n",
      "7/8, train_loss: 0.0333 step time: 0.1846\n",
      "8/8, train_loss: 0.0271 step time: 0.1817\n",
      "epoch 65 average loss: 0.0305\n",
      "saved new best metric model\n",
      "current epoch: 65 current mean dice: 0.9332 best mean dice: 0.9332 at epoch: 65\n",
      "time consuming of epoch 65 is: 2.5025\n",
      "----------\n",
      "epoch 66/600\n",
      "1/8, train_loss: 0.0386 step time: 0.2392\n",
      "2/8, train_loss: 0.0278 step time: 0.1978\n",
      "3/8, train_loss: 0.0361 step time: 0.1991\n",
      "4/8, train_loss: 0.0286 step time: 0.1963\n",
      "5/8, train_loss: 0.0236 step time: 0.1998\n",
      "6/8, train_loss: 0.0279 step time: 0.2001\n",
      "7/8, train_loss: 0.0222 step time: 0.1820\n",
      "8/8, train_loss: 0.0405 step time: 0.1861\n",
      "epoch 66 average loss: 0.0307\n",
      "time consuming of epoch 66 is: 1.6016\n",
      "----------\n",
      "epoch 67/600\n",
      "1/8, train_loss: 0.0247 step time: 0.2417\n",
      "2/8, train_loss: 0.0279 step time: 0.2066\n",
      "3/8, train_loss: 0.0303 step time: 0.2041\n",
      "4/8, train_loss: 0.0221 step time: 0.2024\n",
      "5/8, train_loss: 0.0247 step time: 0.2003\n",
      "6/8, train_loss: 0.0222 step time: 0.2075\n",
      "7/8, train_loss: 0.0263 step time: 0.1845\n",
      "8/8, train_loss: 0.0434 step time: 0.1825\n",
      "epoch 67 average loss: 0.0277\n",
      "time consuming of epoch 67 is: 1.6309\n",
      "----------\n",
      "epoch 68/600\n",
      "1/8, train_loss: 0.0261 step time: 0.2403\n",
      "2/8, train_loss: 0.0257 step time: 0.2021\n",
      "3/8, train_loss: 0.0258 step time: 0.2084\n",
      "4/8, train_loss: 0.0263 step time: 0.2047\n",
      "5/8, train_loss: 0.0823 step time: 0.2001\n",
      "6/8, train_loss: 0.0381 step time: 0.2010\n",
      "7/8, train_loss: 0.0322 step time: 0.1832\n",
      "8/8, train_loss: 0.0718 step time: 0.1826\n",
      "epoch 68 average loss: 0.0410\n",
      "time consuming of epoch 68 is: 1.6240\n",
      "----------\n",
      "epoch 69/600\n",
      "1/8, train_loss: 0.0321 step time: 0.2401\n",
      "2/8, train_loss: 0.0313 step time: 0.1986\n",
      "3/8, train_loss: 0.0408 step time: 0.2032\n",
      "4/8, train_loss: 0.0472 step time: 0.2032\n",
      "5/8, train_loss: 0.0313 step time: 0.2000\n",
      "6/8, train_loss: 0.0516 step time: 0.2022\n",
      "7/8, train_loss: 0.0469 step time: 0.1834\n",
      "8/8, train_loss: 0.0330 step time: 0.1828\n",
      "epoch 69 average loss: 0.0393\n",
      "time consuming of epoch 69 is: 1.6151\n",
      "----------\n",
      "epoch 70/600\n",
      "1/8, train_loss: 0.0380 step time: 0.2407\n",
      "2/8, train_loss: 0.0365 step time: 0.2037\n",
      "3/8, train_loss: 0.0387 step time: 0.1995\n",
      "4/8, train_loss: 0.0427 step time: 0.2034\n",
      "5/8, train_loss: 0.0382 step time: 0.2005\n",
      "6/8, train_loss: 0.0243 step time: 0.2044\n",
      "7/8, train_loss: 0.0315 step time: 0.1842\n",
      "8/8, train_loss: 0.0382 step time: 0.1809\n",
      "epoch 70 average loss: 0.0360\n",
      "current epoch: 70 current mean dice: 0.9003 best mean dice: 0.9332 at epoch: 65\n",
      "time consuming of epoch 70 is: 2.3740\n",
      "----------\n",
      "epoch 71/600\n",
      "1/8, train_loss: 0.0297 step time: 0.2377\n",
      "2/8, train_loss: 0.0341 step time: 0.1992\n",
      "3/8, train_loss: 0.0481 step time: 0.2042\n",
      "4/8, train_loss: 0.0278 step time: 0.1992\n",
      "5/8, train_loss: 0.0289 step time: 0.2023\n",
      "6/8, train_loss: 0.0230 step time: 0.1974\n",
      "7/8, train_loss: 0.0232 step time: 0.1831\n",
      "8/8, train_loss: 0.0227 step time: 0.1827\n",
      "epoch 71 average loss: 0.0297\n",
      "time consuming of epoch 71 is: 1.6070\n",
      "----------\n",
      "epoch 72/600\n",
      "1/8, train_loss: 0.0313 step time: 0.3372\n",
      "2/8, train_loss: 0.0234 step time: 0.2026\n",
      "3/8, train_loss: 0.0224 step time: 0.2059\n",
      "4/8, train_loss: 0.0252 step time: 0.2018\n",
      "5/8, train_loss: 0.0258 step time: 0.2015\n",
      "6/8, train_loss: 0.0336 step time: 0.2067\n",
      "7/8, train_loss: 0.0428 step time: 0.1831\n",
      "8/8, train_loss: 0.0440 step time: 0.1823\n",
      "epoch 72 average loss: 0.0311\n",
      "time consuming of epoch 72 is: 1.7228\n",
      "----------\n",
      "epoch 73/600\n",
      "1/8, train_loss: 0.0217 step time: 0.2370\n",
      "2/8, train_loss: 0.0339 step time: 0.2002\n",
      "3/8, train_loss: 0.0247 step time: 0.1982\n",
      "4/8, train_loss: 0.0269 step time: 0.1957\n",
      "5/8, train_loss: 0.0382 step time: 0.1980\n",
      "6/8, train_loss: 0.0282 step time: 0.1964\n",
      "7/8, train_loss: 0.0282 step time: 0.1817\n",
      "8/8, train_loss: 0.0361 step time: 0.1822\n",
      "epoch 73 average loss: 0.0297\n",
      "time consuming of epoch 73 is: 1.5909\n",
      "----------\n",
      "epoch 74/600\n",
      "1/8, train_loss: 0.0259 step time: 0.2323\n",
      "2/8, train_loss: 0.0309 step time: 0.1972\n",
      "3/8, train_loss: 0.0241 step time: 0.1957\n",
      "4/8, train_loss: 0.0255 step time: 0.1962\n",
      "5/8, train_loss: 0.0326 step time: 0.1966\n",
      "6/8, train_loss: 0.0215 step time: 0.1967\n",
      "7/8, train_loss: 0.0303 step time: 0.1822\n",
      "8/8, train_loss: 0.0234 step time: 0.1827\n",
      "epoch 74 average loss: 0.0268\n",
      "time consuming of epoch 74 is: 1.5809\n",
      "----------\n",
      "epoch 75/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0216 step time: 0.2306\n",
      "2/8, train_loss: 0.0273 step time: 0.1959\n",
      "3/8, train_loss: 0.0226 step time: 0.1968\n",
      "4/8, train_loss: 0.0620 step time: 0.1957\n",
      "5/8, train_loss: 0.0250 step time: 0.1976\n",
      "6/8, train_loss: 0.0252 step time: 0.1996\n",
      "7/8, train_loss: 0.0303 step time: 0.1832\n",
      "8/8, train_loss: 0.0322 step time: 0.1819\n",
      "epoch 75 average loss: 0.0308\n",
      "current epoch: 75 current mean dice: 0.9215 best mean dice: 0.9332 at epoch: 65\n",
      "time consuming of epoch 75 is: 2.3416\n",
      "----------\n",
      "epoch 76/600\n",
      "1/8, train_loss: 0.0250 step time: 0.2373\n",
      "2/8, train_loss: 0.0189 step time: 0.2002\n",
      "3/8, train_loss: 0.0268 step time: 0.2006\n",
      "4/8, train_loss: 0.0237 step time: 0.1986\n",
      "5/8, train_loss: 0.0317 step time: 0.2010\n",
      "6/8, train_loss: 0.0207 step time: 0.2001\n",
      "7/8, train_loss: 0.0304 step time: 0.1825\n",
      "8/8, train_loss: 0.0271 step time: 0.1816\n",
      "epoch 76 average loss: 0.0255\n",
      "time consuming of epoch 76 is: 1.6028\n",
      "----------\n",
      "epoch 77/600\n",
      "1/8, train_loss: 0.0229 step time: 0.2376\n",
      "2/8, train_loss: 0.0251 step time: 0.1977\n",
      "3/8, train_loss: 0.0210 step time: 0.2074\n",
      "4/8, train_loss: 0.0274 step time: 0.2067\n",
      "5/8, train_loss: 0.0301 step time: 0.1991\n",
      "6/8, train_loss: 0.0299 step time: 0.2009\n",
      "7/8, train_loss: 0.0265 step time: 0.1815\n",
      "8/8, train_loss: 0.0250 step time: 0.1840\n",
      "epoch 77 average loss: 0.0260\n",
      "time consuming of epoch 77 is: 1.6165\n",
      "----------\n",
      "epoch 78/600\n",
      "1/8, train_loss: 0.0238 step time: 0.2444\n",
      "2/8, train_loss: 0.0290 step time: 0.2028\n",
      "3/8, train_loss: 0.0248 step time: 0.2024\n",
      "4/8, train_loss: 0.0289 step time: 0.2026\n",
      "5/8, train_loss: 0.0499 step time: 0.1983\n",
      "6/8, train_loss: 0.0196 step time: 0.1990\n",
      "7/8, train_loss: 0.0314 step time: 0.1823\n",
      "8/8, train_loss: 0.0210 step time: 0.1817\n",
      "epoch 78 average loss: 0.0286\n",
      "time consuming of epoch 78 is: 1.6149\n",
      "----------\n",
      "epoch 79/600\n",
      "1/8, train_loss: 0.0243 step time: 0.2439\n",
      "2/8, train_loss: 0.0239 step time: 0.2047\n",
      "3/8, train_loss: 0.0246 step time: 0.2020\n",
      "4/8, train_loss: 0.0298 step time: 0.2029\n",
      "5/8, train_loss: 0.0331 step time: 0.1996\n",
      "6/8, train_loss: 0.0232 step time: 0.2026\n",
      "7/8, train_loss: 0.0403 step time: 0.1830\n",
      "8/8, train_loss: 0.0336 step time: 0.1806\n",
      "epoch 79 average loss: 0.0291\n",
      "time consuming of epoch 79 is: 1.6208\n",
      "----------\n",
      "epoch 80/600\n",
      "1/8, train_loss: 0.0269 step time: 0.2389\n",
      "2/8, train_loss: 0.0274 step time: 0.2033\n",
      "3/8, train_loss: 0.0252 step time: 0.2062\n",
      "4/8, train_loss: 0.0230 step time: 0.2020\n",
      "5/8, train_loss: 0.0370 step time: 0.2029\n",
      "6/8, train_loss: 0.0256 step time: 0.2105\n",
      "7/8, train_loss: 0.0324 step time: 0.1814\n",
      "8/8, train_loss: 0.0320 step time: 0.1804\n",
      "epoch 80 average loss: 0.0287\n",
      "saved new best metric model\n",
      "current epoch: 80 current mean dice: 0.9406 best mean dice: 0.9406 at epoch: 80\n",
      "time consuming of epoch 80 is: 2.5211\n",
      "----------\n",
      "epoch 81/600\n",
      "1/8, train_loss: 0.0318 step time: 0.2323\n",
      "2/8, train_loss: 0.0270 step time: 0.1933\n",
      "3/8, train_loss: 0.0192 step time: 0.1965\n",
      "4/8, train_loss: 0.0219 step time: 0.1929\n",
      "5/8, train_loss: 0.0268 step time: 0.1960\n",
      "6/8, train_loss: 0.0286 step time: 0.1948\n",
      "7/8, train_loss: 0.0337 step time: 0.1822\n",
      "8/8, train_loss: 0.0302 step time: 0.1834\n",
      "epoch 81 average loss: 0.0274\n",
      "time consuming of epoch 81 is: 1.5725\n",
      "----------\n",
      "epoch 82/600\n",
      "1/8, train_loss: 0.0237 step time: 0.2433\n",
      "2/8, train_loss: 0.0260 step time: 0.1973\n",
      "3/8, train_loss: 0.0228 step time: 0.2016\n",
      "4/8, train_loss: 0.0224 step time: 0.1993\n",
      "5/8, train_loss: 0.0391 step time: 0.2006\n",
      "6/8, train_loss: 0.0200 step time: 0.1999\n",
      "7/8, train_loss: 0.0306 step time: 0.1853\n",
      "8/8, train_loss: 0.0290 step time: 0.1808\n",
      "epoch 82 average loss: 0.0267\n",
      "time consuming of epoch 82 is: 1.6094\n",
      "----------\n",
      "epoch 83/600\n",
      "1/8, train_loss: 0.0193 step time: 0.2454\n",
      "2/8, train_loss: 0.0328 step time: 0.2020\n",
      "3/8, train_loss: 0.0216 step time: 0.2025\n",
      "4/8, train_loss: 0.0203 step time: 0.2029\n",
      "5/8, train_loss: 0.0276 step time: 0.2030\n",
      "6/8, train_loss: 0.0382 step time: 0.1997\n",
      "7/8, train_loss: 0.0324 step time: 0.1842\n",
      "8/8, train_loss: 0.0262 step time: 0.1837\n",
      "epoch 83 average loss: 0.0273\n",
      "time consuming of epoch 83 is: 1.6248\n",
      "----------\n",
      "epoch 84/600\n",
      "1/8, train_loss: 0.0230 step time: 0.2404\n",
      "2/8, train_loss: 0.0253 step time: 0.2059\n",
      "3/8, train_loss: 0.0303 step time: 0.2006\n",
      "4/8, train_loss: 0.0286 step time: 0.2007\n",
      "5/8, train_loss: 0.0320 step time: 0.2012\n",
      "6/8, train_loss: 0.0224 step time: 0.2015\n",
      "7/8, train_loss: 0.0264 step time: 0.1839\n",
      "8/8, train_loss: 0.0304 step time: 0.1812\n",
      "epoch 84 average loss: 0.0273\n",
      "time consuming of epoch 84 is: 1.6173\n",
      "----------\n",
      "epoch 85/600\n",
      "1/8, train_loss: 0.0230 step time: 0.2433\n",
      "2/8, train_loss: 0.0229 step time: 0.2022\n",
      "3/8, train_loss: 0.0242 step time: 0.2000\n",
      "4/8, train_loss: 0.0236 step time: 0.2033\n",
      "5/8, train_loss: 0.0237 step time: 0.2021\n",
      "6/8, train_loss: 0.0226 step time: 0.1999\n",
      "7/8, train_loss: 0.0262 step time: 0.1834\n",
      "8/8, train_loss: 0.0199 step time: 0.1837\n",
      "epoch 85 average loss: 0.0233\n",
      "current epoch: 85 current mean dice: 0.9213 best mean dice: 0.9406 at epoch: 80\n",
      "time consuming of epoch 85 is: 2.3774\n",
      "----------\n",
      "epoch 86/600\n",
      "1/8, train_loss: 0.0274 step time: 0.2374\n",
      "2/8, train_loss: 0.0350 step time: 0.2030\n",
      "3/8, train_loss: 0.0265 step time: 0.1985\n",
      "4/8, train_loss: 0.0270 step time: 0.1990\n",
      "5/8, train_loss: 0.0231 step time: 0.2053\n",
      "6/8, train_loss: 0.0263 step time: 0.2026\n",
      "7/8, train_loss: 0.0204 step time: 0.1819\n",
      "8/8, train_loss: 0.0221 step time: 0.1829\n",
      "epoch 86 average loss: 0.0260\n",
      "time consuming of epoch 86 is: 1.6118\n",
      "----------\n",
      "epoch 87/600\n",
      "1/8, train_loss: 0.0285 step time: 0.2430\n",
      "2/8, train_loss: 0.0268 step time: 0.2025\n",
      "3/8, train_loss: 0.0228 step time: 0.2026\n",
      "4/8, train_loss: 0.0202 step time: 0.2040\n",
      "5/8, train_loss: 0.0214 step time: 0.2022\n",
      "6/8, train_loss: 0.0241 step time: 0.1986\n",
      "7/8, train_loss: 0.0211 step time: 0.1824\n",
      "8/8, train_loss: 0.0231 step time: 0.1836\n",
      "epoch 87 average loss: 0.0235\n",
      "time consuming of epoch 87 is: 1.6203\n",
      "----------\n",
      "epoch 88/600\n",
      "1/8, train_loss: 0.0208 step time: 0.2441\n",
      "2/8, train_loss: 0.0212 step time: 0.2043\n",
      "3/8, train_loss: 0.0246 step time: 0.2049\n",
      "4/8, train_loss: 0.0253 step time: 0.2073\n",
      "5/8, train_loss: 0.0205 step time: 0.2020\n",
      "6/8, train_loss: 0.0231 step time: 0.2028\n",
      "7/8, train_loss: 0.0199 step time: 0.1836\n",
      "8/8, train_loss: 0.0211 step time: 0.1834\n",
      "epoch 88 average loss: 0.0221\n",
      "time consuming of epoch 88 is: 1.6342\n",
      "----------\n",
      "epoch 89/600\n",
      "1/8, train_loss: 0.0212 step time: 0.2398\n",
      "2/8, train_loss: 0.0229 step time: 0.2019\n",
      "3/8, train_loss: 0.0267 step time: 0.2025\n",
      "4/8, train_loss: 0.0233 step time: 0.2012\n",
      "5/8, train_loss: 0.0197 step time: 0.2004\n",
      "6/8, train_loss: 0.0233 step time: 0.2016\n",
      "7/8, train_loss: 0.0258 step time: 0.1816\n",
      "8/8, train_loss: 0.0176 step time: 0.1823\n",
      "epoch 89 average loss: 0.0226\n",
      "time consuming of epoch 89 is: 1.6128\n",
      "----------\n",
      "epoch 90/600\n",
      "1/8, train_loss: 0.0194 step time: 0.2419\n",
      "2/8, train_loss: 0.0211 step time: 0.2046\n",
      "3/8, train_loss: 0.0216 step time: 0.2019\n",
      "4/8, train_loss: 0.0271 step time: 0.2005\n",
      "5/8, train_loss: 0.0204 step time: 0.2022\n",
      "6/8, train_loss: 0.0305 step time: 0.2025\n",
      "7/8, train_loss: 0.0248 step time: 0.1816\n",
      "8/8, train_loss: 0.0194 step time: 0.1834\n",
      "epoch 90 average loss: 0.0230\n",
      "current epoch: 90 current mean dice: 0.9367 best mean dice: 0.9406 at epoch: 80\n",
      "time consuming of epoch 90 is: 2.3768\n",
      "----------\n",
      "epoch 91/600\n",
      "1/8, train_loss: 0.0300 step time: 0.2392\n",
      "2/8, train_loss: 0.0294 step time: 0.1982\n",
      "3/8, train_loss: 0.0235 step time: 0.2029\n",
      "4/8, train_loss: 0.0197 step time: 0.1983\n",
      "5/8, train_loss: 0.0235 step time: 0.2018\n",
      "6/8, train_loss: 0.0202 step time: 0.1994\n",
      "7/8, train_loss: 0.0207 step time: 0.1818\n",
      "8/8, train_loss: 0.0194 step time: 0.1823\n",
      "epoch 91 average loss: 0.0233\n",
      "time consuming of epoch 91 is: 1.6051\n",
      "----------\n",
      "epoch 92/600\n",
      "1/8, train_loss: 0.0291 step time: 0.2427\n",
      "2/8, train_loss: 0.0181 step time: 0.2044\n",
      "3/8, train_loss: 0.0215 step time: 0.2041\n",
      "4/8, train_loss: 0.0192 step time: 0.1994\n",
      "5/8, train_loss: 0.0216 step time: 0.2015\n",
      "6/8, train_loss: 0.0209 step time: 0.2025\n",
      "7/8, train_loss: 0.0200 step time: 0.1824\n",
      "8/8, train_loss: 0.0209 step time: 0.1835\n",
      "epoch 92 average loss: 0.0214\n",
      "time consuming of epoch 92 is: 1.6219\n",
      "----------\n",
      "epoch 93/600\n",
      "1/8, train_loss: 0.0201 step time: 0.2391\n",
      "2/8, train_loss: 0.0318 step time: 0.2023\n",
      "3/8, train_loss: 0.0248 step time: 0.1983\n",
      "4/8, train_loss: 0.0213 step time: 0.2018\n",
      "5/8, train_loss: 0.0186 step time: 0.2001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/8, train_loss: 0.0265 step time: 0.2020\n",
      "7/8, train_loss: 0.0233 step time: 0.1824\n",
      "8/8, train_loss: 0.0173 step time: 0.1822\n",
      "epoch 93 average loss: 0.0230\n",
      "time consuming of epoch 93 is: 1.6095\n",
      "----------\n",
      "epoch 94/600\n",
      "1/8, train_loss: 0.0204 step time: 0.2442\n",
      "2/8, train_loss: 0.0272 step time: 0.2057\n",
      "3/8, train_loss: 0.0249 step time: 0.2016\n",
      "4/8, train_loss: 0.0196 step time: 0.1985\n",
      "5/8, train_loss: 0.0199 step time: 0.1990\n",
      "6/8, train_loss: 0.0222 step time: 0.2028\n",
      "7/8, train_loss: 0.0338 step time: 0.1844\n",
      "8/8, train_loss: 0.0366 step time: 0.1836\n",
      "epoch 94 average loss: 0.0256\n",
      "time consuming of epoch 94 is: 1.6215\n",
      "----------\n",
      "epoch 95/600\n",
      "1/8, train_loss: 0.0237 step time: 0.2399\n",
      "2/8, train_loss: 0.0242 step time: 0.2006\n",
      "3/8, train_loss: 0.0224 step time: 0.2037\n",
      "4/8, train_loss: 0.0263 step time: 0.2039\n",
      "5/8, train_loss: 0.0212 step time: 0.2030\n",
      "6/8, train_loss: 0.0596 step time: 0.2020\n",
      "7/8, train_loss: 0.0222 step time: 0.1826\n",
      "8/8, train_loss: 0.0263 step time: 0.1827\n",
      "epoch 95 average loss: 0.0282\n",
      "current epoch: 95 current mean dice: 0.8559 best mean dice: 0.9406 at epoch: 80\n",
      "time consuming of epoch 95 is: 2.3752\n",
      "----------\n",
      "epoch 96/600\n",
      "1/8, train_loss: 0.0259 step time: 0.2378\n",
      "2/8, train_loss: 0.0241 step time: 0.1981\n",
      "3/8, train_loss: 0.0233 step time: 0.1999\n",
      "4/8, train_loss: 0.0335 step time: 0.2036\n",
      "5/8, train_loss: 0.0258 step time: 0.1978\n",
      "6/8, train_loss: 0.0238 step time: 0.1985\n",
      "7/8, train_loss: 0.0305 step time: 0.1821\n",
      "8/8, train_loss: 0.0333 step time: 0.1826\n",
      "epoch 96 average loss: 0.0275\n",
      "time consuming of epoch 96 is: 1.6016\n",
      "----------\n",
      "epoch 97/600\n",
      "1/8, train_loss: 0.0392 step time: 0.2396\n",
      "2/8, train_loss: 0.0229 step time: 0.2020\n",
      "3/8, train_loss: 0.0236 step time: 0.2001\n",
      "4/8, train_loss: 0.0226 step time: 0.1979\n",
      "5/8, train_loss: 0.0357 step time: 0.2000\n",
      "6/8, train_loss: 0.0351 step time: 0.2000\n",
      "7/8, train_loss: 0.0451 step time: 0.1826\n",
      "8/8, train_loss: 0.0206 step time: 0.1822\n",
      "epoch 97 average loss: 0.0306\n",
      "time consuming of epoch 97 is: 1.6059\n",
      "----------\n",
      "epoch 98/600\n",
      "1/8, train_loss: 0.0237 step time: 0.2424\n",
      "2/8, train_loss: 0.0220 step time: 0.2018\n",
      "3/8, train_loss: 0.0866 step time: 0.2020\n",
      "4/8, train_loss: 0.0287 step time: 0.2004\n",
      "5/8, train_loss: 0.0356 step time: 0.1993\n",
      "6/8, train_loss: 0.0263 step time: 0.1995\n",
      "7/8, train_loss: 0.0333 step time: 0.1828\n",
      "8/8, train_loss: 0.0760 step time: 0.1838\n",
      "epoch 98 average loss: 0.0415\n",
      "time consuming of epoch 98 is: 1.6137\n",
      "----------\n",
      "epoch 99/600\n",
      "1/8, train_loss: 0.0303 step time: 0.2418\n",
      "2/8, train_loss: 0.0426 step time: 0.2031\n",
      "3/8, train_loss: 0.0517 step time: 0.2002\n",
      "4/8, train_loss: 0.0378 step time: 0.2018\n",
      "5/8, train_loss: 0.0218 step time: 0.2015\n",
      "6/8, train_loss: 0.0447 step time: 0.2026\n",
      "7/8, train_loss: 0.0354 step time: 0.1826\n",
      "8/8, train_loss: 0.0444 step time: 0.1823\n",
      "epoch 99 average loss: 0.0386\n",
      "time consuming of epoch 99 is: 1.6175\n",
      "----------\n",
      "epoch 100/600\n",
      "1/8, train_loss: 0.0258 step time: 0.2405\n",
      "2/8, train_loss: 0.0392 step time: 0.2043\n",
      "3/8, train_loss: 0.0757 step time: 0.1996\n",
      "4/8, train_loss: 0.0318 step time: 0.1997\n",
      "5/8, train_loss: 0.0238 step time: 0.1994\n",
      "6/8, train_loss: 0.0347 step time: 0.2011\n",
      "7/8, train_loss: 0.0334 step time: 0.1839\n",
      "8/8, train_loss: 0.0374 step time: 0.1819\n",
      "epoch 100 average loss: 0.0377\n",
      "current epoch: 100 current mean dice: 0.9201 best mean dice: 0.9406 at epoch: 80\n",
      "time consuming of epoch 100 is: 2.3680\n",
      "----------\n",
      "epoch 101/600\n",
      "1/8, train_loss: 0.0236 step time: 0.2393\n",
      "2/8, train_loss: 0.0555 step time: 0.2016\n",
      "3/8, train_loss: 0.0259 step time: 0.1974\n",
      "4/8, train_loss: 0.0269 step time: 0.2016\n",
      "5/8, train_loss: 0.0384 step time: 0.2095\n",
      "6/8, train_loss: 0.0308 step time: 0.2069\n",
      "7/8, train_loss: 0.0350 step time: 0.1797\n",
      "8/8, train_loss: 0.0282 step time: 0.1860\n",
      "epoch 101 average loss: 0.0330\n",
      "time consuming of epoch 101 is: 1.6233\n",
      "----------\n",
      "epoch 102/600\n",
      "1/8, train_loss: 0.0240 step time: 0.2352\n",
      "2/8, train_loss: 0.0377 step time: 0.1944\n",
      "3/8, train_loss: 0.0296 step time: 0.1948\n",
      "4/8, train_loss: 0.0284 step time: 0.1975\n",
      "5/8, train_loss: 0.0270 step time: 0.1952\n",
      "6/8, train_loss: 0.0379 step time: 0.1954\n",
      "7/8, train_loss: 0.0246 step time: 0.1813\n",
      "8/8, train_loss: 0.0199 step time: 0.1815\n",
      "epoch 102 average loss: 0.0286\n",
      "time consuming of epoch 102 is: 1.5773\n",
      "----------\n",
      "epoch 103/600\n",
      "1/8, train_loss: 0.0284 step time: 0.2406\n",
      "2/8, train_loss: 0.0274 step time: 0.1991\n",
      "3/8, train_loss: 0.0235 step time: 0.2054\n",
      "4/8, train_loss: 0.0322 step time: 0.1996\n",
      "5/8, train_loss: 0.0225 step time: 0.2009\n",
      "6/8, train_loss: 0.0233 step time: 0.1995\n",
      "7/8, train_loss: 0.0317 step time: 0.1840\n",
      "8/8, train_loss: 0.0237 step time: 0.1828\n",
      "epoch 103 average loss: 0.0266\n",
      "time consuming of epoch 103 is: 1.6133\n",
      "----------\n",
      "epoch 104/600\n",
      "1/8, train_loss: 0.0222 step time: 0.2378\n",
      "2/8, train_loss: 0.0614 step time: 0.1988\n",
      "3/8, train_loss: 0.0276 step time: 0.2065\n",
      "4/8, train_loss: 0.0284 step time: 0.2045\n",
      "5/8, train_loss: 0.0293 step time: 0.2030\n",
      "6/8, train_loss: 0.0266 step time: 0.2026\n",
      "7/8, train_loss: 0.0233 step time: 0.1824\n",
      "8/8, train_loss: 0.0246 step time: 0.1824\n",
      "epoch 104 average loss: 0.0304\n",
      "time consuming of epoch 104 is: 1.6197\n",
      "----------\n",
      "epoch 105/600\n",
      "1/8, train_loss: 0.0341 step time: 0.2425\n",
      "2/8, train_loss: 0.0279 step time: 0.2046\n",
      "3/8, train_loss: 0.0280 step time: 0.2004\n",
      "4/8, train_loss: 0.0268 step time: 0.2001\n",
      "5/8, train_loss: 0.0361 step time: 0.2004\n",
      "6/8, train_loss: 0.0281 step time: 0.1973\n",
      "7/8, train_loss: 0.0292 step time: 0.1791\n",
      "8/8, train_loss: 0.0297 step time: 0.1789\n",
      "epoch 105 average loss: 0.0300\n",
      "current epoch: 105 current mean dice: 0.9040 best mean dice: 0.9406 at epoch: 80\n",
      "time consuming of epoch 105 is: 2.3569\n",
      "----------\n",
      "epoch 106/600\n",
      "1/8, train_loss: 0.0380 step time: 0.2342\n",
      "2/8, train_loss: 0.0264 step time: 0.1948\n",
      "3/8, train_loss: 0.0398 step time: 0.1973\n",
      "4/8, train_loss: 0.0284 step time: 0.1974\n",
      "5/8, train_loss: 0.0244 step time: 0.1960\n",
      "6/8, train_loss: 0.0273 step time: 0.1964\n",
      "7/8, train_loss: 0.0221 step time: 0.1789\n",
      "8/8, train_loss: 0.0262 step time: 0.1792\n",
      "epoch 106 average loss: 0.0291\n",
      "time consuming of epoch 106 is: 1.5754\n",
      "----------\n",
      "epoch 107/600\n",
      "1/8, train_loss: 0.0240 step time: 0.2325\n",
      "2/8, train_loss: 0.0288 step time: 0.1928\n",
      "3/8, train_loss: 0.0257 step time: 0.1950\n",
      "4/8, train_loss: 0.0394 step time: 0.1971\n",
      "5/8, train_loss: 0.0194 step time: 0.1949\n",
      "6/8, train_loss: 0.0246 step time: 0.1963\n",
      "7/8, train_loss: 0.0406 step time: 0.1790\n",
      "8/8, train_loss: 0.0316 step time: 0.1790\n",
      "epoch 107 average loss: 0.0293\n",
      "time consuming of epoch 107 is: 1.5676\n",
      "----------\n",
      "epoch 108/600\n",
      "1/8, train_loss: 0.0326 step time: 0.2330\n",
      "2/8, train_loss: 0.0245 step time: 0.1947\n",
      "3/8, train_loss: 0.0246 step time: 0.1967\n",
      "4/8, train_loss: 0.0225 step time: 0.1973\n",
      "5/8, train_loss: 0.0282 step time: 0.1972\n",
      "6/8, train_loss: 0.0335 step time: 0.1975\n",
      "7/8, train_loss: 0.0271 step time: 0.1789\n",
      "8/8, train_loss: 0.0193 step time: 0.1789\n",
      "epoch 108 average loss: 0.0265\n",
      "time consuming of epoch 108 is: 1.5752\n",
      "----------\n",
      "epoch 109/600\n",
      "1/8, train_loss: 0.0200 step time: 0.2318\n",
      "2/8, train_loss: 0.0243 step time: 0.1956\n",
      "3/8, train_loss: 0.0268 step time: 0.1982\n",
      "4/8, train_loss: 0.0225 step time: 0.1971\n",
      "5/8, train_loss: 0.0206 step time: 0.1967\n",
      "6/8, train_loss: 0.0203 step time: 0.1957\n",
      "7/8, train_loss: 0.0298 step time: 0.1789\n",
      "8/8, train_loss: 0.0247 step time: 0.1792\n",
      "epoch 109 average loss: 0.0236\n",
      "time consuming of epoch 109 is: 1.5741\n",
      "----------\n",
      "epoch 110/600\n",
      "1/8, train_loss: 0.0198 step time: 0.2355\n",
      "2/8, train_loss: 0.0216 step time: 0.1946\n",
      "3/8, train_loss: 0.0187 step time: 0.1972\n",
      "4/8, train_loss: 0.0317 step time: 0.1976\n",
      "5/8, train_loss: 0.0226 step time: 0.1967\n",
      "6/8, train_loss: 0.0216 step time: 0.1976\n",
      "7/8, train_loss: 0.0193 step time: 0.1787\n",
      "8/8, train_loss: 0.0222 step time: 0.1790\n",
      "epoch 110 average loss: 0.0222\n",
      "saved new best metric model\n",
      "current epoch: 110 current mean dice: 0.9429 best mean dice: 0.9429 at epoch: 110\n",
      "time consuming of epoch 110 is: 2.4684\n",
      "----------\n",
      "epoch 111/600\n",
      "1/8, train_loss: 0.0237 step time: 0.2339\n",
      "2/8, train_loss: 0.0239 step time: 0.1934\n",
      "3/8, train_loss: 0.0254 step time: 0.1978\n",
      "4/8, train_loss: 0.0229 step time: 0.1946\n",
      "5/8, train_loss: 0.0173 step time: 0.1963\n",
      "6/8, train_loss: 0.0242 step time: 0.1972\n",
      "7/8, train_loss: 0.0233 step time: 0.1786\n",
      "8/8, train_loss: 0.0243 step time: 0.1793\n",
      "epoch 111 average loss: 0.0231\n",
      "time consuming of epoch 111 is: 1.5722\n",
      "----------\n",
      "epoch 112/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0205 step time: 0.2440\n",
      "2/8, train_loss: 0.0197 step time: 0.2001\n",
      "3/8, train_loss: 0.0181 step time: 0.2000\n",
      "4/8, train_loss: 0.0190 step time: 0.2059\n",
      "5/8, train_loss: 0.0287 step time: 0.2013\n",
      "6/8, train_loss: 0.0189 step time: 0.2006\n",
      "7/8, train_loss: 0.0196 step time: 0.1828\n",
      "8/8, train_loss: 0.0300 step time: 0.1830\n",
      "epoch 112 average loss: 0.0218\n",
      "time consuming of epoch 112 is: 1.6191\n",
      "----------\n",
      "epoch 113/600\n",
      "1/8, train_loss: 0.0191 step time: 0.2427\n",
      "2/8, train_loss: 0.0228 step time: 0.1994\n",
      "3/8, train_loss: 0.0315 step time: 0.2009\n",
      "4/8, train_loss: 0.0204 step time: 0.2002\n",
      "5/8, train_loss: 0.0225 step time: 0.2023\n",
      "6/8, train_loss: 0.0193 step time: 0.2011\n",
      "7/8, train_loss: 0.0191 step time: 0.1827\n",
      "8/8, train_loss: 0.0183 step time: 0.1823\n",
      "epoch 113 average loss: 0.0216\n",
      "time consuming of epoch 113 is: 1.6131\n",
      "----------\n",
      "epoch 114/600\n",
      "1/8, train_loss: 0.0267 step time: 0.2419\n",
      "2/8, train_loss: 0.0220 step time: 0.1992\n",
      "3/8, train_loss: 0.0192 step time: 0.2009\n",
      "4/8, train_loss: 0.0327 step time: 0.1996\n",
      "5/8, train_loss: 0.0228 step time: 0.2001\n",
      "6/8, train_loss: 0.0217 step time: 0.2003\n",
      "7/8, train_loss: 0.0260 step time: 0.1833\n",
      "8/8, train_loss: 0.0213 step time: 0.1824\n",
      "epoch 114 average loss: 0.0240\n",
      "time consuming of epoch 114 is: 1.6090\n",
      "----------\n",
      "epoch 115/600\n",
      "1/8, train_loss: 0.0242 step time: 0.2424\n",
      "2/8, train_loss: 0.0326 step time: 0.2019\n",
      "3/8, train_loss: 0.0252 step time: 0.2021\n",
      "4/8, train_loss: 0.0208 step time: 0.2067\n",
      "5/8, train_loss: 0.0203 step time: 0.1985\n",
      "6/8, train_loss: 0.0176 step time: 0.2001\n",
      "7/8, train_loss: 0.0357 step time: 0.1823\n",
      "8/8, train_loss: 0.0219 step time: 0.1823\n",
      "epoch 115 average loss: 0.0248\n",
      "saved new best metric model\n",
      "current epoch: 115 current mean dice: 0.9439 best mean dice: 0.9439 at epoch: 115\n",
      "time consuming of epoch 115 is: 2.5160\n",
      "----------\n",
      "epoch 116/600\n",
      "1/8, train_loss: 0.0222 step time: 0.2425\n",
      "2/8, train_loss: 0.0198 step time: 0.2016\n",
      "3/8, train_loss: 0.0257 step time: 0.1995\n",
      "4/8, train_loss: 0.0287 step time: 0.1984\n",
      "5/8, train_loss: 0.0197 step time: 0.1993\n",
      "6/8, train_loss: 0.0200 step time: 0.2005\n",
      "7/8, train_loss: 0.0204 step time: 0.1822\n",
      "8/8, train_loss: 0.0247 step time: 0.1823\n",
      "epoch 116 average loss: 0.0226\n",
      "time consuming of epoch 116 is: 1.6076\n",
      "----------\n",
      "epoch 117/600\n",
      "1/8, train_loss: 0.0206 step time: 0.2430\n",
      "2/8, train_loss: 0.0194 step time: 0.2005\n",
      "3/8, train_loss: 0.0329 step time: 0.2001\n",
      "4/8, train_loss: 0.0216 step time: 0.1995\n",
      "5/8, train_loss: 0.0205 step time: 0.2036\n",
      "6/8, train_loss: 0.0232 step time: 0.2018\n",
      "7/8, train_loss: 0.0175 step time: 0.1837\n",
      "8/8, train_loss: 0.0282 step time: 0.1843\n",
      "epoch 117 average loss: 0.0230\n",
      "time consuming of epoch 117 is: 1.6176\n",
      "----------\n",
      "epoch 118/600\n",
      "1/8, train_loss: 0.0188 step time: 0.2409\n",
      "2/8, train_loss: 0.0211 step time: 0.2010\n",
      "3/8, train_loss: 0.0200 step time: 0.2029\n",
      "4/8, train_loss: 0.0227 step time: 0.2026\n",
      "5/8, train_loss: 0.0224 step time: 0.1998\n",
      "6/8, train_loss: 0.0238 step time: 0.2014\n",
      "7/8, train_loss: 0.0208 step time: 0.1826\n",
      "8/8, train_loss: 0.0172 step time: 0.1818\n",
      "epoch 118 average loss: 0.0209\n",
      "time consuming of epoch 118 is: 1.6148\n",
      "----------\n",
      "epoch 119/600\n",
      "1/8, train_loss: 0.0200 step time: 0.2407\n",
      "2/8, train_loss: 0.0216 step time: 0.2043\n",
      "3/8, train_loss: 0.0217 step time: 0.2021\n",
      "4/8, train_loss: 0.0211 step time: 0.2001\n",
      "5/8, train_loss: 0.0271 step time: 0.2031\n",
      "6/8, train_loss: 0.0208 step time: 0.1989\n",
      "7/8, train_loss: 0.0220 step time: 0.1825\n",
      "8/8, train_loss: 0.0182 step time: 0.1820\n",
      "epoch 119 average loss: 0.0216\n",
      "time consuming of epoch 119 is: 1.6152\n",
      "----------\n",
      "epoch 120/600\n",
      "1/8, train_loss: 0.0254 step time: 0.2409\n",
      "2/8, train_loss: 0.0231 step time: 0.2051\n",
      "3/8, train_loss: 0.0220 step time: 0.2016\n",
      "4/8, train_loss: 0.0249 step time: 0.2022\n",
      "5/8, train_loss: 0.0282 step time: 0.2066\n",
      "6/8, train_loss: 0.0175 step time: 0.2016\n",
      "7/8, train_loss: 0.0189 step time: 0.1830\n",
      "8/8, train_loss: 0.0217 step time: 0.1817\n",
      "epoch 120 average loss: 0.0227\n",
      "current epoch: 120 current mean dice: 0.9298 best mean dice: 0.9439 at epoch: 115\n",
      "time consuming of epoch 120 is: 2.3808\n",
      "----------\n",
      "epoch 121/600\n",
      "1/8, train_loss: 0.0248 step time: 0.2371\n",
      "2/8, train_loss: 0.0235 step time: 0.2013\n",
      "3/8, train_loss: 0.0179 step time: 0.2007\n",
      "4/8, train_loss: 0.0191 step time: 0.1975\n",
      "5/8, train_loss: 0.0206 step time: 0.2011\n",
      "6/8, train_loss: 0.0207 step time: 0.1994\n",
      "7/8, train_loss: 0.0229 step time: 0.1810\n",
      "8/8, train_loss: 0.0179 step time: 0.1814\n",
      "epoch 121 average loss: 0.0209\n",
      "time consuming of epoch 121 is: 1.6009\n",
      "----------\n",
      "epoch 122/600\n",
      "1/8, train_loss: 0.0244 step time: 0.2413\n",
      "2/8, train_loss: 0.0232 step time: 0.2032\n",
      "3/8, train_loss: 0.0288 step time: 0.2022\n",
      "4/8, train_loss: 0.0179 step time: 0.2014\n",
      "5/8, train_loss: 0.0233 step time: 0.2021\n",
      "6/8, train_loss: 0.0202 step time: 0.2061\n",
      "7/8, train_loss: 0.0230 step time: 0.1823\n",
      "8/8, train_loss: 0.0212 step time: 0.1824\n",
      "epoch 122 average loss: 0.0227\n",
      "time consuming of epoch 122 is: 1.6228\n",
      "----------\n",
      "epoch 123/600\n",
      "1/8, train_loss: 0.0257 step time: 0.2423\n",
      "2/8, train_loss: 0.0208 step time: 0.2025\n",
      "3/8, train_loss: 0.0338 step time: 0.1992\n",
      "4/8, train_loss: 0.0214 step time: 0.2011\n",
      "5/8, train_loss: 0.0217 step time: 0.1992\n",
      "6/8, train_loss: 0.0251 step time: 0.2001\n",
      "7/8, train_loss: 0.0220 step time: 0.1833\n",
      "8/8, train_loss: 0.0190 step time: 0.1808\n",
      "epoch 123 average loss: 0.0237\n",
      "time consuming of epoch 123 is: 1.6101\n",
      "----------\n",
      "epoch 124/600\n",
      "1/8, train_loss: 0.0249 step time: 0.2397\n",
      "2/8, train_loss: 0.0228 step time: 0.2035\n",
      "3/8, train_loss: 0.0191 step time: 0.1998\n",
      "4/8, train_loss: 0.0198 step time: 0.2042\n",
      "5/8, train_loss: 0.0172 step time: 0.1999\n",
      "6/8, train_loss: 0.0230 step time: 0.2018\n",
      "7/8, train_loss: 0.0198 step time: 0.1823\n",
      "8/8, train_loss: 0.0252 step time: 0.1825\n",
      "epoch 124 average loss: 0.0215\n",
      "time consuming of epoch 124 is: 1.6149\n",
      "----------\n",
      "epoch 125/600\n",
      "1/8, train_loss: 0.0225 step time: 0.2396\n",
      "2/8, train_loss: 0.0208 step time: 0.1995\n",
      "3/8, train_loss: 0.0184 step time: 0.2002\n",
      "4/8, train_loss: 0.0197 step time: 0.1987\n",
      "5/8, train_loss: 0.0240 step time: 0.2024\n",
      "6/8, train_loss: 0.0164 step time: 0.2013\n",
      "7/8, train_loss: 0.0207 step time: 0.1835\n",
      "8/8, train_loss: 0.0204 step time: 0.1822\n",
      "epoch 125 average loss: 0.0204\n",
      "current epoch: 125 current mean dice: 0.9411 best mean dice: 0.9439 at epoch: 115\n",
      "time consuming of epoch 125 is: 2.3639\n",
      "----------\n",
      "epoch 126/600\n",
      "1/8, train_loss: 0.0205 step time: 0.2410\n",
      "2/8, train_loss: 0.0202 step time: 0.2086\n",
      "3/8, train_loss: 0.0180 step time: 0.1978\n",
      "4/8, train_loss: 0.0202 step time: 0.2038\n",
      "5/8, train_loss: 0.0198 step time: 0.1999\n",
      "6/8, train_loss: 0.0231 step time: 0.1989\n",
      "7/8, train_loss: 0.0251 step time: 0.1818\n",
      "8/8, train_loss: 0.0290 step time: 0.1841\n",
      "epoch 126 average loss: 0.0220\n",
      "time consuming of epoch 126 is: 1.6170\n",
      "----------\n",
      "epoch 127/600\n",
      "1/8, train_loss: 0.0181 step time: 0.2354\n",
      "2/8, train_loss: 0.0217 step time: 0.2023\n",
      "3/8, train_loss: 0.0189 step time: 0.2026\n",
      "4/8, train_loss: 0.0225 step time: 0.2013\n",
      "5/8, train_loss: 0.0245 step time: 0.2022\n",
      "6/8, train_loss: 0.0209 step time: 0.2023\n",
      "7/8, train_loss: 0.0194 step time: 0.1839\n",
      "8/8, train_loss: 0.0208 step time: 0.1811\n",
      "epoch 127 average loss: 0.0208\n",
      "time consuming of epoch 127 is: 1.6127\n",
      "----------\n",
      "epoch 128/600\n",
      "1/8, train_loss: 0.0224 step time: 0.2383\n",
      "2/8, train_loss: 0.0236 step time: 0.2012\n",
      "3/8, train_loss: 0.0212 step time: 0.2072\n",
      "4/8, train_loss: 0.0191 step time: 0.2027\n",
      "5/8, train_loss: 0.0189 step time: 0.2045\n",
      "6/8, train_loss: 0.0244 step time: 0.2003\n",
      "7/8, train_loss: 0.0194 step time: 0.1849\n",
      "8/8, train_loss: 0.0197 step time: 0.1823\n",
      "epoch 128 average loss: 0.0211\n",
      "time consuming of epoch 128 is: 1.6229\n",
      "----------\n",
      "epoch 129/600\n",
      "1/8, train_loss: 0.0206 step time: 0.2377\n",
      "2/8, train_loss: 0.0202 step time: 0.1967\n",
      "3/8, train_loss: 0.0208 step time: 0.2035\n",
      "4/8, train_loss: 0.0162 step time: 0.1996\n",
      "5/8, train_loss: 0.0194 step time: 0.1999\n",
      "6/8, train_loss: 0.0191 step time: 0.2002\n",
      "7/8, train_loss: 0.0211 step time: 0.1858\n",
      "8/8, train_loss: 0.0196 step time: 0.1835\n",
      "epoch 129 average loss: 0.0196\n",
      "time consuming of epoch 129 is: 1.6081\n",
      "----------\n",
      "epoch 130/600\n",
      "1/8, train_loss: 0.0234 step time: 0.2422\n",
      "2/8, train_loss: 0.0180 step time: 0.1977\n",
      "3/8, train_loss: 0.0179 step time: 0.1996\n",
      "4/8, train_loss: 0.0212 step time: 0.2021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8, train_loss: 0.0192 step time: 0.2018\n",
      "6/8, train_loss: 0.0234 step time: 0.1997\n",
      "7/8, train_loss: 0.0188 step time: 0.1843\n",
      "8/8, train_loss: 0.0191 step time: 0.1810\n",
      "epoch 130 average loss: 0.0201\n",
      "saved new best metric model\n",
      "current epoch: 130 current mean dice: 0.9485 best mean dice: 0.9485 at epoch: 130\n",
      "time consuming of epoch 130 is: 2.5033\n",
      "----------\n",
      "epoch 131/600\n",
      "1/8, train_loss: 0.0179 step time: 0.2372\n",
      "2/8, train_loss: 0.0189 step time: 0.1999\n",
      "3/8, train_loss: 0.0218 step time: 0.1989\n",
      "4/8, train_loss: 0.0189 step time: 0.2000\n",
      "5/8, train_loss: 0.0246 step time: 0.1980\n",
      "6/8, train_loss: 0.0184 step time: 0.2013\n",
      "7/8, train_loss: 0.0215 step time: 0.1850\n",
      "8/8, train_loss: 0.0201 step time: 0.1824\n",
      "epoch 131 average loss: 0.0202\n",
      "time consuming of epoch 131 is: 1.6040\n",
      "----------\n",
      "epoch 132/600\n",
      "1/8, train_loss: 0.0159 step time: 0.2392\n",
      "2/8, train_loss: 0.0199 step time: 0.2020\n",
      "3/8, train_loss: 0.0201 step time: 0.1996\n",
      "4/8, train_loss: 0.0199 step time: 0.2019\n",
      "5/8, train_loss: 0.0181 step time: 0.2006\n",
      "6/8, train_loss: 0.0182 step time: 0.1982\n",
      "7/8, train_loss: 0.0175 step time: 0.1822\n",
      "8/8, train_loss: 0.0264 step time: 0.1825\n",
      "epoch 132 average loss: 0.0195\n",
      "time consuming of epoch 132 is: 1.6074\n",
      "----------\n",
      "epoch 133/600\n",
      "1/8, train_loss: 0.0175 step time: 0.2413\n",
      "2/8, train_loss: 0.0241 step time: 0.2036\n",
      "3/8, train_loss: 0.0188 step time: 0.2027\n",
      "4/8, train_loss: 0.0183 step time: 0.1999\n",
      "5/8, train_loss: 0.0212 step time: 0.2029\n",
      "6/8, train_loss: 0.0183 step time: 0.2021\n",
      "7/8, train_loss: 0.0182 step time: 0.1823\n",
      "8/8, train_loss: 0.0173 step time: 0.1822\n",
      "epoch 133 average loss: 0.0192\n",
      "time consuming of epoch 133 is: 1.6184\n",
      "----------\n",
      "epoch 134/600\n",
      "1/8, train_loss: 0.0175 step time: 0.2389\n",
      "2/8, train_loss: 0.0202 step time: 0.1999\n",
      "3/8, train_loss: 0.0192 step time: 0.1952\n",
      "4/8, train_loss: 0.0185 step time: 0.1962\n",
      "5/8, train_loss: 0.0211 step time: 0.1965\n",
      "6/8, train_loss: 0.0169 step time: 0.1963\n",
      "7/8, train_loss: 0.0187 step time: 0.1828\n",
      "8/8, train_loss: 0.0226 step time: 0.1818\n",
      "epoch 134 average loss: 0.0194\n",
      "time consuming of epoch 134 is: 1.5890\n",
      "----------\n",
      "epoch 135/600\n",
      "1/8, train_loss: 0.0159 step time: 0.2415\n",
      "2/8, train_loss: 0.0189 step time: 0.2013\n",
      "3/8, train_loss: 0.0198 step time: 0.2025\n",
      "4/8, train_loss: 0.0179 step time: 0.2037\n",
      "5/8, train_loss: 0.0250 step time: 0.1994\n",
      "6/8, train_loss: 0.0236 step time: 0.2006\n",
      "7/8, train_loss: 0.0185 step time: 0.1833\n",
      "8/8, train_loss: 0.0204 step time: 0.1815\n",
      "epoch 135 average loss: 0.0200\n",
      "saved new best metric model\n",
      "current epoch: 135 current mean dice: 0.9498 best mean dice: 0.9498 at epoch: 135\n",
      "time consuming of epoch 135 is: 2.5137\n",
      "----------\n",
      "epoch 136/600\n",
      "1/8, train_loss: 0.0177 step time: 0.2385\n",
      "2/8, train_loss: 0.0203 step time: 0.2017\n",
      "3/8, train_loss: 0.0213 step time: 0.2051\n",
      "4/8, train_loss: 0.0147 step time: 0.2022\n",
      "5/8, train_loss: 0.0233 step time: 0.2005\n",
      "6/8, train_loss: 0.0187 step time: 0.1999\n",
      "7/8, train_loss: 0.0253 step time: 0.1830\n",
      "8/8, train_loss: 0.0170 step time: 0.1814\n",
      "epoch 136 average loss: 0.0198\n",
      "time consuming of epoch 136 is: 1.6137\n",
      "----------\n",
      "epoch 137/600\n",
      "1/8, train_loss: 0.0194 step time: 0.2390\n",
      "2/8, train_loss: 0.0214 step time: 0.1991\n",
      "3/8, train_loss: 0.0202 step time: 0.2019\n",
      "4/8, train_loss: 0.0158 step time: 0.1998\n",
      "5/8, train_loss: 0.0169 step time: 0.2042\n",
      "6/8, train_loss: 0.0178 step time: 0.2016\n",
      "7/8, train_loss: 0.0213 step time: 0.1811\n",
      "8/8, train_loss: 0.0207 step time: 0.1831\n",
      "epoch 137 average loss: 0.0192\n",
      "time consuming of epoch 137 is: 1.6111\n",
      "----------\n",
      "epoch 138/600\n",
      "1/8, train_loss: 0.0161 step time: 0.2392\n",
      "2/8, train_loss: 0.0214 step time: 0.2033\n",
      "3/8, train_loss: 0.0201 step time: 0.1973\n",
      "4/8, train_loss: 0.0176 step time: 0.2014\n",
      "5/8, train_loss: 0.0234 step time: 0.2012\n",
      "6/8, train_loss: 0.0183 step time: 0.2038\n",
      "7/8, train_loss: 0.0195 step time: 0.1848\n",
      "8/8, train_loss: 0.0187 step time: 0.1823\n",
      "epoch 138 average loss: 0.0194\n",
      "time consuming of epoch 138 is: 1.6148\n",
      "----------\n",
      "epoch 139/600\n",
      "1/8, train_loss: 0.0183 step time: 0.2395\n",
      "2/8, train_loss: 0.0164 step time: 0.1998\n",
      "3/8, train_loss: 0.0168 step time: 0.2023\n",
      "4/8, train_loss: 0.0181 step time: 0.2022\n",
      "5/8, train_loss: 0.0184 step time: 0.1996\n",
      "6/8, train_loss: 0.0214 step time: 0.2043\n",
      "7/8, train_loss: 0.0180 step time: 0.1845\n",
      "8/8, train_loss: 0.0257 step time: 0.1842\n",
      "epoch 139 average loss: 0.0191\n",
      "time consuming of epoch 139 is: 1.6180\n",
      "----------\n",
      "epoch 140/600\n",
      "1/8, train_loss: 0.0180 step time: 0.2412\n",
      "2/8, train_loss: 0.0188 step time: 0.2098\n",
      "3/8, train_loss: 0.0205 step time: 0.2041\n",
      "4/8, train_loss: 0.0196 step time: 0.2029\n",
      "5/8, train_loss: 0.0166 step time: 0.2015\n",
      "6/8, train_loss: 0.0192 step time: 0.1961\n",
      "7/8, train_loss: 0.0200 step time: 0.1837\n",
      "8/8, train_loss: 0.0187 step time: 0.1818\n",
      "epoch 140 average loss: 0.0189\n",
      "current epoch: 140 current mean dice: 0.9476 best mean dice: 0.9498 at epoch: 135\n",
      "time consuming of epoch 140 is: 2.3779\n",
      "----------\n",
      "epoch 141/600\n",
      "1/8, train_loss: 0.0203 step time: 0.2382\n",
      "2/8, train_loss: 0.0168 step time: 0.2017\n",
      "3/8, train_loss: 0.0158 step time: 0.2023\n",
      "4/8, train_loss: 0.0211 step time: 0.1989\n",
      "5/8, train_loss: 0.0163 step time: 0.1996\n",
      "6/8, train_loss: 0.0150 step time: 0.1992\n",
      "7/8, train_loss: 0.0185 step time: 0.1813\n",
      "8/8, train_loss: 0.0204 step time: 0.1815\n",
      "epoch 141 average loss: 0.0180\n",
      "time consuming of epoch 141 is: 1.6038\n",
      "----------\n",
      "epoch 142/600\n",
      "1/8, train_loss: 0.0176 step time: 0.2416\n",
      "2/8, train_loss: 0.0218 step time: 0.2026\n",
      "3/8, train_loss: 0.0148 step time: 0.1993\n",
      "4/8, train_loss: 0.0164 step time: 0.2014\n",
      "5/8, train_loss: 0.0169 step time: 0.2044\n",
      "6/8, train_loss: 0.0271 step time: 0.2018\n",
      "7/8, train_loss: 0.0232 step time: 0.1819\n",
      "8/8, train_loss: 0.0196 step time: 0.1819\n",
      "epoch 142 average loss: 0.0197\n",
      "time consuming of epoch 142 is: 1.6162\n",
      "----------\n",
      "epoch 143/600\n",
      "1/8, train_loss: 0.0173 step time: 0.2398\n",
      "2/8, train_loss: 0.0205 step time: 0.2047\n",
      "3/8, train_loss: 0.0195 step time: 0.1988\n",
      "4/8, train_loss: 0.0193 step time: 0.1980\n",
      "5/8, train_loss: 0.0170 step time: 0.1989\n",
      "6/8, train_loss: 0.0209 step time: 0.1998\n",
      "7/8, train_loss: 0.0226 step time: 0.1810\n",
      "8/8, train_loss: 0.0195 step time: 0.1832\n",
      "epoch 143 average loss: 0.0196\n",
      "time consuming of epoch 143 is: 1.6058\n",
      "----------\n",
      "epoch 144/600\n",
      "1/8, train_loss: 0.0179 step time: 0.2386\n",
      "2/8, train_loss: 0.0198 step time: 0.1989\n",
      "3/8, train_loss: 0.0217 step time: 0.1997\n",
      "4/8, train_loss: 0.0254 step time: 0.1991\n",
      "5/8, train_loss: 0.0174 step time: 0.1980\n",
      "6/8, train_loss: 0.0164 step time: 0.1980\n",
      "7/8, train_loss: 0.0198 step time: 0.1822\n",
      "8/8, train_loss: 0.0208 step time: 0.1841\n",
      "epoch 144 average loss: 0.0199\n",
      "time consuming of epoch 144 is: 1.5998\n",
      "----------\n",
      "epoch 145/600\n",
      "1/8, train_loss: 0.0183 step time: 0.2323\n",
      "2/8, train_loss: 0.0181 step time: 0.1962\n",
      "3/8, train_loss: 0.0226 step time: 0.2033\n",
      "4/8, train_loss: 0.0164 step time: 0.2002\n",
      "5/8, train_loss: 0.0220 step time: 0.1979\n",
      "6/8, train_loss: 0.0209 step time: 0.1998\n",
      "7/8, train_loss: 0.0202 step time: 0.1836\n",
      "8/8, train_loss: 0.0169 step time: 0.1848\n",
      "epoch 145 average loss: 0.0194\n",
      "current epoch: 145 current mean dice: 0.9470 best mean dice: 0.9498 at epoch: 135\n",
      "time consuming of epoch 145 is: 2.3578\n",
      "----------\n",
      "epoch 146/600\n",
      "1/8, train_loss: 0.0163 step time: 0.2453\n",
      "2/8, train_loss: 0.0201 step time: 0.2096\n",
      "3/8, train_loss: 0.0175 step time: 0.2184\n",
      "4/8, train_loss: 0.0211 step time: 0.1985\n",
      "5/8, train_loss: 0.0226 step time: 0.2040\n",
      "6/8, train_loss: 0.0217 step time: 0.1986\n",
      "7/8, train_loss: 0.0218 step time: 0.1828\n",
      "8/8, train_loss: 0.0212 step time: 0.1837\n",
      "epoch 146 average loss: 0.0203\n",
      "time consuming of epoch 146 is: 1.6427\n",
      "----------\n",
      "epoch 147/600\n",
      "1/8, train_loss: 0.0197 step time: 0.2320\n",
      "2/8, train_loss: 0.0183 step time: 0.1950\n",
      "3/8, train_loss: 0.0201 step time: 0.1968\n",
      "4/8, train_loss: 0.0209 step time: 0.1996\n",
      "5/8, train_loss: 0.0192 step time: 0.2022\n",
      "6/8, train_loss: 0.0224 step time: 0.2027\n",
      "7/8, train_loss: 0.0160 step time: 0.1835\n",
      "8/8, train_loss: 0.0215 step time: 0.1832\n",
      "epoch 147 average loss: 0.0197\n",
      "time consuming of epoch 147 is: 1.5962\n",
      "----------\n",
      "epoch 148/600\n",
      "1/8, train_loss: 0.0180 step time: 0.2429\n",
      "2/8, train_loss: 0.0214 step time: 0.2028\n",
      "3/8, train_loss: 0.0182 step time: 0.1997\n",
      "4/8, train_loss: 0.0220 step time: 0.2032\n",
      "5/8, train_loss: 0.0194 step time: 0.2018\n",
      "6/8, train_loss: 0.0179 step time: 0.2013\n",
      "7/8, train_loss: 0.0196 step time: 0.1822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8, train_loss: 0.0184 step time: 0.1821\n",
      "epoch 148 average loss: 0.0194\n",
      "time consuming of epoch 148 is: 1.6173\n",
      "----------\n",
      "epoch 149/600\n",
      "1/8, train_loss: 0.0175 step time: 0.2407\n",
      "2/8, train_loss: 0.0179 step time: 0.2030\n",
      "3/8, train_loss: 0.0194 step time: 0.2000\n",
      "4/8, train_loss: 0.0184 step time: 0.1995\n",
      "5/8, train_loss: 0.0202 step time: 0.2004\n",
      "6/8, train_loss: 0.0155 step time: 0.1997\n",
      "7/8, train_loss: 0.0244 step time: 0.1848\n",
      "8/8, train_loss: 0.0163 step time: 0.1804\n",
      "epoch 149 average loss: 0.0187\n",
      "time consuming of epoch 149 is: 1.6100\n",
      "----------\n",
      "epoch 150/600\n",
      "1/8, train_loss: 0.0184 step time: 0.2378\n",
      "2/8, train_loss: 0.0208 step time: 0.2058\n",
      "3/8, train_loss: 0.0194 step time: 0.1996\n",
      "4/8, train_loss: 0.0248 step time: 0.2014\n",
      "5/8, train_loss: 0.0170 step time: 0.2021\n",
      "6/8, train_loss: 0.0188 step time: 0.1989\n",
      "7/8, train_loss: 0.0144 step time: 0.1820\n",
      "8/8, train_loss: 0.0275 step time: 0.1825\n",
      "epoch 150 average loss: 0.0201\n",
      "current epoch: 150 current mean dice: 0.9454 best mean dice: 0.9498 at epoch: 135\n",
      "time consuming of epoch 150 is: 2.3690\n",
      "----------\n",
      "epoch 151/600\n",
      "1/8, train_loss: 0.0285 step time: 0.2389\n",
      "2/8, train_loss: 0.0224 step time: 0.1981\n",
      "3/8, train_loss: 0.0211 step time: 0.2002\n",
      "4/8, train_loss: 0.0257 step time: 0.1968\n",
      "5/8, train_loss: 0.0169 step time: 0.2002\n",
      "6/8, train_loss: 0.0189 step time: 0.2000\n",
      "7/8, train_loss: 0.0181 step time: 0.1846\n",
      "8/8, train_loss: 0.0166 step time: 0.1804\n",
      "epoch 151 average loss: 0.0210\n",
      "time consuming of epoch 151 is: 1.6003\n",
      "----------\n",
      "epoch 152/600\n",
      "1/8, train_loss: 0.0232 step time: 0.2466\n",
      "2/8, train_loss: 0.0168 step time: 0.2007\n",
      "3/8, train_loss: 0.0167 step time: 0.2046\n",
      "4/8, train_loss: 0.0269 step time: 0.2052\n",
      "5/8, train_loss: 0.0181 step time: 0.1997\n",
      "6/8, train_loss: 0.0155 step time: 0.1991\n",
      "7/8, train_loss: 0.0224 step time: 0.1822\n",
      "8/8, train_loss: 0.0212 step time: 0.1821\n",
      "epoch 152 average loss: 0.0201\n",
      "time consuming of epoch 152 is: 1.6216\n",
      "----------\n",
      "epoch 153/600\n",
      "1/8, train_loss: 0.0185 step time: 0.2395\n",
      "2/8, train_loss: 0.0218 step time: 0.2041\n",
      "3/8, train_loss: 0.0203 step time: 0.1990\n",
      "4/8, train_loss: 0.0198 step time: 0.1990\n",
      "5/8, train_loss: 0.0176 step time: 0.2012\n",
      "6/8, train_loss: 0.0173 step time: 0.2035\n",
      "7/8, train_loss: 0.0154 step time: 0.1829\n",
      "8/8, train_loss: 0.0182 step time: 0.1820\n",
      "epoch 153 average loss: 0.0186\n",
      "time consuming of epoch 153 is: 1.6127\n",
      "----------\n",
      "epoch 154/600\n",
      "1/8, train_loss: 0.0179 step time: 0.2401\n",
      "2/8, train_loss: 0.0197 step time: 0.2029\n",
      "3/8, train_loss: 0.0200 step time: 0.2012\n",
      "4/8, train_loss: 0.0196 step time: 0.2025\n",
      "5/8, train_loss: 0.0141 step time: 0.2005\n",
      "6/8, train_loss: 0.0186 step time: 0.2003\n",
      "7/8, train_loss: 0.0243 step time: 0.1831\n",
      "8/8, train_loss: 0.0206 step time: 0.1837\n",
      "epoch 154 average loss: 0.0194\n",
      "time consuming of epoch 154 is: 1.6154\n",
      "----------\n",
      "epoch 155/600\n",
      "1/8, train_loss: 0.0179 step time: 0.2373\n",
      "2/8, train_loss: 0.0153 step time: 0.1991\n",
      "3/8, train_loss: 0.0210 step time: 0.2045\n",
      "4/8, train_loss: 0.0213 step time: 0.2002\n",
      "5/8, train_loss: 0.0165 step time: 0.2026\n",
      "6/8, train_loss: 0.0223 step time: 0.2029\n",
      "7/8, train_loss: 0.0184 step time: 0.1818\n",
      "8/8, train_loss: 0.0207 step time: 0.1809\n",
      "epoch 155 average loss: 0.0192\n",
      "saved new best metric model\n",
      "current epoch: 155 current mean dice: 0.9501 best mean dice: 0.9501 at epoch: 155\n",
      "time consuming of epoch 155 is: 2.5087\n",
      "----------\n",
      "epoch 156/600\n",
      "1/8, train_loss: 0.0180 step time: 0.2384\n",
      "2/8, train_loss: 0.0180 step time: 0.1987\n",
      "3/8, train_loss: 0.0175 step time: 0.2001\n",
      "4/8, train_loss: 0.0237 step time: 0.2067\n",
      "5/8, train_loss: 0.0187 step time: 0.2028\n",
      "6/8, train_loss: 0.0226 step time: 0.2005\n",
      "7/8, train_loss: 0.0189 step time: 0.1814\n",
      "8/8, train_loss: 0.0190 step time: 0.1814\n",
      "epoch 156 average loss: 0.0196\n",
      "time consuming of epoch 156 is: 1.6112\n",
      "----------\n",
      "epoch 157/600\n",
      "1/8, train_loss: 0.0209 step time: 0.2423\n",
      "2/8, train_loss: 0.0236 step time: 0.1992\n",
      "3/8, train_loss: 0.0152 step time: 0.2034\n",
      "4/8, train_loss: 0.0252 step time: 0.2107\n",
      "5/8, train_loss: 0.0151 step time: 0.2018\n",
      "6/8, train_loss: 0.0188 step time: 0.1998\n",
      "7/8, train_loss: 0.0183 step time: 0.1832\n",
      "8/8, train_loss: 0.0195 step time: 0.1819\n",
      "epoch 157 average loss: 0.0196\n",
      "time consuming of epoch 157 is: 1.6237\n",
      "----------\n",
      "epoch 158/600\n",
      "1/8, train_loss: 0.0187 step time: 0.2394\n",
      "2/8, train_loss: 0.0182 step time: 0.1977\n",
      "3/8, train_loss: 0.0164 step time: 0.1986\n",
      "4/8, train_loss: 0.0184 step time: 0.1973\n",
      "5/8, train_loss: 0.0170 step time: 0.2011\n",
      "6/8, train_loss: 0.0281 step time: 0.1992\n",
      "7/8, train_loss: 0.0186 step time: 0.1828\n",
      "8/8, train_loss: 0.0208 step time: 0.1808\n",
      "epoch 158 average loss: 0.0195\n",
      "time consuming of epoch 158 is: 1.5981\n",
      "----------\n",
      "epoch 159/600\n",
      "1/8, train_loss: 0.0188 step time: 0.2381\n",
      "2/8, train_loss: 0.0188 step time: 0.2018\n",
      "3/8, train_loss: 0.0200 step time: 0.1985\n",
      "4/8, train_loss: 0.0193 step time: 0.2038\n",
      "5/8, train_loss: 0.0239 step time: 0.2000\n",
      "6/8, train_loss: 0.0198 step time: 0.2014\n",
      "7/8, train_loss: 0.0179 step time: 0.1821\n",
      "8/8, train_loss: 0.0221 step time: 0.1832\n",
      "epoch 159 average loss: 0.0201\n",
      "time consuming of epoch 159 is: 1.6101\n",
      "----------\n",
      "epoch 160/600\n",
      "1/8, train_loss: 0.0173 step time: 0.2394\n",
      "2/8, train_loss: 0.0182 step time: 0.1972\n",
      "3/8, train_loss: 0.0178 step time: 0.2011\n",
      "4/8, train_loss: 0.0227 step time: 0.1984\n",
      "5/8, train_loss: 0.0180 step time: 0.1999\n",
      "6/8, train_loss: 0.0186 step time: 0.1994\n",
      "7/8, train_loss: 0.0174 step time: 0.1834\n",
      "8/8, train_loss: 0.0206 step time: 0.1830\n",
      "epoch 160 average loss: 0.0188\n",
      "current epoch: 160 current mean dice: 0.9438 best mean dice: 0.9501 at epoch: 155\n",
      "time consuming of epoch 160 is: 2.3585\n",
      "----------\n",
      "epoch 161/600\n",
      "1/8, train_loss: 0.0171 step time: 0.2355\n",
      "2/8, train_loss: 0.0202 step time: 0.1955\n",
      "3/8, train_loss: 0.0186 step time: 0.1978\n",
      "4/8, train_loss: 0.0233 step time: 0.2002\n",
      "5/8, train_loss: 0.0195 step time: 0.2004\n",
      "6/8, train_loss: 0.0179 step time: 0.2000\n",
      "7/8, train_loss: 0.0143 step time: 0.1847\n",
      "8/8, train_loss: 0.0226 step time: 0.1809\n",
      "epoch 161 average loss: 0.0192\n",
      "time consuming of epoch 161 is: 1.5961\n",
      "----------\n",
      "epoch 162/600\n",
      "1/8, train_loss: 0.0188 step time: 0.2400\n",
      "2/8, train_loss: 0.0216 step time: 0.2045\n",
      "3/8, train_loss: 0.0209 step time: 0.2043\n",
      "4/8, train_loss: 0.0229 step time: 0.1975\n",
      "5/8, train_loss: 0.0179 step time: 0.2054\n",
      "6/8, train_loss: 0.0158 step time: 0.2033\n",
      "7/8, train_loss: 0.0205 step time: 0.1837\n",
      "8/8, train_loss: 0.0165 step time: 0.1821\n",
      "epoch 162 average loss: 0.0194\n",
      "time consuming of epoch 162 is: 1.6223\n",
      "----------\n",
      "epoch 163/600\n",
      "1/8, train_loss: 0.0186 step time: 0.2394\n",
      "2/8, train_loss: 0.0178 step time: 0.1990\n",
      "3/8, train_loss: 0.0177 step time: 0.1955\n",
      "4/8, train_loss: 0.0156 step time: 0.1957\n",
      "5/8, train_loss: 0.0176 step time: 0.1965\n",
      "6/8, train_loss: 0.0348 step time: 0.1944\n",
      "7/8, train_loss: 0.0221 step time: 0.1825\n",
      "8/8, train_loss: 0.0141 step time: 0.1842\n",
      "epoch 163 average loss: 0.0198\n",
      "time consuming of epoch 163 is: 1.5888\n",
      "----------\n",
      "epoch 164/600\n",
      "1/8, train_loss: 0.0269 step time: 0.2341\n",
      "2/8, train_loss: 0.0188 step time: 0.1981\n",
      "3/8, train_loss: 0.0203 step time: 0.1966\n",
      "4/8, train_loss: 0.0225 step time: 0.1963\n",
      "5/8, train_loss: 0.0241 step time: 0.1958\n",
      "6/8, train_loss: 0.0248 step time: 0.1957\n",
      "7/8, train_loss: 0.0167 step time: 0.1839\n",
      "8/8, train_loss: 0.0259 step time: 0.1817\n",
      "epoch 164 average loss: 0.0225\n",
      "time consuming of epoch 164 is: 1.5834\n",
      "----------\n",
      "epoch 165/600\n",
      "1/8, train_loss: 0.0240 step time: 0.2323\n",
      "2/8, train_loss: 0.0164 step time: 0.1987\n",
      "3/8, train_loss: 0.0234 step time: 0.2070\n",
      "4/8, train_loss: 0.0230 step time: 0.1954\n",
      "5/8, train_loss: 0.0226 step time: 0.2034\n",
      "6/8, train_loss: 0.0222 step time: 0.2004\n",
      "7/8, train_loss: 0.0205 step time: 0.1840\n",
      "8/8, train_loss: 0.0198 step time: 0.1845\n",
      "epoch 165 average loss: 0.0215\n",
      "current epoch: 165 current mean dice: 0.9229 best mean dice: 0.9501 at epoch: 155\n",
      "time consuming of epoch 165 is: 2.3624\n",
      "----------\n",
      "epoch 166/600\n",
      "1/8, train_loss: 0.0194 step time: 0.2261\n",
      "2/8, train_loss: 0.0179 step time: 0.1897\n",
      "3/8, train_loss: 0.0192 step time: 0.1903\n",
      "4/8, train_loss: 0.0201 step time: 0.1897\n",
      "5/8, train_loss: 0.0342 step time: 0.1914\n",
      "6/8, train_loss: 0.0234 step time: 0.1916\n",
      "7/8, train_loss: 0.0241 step time: 0.1809\n",
      "8/8, train_loss: 0.0244 step time: 0.1810\n",
      "epoch 166 average loss: 0.0228\n",
      "time consuming of epoch 166 is: 1.5418\n",
      "----------\n",
      "epoch 167/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0188 step time: 0.2390\n",
      "2/8, train_loss: 0.0245 step time: 0.2020\n",
      "3/8, train_loss: 0.0258 step time: 0.1984\n",
      "4/8, train_loss: 0.0223 step time: 0.2013\n",
      "5/8, train_loss: 0.0216 step time: 0.1975\n",
      "6/8, train_loss: 0.0208 step time: 0.2016\n",
      "7/8, train_loss: 0.0267 step time: 0.1845\n",
      "8/8, train_loss: 0.0146 step time: 0.1838\n",
      "epoch 167 average loss: 0.0219\n",
      "time consuming of epoch 167 is: 1.6092\n",
      "----------\n",
      "epoch 168/600\n",
      "1/8, train_loss: 0.0196 step time: 0.2391\n",
      "2/8, train_loss: 0.0171 step time: 0.1980\n",
      "3/8, train_loss: 0.0251 step time: 0.2007\n",
      "4/8, train_loss: 0.0203 step time: 0.1991\n",
      "5/8, train_loss: 0.0238 step time: 0.1999\n",
      "6/8, train_loss: 0.0170 step time: 0.1989\n",
      "7/8, train_loss: 0.0198 step time: 0.1838\n",
      "8/8, train_loss: 0.0218 step time: 0.1831\n",
      "epoch 168 average loss: 0.0206\n",
      "time consuming of epoch 168 is: 1.6044\n",
      "----------\n",
      "epoch 169/600\n",
      "1/8, train_loss: 0.0186 step time: 0.2382\n",
      "2/8, train_loss: 0.0185 step time: 0.2005\n",
      "3/8, train_loss: 0.0174 step time: 0.1988\n",
      "4/8, train_loss: 0.0184 step time: 0.1984\n",
      "5/8, train_loss: 0.0184 step time: 0.1989\n",
      "6/8, train_loss: 0.0195 step time: 0.1995\n",
      "7/8, train_loss: 0.0194 step time: 0.1840\n",
      "8/8, train_loss: 0.0224 step time: 0.1810\n",
      "epoch 169 average loss: 0.0191\n",
      "time consuming of epoch 169 is: 1.6011\n",
      "----------\n",
      "epoch 170/600\n",
      "1/8, train_loss: 0.0190 step time: 0.2392\n",
      "2/8, train_loss: 0.0231 step time: 0.2026\n",
      "3/8, train_loss: 0.0234 step time: 0.1990\n",
      "4/8, train_loss: 0.0158 step time: 0.2039\n",
      "5/8, train_loss: 0.0187 step time: 0.2052\n",
      "6/8, train_loss: 0.0182 step time: 0.1996\n",
      "7/8, train_loss: 0.0172 step time: 0.1835\n",
      "8/8, train_loss: 0.0218 step time: 0.1820\n",
      "epoch 170 average loss: 0.0197\n",
      "current epoch: 170 current mean dice: 0.9491 best mean dice: 0.9501 at epoch: 155\n",
      "time consuming of epoch 170 is: 2.3705\n",
      "----------\n",
      "epoch 171/600\n",
      "1/8, train_loss: 0.0248 step time: 0.2422\n",
      "2/8, train_loss: 0.0144 step time: 0.1981\n",
      "3/8, train_loss: 0.0197 step time: 0.1999\n",
      "4/8, train_loss: 0.0194 step time: 0.1994\n",
      "5/8, train_loss: 0.0175 step time: 0.1991\n",
      "6/8, train_loss: 0.0182 step time: 0.1992\n",
      "7/8, train_loss: 0.0201 step time: 0.1823\n",
      "8/8, train_loss: 0.0207 step time: 0.1824\n",
      "epoch 171 average loss: 0.0194\n",
      "time consuming of epoch 171 is: 1.6037\n",
      "----------\n",
      "epoch 172/600\n",
      "1/8, train_loss: 0.0189 step time: 0.2385\n",
      "2/8, train_loss: 0.0210 step time: 0.2023\n",
      "3/8, train_loss: 0.0180 step time: 0.2012\n",
      "4/8, train_loss: 0.0186 step time: 0.2001\n",
      "5/8, train_loss: 0.0204 step time: 0.2001\n",
      "6/8, train_loss: 0.0222 step time: 0.2029\n",
      "7/8, train_loss: 0.0210 step time: 0.1813\n",
      "8/8, train_loss: 0.0163 step time: 0.1807\n",
      "epoch 172 average loss: 0.0196\n",
      "time consuming of epoch 172 is: 1.6088\n",
      "----------\n",
      "epoch 173/600\n",
      "1/8, train_loss: 0.0197 step time: 0.2404\n",
      "2/8, train_loss: 0.0177 step time: 0.2012\n",
      "3/8, train_loss: 0.0125 step time: 0.2004\n",
      "4/8, train_loss: 0.0218 step time: 0.2023\n",
      "5/8, train_loss: 0.0169 step time: 0.2018\n",
      "6/8, train_loss: 0.0161 step time: 0.1993\n",
      "7/8, train_loss: 0.0178 step time: 0.1826\n",
      "8/8, train_loss: 0.0206 step time: 0.1842\n",
      "epoch 173 average loss: 0.0179\n",
      "time consuming of epoch 173 is: 1.6136\n",
      "----------\n",
      "epoch 174/600\n",
      "1/8, train_loss: 0.0197 step time: 0.2418\n",
      "2/8, train_loss: 0.0190 step time: 0.2033\n",
      "3/8, train_loss: 0.0201 step time: 0.2002\n",
      "4/8, train_loss: 0.0177 step time: 0.1989\n",
      "5/8, train_loss: 0.0184 step time: 0.2026\n",
      "6/8, train_loss: 0.0177 step time: 0.2015\n",
      "7/8, train_loss: 0.0193 step time: 0.1807\n",
      "8/8, train_loss: 0.0163 step time: 0.1819\n",
      "epoch 174 average loss: 0.0185\n",
      "time consuming of epoch 174 is: 1.6123\n",
      "----------\n",
      "epoch 175/600\n",
      "1/8, train_loss: 0.0203 step time: 0.2464\n",
      "2/8, train_loss: 0.0177 step time: 0.2041\n",
      "3/8, train_loss: 0.0166 step time: 0.2034\n",
      "4/8, train_loss: 0.0198 step time: 0.2015\n",
      "5/8, train_loss: 0.0188 step time: 0.2100\n",
      "6/8, train_loss: 0.0207 step time: 0.2082\n",
      "7/8, train_loss: 0.0185 step time: 0.1821\n",
      "8/8, train_loss: 0.0186 step time: 0.1830\n",
      "epoch 175 average loss: 0.0189\n",
      "current epoch: 175 current mean dice: 0.9474 best mean dice: 0.9501 at epoch: 155\n",
      "time consuming of epoch 175 is: 2.3950\n",
      "----------\n",
      "epoch 176/600\n",
      "1/8, train_loss: 0.0202 step time: 0.2403\n",
      "2/8, train_loss: 0.0202 step time: 0.1983\n",
      "3/8, train_loss: 0.0221 step time: 0.2018\n",
      "4/8, train_loss: 0.0170 step time: 0.2033\n",
      "5/8, train_loss: 0.0207 step time: 0.2001\n",
      "6/8, train_loss: 0.0162 step time: 0.2041\n",
      "7/8, train_loss: 0.0179 step time: 0.1843\n",
      "8/8, train_loss: 0.0154 step time: 0.1838\n",
      "epoch 176 average loss: 0.0187\n",
      "time consuming of epoch 176 is: 1.6172\n",
      "----------\n",
      "epoch 177/600\n",
      "1/8, train_loss: 0.0190 step time: 0.2357\n",
      "2/8, train_loss: 0.0189 step time: 0.1945\n",
      "3/8, train_loss: 0.0170 step time: 0.1965\n",
      "4/8, train_loss: 0.0181 step time: 0.1965\n",
      "5/8, train_loss: 0.0190 step time: 0.1970\n",
      "6/8, train_loss: 0.0202 step time: 0.2031\n",
      "7/8, train_loss: 0.0201 step time: 0.1817\n",
      "8/8, train_loss: 0.0187 step time: 0.1817\n",
      "epoch 177 average loss: 0.0189\n",
      "time consuming of epoch 177 is: 1.5881\n",
      "----------\n",
      "epoch 178/600\n",
      "1/8, train_loss: 0.0219 step time: 0.2319\n",
      "2/8, train_loss: 0.0196 step time: 0.2000\n",
      "3/8, train_loss: 0.0175 step time: 0.2000\n",
      "4/8, train_loss: 0.0166 step time: 0.2006\n",
      "5/8, train_loss: 0.0205 step time: 0.2025\n",
      "6/8, train_loss: 0.0183 step time: 0.1971\n",
      "7/8, train_loss: 0.0194 step time: 0.1809\n",
      "8/8, train_loss: 0.0192 step time: 0.1803\n",
      "epoch 178 average loss: 0.0191\n",
      "time consuming of epoch 178 is: 1.5949\n",
      "----------\n",
      "epoch 179/600\n",
      "1/8, train_loss: 0.0191 step time: 0.2384\n",
      "2/8, train_loss: 0.0213 step time: 0.1997\n",
      "3/8, train_loss: 0.0180 step time: 0.2006\n",
      "4/8, train_loss: 0.0170 step time: 0.2028\n",
      "5/8, train_loss: 0.0189 step time: 0.2025\n",
      "6/8, train_loss: 0.0220 step time: 0.2023\n",
      "7/8, train_loss: 0.0187 step time: 0.1817\n",
      "8/8, train_loss: 0.0197 step time: 0.1822\n",
      "epoch 179 average loss: 0.0193\n",
      "time consuming of epoch 179 is: 1.6113\n",
      "----------\n",
      "epoch 180/600\n",
      "1/8, train_loss: 0.0194 step time: 0.2380\n",
      "2/8, train_loss: 0.0186 step time: 0.2020\n",
      "3/8, train_loss: 0.0209 step time: 0.2005\n",
      "4/8, train_loss: 0.0183 step time: 0.2033\n",
      "5/8, train_loss: 0.0173 step time: 0.1987\n",
      "6/8, train_loss: 0.0192 step time: 0.2012\n",
      "7/8, train_loss: 0.0235 step time: 0.1821\n",
      "8/8, train_loss: 0.0225 step time: 0.1815\n",
      "epoch 180 average loss: 0.0200\n",
      "current epoch: 180 current mean dice: 0.9490 best mean dice: 0.9501 at epoch: 155\n",
      "time consuming of epoch 180 is: 2.3639\n",
      "----------\n",
      "epoch 181/600\n",
      "1/8, train_loss: 0.0207 step time: 0.2288\n",
      "2/8, train_loss: 0.0172 step time: 0.1976\n",
      "3/8, train_loss: 0.0190 step time: 0.1933\n",
      "4/8, train_loss: 0.0185 step time: 0.1949\n",
      "5/8, train_loss: 0.0181 step time: 0.1960\n",
      "6/8, train_loss: 0.0227 step time: 0.1942\n",
      "7/8, train_loss: 0.0161 step time: 0.1819\n",
      "8/8, train_loss: 0.0209 step time: 0.1807\n",
      "epoch 181 average loss: 0.0192\n",
      "time consuming of epoch 181 is: 1.5685\n",
      "----------\n",
      "epoch 182/600\n",
      "1/8, train_loss: 0.0181 step time: 0.2327\n",
      "2/8, train_loss: 0.0182 step time: 0.1983\n",
      "3/8, train_loss: 0.0177 step time: 0.1970\n",
      "4/8, train_loss: 0.0178 step time: 0.1948\n",
      "5/8, train_loss: 0.0167 step time: 0.1973\n",
      "6/8, train_loss: 0.0235 step time: 0.1943\n",
      "7/8, train_loss: 0.0190 step time: 0.1819\n",
      "8/8, train_loss: 0.0196 step time: 0.1822\n",
      "epoch 182 average loss: 0.0188\n",
      "time consuming of epoch 182 is: 1.5797\n",
      "----------\n",
      "epoch 183/600\n",
      "1/8, train_loss: 0.0167 step time: 0.2277\n",
      "2/8, train_loss: 0.0163 step time: 0.1969\n",
      "3/8, train_loss: 0.0269 step time: 0.1977\n",
      "4/8, train_loss: 0.0199 step time: 0.2061\n",
      "5/8, train_loss: 0.0164 step time: 0.1987\n",
      "6/8, train_loss: 0.0227 step time: 0.1983\n",
      "7/8, train_loss: 0.0178 step time: 0.1828\n",
      "8/8, train_loss: 0.0199 step time: 0.1816\n",
      "epoch 183 average loss: 0.0196\n",
      "time consuming of epoch 183 is: 1.5912\n",
      "----------\n",
      "epoch 184/600\n",
      "1/8, train_loss: 0.0176 step time: 0.2408\n",
      "2/8, train_loss: 0.0201 step time: 0.1997\n",
      "3/8, train_loss: 0.0197 step time: 0.2026\n",
      "4/8, train_loss: 0.0159 step time: 0.1983\n",
      "5/8, train_loss: 0.0150 step time: 0.2018\n",
      "6/8, train_loss: 0.0221 step time: 0.2031\n",
      "7/8, train_loss: 0.0205 step time: 0.1826\n",
      "8/8, train_loss: 0.0200 step time: 0.1826\n",
      "epoch 184 average loss: 0.0189\n",
      "time consuming of epoch 184 is: 1.6131\n",
      "----------\n",
      "epoch 185/600\n",
      "1/8, train_loss: 0.0185 step time: 0.2282\n",
      "2/8, train_loss: 0.0173 step time: 0.1957\n",
      "3/8, train_loss: 0.0256 step time: 0.1968\n",
      "4/8, train_loss: 0.0199 step time: 0.1974\n",
      "5/8, train_loss: 0.0171 step time: 0.1938\n",
      "6/8, train_loss: 0.0169 step time: 0.1946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/8, train_loss: 0.0167 step time: 0.1828\n",
      "8/8, train_loss: 0.0171 step time: 0.1817\n",
      "epoch 185 average loss: 0.0186\n",
      "current epoch: 185 current mean dice: 0.9499 best mean dice: 0.9501 at epoch: 155\n",
      "time consuming of epoch 185 is: 2.3252\n",
      "----------\n",
      "epoch 186/600\n",
      "1/8, train_loss: 0.0235 step time: 0.2293\n",
      "2/8, train_loss: 0.0154 step time: 0.1983\n",
      "3/8, train_loss: 0.0207 step time: 0.1952\n",
      "4/8, train_loss: 0.0193 step time: 0.1936\n",
      "5/8, train_loss: 0.0176 step time: 0.1965\n",
      "6/8, train_loss: 0.0205 step time: 0.1950\n",
      "7/8, train_loss: 0.0168 step time: 0.1812\n",
      "8/8, train_loss: 0.0185 step time: 0.1817\n",
      "epoch 186 average loss: 0.0190\n",
      "time consuming of epoch 186 is: 1.5719\n",
      "----------\n",
      "epoch 187/600\n",
      "1/8, train_loss: 0.0228 step time: 0.2409\n",
      "2/8, train_loss: 0.0175 step time: 0.2036\n",
      "3/8, train_loss: 0.0166 step time: 0.2014\n",
      "4/8, train_loss: 0.0238 step time: 0.2020\n",
      "5/8, train_loss: 0.0181 step time: 0.2020\n",
      "6/8, train_loss: 0.0153 step time: 0.1992\n",
      "7/8, train_loss: 0.0181 step time: 0.1826\n",
      "8/8, train_loss: 0.0171 step time: 0.1825\n",
      "epoch 187 average loss: 0.0187\n",
      "time consuming of epoch 187 is: 1.6156\n",
      "----------\n",
      "epoch 188/600\n",
      "1/8, train_loss: 0.0148 step time: 0.2405\n",
      "2/8, train_loss: 0.0222 step time: 0.2040\n",
      "3/8, train_loss: 0.0194 step time: 0.1991\n",
      "4/8, train_loss: 0.0174 step time: 0.2003\n",
      "5/8, train_loss: 0.0172 step time: 0.1992\n",
      "6/8, train_loss: 0.0158 step time: 0.2029\n",
      "7/8, train_loss: 0.0195 step time: 0.1821\n",
      "8/8, train_loss: 0.0178 step time: 0.1827\n",
      "epoch 188 average loss: 0.0180\n",
      "time consuming of epoch 188 is: 1.6122\n",
      "----------\n",
      "epoch 189/600\n",
      "1/8, train_loss: 0.0210 step time: 0.2366\n",
      "2/8, train_loss: 0.0206 step time: 0.2028\n",
      "3/8, train_loss: 0.0167 step time: 0.2002\n",
      "4/8, train_loss: 0.0205 step time: 0.1987\n",
      "5/8, train_loss: 0.0202 step time: 0.1986\n",
      "6/8, train_loss: 0.0163 step time: 0.1989\n",
      "7/8, train_loss: 0.0212 step time: 0.1839\n",
      "8/8, train_loss: 0.0142 step time: 0.1828\n",
      "epoch 189 average loss: 0.0188\n",
      "time consuming of epoch 189 is: 1.6037\n",
      "----------\n",
      "epoch 190/600\n",
      "1/8, train_loss: 0.0161 step time: 0.2408\n",
      "2/8, train_loss: 0.0175 step time: 0.2041\n",
      "3/8, train_loss: 0.0195 step time: 0.1983\n",
      "4/8, train_loss: 0.0176 step time: 0.2033\n",
      "5/8, train_loss: 0.0160 step time: 0.2025\n",
      "6/8, train_loss: 0.0191 step time: 0.1978\n",
      "7/8, train_loss: 0.0217 step time: 0.1842\n",
      "8/8, train_loss: 0.0165 step time: 0.1819\n",
      "epoch 190 average loss: 0.0180\n",
      "current epoch: 190 current mean dice: 0.9500 best mean dice: 0.9501 at epoch: 155\n",
      "time consuming of epoch 190 is: 2.3927\n",
      "----------\n",
      "epoch 191/600\n",
      "1/8, train_loss: 0.0169 step time: 0.2362\n",
      "2/8, train_loss: 0.0167 step time: 0.1992\n",
      "3/8, train_loss: 0.0172 step time: 0.2000\n",
      "4/8, train_loss: 0.0220 step time: 0.1999\n",
      "5/8, train_loss: 0.0145 step time: 0.1995\n",
      "6/8, train_loss: 0.0205 step time: 0.2018\n",
      "7/8, train_loss: 0.0183 step time: 0.1810\n",
      "8/8, train_loss: 0.0234 step time: 0.1823\n",
      "epoch 191 average loss: 0.0187\n",
      "time consuming of epoch 191 is: 1.6012\n",
      "----------\n",
      "epoch 192/600\n",
      "1/8, train_loss: 0.0165 step time: 0.2396\n",
      "2/8, train_loss: 0.0163 step time: 0.2032\n",
      "3/8, train_loss: 0.0231 step time: 0.1986\n",
      "4/8, train_loss: 0.0158 step time: 0.2003\n",
      "5/8, train_loss: 0.0179 step time: 0.2024\n",
      "6/8, train_loss: 0.0188 step time: 0.2012\n",
      "7/8, train_loss: 0.0155 step time: 0.1842\n",
      "8/8, train_loss: 0.0174 step time: 0.1814\n",
      "epoch 192 average loss: 0.0177\n",
      "time consuming of epoch 192 is: 1.6125\n",
      "----------\n",
      "epoch 193/600\n",
      "1/8, train_loss: 0.0170 step time: 0.2395\n",
      "2/8, train_loss: 0.0140 step time: 0.2038\n",
      "3/8, train_loss: 0.0173 step time: 0.2047\n",
      "4/8, train_loss: 0.0189 step time: 0.1977\n",
      "5/8, train_loss: 0.0178 step time: 0.2016\n",
      "6/8, train_loss: 0.0229 step time: 0.1992\n",
      "7/8, train_loss: 0.0175 step time: 0.1859\n",
      "8/8, train_loss: 0.0199 step time: 0.1837\n",
      "epoch 193 average loss: 0.0182\n",
      "time consuming of epoch 193 is: 1.6174\n",
      "----------\n",
      "epoch 194/600\n",
      "1/8, train_loss: 0.0160 step time: 0.2394\n",
      "2/8, train_loss: 0.0200 step time: 0.2025\n",
      "3/8, train_loss: 0.0146 step time: 0.2011\n",
      "4/8, train_loss: 0.0163 step time: 0.2021\n",
      "5/8, train_loss: 0.0182 step time: 0.2019\n",
      "6/8, train_loss: 0.0177 step time: 0.2075\n",
      "7/8, train_loss: 0.0180 step time: 0.1837\n",
      "8/8, train_loss: 0.0188 step time: 0.1846\n",
      "epoch 194 average loss: 0.0175\n",
      "time consuming of epoch 194 is: 1.6242\n",
      "----------\n",
      "epoch 195/600\n",
      "1/8, train_loss: 0.0215 step time: 0.2395\n",
      "2/8, train_loss: 0.0193 step time: 0.2036\n",
      "3/8, train_loss: 0.0199 step time: 0.2014\n",
      "4/8, train_loss: 0.0154 step time: 0.2008\n",
      "5/8, train_loss: 0.0220 step time: 0.2007\n",
      "6/8, train_loss: 0.0196 step time: 0.1998\n",
      "7/8, train_loss: 0.0159 step time: 0.1824\n",
      "8/8, train_loss: 0.0193 step time: 0.1840\n",
      "epoch 195 average loss: 0.0191\n",
      "saved new best metric model\n",
      "current epoch: 195 current mean dice: 0.9513 best mean dice: 0.9513 at epoch: 195\n",
      "time consuming of epoch 195 is: 2.5079\n",
      "----------\n",
      "epoch 196/600\n",
      "1/8, train_loss: 0.0190 step time: 0.2400\n",
      "2/8, train_loss: 0.0158 step time: 0.1964\n",
      "3/8, train_loss: 0.0218 step time: 0.2017\n",
      "4/8, train_loss: 0.0156 step time: 0.2036\n",
      "5/8, train_loss: 0.0170 step time: 0.1979\n",
      "6/8, train_loss: 0.0179 step time: 0.1976\n",
      "7/8, train_loss: 0.0166 step time: 0.1815\n",
      "8/8, train_loss: 0.0174 step time: 0.1814\n",
      "epoch 196 average loss: 0.0176\n",
      "time consuming of epoch 196 is: 1.6013\n",
      "----------\n",
      "epoch 197/600\n",
      "1/8, train_loss: 0.0197 step time: 0.2403\n",
      "2/8, train_loss: 0.0187 step time: 0.2002\n",
      "3/8, train_loss: 0.0173 step time: 0.2074\n",
      "4/8, train_loss: 0.0182 step time: 0.2037\n",
      "5/8, train_loss: 0.0163 step time: 0.2003\n",
      "6/8, train_loss: 0.0218 step time: 0.2014\n",
      "7/8, train_loss: 0.0152 step time: 0.1821\n",
      "8/8, train_loss: 0.0210 step time: 0.1836\n",
      "epoch 197 average loss: 0.0185\n",
      "time consuming of epoch 197 is: 1.6206\n",
      "----------\n",
      "epoch 198/600\n",
      "1/8, train_loss: 0.0156 step time: 0.2419\n",
      "2/8, train_loss: 0.0155 step time: 0.2072\n",
      "3/8, train_loss: 0.0196 step time: 0.2036\n",
      "4/8, train_loss: 0.0183 step time: 0.2018\n",
      "5/8, train_loss: 0.0198 step time: 0.2023\n",
      "6/8, train_loss: 0.0204 step time: 0.2012\n",
      "7/8, train_loss: 0.0129 step time: 0.1842\n",
      "8/8, train_loss: 0.0213 step time: 0.1828\n",
      "epoch 198 average loss: 0.0179\n",
      "time consuming of epoch 198 is: 1.6273\n",
      "----------\n",
      "epoch 199/600\n",
      "1/8, train_loss: 0.0175 step time: 0.2406\n",
      "2/8, train_loss: 0.0189 step time: 0.2046\n",
      "3/8, train_loss: 0.0179 step time: 0.2003\n",
      "4/8, train_loss: 0.0159 step time: 0.2041\n",
      "5/8, train_loss: 0.0166 step time: 0.2110\n",
      "6/8, train_loss: 0.0190 step time: 0.1979\n",
      "7/8, train_loss: 0.0163 step time: 0.1824\n",
      "8/8, train_loss: 0.0154 step time: 0.1837\n",
      "epoch 199 average loss: 0.0172\n",
      "time consuming of epoch 199 is: 1.6263\n",
      "----------\n",
      "epoch 200/600\n",
      "1/8, train_loss: 0.0187 step time: 0.2422\n",
      "2/8, train_loss: 0.0165 step time: 0.2034\n",
      "3/8, train_loss: 0.0169 step time: 0.2003\n",
      "4/8, train_loss: 0.0160 step time: 0.2007\n",
      "5/8, train_loss: 0.0160 step time: 0.2013\n",
      "6/8, train_loss: 0.0185 step time: 0.2029\n",
      "7/8, train_loss: 0.0197 step time: 0.1826\n",
      "8/8, train_loss: 0.0182 step time: 0.1822\n",
      "epoch 200 average loss: 0.0176\n",
      "current epoch: 200 current mean dice: 0.9500 best mean dice: 0.9513 at epoch: 195\n",
      "time consuming of epoch 200 is: 2.3730\n",
      "----------\n",
      "epoch 201/600\n",
      "1/8, train_loss: 0.0156 step time: 0.2391\n",
      "2/8, train_loss: 0.0248 step time: 0.2014\n",
      "3/8, train_loss: 0.0218 step time: 0.2035\n",
      "4/8, train_loss: 0.0156 step time: 0.2006\n",
      "5/8, train_loss: 0.0187 step time: 0.1984\n",
      "6/8, train_loss: 0.0143 step time: 0.1977\n",
      "7/8, train_loss: 0.0163 step time: 0.1815\n",
      "8/8, train_loss: 0.0158 step time: 0.1847\n",
      "epoch 201 average loss: 0.0179\n",
      "time consuming of epoch 201 is: 1.6080\n",
      "----------\n",
      "epoch 202/600\n",
      "1/8, train_loss: 0.0184 step time: 0.2398\n",
      "2/8, train_loss: 0.0196 step time: 0.2033\n",
      "3/8, train_loss: 0.0166 step time: 0.2003\n",
      "4/8, train_loss: 0.0166 step time: 0.2014\n",
      "5/8, train_loss: 0.0174 step time: 0.2073\n",
      "6/8, train_loss: 0.0173 step time: 0.2037\n",
      "7/8, train_loss: 0.0155 step time: 0.1825\n",
      "8/8, train_loss: 0.0167 step time: 0.1826\n",
      "epoch 202 average loss: 0.0173\n",
      "time consuming of epoch 202 is: 1.6225\n",
      "----------\n",
      "epoch 203/600\n",
      "1/8, train_loss: 0.0167 step time: 0.2382\n",
      "2/8, train_loss: 0.0206 step time: 0.2045\n",
      "3/8, train_loss: 0.0164 step time: 0.1984\n",
      "4/8, train_loss: 0.0130 step time: 0.2012\n",
      "5/8, train_loss: 0.0158 step time: 0.1985\n",
      "6/8, train_loss: 0.0201 step time: 0.2001\n",
      "7/8, train_loss: 0.0197 step time: 0.1825\n",
      "8/8, train_loss: 0.0208 step time: 0.1823\n",
      "epoch 203 average loss: 0.0179\n",
      "time consuming of epoch 203 is: 1.6072\n",
      "----------\n",
      "epoch 204/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0176 step time: 0.2407\n",
      "2/8, train_loss: 0.0158 step time: 0.2044\n",
      "3/8, train_loss: 0.0170 step time: 0.1998\n",
      "4/8, train_loss: 0.0175 step time: 0.2018\n",
      "5/8, train_loss: 0.0168 step time: 0.1991\n",
      "6/8, train_loss: 0.0233 step time: 0.2020\n",
      "7/8, train_loss: 0.0183 step time: 0.1825\n",
      "8/8, train_loss: 0.0139 step time: 0.1822\n",
      "epoch 204 average loss: 0.0175\n",
      "time consuming of epoch 204 is: 1.6140\n",
      "----------\n",
      "epoch 205/600\n",
      "1/8, train_loss: 0.0167 step time: 0.2403\n",
      "2/8, train_loss: 0.0186 step time: 0.2011\n",
      "3/8, train_loss: 0.0165 step time: 0.2018\n",
      "4/8, train_loss: 0.0167 step time: 0.2002\n",
      "5/8, train_loss: 0.0182 step time: 0.2012\n",
      "6/8, train_loss: 0.0184 step time: 0.2003\n",
      "7/8, train_loss: 0.0173 step time: 0.1834\n",
      "8/8, train_loss: 0.0180 step time: 0.1830\n",
      "epoch 205 average loss: 0.0176\n",
      "saved new best metric model\n",
      "current epoch: 205 current mean dice: 0.9519 best mean dice: 0.9519 at epoch: 205\n",
      "time consuming of epoch 205 is: 2.5122\n",
      "----------\n",
      "epoch 206/600\n",
      "1/8, train_loss: 0.0199 step time: 0.2356\n",
      "2/8, train_loss: 0.0210 step time: 0.2074\n",
      "3/8, train_loss: 0.0155 step time: 0.1983\n",
      "4/8, train_loss: 0.0138 step time: 0.2011\n",
      "5/8, train_loss: 0.0157 step time: 0.2003\n",
      "6/8, train_loss: 0.0187 step time: 0.2063\n",
      "7/8, train_loss: 0.0222 step time: 0.1834\n",
      "8/8, train_loss: 0.0154 step time: 0.1825\n",
      "epoch 206 average loss: 0.0178\n",
      "time consuming of epoch 206 is: 1.6160\n",
      "----------\n",
      "epoch 207/600\n",
      "1/8, train_loss: 0.0198 step time: 0.2401\n",
      "2/8, train_loss: 0.0197 step time: 0.1991\n",
      "3/8, train_loss: 0.0182 step time: 0.2020\n",
      "4/8, train_loss: 0.0142 step time: 0.1981\n",
      "5/8, train_loss: 0.0168 step time: 0.1980\n",
      "6/8, train_loss: 0.0146 step time: 0.2030\n",
      "7/8, train_loss: 0.0171 step time: 0.1829\n",
      "8/8, train_loss: 0.0202 step time: 0.1827\n",
      "epoch 207 average loss: 0.0176\n",
      "time consuming of epoch 207 is: 1.6073\n",
      "----------\n",
      "epoch 208/600\n",
      "1/8, train_loss: 0.0157 step time: 0.2392\n",
      "2/8, train_loss: 0.0178 step time: 0.2012\n",
      "3/8, train_loss: 0.0160 step time: 0.1985\n",
      "4/8, train_loss: 0.0171 step time: 0.2031\n",
      "5/8, train_loss: 0.0179 step time: 0.1990\n",
      "6/8, train_loss: 0.0177 step time: 0.1990\n",
      "7/8, train_loss: 0.0146 step time: 0.1834\n",
      "8/8, train_loss: 0.0198 step time: 0.1831\n",
      "epoch 208 average loss: 0.0171\n",
      "time consuming of epoch 208 is: 1.6079\n",
      "----------\n",
      "epoch 209/600\n",
      "1/8, train_loss: 0.0176 step time: 0.2399\n",
      "2/8, train_loss: 0.0151 step time: 0.2023\n",
      "3/8, train_loss: 0.0172 step time: 0.1960\n",
      "4/8, train_loss: 0.0172 step time: 0.1950\n",
      "5/8, train_loss: 0.0166 step time: 0.1952\n",
      "6/8, train_loss: 0.0150 step time: 0.1972\n",
      "7/8, train_loss: 0.0175 step time: 0.1848\n",
      "8/8, train_loss: 0.0173 step time: 0.1808\n",
      "epoch 209 average loss: 0.0167\n",
      "time consuming of epoch 209 is: 1.5926\n",
      "----------\n",
      "epoch 210/600\n",
      "1/8, train_loss: 0.0204 step time: 0.2381\n",
      "2/8, train_loss: 0.0164 step time: 0.2021\n",
      "3/8, train_loss: 0.0171 step time: 0.1990\n",
      "4/8, train_loss: 0.0188 step time: 0.2019\n",
      "5/8, train_loss: 0.0141 step time: 0.1978\n",
      "6/8, train_loss: 0.0168 step time: 0.2015\n",
      "7/8, train_loss: 0.0172 step time: 0.1818\n",
      "8/8, train_loss: 0.0162 step time: 0.1823\n",
      "epoch 210 average loss: 0.0171\n",
      "saved new best metric model\n",
      "current epoch: 210 current mean dice: 0.9523 best mean dice: 0.9523 at epoch: 210\n",
      "time consuming of epoch 210 is: 2.5005\n",
      "----------\n",
      "epoch 211/600\n",
      "1/8, train_loss: 0.0168 step time: 0.2388\n",
      "2/8, train_loss: 0.0166 step time: 0.1976\n",
      "3/8, train_loss: 0.0197 step time: 0.1976\n",
      "4/8, train_loss: 0.0156 step time: 0.1999\n",
      "5/8, train_loss: 0.0213 step time: 0.1993\n",
      "6/8, train_loss: 0.0184 step time: 0.2034\n",
      "7/8, train_loss: 0.0183 step time: 0.1811\n",
      "8/8, train_loss: 0.0127 step time: 0.1808\n",
      "epoch 211 average loss: 0.0174\n",
      "time consuming of epoch 211 is: 1.5995\n",
      "----------\n",
      "epoch 212/600\n",
      "1/8, train_loss: 0.0183 step time: 0.2362\n",
      "2/8, train_loss: 0.0143 step time: 0.2002\n",
      "3/8, train_loss: 0.0132 step time: 0.2016\n",
      "4/8, train_loss: 0.0196 step time: 0.1999\n",
      "5/8, train_loss: 0.0184 step time: 0.2067\n",
      "6/8, train_loss: 0.0176 step time: 0.2043\n",
      "7/8, train_loss: 0.0167 step time: 0.1828\n",
      "8/8, train_loss: 0.0187 step time: 0.1817\n",
      "epoch 212 average loss: 0.0171\n",
      "time consuming of epoch 212 is: 1.6146\n",
      "----------\n",
      "epoch 213/600\n",
      "1/8, train_loss: 0.0190 step time: 0.2410\n",
      "2/8, train_loss: 0.0160 step time: 0.2036\n",
      "3/8, train_loss: 0.0151 step time: 0.2018\n",
      "4/8, train_loss: 0.0197 step time: 0.1996\n",
      "5/8, train_loss: 0.0179 step time: 0.2017\n",
      "6/8, train_loss: 0.0172 step time: 0.2013\n",
      "7/8, train_loss: 0.0151 step time: 0.1837\n",
      "8/8, train_loss: 0.0204 step time: 0.1817\n",
      "epoch 213 average loss: 0.0175\n",
      "time consuming of epoch 213 is: 1.6157\n",
      "----------\n",
      "epoch 214/600\n",
      "1/8, train_loss: 0.0165 step time: 0.2402\n",
      "2/8, train_loss: 0.0145 step time: 0.2019\n",
      "3/8, train_loss: 0.0161 step time: 0.1995\n",
      "4/8, train_loss: 0.0183 step time: 0.2019\n",
      "5/8, train_loss: 0.0156 step time: 0.2047\n",
      "6/8, train_loss: 0.0178 step time: 0.2018\n",
      "7/8, train_loss: 0.0176 step time: 0.1818\n",
      "8/8, train_loss: 0.0188 step time: 0.1817\n",
      "epoch 214 average loss: 0.0169\n",
      "time consuming of epoch 214 is: 1.6152\n",
      "----------\n",
      "epoch 215/600\n",
      "1/8, train_loss: 0.0203 step time: 0.2392\n",
      "2/8, train_loss: 0.0155 step time: 0.1971\n",
      "3/8, train_loss: 0.0144 step time: 0.1963\n",
      "4/8, train_loss: 0.0185 step time: 0.2052\n",
      "5/8, train_loss: 0.0170 step time: 0.2010\n",
      "6/8, train_loss: 0.0153 step time: 0.2026\n",
      "7/8, train_loss: 0.0159 step time: 0.1826\n",
      "8/8, train_loss: 0.0184 step time: 0.1821\n",
      "epoch 215 average loss: 0.0169\n",
      "current epoch: 215 current mean dice: 0.9515 best mean dice: 0.9523 at epoch: 210\n",
      "time consuming of epoch 215 is: 2.3635\n",
      "----------\n",
      "epoch 216/600\n",
      "1/8, train_loss: 0.0145 step time: 0.2356\n",
      "2/8, train_loss: 0.0200 step time: 0.2002\n",
      "3/8, train_loss: 0.0179 step time: 0.1993\n",
      "4/8, train_loss: 0.0158 step time: 0.2022\n",
      "5/8, train_loss: 0.0193 step time: 0.1972\n",
      "6/8, train_loss: 0.0184 step time: 0.1999\n",
      "7/8, train_loss: 0.0170 step time: 0.1821\n",
      "8/8, train_loss: 0.0175 step time: 0.1811\n",
      "epoch 216 average loss: 0.0175\n",
      "time consuming of epoch 216 is: 1.5987\n",
      "----------\n",
      "epoch 217/600\n",
      "1/8, train_loss: 0.0180 step time: 0.2404\n",
      "2/8, train_loss: 0.0168 step time: 0.1984\n",
      "3/8, train_loss: 0.0182 step time: 0.2555\n",
      "4/8, train_loss: 0.0203 step time: 0.2040\n",
      "5/8, train_loss: 0.0179 step time: 0.2024\n",
      "6/8, train_loss: 0.0142 step time: 0.2004\n",
      "7/8, train_loss: 0.0229 step time: 0.1853\n",
      "8/8, train_loss: 0.0149 step time: 0.1825\n",
      "epoch 217 average loss: 0.0179\n",
      "time consuming of epoch 217 is: 1.6705\n",
      "----------\n",
      "epoch 218/600\n",
      "1/8, train_loss: 0.0154 step time: 0.2418\n",
      "2/8, train_loss: 0.0167 step time: 0.2016\n",
      "3/8, train_loss: 0.0190 step time: 0.2002\n",
      "4/8, train_loss: 0.0214 step time: 0.2024\n",
      "5/8, train_loss: 0.0165 step time: 0.1987\n",
      "6/8, train_loss: 0.0173 step time: 0.1997\n",
      "7/8, train_loss: 0.0178 step time: 0.1822\n",
      "8/8, train_loss: 0.0203 step time: 0.1809\n",
      "epoch 218 average loss: 0.0181\n",
      "time consuming of epoch 218 is: 1.6093\n",
      "----------\n",
      "epoch 219/600\n",
      "1/8, train_loss: 0.0184 step time: 0.2373\n",
      "2/8, train_loss: 0.0165 step time: 0.2029\n",
      "3/8, train_loss: 0.0190 step time: 0.2040\n",
      "4/8, train_loss: 0.0181 step time: 0.1999\n",
      "5/8, train_loss: 0.0153 step time: 0.1990\n",
      "6/8, train_loss: 0.0192 step time: 0.1998\n",
      "7/8, train_loss: 0.0169 step time: 0.1835\n",
      "8/8, train_loss: 0.0173 step time: 0.1841\n",
      "epoch 219 average loss: 0.0176\n",
      "time consuming of epoch 219 is: 1.6119\n",
      "----------\n",
      "epoch 220/600\n",
      "1/8, train_loss: 0.0195 step time: 0.2389\n",
      "2/8, train_loss: 0.0144 step time: 0.2022\n",
      "3/8, train_loss: 0.0169 step time: 0.1993\n",
      "4/8, train_loss: 0.0168 step time: 0.2014\n",
      "5/8, train_loss: 0.0177 step time: 0.1999\n",
      "6/8, train_loss: 0.0165 step time: 0.2009\n",
      "7/8, train_loss: 0.0203 step time: 0.1824\n",
      "8/8, train_loss: 0.0175 step time: 0.1824\n",
      "epoch 220 average loss: 0.0174\n",
      "current epoch: 220 current mean dice: 0.9507 best mean dice: 0.9523 at epoch: 210\n",
      "time consuming of epoch 220 is: 2.3666\n",
      "----------\n",
      "epoch 221/600\n",
      "1/8, train_loss: 0.0147 step time: 0.2384\n",
      "2/8, train_loss: 0.0173 step time: 0.1994\n",
      "3/8, train_loss: 0.0196 step time: 0.1998\n",
      "4/8, train_loss: 0.0136 step time: 0.1984\n",
      "5/8, train_loss: 0.0171 step time: 0.1994\n",
      "6/8, train_loss: 0.0197 step time: 0.2003\n",
      "7/8, train_loss: 0.0219 step time: 0.1812\n",
      "8/8, train_loss: 0.0180 step time: 0.1812\n",
      "epoch 221 average loss: 0.0177\n",
      "time consuming of epoch 221 is: 1.5991\n",
      "----------\n",
      "epoch 222/600\n",
      "1/8, train_loss: 0.0178 step time: 0.2424\n",
      "2/8, train_loss: 0.0165 step time: 0.2020\n",
      "3/8, train_loss: 0.0178 step time: 0.2001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/8, train_loss: 0.0176 step time: 0.2013\n",
      "5/8, train_loss: 0.0181 step time: 0.2018\n",
      "6/8, train_loss: 0.0185 step time: 0.2072\n",
      "7/8, train_loss: 0.0198 step time: 0.1838\n",
      "8/8, train_loss: 0.0191 step time: 0.1827\n",
      "epoch 222 average loss: 0.0182\n",
      "time consuming of epoch 222 is: 1.6228\n",
      "----------\n",
      "epoch 223/600\n",
      "1/8, train_loss: 0.0173 step time: 0.2406\n",
      "2/8, train_loss: 0.0146 step time: 0.2031\n",
      "3/8, train_loss: 0.0188 step time: 0.2018\n",
      "4/8, train_loss: 0.0215 step time: 0.2041\n",
      "5/8, train_loss: 0.0236 step time: 0.2028\n",
      "6/8, train_loss: 0.0178 step time: 0.1984\n",
      "7/8, train_loss: 0.0212 step time: 0.1833\n",
      "8/8, train_loss: 0.0178 step time: 0.1809\n",
      "epoch 223 average loss: 0.0191\n",
      "time consuming of epoch 223 is: 1.6164\n",
      "----------\n",
      "epoch 224/600\n",
      "1/8, train_loss: 0.0160 step time: 0.2385\n",
      "2/8, train_loss: 0.0167 step time: 0.2019\n",
      "3/8, train_loss: 0.0164 step time: 0.2003\n",
      "4/8, train_loss: 0.0218 step time: 0.2003\n",
      "5/8, train_loss: 0.0160 step time: 0.1984\n",
      "6/8, train_loss: 0.0159 step time: 0.1992\n",
      "7/8, train_loss: 0.0198 step time: 0.1824\n",
      "8/8, train_loss: 0.0185 step time: 0.1820\n",
      "epoch 224 average loss: 0.0176\n",
      "time consuming of epoch 224 is: 1.6043\n",
      "----------\n",
      "epoch 225/600\n",
      "1/8, train_loss: 0.0178 step time: 0.2412\n",
      "2/8, train_loss: 0.0191 step time: 0.2061\n",
      "3/8, train_loss: 0.0157 step time: 0.1989\n",
      "4/8, train_loss: 0.0169 step time: 0.2015\n",
      "5/8, train_loss: 0.0184 step time: 0.2051\n",
      "6/8, train_loss: 0.0209 step time: 0.1932\n",
      "7/8, train_loss: 0.0143 step time: 0.1900\n",
      "8/8, train_loss: 0.0141 step time: 0.1830\n",
      "epoch 225 average loss: 0.0172\n",
      "current epoch: 225 current mean dice: 0.9511 best mean dice: 0.9523 at epoch: 210\n",
      "time consuming of epoch 225 is: 2.3759\n",
      "----------\n",
      "epoch 226/600\n",
      "1/8, train_loss: 0.0158 step time: 0.2327\n",
      "2/8, train_loss: 0.0161 step time: 0.1961\n",
      "3/8, train_loss: 0.0160 step time: 0.1952\n",
      "4/8, train_loss: 0.0197 step time: 0.1937\n",
      "5/8, train_loss: 0.0145 step time: 0.1944\n",
      "6/8, train_loss: 0.0173 step time: 0.1936\n",
      "7/8, train_loss: 0.0183 step time: 0.1811\n",
      "8/8, train_loss: 0.0164 step time: 0.1826\n",
      "epoch 226 average loss: 0.0168\n",
      "time consuming of epoch 226 is: 1.5706\n",
      "----------\n",
      "epoch 227/600\n",
      "1/8, train_loss: 0.0172 step time: 0.2307\n",
      "2/8, train_loss: 0.0142 step time: 0.1989\n",
      "3/8, train_loss: 0.0178 step time: 0.1957\n",
      "4/8, train_loss: 0.0205 step time: 0.1980\n",
      "5/8, train_loss: 0.0181 step time: 0.1976\n",
      "6/8, train_loss: 0.0165 step time: 0.1980\n",
      "7/8, train_loss: 0.0161 step time: 0.1829\n",
      "8/8, train_loss: 0.0171 step time: 0.1814\n",
      "epoch 227 average loss: 0.0172\n",
      "time consuming of epoch 227 is: 1.5845\n",
      "----------\n",
      "epoch 228/600\n",
      "1/8, train_loss: 0.0157 step time: 0.2392\n",
      "2/8, train_loss: 0.0216 step time: 0.2025\n",
      "3/8, train_loss: 0.0164 step time: 0.2010\n",
      "4/8, train_loss: 0.0143 step time: 0.2006\n",
      "5/8, train_loss: 0.0140 step time: 0.2018\n",
      "6/8, train_loss: 0.0172 step time: 0.2029\n",
      "7/8, train_loss: 0.0166 step time: 0.1825\n",
      "8/8, train_loss: 0.0155 step time: 0.1838\n",
      "epoch 228 average loss: 0.0164\n",
      "time consuming of epoch 228 is: 1.6157\n",
      "----------\n",
      "epoch 229/600\n",
      "1/8, train_loss: 0.0169 step time: 0.2411\n",
      "2/8, train_loss: 0.0118 step time: 0.2014\n",
      "3/8, train_loss: 0.0198 step time: 0.2001\n",
      "4/8, train_loss: 0.0175 step time: 0.2019\n",
      "5/8, train_loss: 0.0171 step time: 0.1982\n",
      "6/8, train_loss: 0.0171 step time: 0.1996\n",
      "7/8, train_loss: 0.0140 step time: 0.1838\n",
      "8/8, train_loss: 0.0183 step time: 0.1826\n",
      "epoch 229 average loss: 0.0166\n",
      "time consuming of epoch 229 is: 1.6101\n",
      "----------\n",
      "epoch 230/600\n",
      "1/8, train_loss: 0.0165 step time: 0.2403\n",
      "2/8, train_loss: 0.0178 step time: 0.2044\n",
      "3/8, train_loss: 0.0158 step time: 0.2020\n",
      "4/8, train_loss: 0.0183 step time: 0.1994\n",
      "5/8, train_loss: 0.0158 step time: 0.2028\n",
      "6/8, train_loss: 0.0222 step time: 0.2039\n",
      "7/8, train_loss: 0.0181 step time: 0.1842\n",
      "8/8, train_loss: 0.0154 step time: 0.1821\n",
      "epoch 230 average loss: 0.0175\n",
      "current epoch: 230 current mean dice: 0.9498 best mean dice: 0.9523 at epoch: 210\n",
      "time consuming of epoch 230 is: 2.3772\n",
      "----------\n",
      "epoch 231/600\n",
      "1/8, train_loss: 0.0173 step time: 0.2400\n",
      "2/8, train_loss: 0.0142 step time: 0.1998\n",
      "3/8, train_loss: 0.0152 step time: 0.1999\n",
      "4/8, train_loss: 0.0190 step time: 0.1990\n",
      "5/8, train_loss: 0.0180 step time: 0.1987\n",
      "6/8, train_loss: 0.0161 step time: 0.1997\n",
      "7/8, train_loss: 0.0205 step time: 0.1845\n",
      "8/8, train_loss: 0.0208 step time: 0.1812\n",
      "epoch 231 average loss: 0.0176\n",
      "time consuming of epoch 231 is: 1.6040\n",
      "----------\n",
      "epoch 232/600\n",
      "1/8, train_loss: 0.0166 step time: 0.2441\n",
      "2/8, train_loss: 0.0146 step time: 0.2001\n",
      "3/8, train_loss: 0.0172 step time: 0.2000\n",
      "4/8, train_loss: 0.0188 step time: 0.1969\n",
      "5/8, train_loss: 0.0218 step time: 0.2011\n",
      "6/8, train_loss: 0.0161 step time: 0.1993\n",
      "7/8, train_loss: 0.0182 step time: 0.1830\n",
      "8/8, train_loss: 0.0150 step time: 0.1819\n",
      "epoch 232 average loss: 0.0173\n",
      "time consuming of epoch 232 is: 1.6080\n",
      "----------\n",
      "epoch 233/600\n",
      "1/8, train_loss: 0.0167 step time: 0.2407\n",
      "2/8, train_loss: 0.0165 step time: 0.2030\n",
      "3/8, train_loss: 0.0175 step time: 0.2012\n",
      "4/8, train_loss: 0.0188 step time: 0.2013\n",
      "5/8, train_loss: 0.0169 step time: 0.1997\n",
      "6/8, train_loss: 0.0144 step time: 0.2016\n",
      "7/8, train_loss: 0.0185 step time: 0.1825\n",
      "8/8, train_loss: 0.0180 step time: 0.1825\n",
      "epoch 233 average loss: 0.0172\n",
      "time consuming of epoch 233 is: 1.6141\n",
      "----------\n",
      "epoch 234/600\n",
      "1/8, train_loss: 0.0146 step time: 0.2396\n",
      "2/8, train_loss: 0.0157 step time: 0.2004\n",
      "3/8, train_loss: 0.0160 step time: 0.1987\n",
      "4/8, train_loss: 0.0159 step time: 0.1989\n",
      "5/8, train_loss: 0.0209 step time: 0.2006\n",
      "6/8, train_loss: 0.0144 step time: 0.1981\n",
      "7/8, train_loss: 0.0175 step time: 0.1809\n",
      "8/8, train_loss: 0.0170 step time: 0.1821\n",
      "epoch 234 average loss: 0.0165\n",
      "time consuming of epoch 234 is: 1.6010\n",
      "----------\n",
      "epoch 235/600\n",
      "1/8, train_loss: 0.0160 step time: 0.2402\n",
      "2/8, train_loss: 0.0181 step time: 0.2016\n",
      "3/8, train_loss: 0.0190 step time: 0.2013\n",
      "4/8, train_loss: 0.0171 step time: 0.2019\n",
      "5/8, train_loss: 0.0171 step time: 0.2009\n",
      "6/8, train_loss: 0.0170 step time: 0.1995\n",
      "7/8, train_loss: 0.0160 step time: 0.1808\n",
      "8/8, train_loss: 0.0151 step time: 0.1828\n",
      "epoch 235 average loss: 0.0169\n",
      "saved new best metric model\n",
      "current epoch: 235 current mean dice: 0.9524 best mean dice: 0.9524 at epoch: 235\n",
      "time consuming of epoch 235 is: 2.5054\n",
      "----------\n",
      "epoch 236/600\n",
      "1/8, train_loss: 0.0193 step time: 0.2338\n",
      "2/8, train_loss: 0.0189 step time: 0.1962\n",
      "3/8, train_loss: 0.0166 step time: 0.1959\n",
      "4/8, train_loss: 0.0159 step time: 0.1930\n",
      "5/8, train_loss: 0.0164 step time: 0.1996\n",
      "6/8, train_loss: 0.0167 step time: 0.1975\n",
      "7/8, train_loss: 0.0182 step time: 0.1809\n",
      "8/8, train_loss: 0.0168 step time: 0.1810\n",
      "epoch 236 average loss: 0.0174\n",
      "time consuming of epoch 236 is: 1.5791\n",
      "----------\n",
      "epoch 237/600\n",
      "1/8, train_loss: 0.0163 step time: 0.2412\n",
      "2/8, train_loss: 0.0150 step time: 0.2020\n",
      "3/8, train_loss: 0.0183 step time: 0.1983\n",
      "4/8, train_loss: 0.0158 step time: 0.2015\n",
      "5/8, train_loss: 0.0187 step time: 0.2006\n",
      "6/8, train_loss: 0.0172 step time: 0.2003\n",
      "7/8, train_loss: 0.0162 step time: 0.1824\n",
      "8/8, train_loss: 0.0206 step time: 0.1817\n",
      "epoch 237 average loss: 0.0173\n",
      "time consuming of epoch 237 is: 1.6092\n",
      "----------\n",
      "epoch 238/600\n",
      "1/8, train_loss: 0.0142 step time: 0.2393\n",
      "2/8, train_loss: 0.0203 step time: 0.2044\n",
      "3/8, train_loss: 0.0159 step time: 0.1987\n",
      "4/8, train_loss: 0.0191 step time: 0.2010\n",
      "5/8, train_loss: 0.0177 step time: 0.1985\n",
      "6/8, train_loss: 0.0181 step time: 0.2015\n",
      "7/8, train_loss: 0.0157 step time: 0.1816\n",
      "8/8, train_loss: 0.0157 step time: 0.1819\n",
      "epoch 238 average loss: 0.0171\n",
      "time consuming of epoch 238 is: 1.6083\n",
      "----------\n",
      "epoch 239/600\n",
      "1/8, train_loss: 0.0182 step time: 0.2405\n",
      "2/8, train_loss: 0.0167 step time: 0.2028\n",
      "3/8, train_loss: 0.0167 step time: 0.1953\n",
      "4/8, train_loss: 0.0160 step time: 0.2017\n",
      "5/8, train_loss: 0.0174 step time: 0.1997\n",
      "6/8, train_loss: 0.0156 step time: 0.1994\n",
      "7/8, train_loss: 0.0160 step time: 0.1821\n",
      "8/8, train_loss: 0.0171 step time: 0.1815\n",
      "epoch 239 average loss: 0.0167\n",
      "time consuming of epoch 239 is: 1.6047\n",
      "----------\n",
      "epoch 240/600\n",
      "1/8, train_loss: 0.0185 step time: 0.2422\n",
      "2/8, train_loss: 0.0159 step time: 0.2002\n",
      "3/8, train_loss: 0.0166 step time: 0.2023\n",
      "4/8, train_loss: 0.0162 step time: 0.1982\n",
      "5/8, train_loss: 0.0151 step time: 0.2008\n",
      "6/8, train_loss: 0.0180 step time: 0.2062\n",
      "7/8, train_loss: 0.0162 step time: 0.1823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8, train_loss: 0.0178 step time: 0.1819\n",
      "epoch 240 average loss: 0.0168\n",
      "saved new best metric model\n",
      "current epoch: 240 current mean dice: 0.9530 best mean dice: 0.9530 at epoch: 240\n",
      "time consuming of epoch 240 is: 2.5127\n",
      "----------\n",
      "epoch 241/600\n",
      "1/8, train_loss: 0.0166 step time: 0.2478\n",
      "2/8, train_loss: 0.0148 step time: 0.2094\n",
      "3/8, train_loss: 0.0171 step time: 0.1997\n",
      "4/8, train_loss: 0.0158 step time: 0.2029\n",
      "5/8, train_loss: 0.0188 step time: 0.2000\n",
      "6/8, train_loss: 0.0197 step time: 0.2034\n",
      "7/8, train_loss: 0.0189 step time: 0.1824\n",
      "8/8, train_loss: 0.0150 step time: 0.1818\n",
      "epoch 241 average loss: 0.0171\n",
      "time consuming of epoch 241 is: 1.6286\n",
      "----------\n",
      "epoch 242/600\n",
      "1/8, train_loss: 0.0159 step time: 0.2400\n",
      "2/8, train_loss: 0.0175 step time: 0.2051\n",
      "3/8, train_loss: 0.0160 step time: 0.2013\n",
      "4/8, train_loss: 0.0180 step time: 0.2039\n",
      "5/8, train_loss: 0.0169 step time: 0.2062\n",
      "6/8, train_loss: 0.0151 step time: 0.2042\n",
      "7/8, train_loss: 0.0189 step time: 0.1839\n",
      "8/8, train_loss: 0.0164 step time: 0.1823\n",
      "epoch 242 average loss: 0.0168\n",
      "time consuming of epoch 242 is: 1.6285\n",
      "----------\n",
      "epoch 243/600\n",
      "1/8, train_loss: 0.0189 step time: 0.2386\n",
      "2/8, train_loss: 0.0180 step time: 0.1961\n",
      "3/8, train_loss: 0.0160 step time: 0.1962\n",
      "4/8, train_loss: 0.0166 step time: 0.1952\n",
      "5/8, train_loss: 0.0171 step time: 0.1958\n",
      "6/8, train_loss: 0.0149 step time: 0.1980\n",
      "7/8, train_loss: 0.0159 step time: 0.1836\n",
      "8/8, train_loss: 0.0164 step time: 0.1822\n",
      "epoch 243 average loss: 0.0167\n",
      "time consuming of epoch 243 is: 1.5871\n",
      "----------\n",
      "epoch 244/600\n",
      "1/8, train_loss: 0.0144 step time: 0.2400\n",
      "2/8, train_loss: 0.0172 step time: 0.2021\n",
      "3/8, train_loss: 0.0173 step time: 0.2005\n",
      "4/8, train_loss: 0.0194 step time: 0.2038\n",
      "5/8, train_loss: 0.0239 step time: 0.1974\n",
      "6/8, train_loss: 0.0169 step time: 0.1990\n",
      "7/8, train_loss: 0.0149 step time: 0.1826\n",
      "8/8, train_loss: 0.0155 step time: 0.1818\n",
      "epoch 244 average loss: 0.0174\n",
      "time consuming of epoch 244 is: 1.6088\n",
      "----------\n",
      "epoch 245/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2426\n",
      "2/8, train_loss: 0.0164 step time: 0.2066\n",
      "3/8, train_loss: 0.0175 step time: 0.2023\n",
      "4/8, train_loss: 0.0148 step time: 0.1996\n",
      "5/8, train_loss: 0.0165 step time: 0.1973\n",
      "6/8, train_loss: 0.0165 step time: 0.1973\n",
      "7/8, train_loss: 0.0179 step time: 0.1807\n",
      "8/8, train_loss: 0.0153 step time: 0.1812\n",
      "epoch 245 average loss: 0.0161\n",
      "current epoch: 245 current mean dice: 0.9522 best mean dice: 0.9530 at epoch: 240\n",
      "time consuming of epoch 245 is: 2.3622\n",
      "----------\n",
      "epoch 246/600\n",
      "1/8, train_loss: 0.0120 step time: 0.2349\n",
      "2/8, train_loss: 0.0170 step time: 0.1937\n",
      "3/8, train_loss: 0.0140 step time: 0.2002\n",
      "4/8, train_loss: 0.0189 step time: 0.2022\n",
      "5/8, train_loss: 0.0157 step time: 0.1985\n",
      "6/8, train_loss: 0.0192 step time: 0.2047\n",
      "7/8, train_loss: 0.0182 step time: 0.1814\n",
      "8/8, train_loss: 0.0153 step time: 0.1819\n",
      "epoch 246 average loss: 0.0163\n",
      "time consuming of epoch 246 is: 1.5990\n",
      "----------\n",
      "epoch 247/600\n",
      "1/8, train_loss: 0.0166 step time: 0.2410\n",
      "2/8, train_loss: 0.0201 step time: 0.2006\n",
      "3/8, train_loss: 0.0164 step time: 0.1998\n",
      "4/8, train_loss: 0.0182 step time: 0.1986\n",
      "5/8, train_loss: 0.0169 step time: 0.2016\n",
      "6/8, train_loss: 0.0157 step time: 0.1988\n",
      "7/8, train_loss: 0.0186 step time: 0.1812\n",
      "8/8, train_loss: 0.0182 step time: 0.1820\n",
      "epoch 247 average loss: 0.0176\n",
      "time consuming of epoch 247 is: 1.6050\n",
      "----------\n",
      "epoch 248/600\n",
      "1/8, train_loss: 0.0185 step time: 0.2381\n",
      "2/8, train_loss: 0.0154 step time: 0.2031\n",
      "3/8, train_loss: 0.0158 step time: 0.1992\n",
      "4/8, train_loss: 0.0173 step time: 0.2001\n",
      "5/8, train_loss: 0.0146 step time: 0.2014\n",
      "6/8, train_loss: 0.0168 step time: 0.2014\n",
      "7/8, train_loss: 0.0170 step time: 0.1822\n",
      "8/8, train_loss: 0.0186 step time: 0.1836\n",
      "epoch 248 average loss: 0.0167\n",
      "time consuming of epoch 248 is: 1.6107\n",
      "----------\n",
      "epoch 249/600\n",
      "1/8, train_loss: 0.0182 step time: 0.2396\n",
      "2/8, train_loss: 0.0173 step time: 0.2021\n",
      "3/8, train_loss: 0.0146 step time: 0.2002\n",
      "4/8, train_loss: 0.0126 step time: 0.2018\n",
      "5/8, train_loss: 0.0190 step time: 0.2002\n",
      "6/8, train_loss: 0.0184 step time: 0.2016\n",
      "7/8, train_loss: 0.0164 step time: 0.1838\n",
      "8/8, train_loss: 0.0165 step time: 0.1822\n",
      "epoch 249 average loss: 0.0166\n",
      "time consuming of epoch 249 is: 1.6130\n",
      "----------\n",
      "epoch 250/600\n",
      "1/8, train_loss: 0.0184 step time: 0.2405\n",
      "2/8, train_loss: 0.0180 step time: 0.2005\n",
      "3/8, train_loss: 0.0179 step time: 0.2006\n",
      "4/8, train_loss: 0.0140 step time: 0.1989\n",
      "5/8, train_loss: 0.0170 step time: 0.1992\n",
      "6/8, train_loss: 0.0188 step time: 0.1994\n",
      "7/8, train_loss: 0.0200 step time: 0.1823\n",
      "8/8, train_loss: 0.0167 step time: 0.1800\n",
      "epoch 250 average loss: 0.0176\n",
      "current epoch: 250 current mean dice: 0.9511 best mean dice: 0.9530 at epoch: 240\n",
      "time consuming of epoch 250 is: 2.3547\n",
      "----------\n",
      "epoch 251/600\n",
      "1/8, train_loss: 0.0199 step time: 0.2303\n",
      "2/8, train_loss: 0.0197 step time: 0.1907\n",
      "3/8, train_loss: 0.0209 step time: 0.1937\n",
      "4/8, train_loss: 0.0192 step time: 0.1930\n",
      "5/8, train_loss: 0.0169 step time: 0.1920\n",
      "6/8, train_loss: 0.0168 step time: 0.1926\n",
      "7/8, train_loss: 0.0155 step time: 0.1814\n",
      "8/8, train_loss: 0.0180 step time: 0.1808\n",
      "epoch 251 average loss: 0.0184\n",
      "time consuming of epoch 251 is: 1.5556\n",
      "----------\n",
      "epoch 252/600\n",
      "1/8, train_loss: 0.0188 step time: 0.2354\n",
      "2/8, train_loss: 0.0180 step time: 0.1976\n",
      "3/8, train_loss: 0.0168 step time: 0.1964\n",
      "4/8, train_loss: 0.0180 step time: 0.1959\n",
      "5/8, train_loss: 0.0167 step time: 0.1946\n",
      "6/8, train_loss: 0.0175 step time: 0.1996\n",
      "7/8, train_loss: 0.0186 step time: 0.1830\n",
      "8/8, train_loss: 0.0176 step time: 0.1831\n",
      "epoch 252 average loss: 0.0178\n",
      "time consuming of epoch 252 is: 1.5872\n",
      "----------\n",
      "epoch 253/600\n",
      "1/8, train_loss: 0.0128 step time: 0.2399\n",
      "2/8, train_loss: 0.0169 step time: 0.2043\n",
      "3/8, train_loss: 0.0149 step time: 0.2028\n",
      "4/8, train_loss: 0.0189 step time: 0.2004\n",
      "5/8, train_loss: 0.0188 step time: 0.2026\n",
      "6/8, train_loss: 0.0173 step time: 0.2063\n",
      "7/8, train_loss: 0.0195 step time: 0.1826\n",
      "8/8, train_loss: 0.0175 step time: 0.1832\n",
      "epoch 253 average loss: 0.0171\n",
      "time consuming of epoch 253 is: 1.6240\n",
      "----------\n",
      "epoch 254/600\n",
      "1/8, train_loss: 0.0158 step time: 0.2407\n",
      "2/8, train_loss: 0.0156 step time: 0.2044\n",
      "3/8, train_loss: 0.0155 step time: 0.2014\n",
      "4/8, train_loss: 0.0187 step time: 0.1964\n",
      "5/8, train_loss: 0.0180 step time: 0.1970\n",
      "6/8, train_loss: 0.0168 step time: 0.1984\n",
      "7/8, train_loss: 0.0227 step time: 0.1838\n",
      "8/8, train_loss: 0.0189 step time: 0.1822\n",
      "epoch 254 average loss: 0.0178\n",
      "time consuming of epoch 254 is: 1.6058\n",
      "----------\n",
      "epoch 255/600\n",
      "1/8, train_loss: 0.0160 step time: 0.2428\n",
      "2/8, train_loss: 0.0155 step time: 0.2036\n",
      "3/8, train_loss: 0.0158 step time: 0.1995\n",
      "4/8, train_loss: 0.0200 step time: 0.2049\n",
      "5/8, train_loss: 0.0151 step time: 0.2034\n",
      "6/8, train_loss: 0.0161 step time: 0.1996\n",
      "7/8, train_loss: 0.0167 step time: 0.1842\n",
      "8/8, train_loss: 0.0172 step time: 0.1821\n",
      "epoch 255 average loss: 0.0166\n",
      "current epoch: 255 current mean dice: 0.9528 best mean dice: 0.9530 at epoch: 240\n",
      "time consuming of epoch 255 is: 2.3779\n",
      "----------\n",
      "epoch 256/600\n",
      "1/8, train_loss: 0.0202 step time: 0.2370\n",
      "2/8, train_loss: 0.0169 step time: 0.1984\n",
      "3/8, train_loss: 0.0172 step time: 0.2003\n",
      "4/8, train_loss: 0.0114 step time: 0.1976\n",
      "5/8, train_loss: 0.0202 step time: 0.2002\n",
      "6/8, train_loss: 0.0168 step time: 0.1982\n",
      "7/8, train_loss: 0.0170 step time: 0.1813\n",
      "8/8, train_loss: 0.0143 step time: 0.1836\n",
      "epoch 256 average loss: 0.0168\n",
      "time consuming of epoch 256 is: 1.5978\n",
      "----------\n",
      "epoch 257/600\n",
      "1/8, train_loss: 0.0167 step time: 0.2377\n",
      "2/8, train_loss: 0.0171 step time: 0.2040\n",
      "3/8, train_loss: 0.0152 step time: 0.2005\n",
      "4/8, train_loss: 0.0168 step time: 0.1999\n",
      "5/8, train_loss: 0.0161 step time: 0.2014\n",
      "6/8, train_loss: 0.0156 step time: 0.2021\n",
      "7/8, train_loss: 0.0200 step time: 0.1828\n",
      "8/8, train_loss: 0.0192 step time: 0.1825\n",
      "epoch 257 average loss: 0.0171\n",
      "time consuming of epoch 257 is: 1.6122\n",
      "----------\n",
      "epoch 258/600\n",
      "1/8, train_loss: 0.0159 step time: 0.2417\n",
      "2/8, train_loss: 0.0133 step time: 0.2019\n",
      "3/8, train_loss: 0.0168 step time: 0.1992\n",
      "4/8, train_loss: 0.0145 step time: 0.2016\n",
      "5/8, train_loss: 0.0151 step time: 0.1991\n",
      "6/8, train_loss: 0.0158 step time: 0.2009\n",
      "7/8, train_loss: 0.0204 step time: 0.1827\n",
      "8/8, train_loss: 0.0173 step time: 0.1823\n",
      "epoch 258 average loss: 0.0161\n",
      "time consuming of epoch 258 is: 1.6106\n",
      "----------\n",
      "epoch 259/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0198 step time: 0.2423\n",
      "2/8, train_loss: 0.0175 step time: 0.2021\n",
      "3/8, train_loss: 0.0143 step time: 0.2014\n",
      "4/8, train_loss: 0.0171 step time: 0.1995\n",
      "5/8, train_loss: 0.0150 step time: 0.2000\n",
      "6/8, train_loss: 0.0134 step time: 0.2023\n",
      "7/8, train_loss: 0.0193 step time: 0.1845\n",
      "8/8, train_loss: 0.0174 step time: 0.1843\n",
      "epoch 259 average loss: 0.0167\n",
      "time consuming of epoch 259 is: 1.6178\n",
      "----------\n",
      "epoch 260/600\n",
      "1/8, train_loss: 0.0213 step time: 0.2411\n",
      "2/8, train_loss: 0.0170 step time: 0.2038\n",
      "3/8, train_loss: 0.0142 step time: 0.2017\n",
      "4/8, train_loss: 0.0182 step time: 0.2019\n",
      "5/8, train_loss: 0.0141 step time: 0.2091\n",
      "6/8, train_loss: 0.0170 step time: 0.2013\n",
      "7/8, train_loss: 0.0179 step time: 0.1868\n",
      "8/8, train_loss: 0.0167 step time: 0.1905\n",
      "epoch 260 average loss: 0.0171\n",
      "saved new best metric model\n",
      "current epoch: 260 current mean dice: 0.9531 best mean dice: 0.9531 at epoch: 260\n",
      "time consuming of epoch 260 is: 2.5311\n",
      "----------\n",
      "epoch 261/600\n",
      "1/8, train_loss: 0.0198 step time: 0.2337\n",
      "2/8, train_loss: 0.0147 step time: 0.2030\n",
      "3/8, train_loss: 0.0162 step time: 0.1960\n",
      "4/8, train_loss: 0.0191 step time: 0.1972\n",
      "5/8, train_loss: 0.0143 step time: 0.1997\n",
      "6/8, train_loss: 0.0163 step time: 0.2023\n",
      "7/8, train_loss: 0.0154 step time: 0.1827\n",
      "8/8, train_loss: 0.0157 step time: 0.1834\n",
      "epoch 261 average loss: 0.0165\n",
      "time consuming of epoch 261 is: 1.5992\n",
      "----------\n",
      "epoch 262/600\n",
      "1/8, train_loss: 0.0175 step time: 0.2386\n",
      "2/8, train_loss: 0.0153 step time: 0.2005\n",
      "3/8, train_loss: 0.0160 step time: 0.2012\n",
      "4/8, train_loss: 0.0163 step time: 0.2023\n",
      "5/8, train_loss: 0.0164 step time: 0.2043\n",
      "6/8, train_loss: 0.0168 step time: 0.2002\n",
      "7/8, train_loss: 0.0146 step time: 0.1820\n",
      "8/8, train_loss: 0.0191 step time: 0.1818\n",
      "epoch 262 average loss: 0.0165\n",
      "time consuming of epoch 262 is: 1.6124\n",
      "----------\n",
      "epoch 263/600\n",
      "1/8, train_loss: 0.0170 step time: 0.2407\n",
      "2/8, train_loss: 0.0138 step time: 0.2031\n",
      "3/8, train_loss: 0.0169 step time: 0.1982\n",
      "4/8, train_loss: 0.0150 step time: 0.2058\n",
      "5/8, train_loss: 0.0158 step time: 0.2016\n",
      "6/8, train_loss: 0.0186 step time: 0.2004\n",
      "7/8, train_loss: 0.0157 step time: 0.1846\n",
      "8/8, train_loss: 0.0164 step time: 0.1841\n",
      "epoch 263 average loss: 0.0161\n",
      "time consuming of epoch 263 is: 1.6198\n",
      "----------\n",
      "epoch 264/600\n",
      "1/8, train_loss: 0.0218 step time: 0.2402\n",
      "2/8, train_loss: 0.0188 step time: 0.2004\n",
      "3/8, train_loss: 0.0158 step time: 0.2023\n",
      "4/8, train_loss: 0.0163 step time: 0.1996\n",
      "5/8, train_loss: 0.0169 step time: 0.1991\n",
      "6/8, train_loss: 0.0170 step time: 0.1986\n",
      "7/8, train_loss: 0.0174 step time: 0.1833\n",
      "8/8, train_loss: 0.0164 step time: 0.1816\n",
      "epoch 264 average loss: 0.0175\n",
      "time consuming of epoch 264 is: 1.6065\n",
      "----------\n",
      "epoch 265/600\n",
      "1/8, train_loss: 0.0153 step time: 0.2411\n",
      "2/8, train_loss: 0.0207 step time: 0.2004\n",
      "3/8, train_loss: 0.0159 step time: 0.2007\n",
      "4/8, train_loss: 0.0182 step time: 0.1989\n",
      "5/8, train_loss: 0.0163 step time: 0.2035\n",
      "6/8, train_loss: 0.0165 step time: 0.2016\n",
      "7/8, train_loss: 0.0163 step time: 0.1826\n",
      "8/8, train_loss: 0.0150 step time: 0.1813\n",
      "epoch 265 average loss: 0.0168\n",
      "current epoch: 265 current mean dice: 0.9523 best mean dice: 0.9531 at epoch: 260\n",
      "time consuming of epoch 265 is: 2.3670\n",
      "----------\n",
      "epoch 266/600\n",
      "1/8, train_loss: 0.0145 step time: 0.2372\n",
      "2/8, train_loss: 0.0166 step time: 0.1999\n",
      "3/8, train_loss: 0.0153 step time: 0.2000\n",
      "4/8, train_loss: 0.0183 step time: 0.2018\n",
      "5/8, train_loss: 0.0151 step time: 0.1974\n",
      "6/8, train_loss: 0.0165 step time: 0.2030\n",
      "7/8, train_loss: 0.0162 step time: 0.1832\n",
      "8/8, train_loss: 0.0151 step time: 0.1817\n",
      "epoch 266 average loss: 0.0160\n",
      "time consuming of epoch 266 is: 1.6054\n",
      "----------\n",
      "epoch 267/600\n",
      "1/8, train_loss: 0.0188 step time: 0.2407\n",
      "2/8, train_loss: 0.0170 step time: 0.2013\n",
      "3/8, train_loss: 0.0150 step time: 0.1988\n",
      "4/8, train_loss: 0.0135 step time: 0.2024\n",
      "5/8, train_loss: 0.0169 step time: 0.2012\n",
      "6/8, train_loss: 0.0167 step time: 0.1995\n",
      "7/8, train_loss: 0.0165 step time: 0.1825\n",
      "8/8, train_loss: 0.0194 step time: 0.1820\n",
      "epoch 267 average loss: 0.0167\n",
      "time consuming of epoch 267 is: 1.6100\n",
      "----------\n",
      "epoch 268/600\n",
      "1/8, train_loss: 0.0188 step time: 0.2393\n",
      "2/8, train_loss: 0.0158 step time: 0.1969\n",
      "3/8, train_loss: 0.0176 step time: 0.2035\n",
      "4/8, train_loss: 0.0155 step time: 0.2022\n",
      "5/8, train_loss: 0.0153 step time: 0.1984\n",
      "6/8, train_loss: 0.0171 step time: 0.1980\n",
      "7/8, train_loss: 0.0170 step time: 0.1825\n",
      "8/8, train_loss: 0.0160 step time: 0.1823\n",
      "epoch 268 average loss: 0.0166\n",
      "time consuming of epoch 268 is: 1.6046\n",
      "----------\n",
      "epoch 269/600\n",
      "1/8, train_loss: 0.0168 step time: 0.2374\n",
      "2/8, train_loss: 0.0205 step time: 0.2033\n",
      "3/8, train_loss: 0.0123 step time: 0.1985\n",
      "4/8, train_loss: 0.0166 step time: 0.2048\n",
      "5/8, train_loss: 0.0187 step time: 0.1990\n",
      "6/8, train_loss: 0.0146 step time: 0.2059\n",
      "7/8, train_loss: 0.0157 step time: 0.1823\n",
      "8/8, train_loss: 0.0207 step time: 0.1821\n",
      "epoch 269 average loss: 0.0170\n",
      "time consuming of epoch 269 is: 1.6150\n",
      "----------\n",
      "epoch 270/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2363\n",
      "2/8, train_loss: 0.0200 step time: 0.2030\n",
      "3/8, train_loss: 0.0164 step time: 0.2020\n",
      "4/8, train_loss: 0.0158 step time: 0.1986\n",
      "5/8, train_loss: 0.0185 step time: 0.2032\n",
      "6/8, train_loss: 0.0155 step time: 0.1988\n",
      "7/8, train_loss: 0.0188 step time: 0.1836\n",
      "8/8, train_loss: 0.0130 step time: 0.1845\n",
      "epoch 270 average loss: 0.0166\n",
      "saved new best metric model\n",
      "current epoch: 270 current mean dice: 0.9533 best mean dice: 0.9533 at epoch: 270\n",
      "time consuming of epoch 270 is: 2.5072\n",
      "----------\n",
      "epoch 271/600\n",
      "1/8, train_loss: 0.0192 step time: 0.2405\n",
      "2/8, train_loss: 0.0168 step time: 0.1983\n",
      "3/8, train_loss: 0.0162 step time: 0.2010\n",
      "4/8, train_loss: 0.0145 step time: 0.1982\n",
      "5/8, train_loss: 0.0180 step time: 0.2049\n",
      "6/8, train_loss: 0.0157 step time: 0.1970\n",
      "7/8, train_loss: 0.0166 step time: 0.1842\n",
      "8/8, train_loss: 0.0135 step time: 0.1820\n",
      "epoch 271 average loss: 0.0163\n",
      "time consuming of epoch 271 is: 1.6075\n",
      "----------\n",
      "epoch 272/600\n",
      "1/8, train_loss: 0.0171 step time: 0.2399\n",
      "2/8, train_loss: 0.0134 step time: 0.2070\n",
      "3/8, train_loss: 0.0139 step time: 0.2005\n",
      "4/8, train_loss: 0.0205 step time: 0.2041\n",
      "5/8, train_loss: 0.0151 step time: 0.2003\n",
      "6/8, train_loss: 0.0176 step time: 0.1997\n",
      "7/8, train_loss: 0.0162 step time: 0.1827\n",
      "8/8, train_loss: 0.0162 step time: 0.1812\n",
      "epoch 272 average loss: 0.0163\n",
      "time consuming of epoch 272 is: 1.6166\n",
      "----------\n",
      "epoch 273/600\n",
      "1/8, train_loss: 0.0164 step time: 0.2391\n",
      "2/8, train_loss: 0.0162 step time: 0.2026\n",
      "3/8, train_loss: 0.0151 step time: 0.2015\n",
      "4/8, train_loss: 0.0194 step time: 0.1985\n",
      "5/8, train_loss: 0.0149 step time: 0.2006\n",
      "6/8, train_loss: 0.0211 step time: 0.1999\n",
      "7/8, train_loss: 0.0136 step time: 0.1838\n",
      "8/8, train_loss: 0.0174 step time: 0.1826\n",
      "epoch 273 average loss: 0.0168\n",
      "time consuming of epoch 273 is: 1.6098\n",
      "----------\n",
      "epoch 274/600\n",
      "1/8, train_loss: 0.0178 step time: 0.2398\n",
      "2/8, train_loss: 0.0173 step time: 0.2031\n",
      "3/8, train_loss: 0.0144 step time: 0.2018\n",
      "4/8, train_loss: 0.0157 step time: 0.2014\n",
      "5/8, train_loss: 0.0203 step time: 0.2001\n",
      "6/8, train_loss: 0.0140 step time: 0.2011\n",
      "7/8, train_loss: 0.0184 step time: 0.1831\n",
      "8/8, train_loss: 0.0173 step time: 0.1817\n",
      "epoch 274 average loss: 0.0169\n",
      "time consuming of epoch 274 is: 1.6137\n",
      "----------\n",
      "epoch 275/600\n",
      "1/8, train_loss: 0.0142 step time: 0.2395\n",
      "2/8, train_loss: 0.0173 step time: 0.2030\n",
      "3/8, train_loss: 0.0192 step time: 0.2006\n",
      "4/8, train_loss: 0.0163 step time: 0.1991\n",
      "5/8, train_loss: 0.0153 step time: 0.2013\n",
      "6/8, train_loss: 0.0145 step time: 0.1981\n",
      "7/8, train_loss: 0.0196 step time: 0.1823\n",
      "8/8, train_loss: 0.0142 step time: 0.1829\n",
      "epoch 275 average loss: 0.0163\n",
      "current epoch: 275 current mean dice: 0.9527 best mean dice: 0.9533 at epoch: 270\n",
      "time consuming of epoch 275 is: 2.3639\n",
      "----------\n",
      "epoch 276/600\n",
      "1/8, train_loss: 0.0148 step time: 0.2399\n",
      "2/8, train_loss: 0.0203 step time: 0.2002\n",
      "3/8, train_loss: 0.0169 step time: 0.2014\n",
      "4/8, train_loss: 0.0112 step time: 0.1991\n",
      "5/8, train_loss: 0.0183 step time: 0.2012\n",
      "6/8, train_loss: 0.0165 step time: 0.1984\n",
      "7/8, train_loss: 0.0153 step time: 0.1810\n",
      "8/8, train_loss: 0.0212 step time: 0.1814\n",
      "epoch 276 average loss: 0.0168\n",
      "time consuming of epoch 276 is: 1.6037\n",
      "----------\n",
      "epoch 277/600\n",
      "1/8, train_loss: 0.0139 step time: 0.2390\n",
      "2/8, train_loss: 0.0165 step time: 0.1956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8, train_loss: 0.0197 step time: 0.2001\n",
      "4/8, train_loss: 0.0164 step time: 0.2017\n",
      "5/8, train_loss: 0.0156 step time: 0.1990\n",
      "6/8, train_loss: 0.0150 step time: 0.2009\n",
      "7/8, train_loss: 0.0196 step time: 0.1817\n",
      "8/8, train_loss: 0.0134 step time: 0.1818\n",
      "epoch 277 average loss: 0.0163\n",
      "time consuming of epoch 277 is: 1.6008\n",
      "----------\n",
      "epoch 278/600\n",
      "1/8, train_loss: 0.0169 step time: 0.2407\n",
      "2/8, train_loss: 0.0149 step time: 0.2001\n",
      "3/8, train_loss: 0.0167 step time: 0.2030\n",
      "4/8, train_loss: 0.0142 step time: 0.2027\n",
      "5/8, train_loss: 0.0173 step time: 0.1996\n",
      "6/8, train_loss: 0.0161 step time: 0.2028\n",
      "7/8, train_loss: 0.0164 step time: 0.1829\n",
      "8/8, train_loss: 0.0192 step time: 0.1813\n",
      "epoch 278 average loss: 0.0165\n",
      "time consuming of epoch 278 is: 1.6145\n",
      "----------\n",
      "epoch 279/600\n",
      "1/8, train_loss: 0.0124 step time: 0.2379\n",
      "2/8, train_loss: 0.0155 step time: 0.2031\n",
      "3/8, train_loss: 0.0171 step time: 0.2001\n",
      "4/8, train_loss: 0.0152 step time: 0.2018\n",
      "5/8, train_loss: 0.0157 step time: 0.2045\n",
      "6/8, train_loss: 0.0162 step time: 0.2003\n",
      "7/8, train_loss: 0.0173 step time: 0.1842\n",
      "8/8, train_loss: 0.0180 step time: 0.1828\n",
      "epoch 279 average loss: 0.0159\n",
      "time consuming of epoch 279 is: 1.6160\n",
      "----------\n",
      "epoch 280/600\n",
      "1/8, train_loss: 0.0168 step time: 0.2416\n",
      "2/8, train_loss: 0.0183 step time: 0.1982\n",
      "3/8, train_loss: 0.0121 step time: 0.1985\n",
      "4/8, train_loss: 0.0157 step time: 0.2019\n",
      "5/8, train_loss: 0.0163 step time: 0.2003\n",
      "6/8, train_loss: 0.0168 step time: 0.1985\n",
      "7/8, train_loss: 0.0178 step time: 0.1823\n",
      "8/8, train_loss: 0.0174 step time: 0.1842\n",
      "epoch 280 average loss: 0.0164\n",
      "saved new best metric model\n",
      "current epoch: 280 current mean dice: 0.9543 best mean dice: 0.9543 at epoch: 280\n",
      "time consuming of epoch 280 is: 2.5070\n",
      "----------\n",
      "epoch 281/600\n",
      "1/8, train_loss: 0.0199 step time: 0.2395\n",
      "2/8, train_loss: 0.0165 step time: 0.1996\n",
      "3/8, train_loss: 0.0154 step time: 0.1991\n",
      "4/8, train_loss: 0.0201 step time: 0.2029\n",
      "5/8, train_loss: 0.0172 step time: 0.2012\n",
      "6/8, train_loss: 0.0168 step time: 0.1990\n",
      "7/8, train_loss: 0.0163 step time: 0.1849\n",
      "8/8, train_loss: 0.0132 step time: 0.1815\n",
      "epoch 281 average loss: 0.0169\n",
      "time consuming of epoch 281 is: 1.6089\n",
      "----------\n",
      "epoch 282/600\n",
      "1/8, train_loss: 0.0147 step time: 0.2406\n",
      "2/8, train_loss: 0.0157 step time: 0.2050\n",
      "3/8, train_loss: 0.0159 step time: 0.1993\n",
      "4/8, train_loss: 0.0123 step time: 0.2029\n",
      "5/8, train_loss: 0.0187 step time: 0.2011\n",
      "6/8, train_loss: 0.0136 step time: 0.2010\n",
      "7/8, train_loss: 0.0158 step time: 0.1843\n",
      "8/8, train_loss: 0.0174 step time: 0.1821\n",
      "epoch 282 average loss: 0.0155\n",
      "time consuming of epoch 282 is: 1.6178\n",
      "----------\n",
      "epoch 283/600\n",
      "1/8, train_loss: 0.0139 step time: 0.2410\n",
      "2/8, train_loss: 0.0140 step time: 0.2014\n",
      "3/8, train_loss: 0.0151 step time: 0.2031\n",
      "4/8, train_loss: 0.0163 step time: 0.1996\n",
      "5/8, train_loss: 0.0203 step time: 0.2008\n",
      "6/8, train_loss: 0.0169 step time: 0.2005\n",
      "7/8, train_loss: 0.0164 step time: 0.1837\n",
      "8/8, train_loss: 0.0196 step time: 0.1829\n",
      "epoch 283 average loss: 0.0165\n",
      "time consuming of epoch 283 is: 1.6145\n",
      "----------\n",
      "epoch 284/600\n",
      "1/8, train_loss: 0.0147 step time: 0.2436\n",
      "2/8, train_loss: 0.0151 step time: 0.2038\n",
      "3/8, train_loss: 0.0141 step time: 0.2013\n",
      "4/8, train_loss: 0.0172 step time: 0.2045\n",
      "5/8, train_loss: 0.0199 step time: 0.1996\n",
      "6/8, train_loss: 0.0178 step time: 0.2062\n",
      "7/8, train_loss: 0.0175 step time: 0.1837\n",
      "8/8, train_loss: 0.0153 step time: 0.1845\n",
      "epoch 284 average loss: 0.0165\n",
      "time consuming of epoch 284 is: 1.6289\n",
      "----------\n",
      "epoch 285/600\n",
      "1/8, train_loss: 0.0159 step time: 0.2390\n",
      "2/8, train_loss: 0.0200 step time: 0.1982\n",
      "3/8, train_loss: 0.0181 step time: 0.1984\n",
      "4/8, train_loss: 0.0153 step time: 0.1966\n",
      "5/8, train_loss: 0.0155 step time: 0.1987\n",
      "6/8, train_loss: 0.0164 step time: 0.1966\n",
      "7/8, train_loss: 0.0153 step time: 0.1836\n",
      "8/8, train_loss: 0.0176 step time: 0.1847\n",
      "epoch 285 average loss: 0.0168\n",
      "current epoch: 285 current mean dice: 0.9512 best mean dice: 0.9543 at epoch: 280\n",
      "time consuming of epoch 285 is: 2.3539\n",
      "----------\n",
      "epoch 286/600\n",
      "1/8, train_loss: 0.0183 step time: 0.2383\n",
      "2/8, train_loss: 0.0151 step time: 0.2005\n",
      "3/8, train_loss: 0.0149 step time: 0.2014\n",
      "4/8, train_loss: 0.0150 step time: 0.1950\n",
      "5/8, train_loss: 0.0178 step time: 0.1943\n",
      "6/8, train_loss: 0.0153 step time: 0.1950\n",
      "7/8, train_loss: 0.0184 step time: 0.1826\n",
      "8/8, train_loss: 0.0131 step time: 0.1825\n",
      "epoch 286 average loss: 0.0160\n",
      "time consuming of epoch 286 is: 1.5906\n",
      "----------\n",
      "epoch 287/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2418\n",
      "2/8, train_loss: 0.0175 step time: 0.1981\n",
      "3/8, train_loss: 0.0171 step time: 0.1996\n",
      "4/8, train_loss: 0.0166 step time: 0.1943\n",
      "5/8, train_loss: 0.0178 step time: 0.1975\n",
      "6/8, train_loss: 0.0163 step time: 0.1980\n",
      "7/8, train_loss: 0.0147 step time: 0.1790\n",
      "8/8, train_loss: 0.0170 step time: 0.1791\n",
      "epoch 287 average loss: 0.0162\n",
      "time consuming of epoch 287 is: 1.5888\n",
      "----------\n",
      "epoch 288/600\n",
      "1/8, train_loss: 0.0146 step time: 0.2384\n",
      "2/8, train_loss: 0.0166 step time: 0.1933\n",
      "3/8, train_loss: 0.0174 step time: 0.1972\n",
      "4/8, train_loss: 0.0168 step time: 0.1973\n",
      "5/8, train_loss: 0.0175 step time: 0.1959\n",
      "6/8, train_loss: 0.0140 step time: 0.1966\n",
      "7/8, train_loss: 0.0121 step time: 0.1814\n",
      "8/8, train_loss: 0.0169 step time: 0.1791\n",
      "epoch 288 average loss: 0.0157\n",
      "time consuming of epoch 288 is: 1.5802\n",
      "----------\n",
      "epoch 289/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2342\n",
      "2/8, train_loss: 0.0173 step time: 0.1940\n",
      "3/8, train_loss: 0.0158 step time: 0.1989\n",
      "4/8, train_loss: 0.0163 step time: 0.2079\n",
      "5/8, train_loss: 0.0141 step time: 0.2092\n",
      "6/8, train_loss: 0.0145 step time: 0.2052\n",
      "7/8, train_loss: 0.0160 step time: 0.1837\n",
      "8/8, train_loss: 0.0214 step time: 0.1832\n",
      "epoch 289 average loss: 0.0163\n",
      "time consuming of epoch 289 is: 1.6175\n",
      "----------\n",
      "epoch 290/600\n",
      "1/8, train_loss: 0.0169 step time: 0.2399\n",
      "2/8, train_loss: 0.0153 step time: 0.2000\n",
      "3/8, train_loss: 0.0140 step time: 0.2018\n",
      "4/8, train_loss: 0.0171 step time: 0.2012\n",
      "5/8, train_loss: 0.0144 step time: 0.2051\n",
      "6/8, train_loss: 0.0147 step time: 0.2020\n",
      "7/8, train_loss: 0.0141 step time: 0.1825\n",
      "8/8, train_loss: 0.0185 step time: 0.1819\n",
      "epoch 290 average loss: 0.0156\n",
      "current epoch: 290 current mean dice: 0.9535 best mean dice: 0.9543 at epoch: 280\n",
      "time consuming of epoch 290 is: 2.3731\n",
      "----------\n",
      "epoch 291/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2346\n",
      "2/8, train_loss: 0.0199 step time: 0.1968\n",
      "3/8, train_loss: 0.0179 step time: 0.2006\n",
      "4/8, train_loss: 0.0151 step time: 0.2005\n",
      "5/8, train_loss: 0.0184 step time: 0.1995\n",
      "6/8, train_loss: 0.0121 step time: 0.2005\n",
      "7/8, train_loss: 0.0158 step time: 0.1814\n",
      "8/8, train_loss: 0.0181 step time: 0.1807\n",
      "epoch 291 average loss: 0.0166\n",
      "time consuming of epoch 291 is: 1.5956\n",
      "----------\n",
      "epoch 292/600\n",
      "1/8, train_loss: 0.0162 step time: 0.2385\n",
      "2/8, train_loss: 0.0154 step time: 0.2034\n",
      "3/8, train_loss: 0.0129 step time: 0.1994\n",
      "4/8, train_loss: 0.0183 step time: 0.2000\n",
      "5/8, train_loss: 0.0182 step time: 0.2001\n",
      "6/8, train_loss: 0.0169 step time: 0.2011\n",
      "7/8, train_loss: 0.0144 step time: 0.1821\n",
      "8/8, train_loss: 0.0173 step time: 0.1818\n",
      "epoch 292 average loss: 0.0162\n",
      "time consuming of epoch 292 is: 1.6079\n",
      "----------\n",
      "epoch 293/600\n",
      "1/8, train_loss: 0.0163 step time: 0.2398\n",
      "2/8, train_loss: 0.0118 step time: 0.2016\n",
      "3/8, train_loss: 0.0156 step time: 0.1995\n",
      "4/8, train_loss: 0.0151 step time: 0.2033\n",
      "5/8, train_loss: 0.0155 step time: 0.2002\n",
      "6/8, train_loss: 0.0151 step time: 0.2024\n",
      "7/8, train_loss: 0.0194 step time: 0.1844\n",
      "8/8, train_loss: 0.0177 step time: 0.1813\n",
      "epoch 293 average loss: 0.0158\n",
      "time consuming of epoch 293 is: 1.6137\n",
      "----------\n",
      "epoch 294/600\n",
      "1/8, train_loss: 0.0143 step time: 0.2380\n",
      "2/8, train_loss: 0.0162 step time: 0.1998\n",
      "3/8, train_loss: 0.0207 step time: 0.2001\n",
      "4/8, train_loss: 0.0154 step time: 0.2041\n",
      "5/8, train_loss: 0.0148 step time: 0.2019\n",
      "6/8, train_loss: 0.0152 step time: 0.2025\n",
      "7/8, train_loss: 0.0175 step time: 0.1835\n",
      "8/8, train_loss: 0.0161 step time: 0.1816\n",
      "epoch 294 average loss: 0.0163\n",
      "time consuming of epoch 294 is: 1.6129\n",
      "----------\n",
      "epoch 295/600\n",
      "1/8, train_loss: 0.0192 step time: 0.2391\n",
      "2/8, train_loss: 0.0125 step time: 0.2134\n",
      "3/8, train_loss: 0.0142 step time: 0.1955\n",
      "4/8, train_loss: 0.0148 step time: 0.2063\n",
      "5/8, train_loss: 0.0151 step time: 0.2095\n",
      "6/8, train_loss: 0.0176 step time: 0.1974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/8, train_loss: 0.0176 step time: 0.1814\n",
      "8/8, train_loss: 0.0152 step time: 0.1810\n",
      "epoch 295 average loss: 0.0158\n",
      "current epoch: 295 current mean dice: 0.9537 best mean dice: 0.9543 at epoch: 280\n",
      "time consuming of epoch 295 is: 2.3779\n",
      "----------\n",
      "epoch 296/600\n",
      "1/8, train_loss: 0.0145 step time: 0.2389\n",
      "2/8, train_loss: 0.0188 step time: 0.1973\n",
      "3/8, train_loss: 0.0148 step time: 0.2004\n",
      "4/8, train_loss: 0.0142 step time: 0.1999\n",
      "5/8, train_loss: 0.0178 step time: 0.1994\n",
      "6/8, train_loss: 0.0197 step time: 0.2018\n",
      "7/8, train_loss: 0.0165 step time: 0.1811\n",
      "8/8, train_loss: 0.0176 step time: 0.1811\n",
      "epoch 296 average loss: 0.0167\n",
      "time consuming of epoch 296 is: 1.6010\n",
      "----------\n",
      "epoch 297/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2402\n",
      "2/8, train_loss: 0.0175 step time: 0.1995\n",
      "3/8, train_loss: 0.0151 step time: 0.2013\n",
      "4/8, train_loss: 0.0182 step time: 0.2012\n",
      "5/8, train_loss: 0.0154 step time: 0.2028\n",
      "6/8, train_loss: 0.0137 step time: 0.1980\n",
      "7/8, train_loss: 0.0158 step time: 0.1834\n",
      "8/8, train_loss: 0.0170 step time: 0.1808\n",
      "epoch 297 average loss: 0.0158\n",
      "time consuming of epoch 297 is: 1.6086\n",
      "----------\n",
      "epoch 298/600\n",
      "1/8, train_loss: 0.0128 step time: 0.2383\n",
      "2/8, train_loss: 0.0177 step time: 0.2093\n",
      "3/8, train_loss: 0.0172 step time: 0.2037\n",
      "4/8, train_loss: 0.0132 step time: 0.1995\n",
      "5/8, train_loss: 0.0170 step time: 0.1999\n",
      "6/8, train_loss: 0.0155 step time: 0.1999\n",
      "7/8, train_loss: 0.0164 step time: 0.1818\n",
      "8/8, train_loss: 0.0166 step time: 0.1846\n",
      "epoch 298 average loss: 0.0158\n",
      "time consuming of epoch 298 is: 1.6185\n",
      "----------\n",
      "epoch 299/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2408\n",
      "2/8, train_loss: 0.0160 step time: 0.2077\n",
      "3/8, train_loss: 0.0175 step time: 0.2033\n",
      "4/8, train_loss: 0.0110 step time: 0.2059\n",
      "5/8, train_loss: 0.0166 step time: 0.2078\n",
      "6/8, train_loss: 0.0163 step time: 0.2027\n",
      "7/8, train_loss: 0.0170 step time: 0.1825\n",
      "8/8, train_loss: 0.0155 step time: 0.1817\n",
      "epoch 299 average loss: 0.0156\n",
      "time consuming of epoch 299 is: 1.6342\n",
      "----------\n",
      "epoch 300/600\n",
      "1/8, train_loss: 0.0178 step time: 0.2421\n",
      "2/8, train_loss: 0.0156 step time: 0.2023\n",
      "3/8, train_loss: 0.0147 step time: 0.1998\n",
      "4/8, train_loss: 0.0148 step time: 0.2007\n",
      "5/8, train_loss: 0.0146 step time: 0.2005\n",
      "6/8, train_loss: 0.0141 step time: 0.2026\n",
      "7/8, train_loss: 0.0158 step time: 0.1828\n",
      "8/8, train_loss: 0.0169 step time: 0.1831\n",
      "epoch 300 average loss: 0.0155\n",
      "current epoch: 300 current mean dice: 0.9542 best mean dice: 0.9543 at epoch: 280\n",
      "time consuming of epoch 300 is: 2.3721\n",
      "----------\n",
      "epoch 301/600\n",
      "1/8, train_loss: 0.0183 step time: 0.2368\n",
      "2/8, train_loss: 0.0170 step time: 0.1996\n",
      "3/8, train_loss: 0.0145 step time: 0.1988\n",
      "4/8, train_loss: 0.0156 step time: 0.1991\n",
      "5/8, train_loss: 0.0143 step time: 0.1986\n",
      "6/8, train_loss: 0.0174 step time: 0.1984\n",
      "7/8, train_loss: 0.0141 step time: 0.1811\n",
      "8/8, train_loss: 0.0155 step time: 0.1809\n",
      "epoch 301 average loss: 0.0159\n",
      "time consuming of epoch 301 is: 1.5944\n",
      "----------\n",
      "epoch 302/600\n",
      "1/8, train_loss: 0.0150 step time: 0.2388\n",
      "2/8, train_loss: 0.0150 step time: 0.2033\n",
      "3/8, train_loss: 0.0184 step time: 0.1989\n",
      "4/8, train_loss: 0.0162 step time: 0.1997\n",
      "5/8, train_loss: 0.0164 step time: 0.1994\n",
      "6/8, train_loss: 0.0164 step time: 0.2011\n",
      "7/8, train_loss: 0.0185 step time: 0.1836\n",
      "8/8, train_loss: 0.0169 step time: 0.1824\n",
      "epoch 302 average loss: 0.0166\n",
      "time consuming of epoch 302 is: 1.6084\n",
      "----------\n",
      "epoch 303/600\n",
      "1/8, train_loss: 0.0165 step time: 0.2378\n",
      "2/8, train_loss: 0.0177 step time: 0.2014\n",
      "3/8, train_loss: 0.0158 step time: 0.2065\n",
      "4/8, train_loss: 0.0159 step time: 0.2037\n",
      "5/8, train_loss: 0.0197 step time: 0.2001\n",
      "6/8, train_loss: 0.0143 step time: 0.2017\n",
      "7/8, train_loss: 0.0216 step time: 0.1830\n",
      "8/8, train_loss: 0.0167 step time: 0.1834\n",
      "epoch 303 average loss: 0.0173\n",
      "time consuming of epoch 303 is: 1.6193\n",
      "----------\n",
      "epoch 304/600\n",
      "1/8, train_loss: 0.0199 step time: 0.2416\n",
      "2/8, train_loss: 0.0151 step time: 0.2000\n",
      "3/8, train_loss: 0.0171 step time: 0.2021\n",
      "4/8, train_loss: 0.0170 step time: 0.2005\n",
      "5/8, train_loss: 0.0149 step time: 0.2022\n",
      "6/8, train_loss: 0.0171 step time: 0.2019\n",
      "7/8, train_loss: 0.0177 step time: 0.1807\n",
      "8/8, train_loss: 0.0133 step time: 0.1829\n",
      "epoch 304 average loss: 0.0165\n",
      "time consuming of epoch 304 is: 1.6131\n",
      "----------\n",
      "epoch 305/600\n",
      "1/8, train_loss: 0.0164 step time: 0.2413\n",
      "2/8, train_loss: 0.0167 step time: 0.2014\n",
      "3/8, train_loss: 0.0176 step time: 0.2003\n",
      "4/8, train_loss: 0.0179 step time: 0.1998\n",
      "5/8, train_loss: 0.0155 step time: 0.2026\n",
      "6/8, train_loss: 0.0169 step time: 0.2001\n",
      "7/8, train_loss: 0.0154 step time: 0.1825\n",
      "8/8, train_loss: 0.0168 step time: 0.1817\n",
      "epoch 305 average loss: 0.0167\n",
      "current epoch: 305 current mean dice: 0.9536 best mean dice: 0.9543 at epoch: 280\n",
      "time consuming of epoch 305 is: 2.3662\n",
      "----------\n",
      "epoch 306/600\n",
      "1/8, train_loss: 0.0161 step time: 0.2390\n",
      "2/8, train_loss: 0.0177 step time: 0.1989\n",
      "3/8, train_loss: 0.0213 step time: 0.2026\n",
      "4/8, train_loss: 0.0148 step time: 0.1934\n",
      "5/8, train_loss: 0.0157 step time: 0.1989\n",
      "6/8, train_loss: 0.0158 step time: 0.2017\n",
      "7/8, train_loss: 0.0181 step time: 0.1838\n",
      "8/8, train_loss: 0.0153 step time: 0.1814\n",
      "epoch 306 average loss: 0.0169\n",
      "time consuming of epoch 306 is: 1.6009\n",
      "----------\n",
      "epoch 307/600\n",
      "1/8, train_loss: 0.0184 step time: 0.2411\n",
      "2/8, train_loss: 0.0143 step time: 0.2026\n",
      "3/8, train_loss: 0.0145 step time: 0.1987\n",
      "4/8, train_loss: 0.0144 step time: 0.2025\n",
      "5/8, train_loss: 0.0143 step time: 0.1988\n",
      "6/8, train_loss: 0.0195 step time: 0.2017\n",
      "7/8, train_loss: 0.0190 step time: 0.1833\n",
      "8/8, train_loss: 0.0185 step time: 0.1827\n",
      "epoch 307 average loss: 0.0166\n",
      "time consuming of epoch 307 is: 1.6130\n",
      "----------\n",
      "epoch 308/600\n",
      "1/8, train_loss: 0.0157 step time: 0.2391\n",
      "2/8, train_loss: 0.0189 step time: 0.2002\n",
      "3/8, train_loss: 0.0167 step time: 0.2009\n",
      "4/8, train_loss: 0.0160 step time: 0.2055\n",
      "5/8, train_loss: 0.0150 step time: 0.1991\n",
      "6/8, train_loss: 0.0149 step time: 0.2039\n",
      "7/8, train_loss: 0.0153 step time: 0.1821\n",
      "8/8, train_loss: 0.0150 step time: 0.1821\n",
      "epoch 308 average loss: 0.0160\n",
      "time consuming of epoch 308 is: 1.6144\n",
      "----------\n",
      "epoch 309/600\n",
      "1/8, train_loss: 0.0157 step time: 0.2356\n",
      "2/8, train_loss: 0.0150 step time: 0.1970\n",
      "3/8, train_loss: 0.0125 step time: 0.1986\n",
      "4/8, train_loss: 0.0147 step time: 0.1984\n",
      "5/8, train_loss: 0.0170 step time: 0.2001\n",
      "6/8, train_loss: 0.0161 step time: 0.1989\n",
      "7/8, train_loss: 0.0213 step time: 0.1813\n",
      "8/8, train_loss: 0.0152 step time: 0.1844\n",
      "epoch 309 average loss: 0.0159\n",
      "time consuming of epoch 309 is: 1.5955\n",
      "----------\n",
      "epoch 310/600\n",
      "1/8, train_loss: 0.0172 step time: 0.2430\n",
      "2/8, train_loss: 0.0170 step time: 0.2046\n",
      "3/8, train_loss: 0.0164 step time: 0.2034\n",
      "4/8, train_loss: 0.0174 step time: 0.2035\n",
      "5/8, train_loss: 0.0169 step time: 0.1977\n",
      "6/8, train_loss: 0.0176 step time: 0.2024\n",
      "7/8, train_loss: 0.0134 step time: 0.1825\n",
      "8/8, train_loss: 0.0149 step time: 0.1826\n",
      "epoch 310 average loss: 0.0164\n",
      "current epoch: 310 current mean dice: 0.9531 best mean dice: 0.9543 at epoch: 280\n",
      "time consuming of epoch 310 is: 2.3764\n",
      "----------\n",
      "epoch 311/600\n",
      "1/8, train_loss: 0.0168 step time: 0.2378\n",
      "2/8, train_loss: 0.0172 step time: 0.1972\n",
      "3/8, train_loss: 0.0159 step time: 0.1985\n",
      "4/8, train_loss: 0.0161 step time: 0.1987\n",
      "5/8, train_loss: 0.0172 step time: 0.1983\n",
      "6/8, train_loss: 0.0156 step time: 0.1988\n",
      "7/8, train_loss: 0.0141 step time: 0.1813\n",
      "8/8, train_loss: 0.0141 step time: 0.1813\n",
      "epoch 311 average loss: 0.0159\n",
      "time consuming of epoch 311 is: 1.5934\n",
      "----------\n",
      "epoch 312/600\n",
      "1/8, train_loss: 0.0165 step time: 0.2377\n",
      "2/8, train_loss: 0.0154 step time: 0.1993\n",
      "3/8, train_loss: 0.0148 step time: 0.1992\n",
      "4/8, train_loss: 0.0187 step time: 0.1992\n",
      "5/8, train_loss: 0.0159 step time: 0.1985\n",
      "6/8, train_loss: 0.0129 step time: 0.2012\n",
      "7/8, train_loss: 0.0189 step time: 0.1832\n",
      "8/8, train_loss: 0.0192 step time: 0.1821\n",
      "epoch 312 average loss: 0.0166\n",
      "time consuming of epoch 312 is: 1.6018\n",
      "----------\n",
      "epoch 313/600\n",
      "1/8, train_loss: 0.0173 step time: 0.2374\n",
      "2/8, train_loss: 0.0156 step time: 0.1985\n",
      "3/8, train_loss: 0.0181 step time: 0.1997\n",
      "4/8, train_loss: 0.0154 step time: 0.2011\n",
      "5/8, train_loss: 0.0157 step time: 0.2017\n",
      "6/8, train_loss: 0.0175 step time: 0.1997\n",
      "7/8, train_loss: 0.0165 step time: 0.1839\n",
      "8/8, train_loss: 0.0166 step time: 0.1820\n",
      "epoch 313 average loss: 0.0166\n",
      "time consuming of epoch 313 is: 1.6057\n",
      "----------\n",
      "epoch 314/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0183 step time: 0.2387\n",
      "2/8, train_loss: 0.0169 step time: 0.2020\n",
      "3/8, train_loss: 0.0145 step time: 0.2014\n",
      "4/8, train_loss: 0.0147 step time: 0.1980\n",
      "5/8, train_loss: 0.0182 step time: 0.1996\n",
      "6/8, train_loss: 0.0156 step time: 0.1999\n",
      "7/8, train_loss: 0.0156 step time: 0.1845\n",
      "8/8, train_loss: 0.0167 step time: 0.1942\n",
      "epoch 314 average loss: 0.0163\n",
      "time consuming of epoch 314 is: 1.6198\n",
      "----------\n",
      "epoch 315/600\n",
      "1/8, train_loss: 0.0172 step time: 0.2588\n",
      "2/8, train_loss: 0.0156 step time: 0.2493\n",
      "3/8, train_loss: 0.0166 step time: 0.1945\n",
      "4/8, train_loss: 0.0175 step time: 0.1966\n",
      "5/8, train_loss: 0.0195 step time: 0.1943\n",
      "6/8, train_loss: 0.0198 step time: 0.1952\n",
      "7/8, train_loss: 0.0142 step time: 0.1826\n",
      "8/8, train_loss: 0.0147 step time: 0.1821\n",
      "epoch 315 average loss: 0.0169\n",
      "current epoch: 315 current mean dice: 0.9516 best mean dice: 0.9543 at epoch: 280\n",
      "time consuming of epoch 315 is: 2.4116\n",
      "----------\n",
      "epoch 316/600\n",
      "1/8, train_loss: 0.0148 step time: 0.2450\n",
      "2/8, train_loss: 0.0168 step time: 0.2068\n",
      "3/8, train_loss: 0.0162 step time: 0.2041\n",
      "4/8, train_loss: 0.0153 step time: 0.2024\n",
      "5/8, train_loss: 0.0136 step time: 0.1987\n",
      "6/8, train_loss: 0.0182 step time: 0.2034\n",
      "7/8, train_loss: 0.0175 step time: 0.1837\n",
      "8/8, train_loss: 0.0189 step time: 0.1815\n",
      "epoch 316 average loss: 0.0164\n",
      "time consuming of epoch 316 is: 1.6268\n",
      "----------\n",
      "epoch 317/600\n",
      "1/8, train_loss: 0.0140 step time: 0.2434\n",
      "2/8, train_loss: 0.0158 step time: 0.2005\n",
      "3/8, train_loss: 0.0187 step time: 0.1999\n",
      "4/8, train_loss: 0.0157 step time: 0.1975\n",
      "5/8, train_loss: 0.0155 step time: 0.2007\n",
      "6/8, train_loss: 0.0177 step time: 0.1986\n",
      "7/8, train_loss: 0.0166 step time: 0.1839\n",
      "8/8, train_loss: 0.0160 step time: 0.1818\n",
      "epoch 317 average loss: 0.0162\n",
      "time consuming of epoch 317 is: 1.6077\n",
      "----------\n",
      "epoch 318/600\n",
      "1/8, train_loss: 0.0157 step time: 0.2369\n",
      "2/8, train_loss: 0.0199 step time: 0.1976\n",
      "3/8, train_loss: 0.0156 step time: 0.1954\n",
      "4/8, train_loss: 0.0167 step time: 0.1947\n",
      "5/8, train_loss: 0.0186 step time: 0.1955\n",
      "6/8, train_loss: 0.0170 step time: 0.1963\n",
      "7/8, train_loss: 0.0122 step time: 0.1820\n",
      "8/8, train_loss: 0.0113 step time: 0.1834\n",
      "epoch 318 average loss: 0.0159\n",
      "time consuming of epoch 318 is: 1.5832\n",
      "----------\n",
      "epoch 319/600\n",
      "1/8, train_loss: 0.0166 step time: 0.2328\n",
      "2/8, train_loss: 0.0151 step time: 0.2036\n",
      "3/8, train_loss: 0.0177 step time: 0.1998\n",
      "4/8, train_loss: 0.0164 step time: 0.2005\n",
      "5/8, train_loss: 0.0149 step time: 0.2001\n",
      "6/8, train_loss: 0.0134 step time: 0.2038\n",
      "7/8, train_loss: 0.0149 step time: 0.1840\n",
      "8/8, train_loss: 0.0171 step time: 0.1818\n",
      "epoch 319 average loss: 0.0158\n",
      "time consuming of epoch 319 is: 1.6084\n",
      "----------\n",
      "epoch 320/600\n",
      "1/8, train_loss: 0.0136 step time: 0.2419\n",
      "2/8, train_loss: 0.0156 step time: 0.2006\n",
      "3/8, train_loss: 0.0165 step time: 0.2102\n",
      "4/8, train_loss: 0.0192 step time: 0.2104\n",
      "5/8, train_loss: 0.0182 step time: 0.2106\n",
      "6/8, train_loss: 0.0135 step time: 0.2172\n",
      "7/8, train_loss: 0.0132 step time: 0.1856\n",
      "8/8, train_loss: 0.0149 step time: 0.1843\n",
      "epoch 320 average loss: 0.0156\n",
      "saved new best metric model\n",
      "current epoch: 320 current mean dice: 0.9555 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 320 is: 2.6076\n",
      "----------\n",
      "epoch 321/600\n",
      "1/8, train_loss: 0.0120 step time: 0.2672\n",
      "2/8, train_loss: 0.0176 step time: 0.2191\n",
      "3/8, train_loss: 0.0158 step time: 0.2196\n",
      "4/8, train_loss: 0.0176 step time: 0.2085\n",
      "5/8, train_loss: 0.0156 step time: 0.2165\n",
      "6/8, train_loss: 0.0153 step time: 0.2196\n",
      "7/8, train_loss: 0.0146 step time: 0.1882\n",
      "8/8, train_loss: 0.0158 step time: 0.1839\n",
      "epoch 321 average loss: 0.0155\n",
      "time consuming of epoch 321 is: 1.7242\n",
      "----------\n",
      "epoch 322/600\n",
      "1/8, train_loss: 0.0150 step time: 0.2648\n",
      "2/8, train_loss: 0.0180 step time: 0.2228\n",
      "3/8, train_loss: 0.0138 step time: 0.2161\n",
      "4/8, train_loss: 0.0159 step time: 0.2235\n",
      "5/8, train_loss: 0.0154 step time: 0.2121\n",
      "6/8, train_loss: 0.0177 step time: 0.2270\n",
      "7/8, train_loss: 0.0137 step time: 0.1849\n",
      "8/8, train_loss: 0.0162 step time: 0.1832\n",
      "epoch 322 average loss: 0.0157\n",
      "time consuming of epoch 322 is: 1.7361\n",
      "----------\n",
      "epoch 323/600\n",
      "1/8, train_loss: 0.0163 step time: 0.2426\n",
      "2/8, train_loss: 0.0149 step time: 0.2027\n",
      "3/8, train_loss: 0.0166 step time: 0.2069\n",
      "4/8, train_loss: 0.0175 step time: 0.2027\n",
      "5/8, train_loss: 0.0180 step time: 0.2026\n",
      "6/8, train_loss: 0.0146 step time: 0.2023\n",
      "7/8, train_loss: 0.0155 step time: 0.1814\n",
      "8/8, train_loss: 0.0145 step time: 0.1830\n",
      "epoch 323 average loss: 0.0160\n",
      "time consuming of epoch 323 is: 1.6258\n",
      "----------\n",
      "epoch 324/600\n",
      "1/8, train_loss: 0.0189 step time: 0.2381\n",
      "2/8, train_loss: 0.0163 step time: 0.2011\n",
      "3/8, train_loss: 0.0150 step time: 0.1995\n",
      "4/8, train_loss: 0.0133 step time: 0.1977\n",
      "5/8, train_loss: 0.0163 step time: 0.1999\n",
      "6/8, train_loss: 0.0154 step time: 0.2010\n",
      "7/8, train_loss: 0.0151 step time: 0.1819\n",
      "8/8, train_loss: 0.0156 step time: 0.1819\n",
      "epoch 324 average loss: 0.0157\n",
      "time consuming of epoch 324 is: 1.6025\n",
      "----------\n",
      "epoch 325/600\n",
      "1/8, train_loss: 0.0161 step time: 0.2430\n",
      "2/8, train_loss: 0.0167 step time: 0.2054\n",
      "3/8, train_loss: 0.0147 step time: 0.2031\n",
      "4/8, train_loss: 0.0200 step time: 0.2005\n",
      "5/8, train_loss: 0.0129 step time: 0.2012\n",
      "6/8, train_loss: 0.0135 step time: 0.2005\n",
      "7/8, train_loss: 0.0160 step time: 0.1834\n",
      "8/8, train_loss: 0.0167 step time: 0.1840\n",
      "epoch 325 average loss: 0.0158\n",
      "current epoch: 325 current mean dice: 0.9547 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 325 is: 2.3790\n",
      "----------\n",
      "epoch 326/600\n",
      "1/8, train_loss: 0.0143 step time: 0.2374\n",
      "2/8, train_loss: 0.0163 step time: 0.2054\n",
      "3/8, train_loss: 0.0162 step time: 0.2001\n",
      "4/8, train_loss: 0.0152 step time: 0.2025\n",
      "5/8, train_loss: 0.0159 step time: 0.1997\n",
      "6/8, train_loss: 0.0192 step time: 0.2012\n",
      "7/8, train_loss: 0.0185 step time: 0.1838\n",
      "8/8, train_loss: 0.0155 step time: 0.1818\n",
      "epoch 326 average loss: 0.0164\n",
      "time consuming of epoch 326 is: 1.6131\n",
      "----------\n",
      "epoch 327/600\n",
      "1/8, train_loss: 0.0130 step time: 0.2390\n",
      "2/8, train_loss: 0.0144 step time: 0.2058\n",
      "3/8, train_loss: 0.0155 step time: 0.2043\n",
      "4/8, train_loss: 0.0178 step time: 0.2004\n",
      "5/8, train_loss: 0.0150 step time: 0.2019\n",
      "6/8, train_loss: 0.0178 step time: 0.2023\n",
      "7/8, train_loss: 0.0182 step time: 0.1830\n",
      "8/8, train_loss: 0.0181 step time: 0.1821\n",
      "epoch 327 average loss: 0.0162\n",
      "time consuming of epoch 327 is: 1.6204\n",
      "----------\n",
      "epoch 328/600\n",
      "1/8, train_loss: 0.0172 step time: 0.2434\n",
      "2/8, train_loss: 0.0151 step time: 0.2018\n",
      "3/8, train_loss: 0.0137 step time: 0.1991\n",
      "4/8, train_loss: 0.0152 step time: 0.2007\n",
      "5/8, train_loss: 0.0186 step time: 0.1988\n",
      "6/8, train_loss: 0.0147 step time: 0.1998\n",
      "7/8, train_loss: 0.0190 step time: 0.1834\n",
      "8/8, train_loss: 0.0164 step time: 0.1821\n",
      "epoch 328 average loss: 0.0162\n",
      "time consuming of epoch 328 is: 1.6107\n",
      "----------\n",
      "epoch 329/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2404\n",
      "2/8, train_loss: 0.0139 step time: 0.2017\n",
      "3/8, train_loss: 0.0147 step time: 0.2034\n",
      "4/8, train_loss: 0.0156 step time: 0.2037\n",
      "5/8, train_loss: 0.0163 step time: 0.1996\n",
      "6/8, train_loss: 0.0160 step time: 0.1995\n",
      "7/8, train_loss: 0.0163 step time: 0.1844\n",
      "8/8, train_loss: 0.0154 step time: 0.1842\n",
      "epoch 329 average loss: 0.0154\n",
      "time consuming of epoch 329 is: 1.6186\n",
      "----------\n",
      "epoch 330/600\n",
      "1/8, train_loss: 0.0184 step time: 0.2398\n",
      "2/8, train_loss: 0.0132 step time: 0.1989\n",
      "3/8, train_loss: 0.0130 step time: 0.2022\n",
      "4/8, train_loss: 0.0169 step time: 0.2022\n",
      "5/8, train_loss: 0.0175 step time: 0.1985\n",
      "6/8, train_loss: 0.0175 step time: 0.2008\n",
      "7/8, train_loss: 0.0150 step time: 0.1812\n",
      "8/8, train_loss: 0.0157 step time: 0.1809\n",
      "epoch 330 average loss: 0.0159\n",
      "current epoch: 330 current mean dice: 0.9541 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 330 is: 2.3546\n",
      "----------\n",
      "epoch 331/600\n",
      "1/8, train_loss: 0.0148 step time: 0.2352\n",
      "2/8, train_loss: 0.0162 step time: 0.1966\n",
      "3/8, train_loss: 0.0157 step time: 0.1960\n",
      "4/8, train_loss: 0.0141 step time: 0.2039\n",
      "5/8, train_loss: 0.0169 step time: 0.2007\n",
      "6/8, train_loss: 0.0183 step time: 0.2045\n",
      "7/8, train_loss: 0.0181 step time: 0.1844\n",
      "8/8, train_loss: 0.0122 step time: 0.1832\n",
      "epoch 331 average loss: 0.0158\n",
      "time consuming of epoch 331 is: 1.6056\n",
      "----------\n",
      "epoch 332/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2405\n",
      "2/8, train_loss: 0.0141 step time: 0.1997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8, train_loss: 0.0148 step time: 0.2025\n",
      "4/8, train_loss: 0.0210 step time: 0.2003\n",
      "5/8, train_loss: 0.0163 step time: 0.2060\n",
      "6/8, train_loss: 0.0153 step time: 0.2017\n",
      "7/8, train_loss: 0.0151 step time: 0.1843\n",
      "8/8, train_loss: 0.0148 step time: 0.1824\n",
      "epoch 332 average loss: 0.0158\n",
      "time consuming of epoch 332 is: 1.6189\n",
      "----------\n",
      "epoch 333/600\n",
      "1/8, train_loss: 0.0160 step time: 0.2409\n",
      "2/8, train_loss: 0.0158 step time: 0.2030\n",
      "3/8, train_loss: 0.0166 step time: 0.2038\n",
      "4/8, train_loss: 0.0172 step time: 0.2067\n",
      "5/8, train_loss: 0.0166 step time: 0.2004\n",
      "6/8, train_loss: 0.0156 step time: 0.2021\n",
      "7/8, train_loss: 0.0163 step time: 0.1829\n",
      "8/8, train_loss: 0.0148 step time: 0.1818\n",
      "epoch 333 average loss: 0.0161\n",
      "time consuming of epoch 333 is: 1.6231\n",
      "----------\n",
      "epoch 334/600\n",
      "1/8, train_loss: 0.0162 step time: 0.2413\n",
      "2/8, train_loss: 0.0157 step time: 0.2017\n",
      "3/8, train_loss: 0.0180 step time: 0.2034\n",
      "4/8, train_loss: 0.0128 step time: 0.2016\n",
      "5/8, train_loss: 0.0143 step time: 0.2025\n",
      "6/8, train_loss: 0.0150 step time: 0.1997\n",
      "7/8, train_loss: 0.0158 step time: 0.1825\n",
      "8/8, train_loss: 0.0143 step time: 0.1813\n",
      "epoch 334 average loss: 0.0153\n",
      "time consuming of epoch 334 is: 1.6158\n",
      "----------\n",
      "epoch 335/600\n",
      "1/8, train_loss: 0.0143 step time: 0.2452\n",
      "2/8, train_loss: 0.0145 step time: 0.2025\n",
      "3/8, train_loss: 0.0158 step time: 0.2013\n",
      "4/8, train_loss: 0.0147 step time: 0.2004\n",
      "5/8, train_loss: 0.0160 step time: 0.2009\n",
      "6/8, train_loss: 0.0161 step time: 0.2021\n",
      "7/8, train_loss: 0.0138 step time: 0.1818\n",
      "8/8, train_loss: 0.0169 step time: 0.1816\n",
      "epoch 335 average loss: 0.0153\n",
      "current epoch: 335 current mean dice: 0.9543 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 335 is: 2.3728\n",
      "----------\n",
      "epoch 336/600\n",
      "1/8, train_loss: 0.0148 step time: 0.2386\n",
      "2/8, train_loss: 0.0148 step time: 0.2004\n",
      "3/8, train_loss: 0.0146 step time: 0.1998\n",
      "4/8, train_loss: 0.0206 step time: 0.1996\n",
      "5/8, train_loss: 0.0172 step time: 0.1991\n",
      "6/8, train_loss: 0.0139 step time: 0.1997\n",
      "7/8, train_loss: 0.0165 step time: 0.1831\n",
      "8/8, train_loss: 0.0159 step time: 0.1810\n",
      "epoch 336 average loss: 0.0160\n",
      "time consuming of epoch 336 is: 1.6023\n",
      "----------\n",
      "epoch 337/600\n",
      "1/8, train_loss: 0.0199 step time: 0.2438\n",
      "2/8, train_loss: 0.0146 step time: 0.2023\n",
      "3/8, train_loss: 0.0160 step time: 0.2020\n",
      "4/8, train_loss: 0.0160 step time: 0.2009\n",
      "5/8, train_loss: 0.0135 step time: 0.2021\n",
      "6/8, train_loss: 0.0180 step time: 0.2025\n",
      "7/8, train_loss: 0.0134 step time: 0.1827\n",
      "8/8, train_loss: 0.0156 step time: 0.1816\n",
      "epoch 337 average loss: 0.0159\n",
      "time consuming of epoch 337 is: 1.6193\n",
      "----------\n",
      "epoch 338/600\n",
      "1/8, train_loss: 0.0160 step time: 0.2404\n",
      "2/8, train_loss: 0.0152 step time: 0.2214\n",
      "3/8, train_loss: 0.0156 step time: 0.1921\n",
      "4/8, train_loss: 0.0134 step time: 0.2124\n",
      "5/8, train_loss: 0.0175 step time: 0.2052\n",
      "6/8, train_loss: 0.0142 step time: 0.2058\n",
      "7/8, train_loss: 0.0144 step time: 0.1815\n",
      "8/8, train_loss: 0.0140 step time: 0.1832\n",
      "epoch 338 average loss: 0.0150\n",
      "time consuming of epoch 338 is: 1.6432\n",
      "----------\n",
      "epoch 339/600\n",
      "1/8, train_loss: 0.0164 step time: 0.2303\n",
      "2/8, train_loss: 0.0171 step time: 0.1985\n",
      "3/8, train_loss: 0.0180 step time: 0.1978\n",
      "4/8, train_loss: 0.0141 step time: 0.1981\n",
      "5/8, train_loss: 0.0135 step time: 0.2016\n",
      "6/8, train_loss: 0.0147 step time: 0.2005\n",
      "7/8, train_loss: 0.0167 step time: 0.1856\n",
      "8/8, train_loss: 0.0158 step time: 0.1822\n",
      "epoch 339 average loss: 0.0158\n",
      "time consuming of epoch 339 is: 1.5959\n",
      "----------\n",
      "epoch 340/600\n",
      "1/8, train_loss: 0.0156 step time: 0.2394\n",
      "2/8, train_loss: 0.0120 step time: 0.2093\n",
      "3/8, train_loss: 0.0145 step time: 0.2066\n",
      "4/8, train_loss: 0.0137 step time: 0.2106\n",
      "5/8, train_loss: 0.0153 step time: 0.1996\n",
      "6/8, train_loss: 0.0164 step time: 0.2019\n",
      "7/8, train_loss: 0.0166 step time: 0.1826\n",
      "8/8, train_loss: 0.0169 step time: 0.1830\n",
      "epoch 340 average loss: 0.0151\n",
      "current epoch: 340 current mean dice: 0.9551 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 340 is: 2.3895\n",
      "----------\n",
      "epoch 341/600\n",
      "1/8, train_loss: 0.0172 step time: 0.2351\n",
      "2/8, train_loss: 0.0151 step time: 0.1997\n",
      "3/8, train_loss: 0.0167 step time: 0.1988\n",
      "4/8, train_loss: 0.0167 step time: 0.1983\n",
      "5/8, train_loss: 0.0179 step time: 0.2045\n",
      "6/8, train_loss: 0.0156 step time: 0.2019\n",
      "7/8, train_loss: 0.0177 step time: 0.1805\n",
      "8/8, train_loss: 0.0114 step time: 0.1803\n",
      "epoch 341 average loss: 0.0161\n",
      "time consuming of epoch 341 is: 1.6003\n",
      "----------\n",
      "epoch 342/600\n",
      "1/8, train_loss: 0.0140 step time: 0.2395\n",
      "2/8, train_loss: 0.0162 step time: 0.2023\n",
      "3/8, train_loss: 0.0162 step time: 0.1995\n",
      "4/8, train_loss: 0.0139 step time: 0.1979\n",
      "5/8, train_loss: 0.0178 step time: 0.1994\n",
      "6/8, train_loss: 0.0169 step time: 0.2004\n",
      "7/8, train_loss: 0.0136 step time: 0.1823\n",
      "8/8, train_loss: 0.0174 step time: 0.1843\n",
      "epoch 342 average loss: 0.0158\n",
      "time consuming of epoch 342 is: 1.6067\n",
      "----------\n",
      "epoch 343/600\n",
      "1/8, train_loss: 0.0145 step time: 0.2379\n",
      "2/8, train_loss: 0.0156 step time: 0.1999\n",
      "3/8, train_loss: 0.0141 step time: 0.2007\n",
      "4/8, train_loss: 0.0189 step time: 0.2037\n",
      "5/8, train_loss: 0.0176 step time: 0.2016\n",
      "6/8, train_loss: 0.0147 step time: 0.2034\n",
      "7/8, train_loss: 0.0166 step time: 0.1839\n",
      "8/8, train_loss: 0.0140 step time: 0.1852\n",
      "epoch 343 average loss: 0.0157\n",
      "time consuming of epoch 343 is: 1.6177\n",
      "----------\n",
      "epoch 344/600\n",
      "1/8, train_loss: 0.0138 step time: 0.2540\n",
      "2/8, train_loss: 0.0170 step time: 0.2169\n",
      "3/8, train_loss: 0.0153 step time: 0.2084\n",
      "4/8, train_loss: 0.0150 step time: 0.2130\n",
      "5/8, train_loss: 0.0160 step time: 0.2140\n",
      "6/8, train_loss: 0.0150 step time: 0.2183\n",
      "7/8, train_loss: 0.0191 step time: 0.1873\n",
      "8/8, train_loss: 0.0172 step time: 0.1857\n",
      "epoch 344 average loss: 0.0161\n",
      "time consuming of epoch 344 is: 1.6991\n",
      "----------\n",
      "epoch 345/600\n",
      "1/8, train_loss: 0.0132 step time: 0.2582\n",
      "2/8, train_loss: 0.0128 step time: 0.1997\n",
      "3/8, train_loss: 0.0146 step time: 0.2000\n",
      "4/8, train_loss: 0.0188 step time: 0.2105\n",
      "5/8, train_loss: 0.0140 step time: 0.2184\n",
      "6/8, train_loss: 0.0186 step time: 0.2195\n",
      "7/8, train_loss: 0.0153 step time: 0.1854\n",
      "8/8, train_loss: 0.0142 step time: 0.1837\n",
      "epoch 345 average loss: 0.0152\n",
      "current epoch: 345 current mean dice: 0.9554 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 345 is: 2.4353\n",
      "----------\n",
      "epoch 346/600\n",
      "1/8, train_loss: 0.0169 step time: 0.2573\n",
      "2/8, train_loss: 0.0183 step time: 0.2110\n",
      "3/8, train_loss: 0.0198 step time: 0.2089\n",
      "4/8, train_loss: 0.0143 step time: 0.2026\n",
      "5/8, train_loss: 0.0178 step time: 0.2036\n",
      "6/8, train_loss: 0.0152 step time: 0.2005\n",
      "7/8, train_loss: 0.0110 step time: 0.1829\n",
      "8/8, train_loss: 0.0169 step time: 0.1845\n",
      "epoch 346 average loss: 0.0163\n",
      "time consuming of epoch 346 is: 1.6525\n",
      "----------\n",
      "epoch 347/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2435\n",
      "2/8, train_loss: 0.0168 step time: 0.2119\n",
      "3/8, train_loss: 0.0201 step time: 0.2088\n",
      "4/8, train_loss: 0.0158 step time: 0.2116\n",
      "5/8, train_loss: 0.0153 step time: 0.2059\n",
      "6/8, train_loss: 0.0138 step time: 0.2131\n",
      "7/8, train_loss: 0.0164 step time: 0.1836\n",
      "8/8, train_loss: 0.0146 step time: 0.1831\n",
      "epoch 347 average loss: 0.0160\n",
      "time consuming of epoch 347 is: 1.6630\n",
      "----------\n",
      "epoch 348/600\n",
      "1/8, train_loss: 0.0132 step time: 0.2605\n",
      "2/8, train_loss: 0.0187 step time: 0.2155\n",
      "3/8, train_loss: 0.0146 step time: 0.2066\n",
      "4/8, train_loss: 0.0148 step time: 0.1991\n",
      "5/8, train_loss: 0.0156 step time: 0.2072\n",
      "6/8, train_loss: 0.0157 step time: 0.2109\n",
      "7/8, train_loss: 0.0154 step time: 0.1844\n",
      "8/8, train_loss: 0.0179 step time: 0.1856\n",
      "epoch 348 average loss: 0.0157\n",
      "time consuming of epoch 348 is: 1.6712\n",
      "----------\n",
      "epoch 349/600\n",
      "1/8, train_loss: 0.0182 step time: 0.2488\n",
      "2/8, train_loss: 0.0150 step time: 0.2064\n",
      "3/8, train_loss: 0.0118 step time: 0.2111\n",
      "4/8, train_loss: 0.0180 step time: 0.2105\n",
      "5/8, train_loss: 0.0187 step time: 0.2088\n",
      "6/8, train_loss: 0.0170 step time: 0.2103\n",
      "7/8, train_loss: 0.0155 step time: 0.1865\n",
      "8/8, train_loss: 0.0189 step time: 0.1846\n",
      "epoch 349 average loss: 0.0166\n",
      "time consuming of epoch 349 is: 1.6685\n",
      "----------\n",
      "epoch 350/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2416\n",
      "2/8, train_loss: 0.0120 step time: 0.2030\n",
      "3/8, train_loss: 0.0157 step time: 0.2031\n",
      "4/8, train_loss: 0.0168 step time: 0.2041\n",
      "5/8, train_loss: 0.0157 step time: 0.1969\n",
      "6/8, train_loss: 0.0201 step time: 0.2025\n",
      "7/8, train_loss: 0.0164 step time: 0.1840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8, train_loss: 0.0167 step time: 0.1852\n",
      "epoch 350 average loss: 0.0160\n",
      "current epoch: 350 current mean dice: 0.9553 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 350 is: 2.3810\n",
      "----------\n",
      "epoch 351/600\n",
      "1/8, train_loss: 0.0156 step time: 0.2515\n",
      "2/8, train_loss: 0.0132 step time: 0.2156\n",
      "3/8, train_loss: 0.0149 step time: 0.2064\n",
      "4/8, train_loss: 0.0164 step time: 0.2132\n",
      "5/8, train_loss: 0.0134 step time: 0.2159\n",
      "6/8, train_loss: 0.0154 step time: 0.2025\n",
      "7/8, train_loss: 0.0157 step time: 0.1857\n",
      "8/8, train_loss: 0.0175 step time: 0.1815\n",
      "epoch 351 average loss: 0.0153\n",
      "time consuming of epoch 351 is: 1.6736\n",
      "----------\n",
      "epoch 352/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2479\n",
      "2/8, train_loss: 0.0152 step time: 0.2109\n",
      "3/8, train_loss: 0.0142 step time: 0.2097\n",
      "4/8, train_loss: 0.0144 step time: 0.2137\n",
      "5/8, train_loss: 0.0159 step time: 0.2182\n",
      "6/8, train_loss: 0.0232 step time: 0.2193\n",
      "7/8, train_loss: 0.0160 step time: 0.1850\n",
      "8/8, train_loss: 0.0164 step time: 0.1842\n",
      "epoch 352 average loss: 0.0163\n",
      "time consuming of epoch 352 is: 1.6903\n",
      "----------\n",
      "epoch 353/600\n",
      "1/8, train_loss: 0.0160 step time: 0.2690\n",
      "2/8, train_loss: 0.0170 step time: 0.2027\n",
      "3/8, train_loss: 0.0150 step time: 0.2080\n",
      "4/8, train_loss: 0.0153 step time: 0.2025\n",
      "5/8, train_loss: 0.0158 step time: 0.2021\n",
      "6/8, train_loss: 0.0158 step time: 0.1988\n",
      "7/8, train_loss: 0.0142 step time: 0.1825\n",
      "8/8, train_loss: 0.0134 step time: 0.1853\n",
      "epoch 353 average loss: 0.0153\n",
      "time consuming of epoch 353 is: 1.6526\n",
      "----------\n",
      "epoch 354/600\n",
      "1/8, train_loss: 0.0161 step time: 0.2493\n",
      "2/8, train_loss: 0.0197 step time: 0.2152\n",
      "3/8, train_loss: 0.0142 step time: 0.2229\n",
      "4/8, train_loss: 0.0150 step time: 0.2143\n",
      "5/8, train_loss: 0.0158 step time: 0.2128\n",
      "6/8, train_loss: 0.0129 step time: 0.2196\n",
      "7/8, train_loss: 0.0134 step time: 0.1846\n",
      "8/8, train_loss: 0.0153 step time: 0.1820\n",
      "epoch 354 average loss: 0.0153\n",
      "time consuming of epoch 354 is: 1.7023\n",
      "----------\n",
      "epoch 355/600\n",
      "1/8, train_loss: 0.0138 step time: 0.2556\n",
      "2/8, train_loss: 0.0216 step time: 0.2053\n",
      "3/8, train_loss: 0.0192 step time: 0.2017\n",
      "4/8, train_loss: 0.0165 step time: 0.2091\n",
      "5/8, train_loss: 0.0144 step time: 0.2186\n",
      "6/8, train_loss: 0.0131 step time: 0.2183\n",
      "7/8, train_loss: 0.0138 step time: 0.1855\n",
      "8/8, train_loss: 0.0169 step time: 0.1883\n",
      "epoch 355 average loss: 0.0162\n",
      "current epoch: 355 current mean dice: 0.9552 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 355 is: 2.4491\n",
      "----------\n",
      "epoch 356/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2490\n",
      "2/8, train_loss: 0.0131 step time: 0.2102\n",
      "3/8, train_loss: 0.0164 step time: 0.2049\n",
      "4/8, train_loss: 0.0141 step time: 0.2039\n",
      "5/8, train_loss: 0.0151 step time: 0.2054\n",
      "6/8, train_loss: 0.0157 step time: 0.2055\n",
      "7/8, train_loss: 0.0210 step time: 0.1824\n",
      "8/8, train_loss: 0.0151 step time: 0.1830\n",
      "epoch 356 average loss: 0.0155\n",
      "time consuming of epoch 356 is: 1.6458\n",
      "----------\n",
      "epoch 357/600\n",
      "1/8, train_loss: 0.0152 step time: 0.2398\n",
      "2/8, train_loss: 0.0139 step time: 0.2023\n",
      "3/8, train_loss: 0.0204 step time: 0.2018\n",
      "4/8, train_loss: 0.0156 step time: 0.2017\n",
      "5/8, train_loss: 0.0139 step time: 0.2003\n",
      "6/8, train_loss: 0.0167 step time: 0.2004\n",
      "7/8, train_loss: 0.0180 step time: 0.1830\n",
      "8/8, train_loss: 0.0126 step time: 0.1827\n",
      "epoch 357 average loss: 0.0158\n",
      "time consuming of epoch 357 is: 1.6132\n",
      "----------\n",
      "epoch 358/600\n",
      "1/8, train_loss: 0.0146 step time: 0.2389\n",
      "2/8, train_loss: 0.0153 step time: 0.1980\n",
      "3/8, train_loss: 0.0158 step time: 0.1998\n",
      "4/8, train_loss: 0.0172 step time: 0.2024\n",
      "5/8, train_loss: 0.0183 step time: 0.2005\n",
      "6/8, train_loss: 0.0127 step time: 0.1978\n",
      "7/8, train_loss: 0.0147 step time: 0.1839\n",
      "8/8, train_loss: 0.0156 step time: 0.1827\n",
      "epoch 358 average loss: 0.0155\n",
      "time consuming of epoch 358 is: 1.6052\n",
      "----------\n",
      "epoch 359/600\n",
      "1/8, train_loss: 0.0126 step time: 0.2425\n",
      "2/8, train_loss: 0.0165 step time: 0.1997\n",
      "3/8, train_loss: 0.0165 step time: 0.1988\n",
      "4/8, train_loss: 0.0186 step time: 0.2045\n",
      "5/8, train_loss: 0.0155 step time: 0.2034\n",
      "6/8, train_loss: 0.0147 step time: 0.1977\n",
      "7/8, train_loss: 0.0157 step time: 0.1825\n",
      "8/8, train_loss: 0.0133 step time: 0.1819\n",
      "epoch 359 average loss: 0.0154\n",
      "time consuming of epoch 359 is: 1.6126\n",
      "----------\n",
      "epoch 360/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2408\n",
      "2/8, train_loss: 0.0149 step time: 0.2006\n",
      "3/8, train_loss: 0.0136 step time: 0.2048\n",
      "4/8, train_loss: 0.0169 step time: 0.2014\n",
      "5/8, train_loss: 0.0142 step time: 0.2070\n",
      "6/8, train_loss: 0.0143 step time: 0.2022\n",
      "7/8, train_loss: 0.0161 step time: 0.1839\n",
      "8/8, train_loss: 0.0185 step time: 0.1844\n",
      "epoch 360 average loss: 0.0153\n",
      "current epoch: 360 current mean dice: 0.9549 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 360 is: 2.3833\n",
      "----------\n",
      "epoch 361/600\n",
      "1/8, train_loss: 0.0152 step time: 0.2360\n",
      "2/8, train_loss: 0.0147 step time: 0.2003\n",
      "3/8, train_loss: 0.0156 step time: 0.2006\n",
      "4/8, train_loss: 0.0145 step time: 0.2030\n",
      "5/8, train_loss: 0.0144 step time: 0.2017\n",
      "6/8, train_loss: 0.0132 step time: 0.2031\n",
      "7/8, train_loss: 0.0171 step time: 0.1832\n",
      "8/8, train_loss: 0.0157 step time: 0.1837\n",
      "epoch 361 average loss: 0.0151\n",
      "time consuming of epoch 361 is: 1.6128\n",
      "----------\n",
      "epoch 362/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2404\n",
      "2/8, train_loss: 0.0158 step time: 0.2017\n",
      "3/8, train_loss: 0.0155 step time: 0.2030\n",
      "4/8, train_loss: 0.0173 step time: 0.2006\n",
      "5/8, train_loss: 0.0149 step time: 0.2037\n",
      "6/8, train_loss: 0.0153 step time: 0.2058\n",
      "7/8, train_loss: 0.0150 step time: 0.1826\n",
      "8/8, train_loss: 0.0153 step time: 0.1830\n",
      "epoch 362 average loss: 0.0150\n",
      "time consuming of epoch 362 is: 1.6222\n",
      "----------\n",
      "epoch 363/600\n",
      "1/8, train_loss: 0.0130 step time: 0.2416\n",
      "2/8, train_loss: 0.0161 step time: 0.2058\n",
      "3/8, train_loss: 0.0121 step time: 0.1999\n",
      "4/8, train_loss: 0.0157 step time: 0.1991\n",
      "5/8, train_loss: 0.0177 step time: 0.2018\n",
      "6/8, train_loss: 0.0165 step time: 0.2025\n",
      "7/8, train_loss: 0.0202 step time: 0.1832\n",
      "8/8, train_loss: 0.0162 step time: 0.1852\n",
      "epoch 363 average loss: 0.0159\n",
      "time consuming of epoch 363 is: 1.6207\n",
      "----------\n",
      "epoch 364/600\n",
      "1/8, train_loss: 0.0147 step time: 0.2361\n",
      "2/8, train_loss: 0.0145 step time: 0.1979\n",
      "3/8, train_loss: 0.0158 step time: 0.1961\n",
      "4/8, train_loss: 0.0157 step time: 0.2418\n",
      "5/8, train_loss: 0.0158 step time: 0.1987\n",
      "6/8, train_loss: 0.0113 step time: 0.1949\n",
      "7/8, train_loss: 0.0186 step time: 0.1852\n",
      "8/8, train_loss: 0.0148 step time: 0.1823\n",
      "epoch 364 average loss: 0.0152\n",
      "time consuming of epoch 364 is: 1.6343\n",
      "----------\n",
      "epoch 365/600\n",
      "1/8, train_loss: 0.0164 step time: 0.2315\n",
      "2/8, train_loss: 0.0142 step time: 0.1968\n",
      "3/8, train_loss: 0.0125 step time: 0.1975\n",
      "4/8, train_loss: 0.0151 step time: 0.1989\n",
      "5/8, train_loss: 0.0133 step time: 0.2007\n",
      "6/8, train_loss: 0.0173 step time: 0.2021\n",
      "7/8, train_loss: 0.0160 step time: 0.1824\n",
      "8/8, train_loss: 0.0177 step time: 0.1813\n",
      "epoch 365 average loss: 0.0153\n",
      "current epoch: 365 current mean dice: 0.9528 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 365 is: 2.3462\n",
      "----------\n",
      "epoch 366/600\n",
      "1/8, train_loss: 0.0160 step time: 0.2385\n",
      "2/8, train_loss: 0.0143 step time: 0.2002\n",
      "3/8, train_loss: 0.0121 step time: 0.2024\n",
      "4/8, train_loss: 0.0205 step time: 0.1937\n",
      "5/8, train_loss: 0.0159 step time: 0.2009\n",
      "6/8, train_loss: 0.0189 step time: 0.1982\n",
      "7/8, train_loss: 0.0159 step time: 0.1854\n",
      "8/8, train_loss: 0.0158 step time: 0.1802\n",
      "epoch 366 average loss: 0.0162\n",
      "time consuming of epoch 366 is: 1.6007\n",
      "----------\n",
      "epoch 367/600\n",
      "1/8, train_loss: 0.0143 step time: 0.2391\n",
      "2/8, train_loss: 0.0144 step time: 0.2027\n",
      "3/8, train_loss: 0.0158 step time: 0.1994\n",
      "4/8, train_loss: 0.0166 step time: 0.1996\n",
      "5/8, train_loss: 0.0156 step time: 0.1993\n",
      "6/8, train_loss: 0.0177 step time: 0.2005\n",
      "7/8, train_loss: 0.0150 step time: 0.1830\n",
      "8/8, train_loss: 0.0158 step time: 0.1836\n",
      "epoch 367 average loss: 0.0157\n",
      "time consuming of epoch 367 is: 1.6084\n",
      "----------\n",
      "epoch 368/600\n",
      "1/8, train_loss: 0.0147 step time: 0.2442\n",
      "2/8, train_loss: 0.0142 step time: 0.2022\n",
      "3/8, train_loss: 0.0174 step time: 0.1993\n",
      "4/8, train_loss: 0.0159 step time: 0.2039\n",
      "5/8, train_loss: 0.0144 step time: 0.2019\n",
      "6/8, train_loss: 0.0148 step time: 0.1997\n",
      "7/8, train_loss: 0.0164 step time: 0.1852\n",
      "8/8, train_loss: 0.0142 step time: 0.1817\n",
      "epoch 368 average loss: 0.0153\n",
      "time consuming of epoch 368 is: 1.6200\n",
      "----------\n",
      "epoch 369/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0164 step time: 0.2385\n",
      "2/8, train_loss: 0.0138 step time: 0.2046\n",
      "3/8, train_loss: 0.0188 step time: 0.2025\n",
      "4/8, train_loss: 0.0149 step time: 0.2033\n",
      "5/8, train_loss: 0.0165 step time: 0.1983\n",
      "6/8, train_loss: 0.0149 step time: 0.1999\n",
      "7/8, train_loss: 0.0156 step time: 0.1827\n",
      "8/8, train_loss: 0.0136 step time: 0.1807\n",
      "epoch 369 average loss: 0.0156\n",
      "time consuming of epoch 369 is: 1.6119\n",
      "----------\n",
      "epoch 370/600\n",
      "1/8, train_loss: 0.0143 step time: 0.2388\n",
      "2/8, train_loss: 0.0147 step time: 0.1988\n",
      "3/8, train_loss: 0.0157 step time: 0.2056\n",
      "4/8, train_loss: 0.0149 step time: 0.2003\n",
      "5/8, train_loss: 0.0153 step time: 0.2065\n",
      "6/8, train_loss: 0.0148 step time: 0.2018\n",
      "7/8, train_loss: 0.0327 step time: 0.1829\n",
      "8/8, train_loss: 0.0176 step time: 0.1822\n",
      "epoch 370 average loss: 0.0175\n",
      "current epoch: 370 current mean dice: 0.8570 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 370 is: 2.3732\n",
      "----------\n",
      "epoch 371/600\n",
      "1/8, train_loss: 0.0172 step time: 0.2389\n",
      "2/8, train_loss: 0.0407 step time: 0.2034\n",
      "3/8, train_loss: 0.0297 step time: 0.1965\n",
      "4/8, train_loss: 0.1165 step time: 0.2012\n",
      "5/8, train_loss: 0.0998 step time: 0.1975\n",
      "6/8, train_loss: 0.0280 step time: 0.1983\n",
      "7/8, train_loss: 0.0473 step time: 0.1821\n",
      "8/8, train_loss: 0.0346 step time: 0.1809\n",
      "epoch 371 average loss: 0.0517\n",
      "time consuming of epoch 371 is: 1.5999\n",
      "----------\n",
      "epoch 372/600\n",
      "1/8, train_loss: 0.0608 step time: 0.2378\n",
      "2/8, train_loss: 0.0467 step time: 0.1998\n",
      "3/8, train_loss: 0.0747 step time: 0.1999\n",
      "4/8, train_loss: 0.1737 step time: 0.1993\n",
      "5/8, train_loss: 0.0444 step time: 0.1997\n",
      "6/8, train_loss: 0.0891 step time: 0.1998\n",
      "7/8, train_loss: 0.0447 step time: 0.1828\n",
      "8/8, train_loss: 0.0732 step time: 0.1829\n",
      "epoch 372 average loss: 0.0759\n",
      "time consuming of epoch 372 is: 1.6035\n",
      "----------\n",
      "epoch 373/600\n",
      "1/8, train_loss: 0.1252 step time: 0.2405\n",
      "2/8, train_loss: 0.0326 step time: 0.1987\n",
      "3/8, train_loss: 0.0406 step time: 0.2020\n",
      "4/8, train_loss: 0.0850 step time: 0.2001\n",
      "5/8, train_loss: 0.0520 step time: 0.1997\n",
      "6/8, train_loss: 0.0455 step time: 0.2016\n",
      "7/8, train_loss: 0.0476 step time: 0.1825\n",
      "8/8, train_loss: 0.0877 step time: 0.1825\n",
      "epoch 373 average loss: 0.0645\n",
      "time consuming of epoch 373 is: 1.6088\n",
      "----------\n",
      "epoch 374/600\n",
      "1/8, train_loss: 0.0402 step time: 0.2365\n",
      "2/8, train_loss: 0.0429 step time: 0.2012\n",
      "3/8, train_loss: 0.0642 step time: 0.1977\n",
      "4/8, train_loss: 0.0364 step time: 0.1981\n",
      "5/8, train_loss: 0.0324 step time: 0.2049\n",
      "6/8, train_loss: 0.0799 step time: 0.1983\n",
      "7/8, train_loss: 0.0522 step time: 0.1814\n",
      "8/8, train_loss: 0.0477 step time: 0.1823\n",
      "epoch 374 average loss: 0.0495\n",
      "time consuming of epoch 374 is: 1.6018\n",
      "----------\n",
      "epoch 375/600\n",
      "1/8, train_loss: 0.0354 step time: 0.2423\n",
      "2/8, train_loss: 0.0298 step time: 0.2011\n",
      "3/8, train_loss: 0.0515 step time: 0.1988\n",
      "4/8, train_loss: 0.0496 step time: 0.2012\n",
      "5/8, train_loss: 0.0470 step time: 0.2031\n",
      "6/8, train_loss: 0.0323 step time: 0.2015\n",
      "7/8, train_loss: 0.0384 step time: 0.1820\n",
      "8/8, train_loss: 0.0437 step time: 0.1819\n",
      "epoch 375 average loss: 0.0410\n",
      "current epoch: 375 current mean dice: 0.8731 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 375 is: 2.3692\n",
      "----------\n",
      "epoch 376/600\n",
      "1/8, train_loss: 0.0258 step time: 0.2363\n",
      "2/8, train_loss: 0.0301 step time: 0.1972\n",
      "3/8, train_loss: 0.0428 step time: 0.2067\n",
      "4/8, train_loss: 0.0884 step time: 0.1991\n",
      "5/8, train_loss: 0.0373 step time: 0.2007\n",
      "6/8, train_loss: 0.0635 step time: 0.2041\n",
      "7/8, train_loss: 0.0638 step time: 0.1824\n",
      "8/8, train_loss: 0.0472 step time: 0.1829\n",
      "epoch 376 average loss: 0.0499\n",
      "time consuming of epoch 376 is: 1.6106\n",
      "----------\n",
      "epoch 377/600\n",
      "1/8, train_loss: 0.0420 step time: 0.2391\n",
      "2/8, train_loss: 0.0443 step time: 0.2029\n",
      "3/8, train_loss: 0.0317 step time: 0.2017\n",
      "4/8, train_loss: 0.0276 step time: 0.2022\n",
      "5/8, train_loss: 0.0728 step time: 0.1997\n",
      "6/8, train_loss: 0.0243 step time: 0.2012\n",
      "7/8, train_loss: 0.0324 step time: 0.1836\n",
      "8/8, train_loss: 0.0501 step time: 0.1825\n",
      "epoch 377 average loss: 0.0407\n",
      "time consuming of epoch 377 is: 1.6145\n",
      "----------\n",
      "epoch 378/600\n",
      "1/8, train_loss: 0.0269 step time: 0.2416\n",
      "2/8, train_loss: 0.0340 step time: 0.2048\n",
      "3/8, train_loss: 0.0363 step time: 0.1996\n",
      "4/8, train_loss: 0.0293 step time: 0.2009\n",
      "5/8, train_loss: 0.0608 step time: 0.2026\n",
      "6/8, train_loss: 0.0302 step time: 0.2000\n",
      "7/8, train_loss: 0.0439 step time: 0.1826\n",
      "8/8, train_loss: 0.0313 step time: 0.1826\n",
      "epoch 378 average loss: 0.0366\n",
      "time consuming of epoch 378 is: 1.6160\n",
      "----------\n",
      "epoch 379/600\n",
      "1/8, train_loss: 0.0411 step time: 0.2409\n",
      "2/8, train_loss: 0.0281 step time: 0.2023\n",
      "3/8, train_loss: 0.0368 step time: 0.2020\n",
      "4/8, train_loss: 0.0215 step time: 0.2004\n",
      "5/8, train_loss: 0.0361 step time: 0.2007\n",
      "6/8, train_loss: 0.0363 step time: 0.2005\n",
      "7/8, train_loss: 0.0242 step time: 0.1832\n",
      "8/8, train_loss: 0.0231 step time: 0.1811\n",
      "epoch 379 average loss: 0.0309\n",
      "time consuming of epoch 379 is: 1.6124\n",
      "----------\n",
      "epoch 380/600\n",
      "1/8, train_loss: 0.0246 step time: 0.2407\n",
      "2/8, train_loss: 0.0658 step time: 0.2045\n",
      "3/8, train_loss: 0.0256 step time: 0.2027\n",
      "4/8, train_loss: 0.0343 step time: 0.1988\n",
      "5/8, train_loss: 0.0319 step time: 0.2017\n",
      "6/8, train_loss: 0.0436 step time: 0.1996\n",
      "7/8, train_loss: 0.0325 step time: 0.1828\n",
      "8/8, train_loss: 0.0595 step time: 0.1839\n",
      "epoch 380 average loss: 0.0397\n",
      "current epoch: 380 current mean dice: 0.3179 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 380 is: 2.3709\n",
      "----------\n",
      "epoch 381/600\n",
      "1/8, train_loss: 0.0640 step time: 0.2398\n",
      "2/8, train_loss: 0.0255 step time: 0.2006\n",
      "3/8, train_loss: 0.0501 step time: 0.2011\n",
      "4/8, train_loss: 0.0323 step time: 0.2023\n",
      "5/8, train_loss: 0.0448 step time: 0.2019\n",
      "6/8, train_loss: 0.0380 step time: 0.1981\n",
      "7/8, train_loss: 0.0442 step time: 0.1810\n",
      "8/8, train_loss: 0.0272 step time: 0.1837\n",
      "epoch 381 average loss: 0.0408\n",
      "time consuming of epoch 381 is: 1.6096\n",
      "----------\n",
      "epoch 382/600\n",
      "1/8, train_loss: 0.0637 step time: 0.2409\n",
      "2/8, train_loss: 0.0286 step time: 0.2042\n",
      "3/8, train_loss: 0.0482 step time: 0.1980\n",
      "4/8, train_loss: 0.0384 step time: 0.1998\n",
      "5/8, train_loss: 0.0364 step time: 0.2006\n",
      "6/8, train_loss: 0.0215 step time: 0.1999\n",
      "7/8, train_loss: 0.0742 step time: 0.1830\n",
      "8/8, train_loss: 0.0351 step time: 0.1822\n",
      "epoch 382 average loss: 0.0433\n",
      "time consuming of epoch 382 is: 1.6097\n",
      "----------\n",
      "epoch 383/600\n",
      "1/8, train_loss: 0.0248 step time: 0.2405\n",
      "2/8, train_loss: 0.0244 step time: 0.2016\n",
      "3/8, train_loss: 0.0256 step time: 0.1985\n",
      "4/8, train_loss: 0.0235 step time: 0.2031\n",
      "5/8, train_loss: 0.0249 step time: 0.1994\n",
      "6/8, train_loss: 0.0250 step time: 0.2007\n",
      "7/8, train_loss: 0.0257 step time: 0.1814\n",
      "8/8, train_loss: 0.0518 step time: 0.1823\n",
      "epoch 383 average loss: 0.0282\n",
      "time consuming of epoch 383 is: 1.6091\n",
      "----------\n",
      "epoch 384/600\n",
      "1/8, train_loss: 0.0332 step time: 0.2385\n",
      "2/8, train_loss: 0.0432 step time: 0.2016\n",
      "3/8, train_loss: 0.0261 step time: 0.2018\n",
      "4/8, train_loss: 0.0268 step time: 0.2009\n",
      "5/8, train_loss: 0.0344 step time: 0.2035\n",
      "6/8, train_loss: 0.0313 step time: 0.2011\n",
      "7/8, train_loss: 0.0915 step time: 0.1851\n",
      "8/8, train_loss: 0.0526 step time: 0.1835\n",
      "epoch 384 average loss: 0.0424\n",
      "time consuming of epoch 384 is: 1.6174\n",
      "----------\n",
      "epoch 385/600\n",
      "1/8, train_loss: 0.0443 step time: 0.2400\n",
      "2/8, train_loss: 0.0262 step time: 0.2030\n",
      "3/8, train_loss: 0.0216 step time: 0.1988\n",
      "4/8, train_loss: 0.0455 step time: 0.2014\n",
      "5/8, train_loss: 0.0352 step time: 0.2024\n",
      "6/8, train_loss: 0.0425 step time: 0.2003\n",
      "7/8, train_loss: 0.0279 step time: 0.1841\n",
      "8/8, train_loss: 0.0279 step time: 0.1822\n",
      "epoch 385 average loss: 0.0339\n",
      "current epoch: 385 current mean dice: 0.9292 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 385 is: 2.3684\n",
      "----------\n",
      "epoch 386/600\n",
      "1/8, train_loss: 0.0255 step time: 0.2293\n",
      "2/8, train_loss: 0.0578 step time: 0.1991\n",
      "3/8, train_loss: 0.0322 step time: 0.1946\n",
      "4/8, train_loss: 0.0461 step time: 0.1960\n",
      "5/8, train_loss: 0.0450 step time: 0.1971\n",
      "6/8, train_loss: 0.0623 step time: 0.1983\n",
      "7/8, train_loss: 0.0355 step time: 0.1829\n",
      "8/8, train_loss: 0.0284 step time: 0.1833\n",
      "epoch 386 average loss: 0.0416\n",
      "time consuming of epoch 386 is: 1.5819\n",
      "----------\n",
      "epoch 387/600\n",
      "1/8, train_loss: 0.0243 step time: 0.2419\n",
      "2/8, train_loss: 0.0386 step time: 0.2035\n",
      "3/8, train_loss: 0.0506 step time: 0.2005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/8, train_loss: 0.0281 step time: 0.2018\n",
      "5/8, train_loss: 0.0292 step time: 0.1984\n",
      "6/8, train_loss: 0.0358 step time: 0.2009\n",
      "7/8, train_loss: 0.1094 step time: 0.1848\n",
      "8/8, train_loss: 0.0262 step time: 0.1821\n",
      "epoch 387 average loss: 0.0428\n",
      "time consuming of epoch 387 is: 1.6156\n",
      "----------\n",
      "epoch 388/600\n",
      "1/8, train_loss: 0.0370 step time: 0.2368\n",
      "2/8, train_loss: 0.0511 step time: 0.1992\n",
      "3/8, train_loss: 0.0266 step time: 0.2021\n",
      "4/8, train_loss: 0.0556 step time: 0.1974\n",
      "5/8, train_loss: 0.0285 step time: 0.1993\n",
      "6/8, train_loss: 0.0272 step time: 0.1975\n",
      "7/8, train_loss: 0.0286 step time: 0.1815\n",
      "8/8, train_loss: 0.0282 step time: 0.1827\n",
      "epoch 388 average loss: 0.0353\n",
      "time consuming of epoch 388 is: 1.5976\n",
      "----------\n",
      "epoch 389/600\n",
      "1/8, train_loss: 0.0375 step time: 0.2291\n",
      "2/8, train_loss: 0.0473 step time: 0.1971\n",
      "3/8, train_loss: 0.0406 step time: 0.2006\n",
      "4/8, train_loss: 0.0384 step time: 0.1952\n",
      "5/8, train_loss: 0.0332 step time: 0.2009\n",
      "6/8, train_loss: 0.0245 step time: 0.2005\n",
      "7/8, train_loss: 0.0368 step time: 0.1829\n",
      "8/8, train_loss: 0.0301 step time: 0.1827\n",
      "epoch 389 average loss: 0.0361\n",
      "time consuming of epoch 389 is: 1.5903\n",
      "----------\n",
      "epoch 390/600\n",
      "1/8, train_loss: 0.0262 step time: 0.2400\n",
      "2/8, train_loss: 0.0208 step time: 0.1981\n",
      "3/8, train_loss: 0.0246 step time: 0.2050\n",
      "4/8, train_loss: 0.0348 step time: 0.1979\n",
      "5/8, train_loss: 0.0251 step time: 0.1997\n",
      "6/8, train_loss: 0.0320 step time: 0.2005\n",
      "7/8, train_loss: 0.0253 step time: 0.1827\n",
      "8/8, train_loss: 0.0245 step time: 0.1821\n",
      "epoch 390 average loss: 0.0267\n",
      "current epoch: 390 current mean dice: 0.8888 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 390 is: 2.3662\n",
      "----------\n",
      "epoch 391/600\n",
      "1/8, train_loss: 0.0286 step time: 0.2376\n",
      "2/8, train_loss: 0.0273 step time: 0.1978\n",
      "3/8, train_loss: 0.0397 step time: 0.1975\n",
      "4/8, train_loss: 0.0258 step time: 0.1996\n",
      "5/8, train_loss: 0.0236 step time: 0.1950\n",
      "6/8, train_loss: 0.0252 step time: 0.2002\n",
      "7/8, train_loss: 0.0302 step time: 0.1816\n",
      "8/8, train_loss: 0.0312 step time: 0.1834\n",
      "epoch 391 average loss: 0.0289\n",
      "time consuming of epoch 391 is: 1.5940\n",
      "----------\n",
      "epoch 392/600\n",
      "1/8, train_loss: 0.0318 step time: 0.2359\n",
      "2/8, train_loss: 0.0324 step time: 0.1967\n",
      "3/8, train_loss: 0.0261 step time: 0.1980\n",
      "4/8, train_loss: 0.0256 step time: 0.1975\n",
      "5/8, train_loss: 0.0290 step time: 0.2026\n",
      "6/8, train_loss: 0.0191 step time: 0.1998\n",
      "7/8, train_loss: 0.0225 step time: 0.1835\n",
      "8/8, train_loss: 0.0225 step time: 0.1837\n",
      "epoch 392 average loss: 0.0261\n",
      "time consuming of epoch 392 is: 1.5994\n",
      "----------\n",
      "epoch 393/600\n",
      "1/8, train_loss: 0.0201 step time: 0.2421\n",
      "2/8, train_loss: 0.0335 step time: 0.2017\n",
      "3/8, train_loss: 0.0251 step time: 0.1994\n",
      "4/8, train_loss: 0.0265 step time: 0.2005\n",
      "5/8, train_loss: 0.0276 step time: 0.1985\n",
      "6/8, train_loss: 0.0200 step time: 0.2007\n",
      "7/8, train_loss: 0.0218 step time: 0.1839\n",
      "8/8, train_loss: 0.0169 step time: 0.1837\n",
      "epoch 393 average loss: 0.0239\n",
      "time consuming of epoch 393 is: 1.6123\n",
      "----------\n",
      "epoch 394/600\n",
      "1/8, train_loss: 0.0236 step time: 0.2350\n",
      "2/8, train_loss: 0.0182 step time: 0.2051\n",
      "3/8, train_loss: 0.0264 step time: 0.2017\n",
      "4/8, train_loss: 0.0214 step time: 0.1969\n",
      "5/8, train_loss: 0.0210 step time: 0.2008\n",
      "6/8, train_loss: 0.0193 step time: 0.2042\n",
      "7/8, train_loss: 0.0231 step time: 0.1882\n",
      "8/8, train_loss: 0.0173 step time: 0.1825\n",
      "epoch 394 average loss: 0.0213\n",
      "time consuming of epoch 394 is: 1.6163\n",
      "----------\n",
      "epoch 395/600\n",
      "1/8, train_loss: 0.0196 step time: 0.2415\n",
      "2/8, train_loss: 0.0235 step time: 0.2016\n",
      "3/8, train_loss: 0.0195 step time: 0.2031\n",
      "4/8, train_loss: 0.0289 step time: 0.2013\n",
      "5/8, train_loss: 0.0213 step time: 0.2007\n",
      "6/8, train_loss: 0.0211 step time: 0.1998\n",
      "7/8, train_loss: 0.0214 step time: 0.1840\n",
      "8/8, train_loss: 0.0187 step time: 0.1812\n",
      "epoch 395 average loss: 0.0218\n",
      "current epoch: 395 current mean dice: 0.9435 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 395 is: 2.3693\n",
      "----------\n",
      "epoch 396/600\n",
      "1/8, train_loss: 0.0192 step time: 0.2388\n",
      "2/8, train_loss: 0.0195 step time: 0.2021\n",
      "3/8, train_loss: 0.0251 step time: 0.1990\n",
      "4/8, train_loss: 0.0210 step time: 0.2012\n",
      "5/8, train_loss: 0.0234 step time: 0.1998\n",
      "6/8, train_loss: 0.0201 step time: 0.2032\n",
      "7/8, train_loss: 0.0159 step time: 0.1827\n",
      "8/8, train_loss: 0.0200 step time: 0.1825\n",
      "epoch 396 average loss: 0.0205\n",
      "time consuming of epoch 396 is: 1.6104\n",
      "----------\n",
      "epoch 397/600\n",
      "1/8, train_loss: 0.0215 step time: 0.2387\n",
      "2/8, train_loss: 0.0167 step time: 0.2034\n",
      "3/8, train_loss: 0.0253 step time: 0.1995\n",
      "4/8, train_loss: 0.0225 step time: 0.2073\n",
      "5/8, train_loss: 0.0215 step time: 0.2020\n",
      "6/8, train_loss: 0.0188 step time: 0.2029\n",
      "7/8, train_loss: 0.0195 step time: 0.1816\n",
      "8/8, train_loss: 0.0204 step time: 0.1816\n",
      "epoch 397 average loss: 0.0208\n",
      "time consuming of epoch 397 is: 1.6187\n",
      "----------\n",
      "epoch 398/600\n",
      "1/8, train_loss: 0.0234 step time: 0.2414\n",
      "2/8, train_loss: 0.0211 step time: 0.2028\n",
      "3/8, train_loss: 0.0237 step time: 0.1975\n",
      "4/8, train_loss: 0.0210 step time: 0.2006\n",
      "5/8, train_loss: 0.0202 step time: 0.1938\n",
      "6/8, train_loss: 0.0189 step time: 0.1975\n",
      "7/8, train_loss: 0.0240 step time: 0.1825\n",
      "8/8, train_loss: 0.0181 step time: 0.1818\n",
      "epoch 398 average loss: 0.0213\n",
      "time consuming of epoch 398 is: 1.5994\n",
      "----------\n",
      "epoch 399/600\n",
      "1/8, train_loss: 0.0209 step time: 0.2402\n",
      "2/8, train_loss: 0.0204 step time: 0.2034\n",
      "3/8, train_loss: 0.0195 step time: 0.2028\n",
      "4/8, train_loss: 0.0200 step time: 0.2036\n",
      "5/8, train_loss: 0.0226 step time: 0.2010\n",
      "6/8, train_loss: 0.0200 step time: 0.1982\n",
      "7/8, train_loss: 0.0221 step time: 0.1839\n",
      "8/8, train_loss: 0.0192 step time: 0.1838\n",
      "epoch 399 average loss: 0.0206\n",
      "time consuming of epoch 399 is: 1.6187\n",
      "----------\n",
      "epoch 400/600\n",
      "1/8, train_loss: 0.0242 step time: 0.2410\n",
      "2/8, train_loss: 0.0169 step time: 0.1963\n",
      "3/8, train_loss: 0.0226 step time: 0.2016\n",
      "4/8, train_loss: 0.0182 step time: 0.2051\n",
      "5/8, train_loss: 0.0265 step time: 0.2005\n",
      "6/8, train_loss: 0.0211 step time: 0.1966\n",
      "7/8, train_loss: 0.0183 step time: 0.1836\n",
      "8/8, train_loss: 0.0255 step time: 0.1821\n",
      "epoch 400 average loss: 0.0217\n",
      "current epoch: 400 current mean dice: 0.9483 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 400 is: 2.3648\n",
      "----------\n",
      "epoch 401/600\n",
      "1/8, train_loss: 0.0181 step time: 0.2396\n",
      "2/8, train_loss: 0.0214 step time: 0.2094\n",
      "3/8, train_loss: 0.0208 step time: 0.2030\n",
      "4/8, train_loss: 0.0168 step time: 0.1952\n",
      "5/8, train_loss: 0.0210 step time: 0.2034\n",
      "6/8, train_loss: 0.0153 step time: 0.1949\n",
      "7/8, train_loss: 0.0212 step time: 0.1819\n",
      "8/8, train_loss: 0.0234 step time: 0.1819\n",
      "epoch 401 average loss: 0.0197\n",
      "time consuming of epoch 401 is: 1.6107\n",
      "----------\n",
      "epoch 402/600\n",
      "1/8, train_loss: 0.0204 step time: 0.2337\n",
      "2/8, train_loss: 0.0194 step time: 0.2002\n",
      "3/8, train_loss: 0.0173 step time: 0.2003\n",
      "4/8, train_loss: 0.0185 step time: 0.2003\n",
      "5/8, train_loss: 0.0231 step time: 0.1981\n",
      "6/8, train_loss: 0.0150 step time: 0.1997\n",
      "7/8, train_loss: 0.0205 step time: 0.1838\n",
      "8/8, train_loss: 0.0185 step time: 0.1833\n",
      "epoch 402 average loss: 0.0191\n",
      "time consuming of epoch 402 is: 1.6007\n",
      "----------\n",
      "epoch 403/600\n",
      "1/8, train_loss: 0.0170 step time: 0.2409\n",
      "2/8, train_loss: 0.0211 step time: 0.2003\n",
      "3/8, train_loss: 0.0218 step time: 0.2000\n",
      "4/8, train_loss: 0.0141 step time: 0.2030\n",
      "5/8, train_loss: 0.0163 step time: 0.2022\n",
      "6/8, train_loss: 0.0200 step time: 0.2038\n",
      "7/8, train_loss: 0.0210 step time: 0.1825\n",
      "8/8, train_loss: 0.0215 step time: 0.1838\n",
      "epoch 403 average loss: 0.0191\n",
      "time consuming of epoch 403 is: 1.6179\n",
      "----------\n",
      "epoch 404/600\n",
      "1/8, train_loss: 0.0174 step time: 0.2384\n",
      "2/8, train_loss: 0.0213 step time: 0.1930\n",
      "3/8, train_loss: 0.0182 step time: 0.1952\n",
      "4/8, train_loss: 0.0236 step time: 0.1949\n",
      "5/8, train_loss: 0.0219 step time: 0.1949\n",
      "6/8, train_loss: 0.0221 step time: 0.1934\n",
      "7/8, train_loss: 0.0170 step time: 0.1835\n",
      "8/8, train_loss: 0.0257 step time: 0.1810\n",
      "epoch 404 average loss: 0.0209\n",
      "time consuming of epoch 404 is: 1.5757\n",
      "----------\n",
      "epoch 405/600\n",
      "1/8, train_loss: 0.0197 step time: 0.2410\n",
      "2/8, train_loss: 0.0202 step time: 0.2018\n",
      "3/8, train_loss: 0.0183 step time: 0.2013\n",
      "4/8, train_loss: 0.0170 step time: 0.2003\n",
      "5/8, train_loss: 0.0195 step time: 0.1999\n",
      "6/8, train_loss: 0.0221 step time: 0.2016\n",
      "7/8, train_loss: 0.0203 step time: 0.1819\n",
      "8/8, train_loss: 0.0181 step time: 0.1822\n",
      "epoch 405 average loss: 0.0194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 405 current mean dice: 0.9479 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 405 is: 2.3662\n",
      "----------\n",
      "epoch 406/600\n",
      "1/8, train_loss: 0.0212 step time: 0.2372\n",
      "2/8, train_loss: 0.0160 step time: 0.1977\n",
      "3/8, train_loss: 0.0216 step time: 0.1971\n",
      "4/8, train_loss: 0.0232 step time: 0.1981\n",
      "5/8, train_loss: 0.0152 step time: 0.2055\n",
      "6/8, train_loss: 0.0215 step time: 0.1996\n",
      "7/8, train_loss: 0.0204 step time: 0.1831\n",
      "8/8, train_loss: 0.0181 step time: 0.1812\n",
      "epoch 406 average loss: 0.0197\n",
      "time consuming of epoch 406 is: 1.6006\n",
      "----------\n",
      "epoch 407/600\n",
      "1/8, train_loss: 0.0168 step time: 0.2383\n",
      "2/8, train_loss: 0.0167 step time: 0.2053\n",
      "3/8, train_loss: 0.0182 step time: 0.2034\n",
      "4/8, train_loss: 0.0217 step time: 0.2037\n",
      "5/8, train_loss: 0.0196 step time: 0.2024\n",
      "6/8, train_loss: 0.0183 step time: 0.2022\n",
      "7/8, train_loss: 0.0177 step time: 0.1830\n",
      "8/8, train_loss: 0.0143 step time: 0.1834\n",
      "epoch 407 average loss: 0.0179\n",
      "time consuming of epoch 407 is: 1.6230\n",
      "----------\n",
      "epoch 408/600\n",
      "1/8, train_loss: 0.0176 step time: 0.2407\n",
      "2/8, train_loss: 0.0193 step time: 0.2033\n",
      "3/8, train_loss: 0.0194 step time: 0.2005\n",
      "4/8, train_loss: 0.0178 step time: 0.2032\n",
      "5/8, train_loss: 0.0162 step time: 0.2035\n",
      "6/8, train_loss: 0.0167 step time: 0.2015\n",
      "7/8, train_loss: 0.0175 step time: 0.1835\n",
      "8/8, train_loss: 0.0163 step time: 0.1810\n",
      "epoch 408 average loss: 0.0176\n",
      "time consuming of epoch 408 is: 1.6186\n",
      "----------\n",
      "epoch 409/600\n",
      "1/8, train_loss: 0.0219 step time: 0.2300\n",
      "2/8, train_loss: 0.0202 step time: 0.1970\n",
      "3/8, train_loss: 0.0169 step time: 0.1967\n",
      "4/8, train_loss: 0.0239 step time: 0.1950\n",
      "5/8, train_loss: 0.0189 step time: 0.1978\n",
      "6/8, train_loss: 0.0183 step time: 0.1979\n",
      "7/8, train_loss: 0.0171 step time: 0.1818\n",
      "8/8, train_loss: 0.0174 step time: 0.1824\n",
      "epoch 409 average loss: 0.0193\n",
      "time consuming of epoch 409 is: 1.5799\n",
      "----------\n",
      "epoch 410/600\n",
      "1/8, train_loss: 0.0180 step time: 0.2423\n",
      "2/8, train_loss: 0.0195 step time: 0.2035\n",
      "3/8, train_loss: 0.0152 step time: 0.2033\n",
      "4/8, train_loss: 0.0182 step time: 0.2042\n",
      "5/8, train_loss: 0.0188 step time: 0.1998\n",
      "6/8, train_loss: 0.0161 step time: 0.2023\n",
      "7/8, train_loss: 0.0188 step time: 0.1830\n",
      "8/8, train_loss: 0.0191 step time: 0.1824\n",
      "epoch 410 average loss: 0.0180\n",
      "current epoch: 410 current mean dice: 0.9511 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 410 is: 2.3775\n",
      "----------\n",
      "epoch 411/600\n",
      "1/8, train_loss: 0.0190 step time: 0.2401\n",
      "2/8, train_loss: 0.0178 step time: 0.2022\n",
      "3/8, train_loss: 0.0183 step time: 0.1996\n",
      "4/8, train_loss: 0.0210 step time: 0.1976\n",
      "5/8, train_loss: 0.0177 step time: 0.2039\n",
      "6/8, train_loss: 0.0228 step time: 0.2019\n",
      "7/8, train_loss: 0.0177 step time: 0.1847\n",
      "8/8, train_loss: 0.0180 step time: 0.1836\n",
      "epoch 411 average loss: 0.0190\n",
      "time consuming of epoch 411 is: 1.6147\n",
      "----------\n",
      "epoch 412/600\n",
      "1/8, train_loss: 0.0172 step time: 0.2406\n",
      "2/8, train_loss: 0.0159 step time: 0.2054\n",
      "3/8, train_loss: 0.0217 step time: 0.2021\n",
      "4/8, train_loss: 0.0176 step time: 0.2001\n",
      "5/8, train_loss: 0.0185 step time: 0.2024\n",
      "6/8, train_loss: 0.0207 step time: 0.2001\n",
      "7/8, train_loss: 0.0161 step time: 0.1837\n",
      "8/8, train_loss: 0.0189 step time: 0.1822\n",
      "epoch 412 average loss: 0.0183\n",
      "time consuming of epoch 412 is: 1.6183\n",
      "----------\n",
      "epoch 413/600\n",
      "1/8, train_loss: 0.0194 step time: 0.2434\n",
      "2/8, train_loss: 0.0192 step time: 0.2029\n",
      "3/8, train_loss: 0.0174 step time: 0.2027\n",
      "4/8, train_loss: 0.0196 step time: 0.2017\n",
      "5/8, train_loss: 0.0160 step time: 0.2005\n",
      "6/8, train_loss: 0.0171 step time: 0.2005\n",
      "7/8, train_loss: 0.0228 step time: 0.1829\n",
      "8/8, train_loss: 0.0191 step time: 0.1811\n",
      "epoch 413 average loss: 0.0188\n",
      "time consuming of epoch 413 is: 1.6170\n",
      "----------\n",
      "epoch 414/600\n",
      "1/8, train_loss: 0.0172 step time: 0.2389\n",
      "2/8, train_loss: 0.0186 step time: 0.2014\n",
      "3/8, train_loss: 0.0233 step time: 0.2001\n",
      "4/8, train_loss: 0.0165 step time: 0.2033\n",
      "5/8, train_loss: 0.0149 step time: 0.2010\n",
      "6/8, train_loss: 0.0210 step time: 0.2022\n",
      "7/8, train_loss: 0.0196 step time: 0.1811\n",
      "8/8, train_loss: 0.0188 step time: 0.1832\n",
      "epoch 414 average loss: 0.0187\n",
      "time consuming of epoch 414 is: 1.6126\n",
      "----------\n",
      "epoch 415/600\n",
      "1/8, train_loss: 0.0175 step time: 0.2404\n",
      "2/8, train_loss: 0.0171 step time: 0.2027\n",
      "3/8, train_loss: 0.0243 step time: 0.1998\n",
      "4/8, train_loss: 0.0191 step time: 0.2019\n",
      "5/8, train_loss: 0.0185 step time: 0.2033\n",
      "6/8, train_loss: 0.0186 step time: 0.2250\n",
      "7/8, train_loss: 0.0152 step time: 0.1819\n",
      "8/8, train_loss: 0.0202 step time: 0.1830\n",
      "epoch 415 average loss: 0.0188\n",
      "current epoch: 415 current mean dice: 0.9504 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 415 is: 2.3935\n",
      "----------\n",
      "epoch 416/600\n",
      "1/8, train_loss: 0.0172 step time: 0.2336\n",
      "2/8, train_loss: 0.0179 step time: 0.1994\n",
      "3/8, train_loss: 0.0168 step time: 0.1989\n",
      "4/8, train_loss: 0.0231 step time: 0.2015\n",
      "5/8, train_loss: 0.0169 step time: 0.1973\n",
      "6/8, train_loss: 0.0170 step time: 0.1990\n",
      "7/8, train_loss: 0.0173 step time: 0.1812\n",
      "8/8, train_loss: 0.0235 step time: 0.1813\n",
      "epoch 416 average loss: 0.0187\n",
      "time consuming of epoch 416 is: 1.5935\n",
      "----------\n",
      "epoch 417/600\n",
      "1/8, train_loss: 0.0177 step time: 0.2332\n",
      "2/8, train_loss: 0.0143 step time: 0.1999\n",
      "3/8, train_loss: 0.0163 step time: 0.1990\n",
      "4/8, train_loss: 0.0184 step time: 0.2010\n",
      "5/8, train_loss: 0.0185 step time: 0.2051\n",
      "6/8, train_loss: 0.0185 step time: 0.2029\n",
      "7/8, train_loss: 0.0202 step time: 0.1842\n",
      "8/8, train_loss: 0.0174 step time: 0.1812\n",
      "epoch 417 average loss: 0.0177\n",
      "time consuming of epoch 417 is: 1.6080\n",
      "----------\n",
      "epoch 418/600\n",
      "1/8, train_loss: 0.0203 step time: 0.2380\n",
      "2/8, train_loss: 0.0223 step time: 0.2017\n",
      "3/8, train_loss: 0.0230 step time: 0.2032\n",
      "4/8, train_loss: 0.0153 step time: 0.1992\n",
      "5/8, train_loss: 0.0159 step time: 0.2022\n",
      "6/8, train_loss: 0.0197 step time: 0.2017\n",
      "7/8, train_loss: 0.0170 step time: 0.1836\n",
      "8/8, train_loss: 0.0155 step time: 0.1810\n",
      "epoch 418 average loss: 0.0186\n",
      "time consuming of epoch 418 is: 1.6119\n",
      "----------\n",
      "epoch 419/600\n",
      "1/8, train_loss: 0.0142 step time: 0.2418\n",
      "2/8, train_loss: 0.0212 step time: 0.2038\n",
      "3/8, train_loss: 0.0181 step time: 0.1995\n",
      "4/8, train_loss: 0.0192 step time: 0.2017\n",
      "5/8, train_loss: 0.0174 step time: 0.1995\n",
      "6/8, train_loss: 0.0176 step time: 0.2007\n",
      "7/8, train_loss: 0.0170 step time: 0.1826\n",
      "8/8, train_loss: 0.0195 step time: 0.1818\n",
      "epoch 419 average loss: 0.0180\n",
      "time consuming of epoch 419 is: 1.6128\n",
      "----------\n",
      "epoch 420/600\n",
      "1/8, train_loss: 0.0172 step time: 0.2406\n",
      "2/8, train_loss: 0.0186 step time: 0.2038\n",
      "3/8, train_loss: 0.0171 step time: 0.2004\n",
      "4/8, train_loss: 0.0162 step time: 0.1988\n",
      "5/8, train_loss: 0.0218 step time: 0.2004\n",
      "6/8, train_loss: 0.0170 step time: 0.2021\n",
      "7/8, train_loss: 0.0175 step time: 0.1820\n",
      "8/8, train_loss: 0.0169 step time: 0.1810\n",
      "epoch 420 average loss: 0.0178\n",
      "current epoch: 420 current mean dice: 0.9505 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 420 is: 2.3649\n",
      "----------\n",
      "epoch 421/600\n",
      "1/8, train_loss: 0.0187 step time: 0.2403\n",
      "2/8, train_loss: 0.0162 step time: 0.1990\n",
      "3/8, train_loss: 0.0171 step time: 0.2022\n",
      "4/8, train_loss: 0.0202 step time: 0.1985\n",
      "5/8, train_loss: 0.0172 step time: 0.1989\n",
      "6/8, train_loss: 0.0165 step time: 0.1974\n",
      "7/8, train_loss: 0.0180 step time: 0.1810\n",
      "8/8, train_loss: 0.0200 step time: 0.1813\n",
      "epoch 421 average loss: 0.0180\n",
      "time consuming of epoch 421 is: 1.5997\n",
      "----------\n",
      "epoch 422/600\n",
      "1/8, train_loss: 0.0198 step time: 0.2402\n",
      "2/8, train_loss: 0.0215 step time: 0.2023\n",
      "3/8, train_loss: 0.0152 step time: 0.2017\n",
      "4/8, train_loss: 0.0168 step time: 0.2004\n",
      "5/8, train_loss: 0.0165 step time: 0.2029\n",
      "6/8, train_loss: 0.0173 step time: 0.2023\n",
      "7/8, train_loss: 0.0208 step time: 0.1825\n",
      "8/8, train_loss: 0.0252 step time: 0.1817\n",
      "epoch 422 average loss: 0.0191\n",
      "time consuming of epoch 422 is: 1.6156\n",
      "----------\n",
      "epoch 423/600\n",
      "1/8, train_loss: 0.0176 step time: 0.2407\n",
      "2/8, train_loss: 0.0179 step time: 0.1993\n",
      "3/8, train_loss: 0.0172 step time: 0.2006\n",
      "4/8, train_loss: 0.0312 step time: 0.1998\n",
      "5/8, train_loss: 0.0175 step time: 0.2004\n",
      "6/8, train_loss: 0.0177 step time: 0.1994\n",
      "7/8, train_loss: 0.0186 step time: 0.1839\n",
      "8/8, train_loss: 0.0178 step time: 0.1832\n",
      "epoch 423 average loss: 0.0195\n",
      "time consuming of epoch 423 is: 1.6087\n",
      "----------\n",
      "epoch 424/600\n",
      "1/8, train_loss: 0.0193 step time: 0.2406\n",
      "2/8, train_loss: 0.0156 step time: 0.2038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8, train_loss: 0.0190 step time: 0.2020\n",
      "4/8, train_loss: 0.0195 step time: 0.2013\n",
      "5/8, train_loss: 0.0167 step time: 0.2019\n",
      "6/8, train_loss: 0.0193 step time: 0.2009\n",
      "7/8, train_loss: 0.0164 step time: 0.1844\n",
      "8/8, train_loss: 0.0150 step time: 0.1828\n",
      "epoch 424 average loss: 0.0176\n",
      "time consuming of epoch 424 is: 1.6192\n",
      "----------\n",
      "epoch 425/600\n",
      "1/8, train_loss: 0.0170 step time: 0.2385\n",
      "2/8, train_loss: 0.0240 step time: 0.2028\n",
      "3/8, train_loss: 0.0156 step time: 0.1986\n",
      "4/8, train_loss: 0.0186 step time: 0.2007\n",
      "5/8, train_loss: 0.0199 step time: 0.2005\n",
      "6/8, train_loss: 0.0180 step time: 0.2057\n",
      "7/8, train_loss: 0.0187 step time: 0.1836\n",
      "8/8, train_loss: 0.0272 step time: 0.1830\n",
      "epoch 425 average loss: 0.0199\n",
      "current epoch: 425 current mean dice: 0.9304 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 425 is: 2.3694\n",
      "----------\n",
      "epoch 426/600\n",
      "1/8, train_loss: 0.0213 step time: 0.2378\n",
      "2/8, train_loss: 0.0185 step time: 0.1988\n",
      "3/8, train_loss: 0.0154 step time: 0.1987\n",
      "4/8, train_loss: 0.0220 step time: 0.2039\n",
      "5/8, train_loss: 0.0199 step time: 0.1971\n",
      "6/8, train_loss: 0.0137 step time: 0.2009\n",
      "7/8, train_loss: 0.0179 step time: 0.1834\n",
      "8/8, train_loss: 0.0180 step time: 0.1835\n",
      "epoch 426 average loss: 0.0183\n",
      "time consuming of epoch 426 is: 1.6052\n",
      "----------\n",
      "epoch 427/600\n",
      "1/8, train_loss: 0.0154 step time: 0.2405\n",
      "2/8, train_loss: 0.0168 step time: 0.1998\n",
      "3/8, train_loss: 0.0186 step time: 0.2131\n",
      "4/8, train_loss: 0.0158 step time: 0.2005\n",
      "5/8, train_loss: 0.0181 step time: 0.2030\n",
      "6/8, train_loss: 0.0186 step time: 0.2019\n",
      "7/8, train_loss: 0.0274 step time: 0.1832\n",
      "8/8, train_loss: 0.0213 step time: 0.1824\n",
      "epoch 427 average loss: 0.0190\n",
      "time consuming of epoch 427 is: 1.6255\n",
      "----------\n",
      "epoch 428/600\n",
      "1/8, train_loss: 0.0210 step time: 0.2413\n",
      "2/8, train_loss: 0.0196 step time: 0.2027\n",
      "3/8, train_loss: 0.0148 step time: 0.2026\n",
      "4/8, train_loss: 0.0175 step time: 0.1986\n",
      "5/8, train_loss: 0.0177 step time: 0.1999\n",
      "6/8, train_loss: 0.0178 step time: 0.2030\n",
      "7/8, train_loss: 0.0199 step time: 0.1836\n",
      "8/8, train_loss: 0.0162 step time: 0.1843\n",
      "epoch 428 average loss: 0.0181\n",
      "time consuming of epoch 428 is: 1.6176\n",
      "----------\n",
      "epoch 429/600\n",
      "1/8, train_loss: 0.0210 step time: 0.2405\n",
      "2/8, train_loss: 0.0207 step time: 0.2023\n",
      "3/8, train_loss: 0.0275 step time: 0.2018\n",
      "4/8, train_loss: 0.0137 step time: 0.1987\n",
      "5/8, train_loss: 0.0161 step time: 0.2032\n",
      "6/8, train_loss: 0.0202 step time: 0.2025\n",
      "7/8, train_loss: 0.0150 step time: 0.1833\n",
      "8/8, train_loss: 0.0156 step time: 0.1819\n",
      "epoch 429 average loss: 0.0187\n",
      "time consuming of epoch 429 is: 1.6156\n",
      "----------\n",
      "epoch 430/600\n",
      "1/8, train_loss: 0.0175 step time: 0.2422\n",
      "2/8, train_loss: 0.0175 step time: 0.2034\n",
      "3/8, train_loss: 0.0174 step time: 0.2016\n",
      "4/8, train_loss: 0.0138 step time: 0.1999\n",
      "5/8, train_loss: 0.0170 step time: 0.2005\n",
      "6/8, train_loss: 0.0184 step time: 0.1912\n",
      "7/8, train_loss: 0.0168 step time: 0.1812\n",
      "8/8, train_loss: 0.0188 step time: 0.1820\n",
      "epoch 430 average loss: 0.0172\n",
      "current epoch: 430 current mean dice: 0.9522 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 430 is: 2.3599\n",
      "----------\n",
      "epoch 431/600\n",
      "1/8, train_loss: 0.0176 step time: 0.2395\n",
      "2/8, train_loss: 0.0193 step time: 0.1976\n",
      "3/8, train_loss: 0.0188 step time: 0.2002\n",
      "4/8, train_loss: 0.0164 step time: 0.1989\n",
      "5/8, train_loss: 0.0138 step time: 0.2000\n",
      "6/8, train_loss: 0.0192 step time: 0.1983\n",
      "7/8, train_loss: 0.0168 step time: 0.1792\n",
      "8/8, train_loss: 0.0206 step time: 0.1788\n",
      "epoch 431 average loss: 0.0178\n",
      "time consuming of epoch 431 is: 1.5937\n",
      "----------\n",
      "epoch 432/600\n",
      "1/8, train_loss: 0.0180 step time: 0.2306\n",
      "2/8, train_loss: 0.0125 step time: 0.1921\n",
      "3/8, train_loss: 0.0168 step time: 0.1933\n",
      "4/8, train_loss: 0.0175 step time: 0.1926\n",
      "5/8, train_loss: 0.0172 step time: 0.1981\n",
      "6/8, train_loss: 0.0162 step time: 0.1974\n",
      "7/8, train_loss: 0.0204 step time: 0.1809\n",
      "8/8, train_loss: 0.0179 step time: 0.1790\n",
      "epoch 432 average loss: 0.0171\n",
      "time consuming of epoch 432 is: 1.5651\n",
      "----------\n",
      "epoch 433/600\n",
      "1/8, train_loss: 0.0179 step time: 0.2260\n",
      "2/8, train_loss: 0.0164 step time: 0.2041\n",
      "3/8, train_loss: 0.0161 step time: 0.1984\n",
      "4/8, train_loss: 0.0150 step time: 0.2098\n",
      "5/8, train_loss: 0.0133 step time: 0.2051\n",
      "6/8, train_loss: 0.0169 step time: 0.2001\n",
      "7/8, train_loss: 0.0198 step time: 0.1829\n",
      "8/8, train_loss: 0.0189 step time: 0.1819\n",
      "epoch 433 average loss: 0.0168\n",
      "time consuming of epoch 433 is: 1.6094\n",
      "----------\n",
      "epoch 434/600\n",
      "1/8, train_loss: 0.0171 step time: 0.2412\n",
      "2/8, train_loss: 0.0159 step time: 0.2038\n",
      "3/8, train_loss: 0.0179 step time: 0.1999\n",
      "4/8, train_loss: 0.0205 step time: 0.2009\n",
      "5/8, train_loss: 0.0146 step time: 0.2002\n",
      "6/8, train_loss: 0.0190 step time: 0.2017\n",
      "7/8, train_loss: 0.0180 step time: 0.1816\n",
      "8/8, train_loss: 0.0170 step time: 0.1821\n",
      "epoch 434 average loss: 0.0175\n",
      "time consuming of epoch 434 is: 1.6129\n",
      "----------\n",
      "epoch 435/600\n",
      "1/8, train_loss: 0.0191 step time: 0.2432\n",
      "2/8, train_loss: 0.0184 step time: 0.2048\n",
      "3/8, train_loss: 0.0173 step time: 0.2018\n",
      "4/8, train_loss: 0.0159 step time: 0.2027\n",
      "5/8, train_loss: 0.0167 step time: 0.1974\n",
      "6/8, train_loss: 0.0167 step time: 0.2016\n",
      "7/8, train_loss: 0.0156 step time: 0.1826\n",
      "8/8, train_loss: 0.0151 step time: 0.1820\n",
      "epoch 435 average loss: 0.0169\n",
      "current epoch: 435 current mean dice: 0.9521 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 435 is: 2.3745\n",
      "----------\n",
      "epoch 436/600\n",
      "1/8, train_loss: 0.0188 step time: 0.2389\n",
      "2/8, train_loss: 0.0178 step time: 0.2018\n",
      "3/8, train_loss: 0.0170 step time: 0.2002\n",
      "4/8, train_loss: 0.0197 step time: 0.2017\n",
      "5/8, train_loss: 0.0192 step time: 0.1976\n",
      "6/8, train_loss: 0.0179 step time: 0.2016\n",
      "7/8, train_loss: 0.0179 step time: 0.1815\n",
      "8/8, train_loss: 0.0184 step time: 0.1827\n",
      "epoch 436 average loss: 0.0183\n",
      "time consuming of epoch 436 is: 1.6072\n",
      "----------\n",
      "epoch 437/600\n",
      "1/8, train_loss: 0.0183 step time: 0.2390\n",
      "2/8, train_loss: 0.0200 step time: 0.1996\n",
      "3/8, train_loss: 0.0202 step time: 0.1997\n",
      "4/8, train_loss: 0.0153 step time: 0.2016\n",
      "5/8, train_loss: 0.0157 step time: 0.2016\n",
      "6/8, train_loss: 0.0167 step time: 0.2016\n",
      "7/8, train_loss: 0.0156 step time: 0.1828\n",
      "8/8, train_loss: 0.0221 step time: 0.1820\n",
      "epoch 437 average loss: 0.0180\n",
      "time consuming of epoch 437 is: 1.6090\n",
      "----------\n",
      "epoch 438/600\n",
      "1/8, train_loss: 0.0189 step time: 0.2421\n",
      "2/8, train_loss: 0.0206 step time: 0.2035\n",
      "3/8, train_loss: 0.0179 step time: 0.2012\n",
      "4/8, train_loss: 0.0149 step time: 0.1996\n",
      "5/8, train_loss: 0.0175 step time: 0.2000\n",
      "6/8, train_loss: 0.0162 step time: 0.2014\n",
      "7/8, train_loss: 0.0159 step time: 0.1823\n",
      "8/8, train_loss: 0.0182 step time: 0.1817\n",
      "epoch 438 average loss: 0.0175\n",
      "time consuming of epoch 438 is: 1.6132\n",
      "----------\n",
      "epoch 439/600\n",
      "1/8, train_loss: 0.0202 step time: 0.2410\n",
      "2/8, train_loss: 0.0172 step time: 0.2128\n",
      "3/8, train_loss: 0.0154 step time: 0.1956\n",
      "4/8, train_loss: 0.0150 step time: 0.1979\n",
      "5/8, train_loss: 0.0167 step time: 0.1951\n",
      "6/8, train_loss: 0.0179 step time: 0.1980\n",
      "7/8, train_loss: 0.0172 step time: 0.1833\n",
      "8/8, train_loss: 0.0170 step time: 0.1824\n",
      "epoch 439 average loss: 0.0171\n",
      "time consuming of epoch 439 is: 1.6074\n",
      "----------\n",
      "epoch 440/600\n",
      "1/8, train_loss: 0.0154 step time: 0.2354\n",
      "2/8, train_loss: 0.0170 step time: 0.1970\n",
      "3/8, train_loss: 0.0160 step time: 0.2001\n",
      "4/8, train_loss: 0.0182 step time: 0.2038\n",
      "5/8, train_loss: 0.0130 step time: 0.2022\n",
      "6/8, train_loss: 0.0223 step time: 0.1992\n",
      "7/8, train_loss: 0.0183 step time: 0.1827\n",
      "8/8, train_loss: 0.0157 step time: 0.1829\n",
      "epoch 440 average loss: 0.0170\n",
      "current epoch: 440 current mean dice: 0.9537 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 440 is: 2.3600\n",
      "----------\n",
      "epoch 441/600\n",
      "1/8, train_loss: 0.0195 step time: 0.2348\n",
      "2/8, train_loss: 0.0193 step time: 0.1993\n",
      "3/8, train_loss: 0.0191 step time: 0.2015\n",
      "4/8, train_loss: 0.0164 step time: 0.1982\n",
      "5/8, train_loss: 0.0153 step time: 0.1980\n",
      "6/8, train_loss: 0.0147 step time: 0.2004\n",
      "7/8, train_loss: 0.0200 step time: 0.1821\n",
      "8/8, train_loss: 0.0163 step time: 0.1818\n",
      "epoch 441 average loss: 0.0176\n",
      "time consuming of epoch 441 is: 1.5971\n",
      "----------\n",
      "epoch 442/600\n",
      "1/8, train_loss: 0.0184 step time: 0.2394\n",
      "2/8, train_loss: 0.0172 step time: 0.2011\n",
      "3/8, train_loss: 0.0199 step time: 0.1985\n",
      "4/8, train_loss: 0.0146 step time: 0.2010\n",
      "5/8, train_loss: 0.0178 step time: 0.2034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/8, train_loss: 0.0115 step time: 0.2035\n",
      "7/8, train_loss: 0.0177 step time: 0.1825\n",
      "8/8, train_loss: 0.0163 step time: 0.1815\n",
      "epoch 442 average loss: 0.0167\n",
      "time consuming of epoch 442 is: 1.6125\n",
      "----------\n",
      "epoch 443/600\n",
      "1/8, train_loss: 0.0186 step time: 0.2383\n",
      "2/8, train_loss: 0.0188 step time: 0.2000\n",
      "3/8, train_loss: 0.0177 step time: 0.2017\n",
      "4/8, train_loss: 0.0148 step time: 0.1980\n",
      "5/8, train_loss: 0.0178 step time: 0.1996\n",
      "6/8, train_loss: 0.0149 step time: 0.1982\n",
      "7/8, train_loss: 0.0179 step time: 0.1820\n",
      "8/8, train_loss: 0.0155 step time: 0.1822\n",
      "epoch 443 average loss: 0.0170\n",
      "time consuming of epoch 443 is: 1.6016\n",
      "----------\n",
      "epoch 444/600\n",
      "1/8, train_loss: 0.0178 step time: 0.2351\n",
      "2/8, train_loss: 0.0157 step time: 0.1989\n",
      "3/8, train_loss: 0.0178 step time: 0.2010\n",
      "4/8, train_loss: 0.0155 step time: 0.1996\n",
      "5/8, train_loss: 0.0154 step time: 0.1990\n",
      "6/8, train_loss: 0.0178 step time: 0.1999\n",
      "7/8, train_loss: 0.0138 step time: 0.1827\n",
      "8/8, train_loss: 0.0152 step time: 0.1839\n",
      "epoch 444 average loss: 0.0161\n",
      "time consuming of epoch 444 is: 1.6016\n",
      "----------\n",
      "epoch 445/600\n",
      "1/8, train_loss: 0.0159 step time: 0.2392\n",
      "2/8, train_loss: 0.0144 step time: 0.2019\n",
      "3/8, train_loss: 0.0157 step time: 0.2045\n",
      "4/8, train_loss: 0.0176 step time: 0.2037\n",
      "5/8, train_loss: 0.0160 step time: 0.2013\n",
      "6/8, train_loss: 0.0152 step time: 0.1985\n",
      "7/8, train_loss: 0.0177 step time: 0.1835\n",
      "8/8, train_loss: 0.0203 step time: 0.1835\n",
      "epoch 445 average loss: 0.0166\n",
      "current epoch: 445 current mean dice: 0.9541 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 445 is: 2.3736\n",
      "----------\n",
      "epoch 446/600\n",
      "1/8, train_loss: 0.0156 step time: 0.2357\n",
      "2/8, train_loss: 0.0158 step time: 0.1989\n",
      "3/8, train_loss: 0.0209 step time: 0.2009\n",
      "4/8, train_loss: 0.0157 step time: 0.2018\n",
      "5/8, train_loss: 0.0160 step time: 0.1978\n",
      "6/8, train_loss: 0.0156 step time: 0.1996\n",
      "7/8, train_loss: 0.0197 step time: 0.1812\n",
      "8/8, train_loss: 0.0150 step time: 0.1828\n",
      "epoch 446 average loss: 0.0168\n",
      "time consuming of epoch 446 is: 1.5998\n",
      "----------\n",
      "epoch 447/600\n",
      "1/8, train_loss: 0.0177 step time: 0.2412\n",
      "2/8, train_loss: 0.0164 step time: 0.2086\n",
      "3/8, train_loss: 0.0155 step time: 0.2001\n",
      "4/8, train_loss: 0.0158 step time: 0.2009\n",
      "5/8, train_loss: 0.0150 step time: 0.1975\n",
      "6/8, train_loss: 0.0165 step time: 0.2086\n",
      "7/8, train_loss: 0.0168 step time: 0.1846\n",
      "8/8, train_loss: 0.0193 step time: 0.1842\n",
      "epoch 447 average loss: 0.0166\n",
      "time consuming of epoch 447 is: 1.6268\n",
      "----------\n",
      "epoch 448/600\n",
      "1/8, train_loss: 0.0167 step time: 0.2427\n",
      "2/8, train_loss: 0.0171 step time: 0.2035\n",
      "3/8, train_loss: 0.0153 step time: 0.2004\n",
      "4/8, train_loss: 0.0183 step time: 0.2016\n",
      "5/8, train_loss: 0.0184 step time: 0.2073\n",
      "6/8, train_loss: 0.0154 step time: 0.2028\n",
      "7/8, train_loss: 0.0148 step time: 0.1824\n",
      "8/8, train_loss: 0.0213 step time: 0.1835\n",
      "epoch 448 average loss: 0.0172\n",
      "time consuming of epoch 448 is: 1.6256\n",
      "----------\n",
      "epoch 449/600\n",
      "1/8, train_loss: 0.0300 step time: 0.2378\n",
      "2/8, train_loss: 0.0152 step time: 0.1994\n",
      "3/8, train_loss: 0.0175 step time: 0.1991\n",
      "4/8, train_loss: 0.0151 step time: 0.2035\n",
      "5/8, train_loss: 0.0171 step time: 0.2045\n",
      "6/8, train_loss: 0.0206 step time: 0.1985\n",
      "7/8, train_loss: 0.0154 step time: 0.1825\n",
      "8/8, train_loss: 0.0197 step time: 0.1822\n",
      "epoch 449 average loss: 0.0188\n",
      "time consuming of epoch 449 is: 1.6093\n",
      "----------\n",
      "epoch 450/600\n",
      "1/8, train_loss: 0.0155 step time: 0.2404\n",
      "2/8, train_loss: 0.0194 step time: 0.2029\n",
      "3/8, train_loss: 0.0208 step time: 0.1995\n",
      "4/8, train_loss: 0.0150 step time: 0.2002\n",
      "5/8, train_loss: 0.0193 step time: 0.1996\n",
      "6/8, train_loss: 0.0195 step time: 0.2004\n",
      "7/8, train_loss: 0.0195 step time: 0.1852\n",
      "8/8, train_loss: 0.0168 step time: 0.1825\n",
      "epoch 450 average loss: 0.0182\n",
      "current epoch: 450 current mean dice: 0.9455 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 450 is: 2.3677\n",
      "----------\n",
      "epoch 451/600\n",
      "1/8, train_loss: 0.0130 step time: 0.2318\n",
      "2/8, train_loss: 0.0198 step time: 0.1910\n",
      "3/8, train_loss: 0.0171 step time: 0.1921\n",
      "4/8, train_loss: 0.0200 step time: 0.1911\n",
      "5/8, train_loss: 0.0208 step time: 0.1912\n",
      "6/8, train_loss: 0.0208 step time: 0.1907\n",
      "7/8, train_loss: 0.0166 step time: 0.1817\n",
      "8/8, train_loss: 0.0158 step time: 0.1816\n",
      "epoch 451 average loss: 0.0180\n",
      "time consuming of epoch 451 is: 1.5523\n",
      "----------\n",
      "epoch 452/600\n",
      "1/8, train_loss: 0.0164 step time: 0.2405\n",
      "2/8, train_loss: 0.0178 step time: 0.2019\n",
      "3/8, train_loss: 0.0141 step time: 0.2000\n",
      "4/8, train_loss: 0.0196 step time: 0.2013\n",
      "5/8, train_loss: 0.0186 step time: 0.1999\n",
      "6/8, train_loss: 0.0173 step time: 0.2016\n",
      "7/8, train_loss: 0.0192 step time: 0.1828\n",
      "8/8, train_loss: 0.0164 step time: 0.1828\n",
      "epoch 452 average loss: 0.0174\n",
      "time consuming of epoch 452 is: 1.6124\n",
      "----------\n",
      "epoch 453/600\n",
      "1/8, train_loss: 0.0141 step time: 0.2397\n",
      "2/8, train_loss: 0.0170 step time: 0.2029\n",
      "3/8, train_loss: 0.0172 step time: 0.2019\n",
      "4/8, train_loss: 0.0199 step time: 0.2012\n",
      "5/8, train_loss: 0.0146 step time: 0.2042\n",
      "6/8, train_loss: 0.0183 step time: 0.2062\n",
      "7/8, train_loss: 0.0169 step time: 0.1826\n",
      "8/8, train_loss: 0.0158 step time: 0.1824\n",
      "epoch 453 average loss: 0.0167\n",
      "time consuming of epoch 453 is: 1.6227\n",
      "----------\n",
      "epoch 454/600\n",
      "1/8, train_loss: 0.0156 step time: 0.2383\n",
      "2/8, train_loss: 0.0193 step time: 0.2013\n",
      "3/8, train_loss: 0.0162 step time: 0.2019\n",
      "4/8, train_loss: 0.0156 step time: 0.2003\n",
      "5/8, train_loss: 0.0164 step time: 0.2003\n",
      "6/8, train_loss: 0.0188 step time: 0.1982\n",
      "7/8, train_loss: 0.0182 step time: 0.1827\n",
      "8/8, train_loss: 0.0167 step time: 0.1823\n",
      "epoch 454 average loss: 0.0171\n",
      "time consuming of epoch 454 is: 1.6068\n",
      "----------\n",
      "epoch 455/600\n",
      "1/8, train_loss: 0.0147 step time: 0.2378\n",
      "2/8, train_loss: 0.0193 step time: 0.2019\n",
      "3/8, train_loss: 0.0166 step time: 0.1994\n",
      "4/8, train_loss: 0.0138 step time: 0.1986\n",
      "5/8, train_loss: 0.0184 step time: 0.1974\n",
      "6/8, train_loss: 0.0207 step time: 0.1999\n",
      "7/8, train_loss: 0.0152 step time: 0.1823\n",
      "8/8, train_loss: 0.0163 step time: 0.1821\n",
      "epoch 455 average loss: 0.0169\n",
      "current epoch: 455 current mean dice: 0.9545 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 455 is: 2.3547\n",
      "----------\n",
      "epoch 456/600\n",
      "1/8, train_loss: 0.0153 step time: 0.2286\n",
      "2/8, train_loss: 0.0133 step time: 0.1976\n",
      "3/8, train_loss: 0.0176 step time: 0.1941\n",
      "4/8, train_loss: 0.0163 step time: 0.1938\n",
      "5/8, train_loss: 0.0162 step time: 0.1963\n",
      "6/8, train_loss: 0.0177 step time: 0.1947\n",
      "7/8, train_loss: 0.0165 step time: 0.1839\n",
      "8/8, train_loss: 0.0156 step time: 0.1846\n",
      "epoch 456 average loss: 0.0161\n",
      "time consuming of epoch 456 is: 1.5746\n",
      "----------\n",
      "epoch 457/600\n",
      "1/8, train_loss: 0.0179 step time: 0.2455\n",
      "2/8, train_loss: 0.0161 step time: 0.2015\n",
      "3/8, train_loss: 0.0167 step time: 0.1971\n",
      "4/8, train_loss: 0.0144 step time: 0.1996\n",
      "5/8, train_loss: 0.0198 step time: 0.1964\n",
      "6/8, train_loss: 0.0159 step time: 0.1965\n",
      "7/8, train_loss: 0.0138 step time: 0.1833\n",
      "8/8, train_loss: 0.0179 step time: 0.1824\n",
      "epoch 457 average loss: 0.0166\n",
      "time consuming of epoch 457 is: 1.6035\n",
      "----------\n",
      "epoch 458/600\n",
      "1/8, train_loss: 0.0144 step time: 0.2321\n",
      "2/8, train_loss: 0.0121 step time: 0.1975\n",
      "3/8, train_loss: 0.0166 step time: 0.1965\n",
      "4/8, train_loss: 0.0162 step time: 0.1979\n",
      "5/8, train_loss: 0.0156 step time: 0.1959\n",
      "6/8, train_loss: 0.0162 step time: 0.1955\n",
      "7/8, train_loss: 0.0164 step time: 0.1827\n",
      "8/8, train_loss: 0.0183 step time: 0.1831\n",
      "epoch 458 average loss: 0.0157\n",
      "time consuming of epoch 458 is: 1.5828\n",
      "----------\n",
      "epoch 459/600\n",
      "1/8, train_loss: 0.0187 step time: 0.2427\n",
      "2/8, train_loss: 0.0162 step time: 0.2001\n",
      "3/8, train_loss: 0.0136 step time: 0.2026\n",
      "4/8, train_loss: 0.0144 step time: 0.2044\n",
      "5/8, train_loss: 0.0176 step time: 0.1994\n",
      "6/8, train_loss: 0.0194 step time: 0.2027\n",
      "7/8, train_loss: 0.0151 step time: 0.1823\n",
      "8/8, train_loss: 0.0178 step time: 0.1822\n",
      "epoch 459 average loss: 0.0166\n",
      "time consuming of epoch 459 is: 1.6181\n",
      "----------\n",
      "epoch 460/600\n",
      "1/8, train_loss: 0.0170 step time: 0.2384\n",
      "2/8, train_loss: 0.0155 step time: 0.2024\n",
      "3/8, train_loss: 0.0130 step time: 0.1992\n",
      "4/8, train_loss: 0.0136 step time: 0.2015\n",
      "5/8, train_loss: 0.0173 step time: 0.1995\n",
      "6/8, train_loss: 0.0164 step time: 0.2015\n",
      "7/8, train_loss: 0.0158 step time: 0.1824\n",
      "8/8, train_loss: 0.0158 step time: 0.1825\n",
      "epoch 460 average loss: 0.0156\n",
      "current epoch: 460 current mean dice: 0.9511 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 460 is: 2.3643\n",
      "----------\n",
      "epoch 461/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0140 step time: 0.2391\n",
      "2/8, train_loss: 0.0143 step time: 0.1999\n",
      "3/8, train_loss: 0.0215 step time: 0.2018\n",
      "4/8, train_loss: 0.0175 step time: 0.2005\n",
      "5/8, train_loss: 0.0159 step time: 0.2013\n",
      "6/8, train_loss: 0.0169 step time: 0.1993\n",
      "7/8, train_loss: 0.0169 step time: 0.1848\n",
      "8/8, train_loss: 0.0182 step time: 0.1812\n",
      "epoch 461 average loss: 0.0169\n",
      "time consuming of epoch 461 is: 1.6090\n",
      "----------\n",
      "epoch 462/600\n",
      "1/8, train_loss: 0.0220 step time: 0.2449\n",
      "2/8, train_loss: 0.0141 step time: 0.2048\n",
      "3/8, train_loss: 0.0172 step time: 0.2085\n",
      "4/8, train_loss: 0.0126 step time: 0.2046\n",
      "5/8, train_loss: 0.0173 step time: 0.1984\n",
      "6/8, train_loss: 0.0175 step time: 0.2041\n",
      "7/8, train_loss: 0.0144 step time: 0.1814\n",
      "8/8, train_loss: 0.0159 step time: 0.1835\n",
      "epoch 462 average loss: 0.0164\n",
      "time consuming of epoch 462 is: 1.6317\n",
      "----------\n",
      "epoch 463/600\n",
      "1/8, train_loss: 0.0211 step time: 0.2381\n",
      "2/8, train_loss: 0.0160 step time: 0.2040\n",
      "3/8, train_loss: 0.0146 step time: 0.2029\n",
      "4/8, train_loss: 0.0154 step time: 0.2035\n",
      "5/8, train_loss: 0.0201 step time: 0.2033\n",
      "6/8, train_loss: 0.0182 step time: 0.1982\n",
      "7/8, train_loss: 0.0148 step time: 0.1839\n",
      "8/8, train_loss: 0.0155 step time: 0.1826\n",
      "epoch 463 average loss: 0.0170\n",
      "time consuming of epoch 463 is: 1.6179\n",
      "----------\n",
      "epoch 464/600\n",
      "1/8, train_loss: 0.0173 step time: 0.2380\n",
      "2/8, train_loss: 0.0156 step time: 0.2030\n",
      "3/8, train_loss: 0.0154 step time: 0.2025\n",
      "4/8, train_loss: 0.0174 step time: 0.1990\n",
      "5/8, train_loss: 0.0161 step time: 0.2057\n",
      "6/8, train_loss: 0.0152 step time: 0.2019\n",
      "7/8, train_loss: 0.0224 step time: 0.1828\n",
      "8/8, train_loss: 0.0185 step time: 0.1871\n",
      "epoch 464 average loss: 0.0172\n",
      "time consuming of epoch 464 is: 1.6218\n",
      "----------\n",
      "epoch 465/600\n",
      "1/8, train_loss: 0.0165 step time: 0.2731\n",
      "2/8, train_loss: 0.0179 step time: 0.1985\n",
      "3/8, train_loss: 0.0165 step time: 0.1970\n",
      "4/8, train_loss: 0.0163 step time: 0.1938\n",
      "5/8, train_loss: 0.0151 step time: 0.2005\n",
      "6/8, train_loss: 0.0150 step time: 0.2020\n",
      "7/8, train_loss: 0.0147 step time: 0.1848\n",
      "8/8, train_loss: 0.0159 step time: 0.1811\n",
      "epoch 465 average loss: 0.0160\n",
      "current epoch: 465 current mean dice: 0.9509 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 465 is: 2.3870\n",
      "----------\n",
      "epoch 466/600\n",
      "1/8, train_loss: 0.0181 step time: 0.2373\n",
      "2/8, train_loss: 0.0160 step time: 0.2038\n",
      "3/8, train_loss: 0.0159 step time: 0.2001\n",
      "4/8, train_loss: 0.0164 step time: 0.2002\n",
      "5/8, train_loss: 0.0176 step time: 0.2005\n",
      "6/8, train_loss: 0.0168 step time: 0.1992\n",
      "7/8, train_loss: 0.0160 step time: 0.1822\n",
      "8/8, train_loss: 0.0148 step time: 0.1811\n",
      "epoch 466 average loss: 0.0164\n",
      "time consuming of epoch 466 is: 1.6056\n",
      "----------\n",
      "epoch 467/600\n",
      "1/8, train_loss: 0.0144 step time: 0.2401\n",
      "2/8, train_loss: 0.0158 step time: 0.2058\n",
      "3/8, train_loss: 0.0202 step time: 0.2002\n",
      "4/8, train_loss: 0.0148 step time: 0.2020\n",
      "5/8, train_loss: 0.0181 step time: 0.2058\n",
      "6/8, train_loss: 0.0157 step time: 0.2244\n",
      "7/8, train_loss: 0.0199 step time: 0.1849\n",
      "8/8, train_loss: 0.0179 step time: 0.1837\n",
      "epoch 467 average loss: 0.0171\n",
      "time consuming of epoch 467 is: 1.6482\n",
      "----------\n",
      "epoch 468/600\n",
      "1/8, train_loss: 0.0170 step time: 0.2367\n",
      "2/8, train_loss: 0.0165 step time: 0.1977\n",
      "3/8, train_loss: 0.0176 step time: 0.2021\n",
      "4/8, train_loss: 0.0126 step time: 0.1908\n",
      "5/8, train_loss: 0.0197 step time: 0.1930\n",
      "6/8, train_loss: 0.0169 step time: 0.1915\n",
      "7/8, train_loss: 0.0159 step time: 0.1833\n",
      "8/8, train_loss: 0.0139 step time: 0.1838\n",
      "epoch 468 average loss: 0.0162\n",
      "time consuming of epoch 468 is: 1.5802\n",
      "----------\n",
      "epoch 469/600\n",
      "1/8, train_loss: 0.0158 step time: 0.2404\n",
      "2/8, train_loss: 0.0167 step time: 0.2031\n",
      "3/8, train_loss: 0.0167 step time: 0.2003\n",
      "4/8, train_loss: 0.0198 step time: 0.2012\n",
      "5/8, train_loss: 0.0141 step time: 0.1997\n",
      "6/8, train_loss: 0.0188 step time: 0.1987\n",
      "7/8, train_loss: 0.0152 step time: 0.1847\n",
      "8/8, train_loss: 0.0139 step time: 0.1836\n",
      "epoch 469 average loss: 0.0164\n",
      "time consuming of epoch 469 is: 1.6135\n",
      "----------\n",
      "epoch 470/600\n",
      "1/8, train_loss: 0.0160 step time: 0.2391\n",
      "2/8, train_loss: 0.0153 step time: 0.2024\n",
      "3/8, train_loss: 0.0173 step time: 0.2000\n",
      "4/8, train_loss: 0.0201 step time: 0.2018\n",
      "5/8, train_loss: 0.0147 step time: 0.2000\n",
      "6/8, train_loss: 0.0139 step time: 0.2200\n",
      "7/8, train_loss: 0.0147 step time: 0.1810\n",
      "8/8, train_loss: 0.0150 step time: 0.1796\n",
      "epoch 470 average loss: 0.0159\n",
      "current epoch: 470 current mean dice: 0.9539 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 470 is: 2.3807\n",
      "----------\n",
      "epoch 471/600\n",
      "1/8, train_loss: 0.0156 step time: 0.2300\n",
      "2/8, train_loss: 0.0157 step time: 0.1946\n",
      "3/8, train_loss: 0.0139 step time: 0.1954\n",
      "4/8, train_loss: 0.0153 step time: 0.1954\n",
      "5/8, train_loss: 0.0226 step time: 0.1977\n",
      "6/8, train_loss: 0.0165 step time: 0.1993\n",
      "7/8, train_loss: 0.0179 step time: 0.1843\n",
      "8/8, train_loss: 0.0149 step time: 0.1806\n",
      "epoch 471 average loss: 0.0165\n",
      "time consuming of epoch 471 is: 1.5785\n",
      "----------\n",
      "epoch 472/600\n",
      "1/8, train_loss: 0.0164 step time: 0.2389\n",
      "2/8, train_loss: 0.0200 step time: 0.2048\n",
      "3/8, train_loss: 0.0153 step time: 0.1990\n",
      "4/8, train_loss: 0.0131 step time: 0.2046\n",
      "5/8, train_loss: 0.0170 step time: 0.1985\n",
      "6/8, train_loss: 0.0166 step time: 0.1983\n",
      "7/8, train_loss: 0.0170 step time: 0.1822\n",
      "8/8, train_loss: 0.0162 step time: 0.1822\n",
      "epoch 472 average loss: 0.0164\n",
      "time consuming of epoch 472 is: 1.6098\n",
      "----------\n",
      "epoch 473/600\n",
      "1/8, train_loss: 0.0156 step time: 0.2409\n",
      "2/8, train_loss: 0.0152 step time: 0.2025\n",
      "3/8, train_loss: 0.0154 step time: 0.2017\n",
      "4/8, train_loss: 0.0176 step time: 0.2020\n",
      "5/8, train_loss: 0.0152 step time: 0.2036\n",
      "6/8, train_loss: 0.0150 step time: 0.2024\n",
      "7/8, train_loss: 0.0177 step time: 0.1842\n",
      "8/8, train_loss: 0.0141 step time: 0.1828\n",
      "epoch 473 average loss: 0.0157\n",
      "time consuming of epoch 473 is: 1.6218\n",
      "----------\n",
      "epoch 474/600\n",
      "1/8, train_loss: 0.0176 step time: 0.2506\n",
      "2/8, train_loss: 0.0145 step time: 0.2097\n",
      "3/8, train_loss: 0.0135 step time: 0.2163\n",
      "4/8, train_loss: 0.0178 step time: 0.2090\n",
      "5/8, train_loss: 0.0177 step time: 0.1985\n",
      "6/8, train_loss: 0.0155 step time: 0.2025\n",
      "7/8, train_loss: 0.0215 step time: 0.1827\n",
      "8/8, train_loss: 0.0168 step time: 0.1809\n",
      "epoch 474 average loss: 0.0169\n",
      "time consuming of epoch 474 is: 1.6522\n",
      "----------\n",
      "epoch 475/600\n",
      "1/8, train_loss: 0.0159 step time: 0.2399\n",
      "2/8, train_loss: 0.0171 step time: 0.2013\n",
      "3/8, train_loss: 0.0189 step time: 0.1979\n",
      "4/8, train_loss: 0.0134 step time: 0.2019\n",
      "5/8, train_loss: 0.0171 step time: 0.2002\n",
      "6/8, train_loss: 0.0168 step time: 0.2009\n",
      "7/8, train_loss: 0.0196 step time: 0.1822\n",
      "8/8, train_loss: 0.0154 step time: 0.1820\n",
      "epoch 475 average loss: 0.0168\n",
      "current epoch: 475 current mean dice: 0.9404 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 475 is: 2.3643\n",
      "----------\n",
      "epoch 476/600\n",
      "1/8, train_loss: 0.0197 step time: 0.2373\n",
      "2/8, train_loss: 0.0201 step time: 0.2017\n",
      "3/8, train_loss: 0.0156 step time: 0.1995\n",
      "4/8, train_loss: 0.0186 step time: 0.2019\n",
      "5/8, train_loss: 0.0144 step time: 0.1963\n",
      "6/8, train_loss: 0.0160 step time: 0.2037\n",
      "7/8, train_loss: 0.0161 step time: 0.1843\n",
      "8/8, train_loss: 0.0182 step time: 0.1832\n",
      "epoch 476 average loss: 0.0174\n",
      "time consuming of epoch 476 is: 1.6091\n",
      "----------\n",
      "epoch 477/600\n",
      "1/8, train_loss: 0.0159 step time: 0.2391\n",
      "2/8, train_loss: 0.0201 step time: 0.1979\n",
      "3/8, train_loss: 0.0184 step time: 0.1983\n",
      "4/8, train_loss: 0.0174 step time: 0.2004\n",
      "5/8, train_loss: 0.0177 step time: 0.2009\n",
      "6/8, train_loss: 0.0148 step time: 0.1978\n",
      "7/8, train_loss: 0.0152 step time: 0.1818\n",
      "8/8, train_loss: 0.0144 step time: 0.1831\n",
      "epoch 477 average loss: 0.0167\n",
      "time consuming of epoch 477 is: 1.6005\n",
      "----------\n",
      "epoch 478/600\n",
      "1/8, train_loss: 0.0180 step time: 0.2400\n",
      "2/8, train_loss: 0.0175 step time: 0.2020\n",
      "3/8, train_loss: 0.0157 step time: 0.2019\n",
      "4/8, train_loss: 0.0180 step time: 0.1978\n",
      "5/8, train_loss: 0.0177 step time: 0.2007\n",
      "6/8, train_loss: 0.0160 step time: 0.2015\n",
      "7/8, train_loss: 0.0138 step time: 0.1822\n",
      "8/8, train_loss: 0.0172 step time: 0.1835\n",
      "epoch 478 average loss: 0.0167\n",
      "time consuming of epoch 478 is: 1.6114\n",
      "----------\n",
      "epoch 479/600\n",
      "1/8, train_loss: 0.0144 step time: 0.2392\n",
      "2/8, train_loss: 0.0142 step time: 0.2019\n",
      "3/8, train_loss: 0.0174 step time: 0.2029\n",
      "4/8, train_loss: 0.0157 step time: 0.2024\n",
      "5/8, train_loss: 0.0160 step time: 0.1991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/8, train_loss: 0.0165 step time: 0.2017\n",
      "7/8, train_loss: 0.0172 step time: 0.1819\n",
      "8/8, train_loss: 0.0159 step time: 0.1817\n",
      "epoch 479 average loss: 0.0159\n",
      "time consuming of epoch 479 is: 1.6123\n",
      "----------\n",
      "epoch 480/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2380\n",
      "2/8, train_loss: 0.0162 step time: 0.1995\n",
      "3/8, train_loss: 0.0145 step time: 0.2013\n",
      "4/8, train_loss: 0.0167 step time: 0.1989\n",
      "5/8, train_loss: 0.0163 step time: 0.1994\n",
      "6/8, train_loss: 0.0148 step time: 0.2020\n",
      "7/8, train_loss: 0.0165 step time: 0.1820\n",
      "8/8, train_loss: 0.0147 step time: 0.1818\n",
      "epoch 480 average loss: 0.0156\n",
      "current epoch: 480 current mean dice: 0.9524 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 480 is: 2.3596\n",
      "----------\n",
      "epoch 481/600\n",
      "1/8, train_loss: 0.0152 step time: 0.2373\n",
      "2/8, train_loss: 0.0161 step time: 0.1993\n",
      "3/8, train_loss: 0.0145 step time: 0.1991\n",
      "4/8, train_loss: 0.0149 step time: 0.2048\n",
      "5/8, train_loss: 0.0170 step time: 0.2021\n",
      "6/8, train_loss: 0.0174 step time: 0.1993\n",
      "7/8, train_loss: 0.0175 step time: 0.1825\n",
      "8/8, train_loss: 0.0172 step time: 0.1819\n",
      "epoch 481 average loss: 0.0162\n",
      "time consuming of epoch 481 is: 1.6073\n",
      "----------\n",
      "epoch 482/600\n",
      "1/8, train_loss: 0.0141 step time: 0.2409\n",
      "2/8, train_loss: 0.0188 step time: 0.2003\n",
      "3/8, train_loss: 0.0147 step time: 0.2012\n",
      "4/8, train_loss: 0.0148 step time: 0.1995\n",
      "5/8, train_loss: 0.0135 step time: 0.1998\n",
      "6/8, train_loss: 0.0170 step time: 0.2006\n",
      "7/8, train_loss: 0.0164 step time: 0.1829\n",
      "8/8, train_loss: 0.0140 step time: 0.1819\n",
      "epoch 482 average loss: 0.0154\n",
      "time consuming of epoch 482 is: 1.6084\n",
      "----------\n",
      "epoch 483/600\n",
      "1/8, train_loss: 0.0122 step time: 0.2408\n",
      "2/8, train_loss: 0.0171 step time: 0.2028\n",
      "3/8, train_loss: 0.0169 step time: 0.2037\n",
      "4/8, train_loss: 0.0172 step time: 0.2020\n",
      "5/8, train_loss: 0.0152 step time: 0.2005\n",
      "6/8, train_loss: 0.0144 step time: 0.1980\n",
      "7/8, train_loss: 0.0177 step time: 0.1822\n",
      "8/8, train_loss: 0.0160 step time: 0.1818\n",
      "epoch 483 average loss: 0.0158\n",
      "time consuming of epoch 483 is: 1.6133\n",
      "----------\n",
      "epoch 484/600\n",
      "1/8, train_loss: 0.0170 step time: 0.2406\n",
      "2/8, train_loss: 0.0141 step time: 0.2019\n",
      "3/8, train_loss: 0.0166 step time: 0.1996\n",
      "4/8, train_loss: 0.0136 step time: 0.1998\n",
      "5/8, train_loss: 0.0167 step time: 0.1989\n",
      "6/8, train_loss: 0.0159 step time: 0.2020\n",
      "7/8, train_loss: 0.0170 step time: 0.1823\n",
      "8/8, train_loss: 0.0141 step time: 0.1817\n",
      "epoch 484 average loss: 0.0156\n",
      "time consuming of epoch 484 is: 1.6084\n",
      "----------\n",
      "epoch 485/600\n",
      "1/8, train_loss: 0.0167 step time: 0.2394\n",
      "2/8, train_loss: 0.0177 step time: 0.1998\n",
      "3/8, train_loss: 0.0166 step time: 0.2022\n",
      "4/8, train_loss: 0.0138 step time: 0.1995\n",
      "5/8, train_loss: 0.0146 step time: 0.1983\n",
      "6/8, train_loss: 0.0161 step time: 0.2053\n",
      "7/8, train_loss: 0.0177 step time: 0.1894\n",
      "8/8, train_loss: 0.0146 step time: 0.1834\n",
      "epoch 485 average loss: 0.0160\n",
      "current epoch: 485 current mean dice: 0.9547 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 485 is: 2.3763\n",
      "----------\n",
      "epoch 486/600\n",
      "1/8, train_loss: 0.0147 step time: 0.2375\n",
      "2/8, train_loss: 0.0168 step time: 0.2047\n",
      "3/8, train_loss: 0.0154 step time: 0.1981\n",
      "4/8, train_loss: 0.0204 step time: 0.2005\n",
      "5/8, train_loss: 0.0136 step time: 0.1976\n",
      "6/8, train_loss: 0.0153 step time: 0.2007\n",
      "7/8, train_loss: 0.0138 step time: 0.1819\n",
      "8/8, train_loss: 0.0148 step time: 0.1808\n",
      "epoch 486 average loss: 0.0156\n",
      "time consuming of epoch 486 is: 1.6030\n",
      "----------\n",
      "epoch 487/600\n",
      "1/8, train_loss: 0.0170 step time: 0.2403\n",
      "2/8, train_loss: 0.0155 step time: 0.2004\n",
      "3/8, train_loss: 0.0172 step time: 0.2021\n",
      "4/8, train_loss: 0.0157 step time: 0.2022\n",
      "5/8, train_loss: 0.0127 step time: 0.2000\n",
      "6/8, train_loss: 0.0139 step time: 0.2011\n",
      "7/8, train_loss: 0.0164 step time: 0.1852\n",
      "8/8, train_loss: 0.0132 step time: 0.1820\n",
      "epoch 487 average loss: 0.0152\n",
      "time consuming of epoch 487 is: 1.6148\n",
      "----------\n",
      "epoch 488/600\n",
      "1/8, train_loss: 0.0154 step time: 0.2369\n",
      "2/8, train_loss: 0.0136 step time: 0.2045\n",
      "3/8, train_loss: 0.0168 step time: 0.1991\n",
      "4/8, train_loss: 0.0143 step time: 0.2005\n",
      "5/8, train_loss: 0.0187 step time: 0.1997\n",
      "6/8, train_loss: 0.0153 step time: 0.2014\n",
      "7/8, train_loss: 0.0178 step time: 0.1828\n",
      "8/8, train_loss: 0.0149 step time: 0.1824\n",
      "epoch 488 average loss: 0.0159\n",
      "time consuming of epoch 488 is: 1.6090\n",
      "----------\n",
      "epoch 489/600\n",
      "1/8, train_loss: 0.0139 step time: 0.2406\n",
      "2/8, train_loss: 0.0169 step time: 0.2023\n",
      "3/8, train_loss: 0.0134 step time: 0.2012\n",
      "4/8, train_loss: 0.0166 step time: 0.1995\n",
      "5/8, train_loss: 0.0156 step time: 0.2014\n",
      "6/8, train_loss: 0.0217 step time: 0.1991\n",
      "7/8, train_loss: 0.0164 step time: 0.1831\n",
      "8/8, train_loss: 0.0148 step time: 0.1823\n",
      "epoch 489 average loss: 0.0161\n",
      "time consuming of epoch 489 is: 1.6110\n",
      "----------\n",
      "epoch 490/600\n",
      "1/8, train_loss: 0.0163 step time: 0.2418\n",
      "2/8, train_loss: 0.0154 step time: 0.2032\n",
      "3/8, train_loss: 0.0155 step time: 0.1999\n",
      "4/8, train_loss: 0.0137 step time: 0.2066\n",
      "5/8, train_loss: 0.0163 step time: 0.1994\n",
      "6/8, train_loss: 0.0171 step time: 0.2014\n",
      "7/8, train_loss: 0.0164 step time: 0.1843\n",
      "8/8, train_loss: 0.0172 step time: 0.1828\n",
      "epoch 490 average loss: 0.0160\n",
      "current epoch: 490 current mean dice: 0.9548 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 490 is: 2.3764\n",
      "----------\n",
      "epoch 491/600\n",
      "1/8, train_loss: 0.0155 step time: 0.2399\n",
      "2/8, train_loss: 0.0141 step time: 0.2031\n",
      "3/8, train_loss: 0.0168 step time: 0.1974\n",
      "4/8, train_loss: 0.0160 step time: 0.1976\n",
      "5/8, train_loss: 0.0177 step time: 0.1998\n",
      "6/8, train_loss: 0.0169 step time: 0.2009\n",
      "7/8, train_loss: 0.0126 step time: 0.1812\n",
      "8/8, train_loss: 0.0156 step time: 0.1812\n",
      "epoch 491 average loss: 0.0157\n",
      "time consuming of epoch 491 is: 1.6027\n",
      "----------\n",
      "epoch 492/600\n",
      "1/8, train_loss: 0.0142 step time: 0.2403\n",
      "2/8, train_loss: 0.0144 step time: 0.2005\n",
      "3/8, train_loss: 0.0167 step time: 0.2027\n",
      "4/8, train_loss: 0.0176 step time: 0.1999\n",
      "5/8, train_loss: 0.0155 step time: 0.2004\n",
      "6/8, train_loss: 0.0157 step time: 0.1984\n",
      "7/8, train_loss: 0.0170 step time: 0.1821\n",
      "8/8, train_loss: 0.0153 step time: 0.1826\n",
      "epoch 492 average loss: 0.0158\n",
      "time consuming of epoch 492 is: 1.6082\n",
      "----------\n",
      "epoch 493/600\n",
      "1/8, train_loss: 0.0150 step time: 0.2377\n",
      "2/8, train_loss: 0.0190 step time: 0.2038\n",
      "3/8, train_loss: 0.0160 step time: 0.2034\n",
      "4/8, train_loss: 0.0200 step time: 0.1990\n",
      "5/8, train_loss: 0.0151 step time: 0.2002\n",
      "6/8, train_loss: 0.0140 step time: 0.2055\n",
      "7/8, train_loss: 0.0152 step time: 0.1821\n",
      "8/8, train_loss: 0.0127 step time: 0.1820\n",
      "epoch 493 average loss: 0.0159\n",
      "time consuming of epoch 493 is: 1.6153\n",
      "----------\n",
      "epoch 494/600\n",
      "1/8, train_loss: 0.0167 step time: 0.2449\n",
      "2/8, train_loss: 0.0151 step time: 0.2005\n",
      "3/8, train_loss: 0.0155 step time: 0.2023\n",
      "4/8, train_loss: 0.0182 step time: 0.1991\n",
      "5/8, train_loss: 0.0155 step time: 0.2012\n",
      "6/8, train_loss: 0.0151 step time: 0.2004\n",
      "7/8, train_loss: 0.0164 step time: 0.1826\n",
      "8/8, train_loss: 0.0140 step time: 0.1818\n",
      "epoch 494 average loss: 0.0158\n",
      "time consuming of epoch 494 is: 1.6142\n",
      "----------\n",
      "epoch 495/600\n",
      "1/8, train_loss: 0.0168 step time: 0.2389\n",
      "2/8, train_loss: 0.0145 step time: 0.2031\n",
      "3/8, train_loss: 0.0180 step time: 0.1980\n",
      "4/8, train_loss: 0.0124 step time: 0.1999\n",
      "5/8, train_loss: 0.0170 step time: 0.2024\n",
      "6/8, train_loss: 0.0162 step time: 0.2019\n",
      "7/8, train_loss: 0.0157 step time: 0.1823\n",
      "8/8, train_loss: 0.0137 step time: 0.1824\n",
      "epoch 495 average loss: 0.0155\n",
      "current epoch: 495 current mean dice: 0.9543 best mean dice: 0.9555 at epoch: 320\n",
      "time consuming of epoch 495 is: 2.3663\n",
      "----------\n",
      "epoch 496/600\n",
      "1/8, train_loss: 0.0157 step time: 0.2368\n",
      "2/8, train_loss: 0.0166 step time: 0.1977\n",
      "3/8, train_loss: 0.0212 step time: 0.2001\n",
      "4/8, train_loss: 0.0149 step time: 0.2005\n",
      "5/8, train_loss: 0.0160 step time: 0.1989\n",
      "6/8, train_loss: 0.0161 step time: 0.1986\n",
      "7/8, train_loss: 0.0155 step time: 0.1815\n",
      "8/8, train_loss: 0.0174 step time: 0.1818\n",
      "epoch 496 average loss: 0.0167\n",
      "time consuming of epoch 496 is: 1.5969\n",
      "----------\n",
      "epoch 497/600\n",
      "1/8, train_loss: 0.0170 step time: 0.2377\n",
      "2/8, train_loss: 0.0165 step time: 0.2005\n",
      "3/8, train_loss: 0.0121 step time: 0.1999\n",
      "4/8, train_loss: 0.0145 step time: 0.1988\n",
      "5/8, train_loss: 0.0168 step time: 0.1985\n",
      "6/8, train_loss: 0.0168 step time: 0.1965\n",
      "7/8, train_loss: 0.0170 step time: 0.1820\n",
      "8/8, train_loss: 0.0138 step time: 0.1822\n",
      "epoch 497 average loss: 0.0156\n",
      "time consuming of epoch 497 is: 1.5972\n",
      "----------\n",
      "epoch 498/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0153 step time: 0.2383\n",
      "2/8, train_loss: 0.0135 step time: 0.1981\n",
      "3/8, train_loss: 0.0150 step time: 0.2024\n",
      "4/8, train_loss: 0.0147 step time: 0.2006\n",
      "5/8, train_loss: 0.0155 step time: 0.2016\n",
      "6/8, train_loss: 0.0193 step time: 0.2006\n",
      "7/8, train_loss: 0.0156 step time: 0.1839\n",
      "8/8, train_loss: 0.0189 step time: 0.1816\n",
      "epoch 498 average loss: 0.0160\n",
      "time consuming of epoch 498 is: 1.6087\n",
      "----------\n",
      "epoch 499/600\n",
      "1/8, train_loss: 0.0175 step time: 0.2368\n",
      "2/8, train_loss: 0.0157 step time: 0.2022\n",
      "3/8, train_loss: 0.0171 step time: 0.1992\n",
      "4/8, train_loss: 0.0141 step time: 0.1998\n",
      "5/8, train_loss: 0.0165 step time: 0.2036\n",
      "6/8, train_loss: 0.0152 step time: 0.1988\n",
      "7/8, train_loss: 0.0159 step time: 0.1841\n",
      "8/8, train_loss: 0.0181 step time: 0.1819\n",
      "epoch 499 average loss: 0.0163\n",
      "time consuming of epoch 499 is: 1.6078\n",
      "----------\n",
      "epoch 500/600\n",
      "1/8, train_loss: 0.0166 step time: 0.2419\n",
      "2/8, train_loss: 0.0177 step time: 0.2039\n",
      "3/8, train_loss: 0.0167 step time: 0.1979\n",
      "4/8, train_loss: 0.0156 step time: 0.2006\n",
      "5/8, train_loss: 0.0172 step time: 0.1989\n",
      "6/8, train_loss: 0.0159 step time: 0.2000\n",
      "7/8, train_loss: 0.0161 step time: 0.1824\n",
      "8/8, train_loss: 0.0154 step time: 0.1817\n",
      "epoch 500 average loss: 0.0164\n",
      "saved new best metric model\n",
      "current epoch: 500 current mean dice: 0.9558 best mean dice: 0.9558 at epoch: 500\n",
      "time consuming of epoch 500 is: 2.5040\n",
      "----------\n",
      "epoch 501/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2355\n",
      "2/8, train_loss: 0.0153 step time: 0.1980\n",
      "3/8, train_loss: 0.0154 step time: 0.2006\n",
      "4/8, train_loss: 0.0153 step time: 0.2001\n",
      "5/8, train_loss: 0.0157 step time: 0.2009\n",
      "6/8, train_loss: 0.0179 step time: 0.1995\n",
      "7/8, train_loss: 0.0160 step time: 0.1822\n",
      "8/8, train_loss: 0.0158 step time: 0.1809\n",
      "epoch 501 average loss: 0.0155\n",
      "time consuming of epoch 501 is: 1.5988\n",
      "----------\n",
      "epoch 502/600\n",
      "1/8, train_loss: 0.0162 step time: 0.2411\n",
      "2/8, train_loss: 0.0145 step time: 0.1996\n",
      "3/8, train_loss: 0.0169 step time: 0.2012\n",
      "4/8, train_loss: 0.0178 step time: 0.2003\n",
      "5/8, train_loss: 0.0129 step time: 0.1999\n",
      "6/8, train_loss: 0.0147 step time: 0.1997\n",
      "7/8, train_loss: 0.0182 step time: 0.1845\n",
      "8/8, train_loss: 0.0170 step time: 0.1809\n",
      "epoch 502 average loss: 0.0160\n",
      "time consuming of epoch 502 is: 1.6085\n",
      "----------\n",
      "epoch 503/600\n",
      "1/8, train_loss: 0.0185 step time: 0.2393\n",
      "2/8, train_loss: 0.0143 step time: 0.2038\n",
      "3/8, train_loss: 0.0154 step time: 0.2029\n",
      "4/8, train_loss: 0.0157 step time: 0.2003\n",
      "5/8, train_loss: 0.0152 step time: 0.2023\n",
      "6/8, train_loss: 0.0132 step time: 0.1993\n",
      "7/8, train_loss: 0.0149 step time: 0.1827\n",
      "8/8, train_loss: 0.0157 step time: 0.1813\n",
      "epoch 503 average loss: 0.0154\n",
      "time consuming of epoch 503 is: 1.6132\n",
      "----------\n",
      "epoch 504/600\n",
      "1/8, train_loss: 0.0156 step time: 0.2400\n",
      "2/8, train_loss: 0.0135 step time: 0.1971\n",
      "3/8, train_loss: 0.0164 step time: 0.2038\n",
      "4/8, train_loss: 0.0143 step time: 0.1986\n",
      "5/8, train_loss: 0.0185 step time: 0.2015\n",
      "6/8, train_loss: 0.0167 step time: 0.2014\n",
      "7/8, train_loss: 0.0170 step time: 0.1825\n",
      "8/8, train_loss: 0.0159 step time: 0.1821\n",
      "epoch 504 average loss: 0.0160\n",
      "time consuming of epoch 504 is: 1.6084\n",
      "----------\n",
      "epoch 505/600\n",
      "1/8, train_loss: 0.0180 step time: 0.2411\n",
      "2/8, train_loss: 0.0148 step time: 0.2055\n",
      "3/8, train_loss: 0.0161 step time: 0.2023\n",
      "4/8, train_loss: 0.0138 step time: 0.2027\n",
      "5/8, train_loss: 0.0155 step time: 0.1979\n",
      "6/8, train_loss: 0.0123 step time: 0.2021\n",
      "7/8, train_loss: 0.0148 step time: 0.1828\n",
      "8/8, train_loss: 0.0126 step time: 0.1835\n",
      "epoch 505 average loss: 0.0147\n",
      "current epoch: 505 current mean dice: 0.9492 best mean dice: 0.9558 at epoch: 500\n",
      "time consuming of epoch 505 is: 2.3758\n",
      "----------\n",
      "epoch 506/600\n",
      "1/8, train_loss: 0.0126 step time: 0.2359\n",
      "2/8, train_loss: 0.0166 step time: 0.2029\n",
      "3/8, train_loss: 0.0162 step time: 0.2004\n",
      "4/8, train_loss: 0.0198 step time: 0.2012\n",
      "5/8, train_loss: 0.0146 step time: 0.2036\n",
      "6/8, train_loss: 0.0138 step time: 0.2017\n",
      "7/8, train_loss: 0.0151 step time: 0.1831\n",
      "8/8, train_loss: 0.0144 step time: 0.1827\n",
      "epoch 506 average loss: 0.0154\n",
      "time consuming of epoch 506 is: 1.6127\n",
      "----------\n",
      "epoch 507/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2388\n",
      "2/8, train_loss: 0.0125 step time: 0.1995\n",
      "3/8, train_loss: 0.0176 step time: 0.2020\n",
      "4/8, train_loss: 0.0147 step time: 0.2035\n",
      "5/8, train_loss: 0.0144 step time: 0.2027\n",
      "6/8, train_loss: 0.0157 step time: 0.1988\n",
      "7/8, train_loss: 0.0142 step time: 0.1846\n",
      "8/8, train_loss: 0.0167 step time: 0.1837\n",
      "epoch 507 average loss: 0.0151\n",
      "time consuming of epoch 507 is: 1.6152\n",
      "----------\n",
      "epoch 508/600\n",
      "1/8, train_loss: 0.0134 step time: 0.2409\n",
      "2/8, train_loss: 0.0152 step time: 0.2017\n",
      "3/8, train_loss: 0.0162 step time: 0.2024\n",
      "4/8, train_loss: 0.0173 step time: 0.2023\n",
      "5/8, train_loss: 0.0154 step time: 0.1992\n",
      "6/8, train_loss: 0.0182 step time: 0.2012\n",
      "7/8, train_loss: 0.0149 step time: 0.1834\n",
      "8/8, train_loss: 0.0134 step time: 0.1813\n",
      "epoch 508 average loss: 0.0155\n",
      "time consuming of epoch 508 is: 1.6142\n",
      "----------\n",
      "epoch 509/600\n",
      "1/8, train_loss: 0.0153 step time: 0.2432\n",
      "2/8, train_loss: 0.0125 step time: 0.2001\n",
      "3/8, train_loss: 0.0141 step time: 0.2007\n",
      "4/8, train_loss: 0.0151 step time: 0.2016\n",
      "5/8, train_loss: 0.0163 step time: 0.1997\n",
      "6/8, train_loss: 0.0189 step time: 0.2002\n",
      "7/8, train_loss: 0.0206 step time: 0.1838\n",
      "8/8, train_loss: 0.0151 step time: 0.1835\n",
      "epoch 509 average loss: 0.0160\n",
      "time consuming of epoch 509 is: 1.6144\n",
      "----------\n",
      "epoch 510/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2384\n",
      "2/8, train_loss: 0.0125 step time: 0.2044\n",
      "3/8, train_loss: 0.0114 step time: 0.2016\n",
      "4/8, train_loss: 0.0158 step time: 0.1990\n",
      "5/8, train_loss: 0.0152 step time: 0.2012\n",
      "6/8, train_loss: 0.0168 step time: 0.2013\n",
      "7/8, train_loss: 0.0131 step time: 0.1825\n",
      "8/8, train_loss: 0.0210 step time: 0.1843\n",
      "epoch 510 average loss: 0.0151\n",
      "current epoch: 510 current mean dice: 0.9539 best mean dice: 0.9558 at epoch: 500\n",
      "time consuming of epoch 510 is: 2.3706\n",
      "----------\n",
      "epoch 511/600\n",
      "1/8, train_loss: 0.0143 step time: 0.2324\n",
      "2/8, train_loss: 0.0169 step time: 0.1918\n",
      "3/8, train_loss: 0.0135 step time: 0.1940\n",
      "4/8, train_loss: 0.0165 step time: 0.2688\n",
      "5/8, train_loss: 0.0182 step time: 0.1955\n",
      "6/8, train_loss: 0.0157 step time: 0.1928\n",
      "7/8, train_loss: 0.0126 step time: 0.1832\n",
      "8/8, train_loss: 0.0137 step time: 0.1838\n",
      "epoch 511 average loss: 0.0152\n",
      "time consuming of epoch 511 is: 1.6434\n",
      "----------\n",
      "epoch 512/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2413\n",
      "2/8, train_loss: 0.0154 step time: 0.2028\n",
      "3/8, train_loss: 0.0156 step time: 0.2031\n",
      "4/8, train_loss: 0.0171 step time: 0.1999\n",
      "5/8, train_loss: 0.0148 step time: 0.2039\n",
      "6/8, train_loss: 0.0200 step time: 0.2003\n",
      "7/8, train_loss: 0.0136 step time: 0.1833\n",
      "8/8, train_loss: 0.0166 step time: 0.1840\n",
      "epoch 512 average loss: 0.0159\n",
      "time consuming of epoch 512 is: 1.6200\n",
      "----------\n",
      "epoch 513/600\n",
      "1/8, train_loss: 0.0154 step time: 0.2416\n",
      "2/8, train_loss: 0.0159 step time: 0.2023\n",
      "3/8, train_loss: 0.0140 step time: 0.2029\n",
      "4/8, train_loss: 0.0147 step time: 0.2017\n",
      "5/8, train_loss: 0.0161 step time: 0.2021\n",
      "6/8, train_loss: 0.0145 step time: 0.2005\n",
      "7/8, train_loss: 0.0165 step time: 0.1846\n",
      "8/8, train_loss: 0.0150 step time: 0.1839\n",
      "epoch 513 average loss: 0.0153\n",
      "time consuming of epoch 513 is: 1.6210\n",
      "----------\n",
      "epoch 514/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2418\n",
      "2/8, train_loss: 0.0167 step time: 0.2040\n",
      "3/8, train_loss: 0.0143 step time: 0.1993\n",
      "4/8, train_loss: 0.0122 step time: 0.2009\n",
      "5/8, train_loss: 0.0175 step time: 0.2005\n",
      "6/8, train_loss: 0.0172 step time: 0.1996\n",
      "7/8, train_loss: 0.0189 step time: 0.1822\n",
      "8/8, train_loss: 0.0158 step time: 0.1811\n",
      "epoch 514 average loss: 0.0160\n",
      "time consuming of epoch 514 is: 1.6108\n",
      "----------\n",
      "epoch 515/600\n",
      "1/8, train_loss: 0.0122 step time: 0.2360\n",
      "2/8, train_loss: 0.0174 step time: 0.2018\n",
      "3/8, train_loss: 0.0136 step time: 0.2018\n",
      "4/8, train_loss: 0.0150 step time: 0.2019\n",
      "5/8, train_loss: 0.0157 step time: 0.2026\n",
      "6/8, train_loss: 0.0153 step time: 0.2012\n",
      "7/8, train_loss: 0.0161 step time: 0.1818\n",
      "8/8, train_loss: 0.0164 step time: 0.1831\n",
      "epoch 515 average loss: 0.0152\n",
      "current epoch: 515 current mean dice: 0.9555 best mean dice: 0.9558 at epoch: 500\n",
      "time consuming of epoch 515 is: 2.3642\n",
      "----------\n",
      "epoch 516/600\n",
      "1/8, train_loss: 0.0167 step time: 0.2349\n",
      "2/8, train_loss: 0.0133 step time: 0.1905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8, train_loss: 0.0171 step time: 0.1915\n",
      "4/8, train_loss: 0.0136 step time: 0.1924\n",
      "5/8, train_loss: 0.0169 step time: 0.2020\n",
      "6/8, train_loss: 0.0172 step time: 0.1988\n",
      "7/8, train_loss: 0.0133 step time: 0.1823\n",
      "8/8, train_loss: 0.0170 step time: 0.1829\n",
      "epoch 516 average loss: 0.0156\n",
      "time consuming of epoch 516 is: 1.5764\n",
      "----------\n",
      "epoch 517/600\n",
      "1/8, train_loss: 0.0144 step time: 0.2379\n",
      "2/8, train_loss: 0.0123 step time: 0.1971\n",
      "3/8, train_loss: 0.0168 step time: 0.2018\n",
      "4/8, train_loss: 0.0185 step time: 0.1970\n",
      "5/8, train_loss: 0.0150 step time: 0.1988\n",
      "6/8, train_loss: 0.0164 step time: 0.1979\n",
      "7/8, train_loss: 0.0194 step time: 0.1793\n",
      "8/8, train_loss: 0.0141 step time: 0.1789\n",
      "epoch 517 average loss: 0.0159\n",
      "time consuming of epoch 517 is: 1.5903\n",
      "----------\n",
      "epoch 518/600\n",
      "1/8, train_loss: 0.0147 step time: 0.2351\n",
      "2/8, train_loss: 0.0151 step time: 0.1944\n",
      "3/8, train_loss: 0.0154 step time: 0.1967\n",
      "4/8, train_loss: 0.0149 step time: 0.1971\n",
      "5/8, train_loss: 0.0118 step time: 0.1949\n",
      "6/8, train_loss: 0.0158 step time: 0.2043\n",
      "7/8, train_loss: 0.0145 step time: 0.1824\n",
      "8/8, train_loss: 0.0145 step time: 0.1818\n",
      "epoch 518 average loss: 0.0146\n",
      "time consuming of epoch 518 is: 1.5879\n",
      "----------\n",
      "epoch 519/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2355\n",
      "2/8, train_loss: 0.0156 step time: 0.1931\n",
      "3/8, train_loss: 0.0129 step time: 0.1916\n",
      "4/8, train_loss: 0.0144 step time: 0.1923\n",
      "5/8, train_loss: 0.0169 step time: 0.1944\n",
      "6/8, train_loss: 0.0131 step time: 0.1926\n",
      "7/8, train_loss: 0.0162 step time: 0.1795\n",
      "8/8, train_loss: 0.0162 step time: 0.1793\n",
      "epoch 519 average loss: 0.0150\n",
      "time consuming of epoch 519 is: 1.5593\n",
      "----------\n",
      "epoch 520/600\n",
      "1/8, train_loss: 0.0138 step time: 0.2319\n",
      "2/8, train_loss: 0.0154 step time: 0.1953\n",
      "3/8, train_loss: 0.0156 step time: 0.1970\n",
      "4/8, train_loss: 0.0169 step time: 0.1975\n",
      "5/8, train_loss: 0.0147 step time: 0.2036\n",
      "6/8, train_loss: 0.0172 step time: 0.2001\n",
      "7/8, train_loss: 0.0147 step time: 0.1833\n",
      "8/8, train_loss: 0.0166 step time: 0.1821\n",
      "epoch 520 average loss: 0.0156\n",
      "current epoch: 520 current mean dice: 0.9549 best mean dice: 0.9558 at epoch: 500\n",
      "time consuming of epoch 520 is: 2.3481\n",
      "----------\n",
      "epoch 521/600\n",
      "1/8, train_loss: 0.0155 step time: 0.2406\n",
      "2/8, train_loss: 0.0179 step time: 0.1976\n",
      "3/8, train_loss: 0.0143 step time: 0.1988\n",
      "4/8, train_loss: 0.0135 step time: 0.2018\n",
      "5/8, train_loss: 0.0138 step time: 0.1954\n",
      "6/8, train_loss: 0.0166 step time: 0.1978\n",
      "7/8, train_loss: 0.0170 step time: 0.1817\n",
      "8/8, train_loss: 0.0156 step time: 0.1818\n",
      "epoch 521 average loss: 0.0155\n",
      "time consuming of epoch 521 is: 1.5965\n",
      "----------\n",
      "epoch 522/600\n",
      "1/8, train_loss: 0.0146 step time: 0.2407\n",
      "2/8, train_loss: 0.0131 step time: 0.2009\n",
      "3/8, train_loss: 0.0170 step time: 0.2029\n",
      "4/8, train_loss: 0.0168 step time: 0.2095\n",
      "5/8, train_loss: 0.0147 step time: 0.2081\n",
      "6/8, train_loss: 0.0142 step time: 0.2101\n",
      "7/8, train_loss: 0.0130 step time: 0.1822\n",
      "8/8, train_loss: 0.0132 step time: 0.1820\n",
      "epoch 522 average loss: 0.0146\n",
      "time consuming of epoch 522 is: 1.6378\n",
      "----------\n",
      "epoch 523/600\n",
      "1/8, train_loss: 0.0139 step time: 0.2418\n",
      "2/8, train_loss: 0.0144 step time: 0.2047\n",
      "3/8, train_loss: 0.0151 step time: 0.2016\n",
      "4/8, train_loss: 0.0165 step time: 0.1986\n",
      "5/8, train_loss: 0.0133 step time: 0.2004\n",
      "6/8, train_loss: 0.0138 step time: 0.2014\n",
      "7/8, train_loss: 0.0137 step time: 0.1826\n",
      "8/8, train_loss: 0.0155 step time: 0.1823\n",
      "epoch 523 average loss: 0.0145\n",
      "time consuming of epoch 523 is: 1.6150\n",
      "----------\n",
      "epoch 524/600\n",
      "1/8, train_loss: 0.0164 step time: 0.2409\n",
      "2/8, train_loss: 0.0176 step time: 0.2000\n",
      "3/8, train_loss: 0.0142 step time: 0.2028\n",
      "4/8, train_loss: 0.0158 step time: 0.2005\n",
      "5/8, train_loss: 0.0170 step time: 0.2023\n",
      "6/8, train_loss: 0.0159 step time: 0.2003\n",
      "7/8, train_loss: 0.0173 step time: 0.1851\n",
      "8/8, train_loss: 0.0153 step time: 0.1821\n",
      "epoch 524 average loss: 0.0162\n",
      "time consuming of epoch 524 is: 1.6153\n",
      "----------\n",
      "epoch 525/600\n",
      "1/8, train_loss: 0.0176 step time: 0.2414\n",
      "2/8, train_loss: 0.0142 step time: 0.2040\n",
      "3/8, train_loss: 0.0160 step time: 0.2020\n",
      "4/8, train_loss: 0.0146 step time: 0.1970\n",
      "5/8, train_loss: 0.0161 step time: 0.2006\n",
      "6/8, train_loss: 0.0147 step time: 0.2026\n",
      "7/8, train_loss: 0.0159 step time: 0.1825\n",
      "8/8, train_loss: 0.0168 step time: 0.1821\n",
      "epoch 525 average loss: 0.0157\n",
      "current epoch: 525 current mean dice: 0.9479 best mean dice: 0.9558 at epoch: 500\n",
      "time consuming of epoch 525 is: 2.3688\n",
      "----------\n",
      "epoch 526/600\n",
      "1/8, train_loss: 0.0213 step time: 0.2413\n",
      "2/8, train_loss: 0.0155 step time: 0.1987\n",
      "3/8, train_loss: 0.0143 step time: 0.1996\n",
      "4/8, train_loss: 0.0163 step time: 0.1988\n",
      "5/8, train_loss: 0.0168 step time: 0.2012\n",
      "6/8, train_loss: 0.0137 step time: 0.2004\n",
      "7/8, train_loss: 0.0181 step time: 0.1820\n",
      "8/8, train_loss: 0.0124 step time: 0.1811\n",
      "epoch 526 average loss: 0.0160\n",
      "time consuming of epoch 526 is: 1.6043\n",
      "----------\n",
      "epoch 527/600\n",
      "1/8, train_loss: 0.0164 step time: 0.2407\n",
      "2/8, train_loss: 0.0136 step time: 0.2043\n",
      "3/8, train_loss: 0.0144 step time: 0.2005\n",
      "4/8, train_loss: 0.0149 step time: 0.2020\n",
      "5/8, train_loss: 0.0135 step time: 0.1992\n",
      "6/8, train_loss: 0.0172 step time: 0.2018\n",
      "7/8, train_loss: 0.0155 step time: 0.1828\n",
      "8/8, train_loss: 0.0155 step time: 0.1827\n",
      "epoch 527 average loss: 0.0151\n",
      "time consuming of epoch 527 is: 1.6156\n",
      "----------\n",
      "epoch 528/600\n",
      "1/8, train_loss: 0.0146 step time: 0.2362\n",
      "2/8, train_loss: 0.0184 step time: 0.1973\n",
      "3/8, train_loss: 0.0122 step time: 0.1970\n",
      "4/8, train_loss: 0.0175 step time: 0.1971\n",
      "5/8, train_loss: 0.0142 step time: 0.1987\n",
      "6/8, train_loss: 0.0146 step time: 0.1966\n",
      "7/8, train_loss: 0.0169 step time: 0.1827\n",
      "8/8, train_loss: 0.0146 step time: 0.1822\n",
      "epoch 528 average loss: 0.0154\n",
      "time consuming of epoch 528 is: 1.5892\n",
      "----------\n",
      "epoch 529/600\n",
      "1/8, train_loss: 0.0191 step time: 0.2294\n",
      "2/8, train_loss: 0.0144 step time: 0.1947\n",
      "3/8, train_loss: 0.0147 step time: 0.1959\n",
      "4/8, train_loss: 0.0147 step time: 0.1975\n",
      "5/8, train_loss: 0.0156 step time: 0.2023\n",
      "6/8, train_loss: 0.0141 step time: 0.2033\n",
      "7/8, train_loss: 0.0112 step time: 0.1841\n",
      "8/8, train_loss: 0.0166 step time: 0.1828\n",
      "epoch 529 average loss: 0.0150\n",
      "time consuming of epoch 529 is: 1.5917\n",
      "----------\n",
      "epoch 530/600\n",
      "1/8, train_loss: 0.0134 step time: 0.2360\n",
      "2/8, train_loss: 0.0134 step time: 0.1978\n",
      "3/8, train_loss: 0.0132 step time: 0.1985\n",
      "4/8, train_loss: 0.0169 step time: 0.1987\n",
      "5/8, train_loss: 0.0138 step time: 0.2012\n",
      "6/8, train_loss: 0.0191 step time: 0.2036\n",
      "7/8, train_loss: 0.0154 step time: 0.1827\n",
      "8/8, train_loss: 0.0165 step time: 0.1838\n",
      "epoch 530 average loss: 0.0152\n",
      "current epoch: 530 current mean dice: 0.9552 best mean dice: 0.9558 at epoch: 500\n",
      "time consuming of epoch 530 is: 2.3614\n",
      "----------\n",
      "epoch 531/600\n",
      "1/8, train_loss: 0.0146 step time: 0.2409\n",
      "2/8, train_loss: 0.0129 step time: 0.1998\n",
      "3/8, train_loss: 0.0139 step time: 0.2010\n",
      "4/8, train_loss: 0.0134 step time: 0.2024\n",
      "5/8, train_loss: 0.0152 step time: 0.1983\n",
      "6/8, train_loss: 0.0138 step time: 0.2019\n",
      "7/8, train_loss: 0.0163 step time: 0.1817\n",
      "8/8, train_loss: 0.0168 step time: 0.1815\n",
      "epoch 531 average loss: 0.0146\n",
      "time consuming of epoch 531 is: 1.6086\n",
      "----------\n",
      "epoch 532/600\n",
      "1/8, train_loss: 0.0176 step time: 0.2404\n",
      "2/8, train_loss: 0.0175 step time: 0.2026\n",
      "3/8, train_loss: 0.0135 step time: 0.2003\n",
      "4/8, train_loss: 0.0154 step time: 0.2018\n",
      "5/8, train_loss: 0.0124 step time: 0.2021\n",
      "6/8, train_loss: 0.0154 step time: 0.2019\n",
      "7/8, train_loss: 0.0152 step time: 0.1825\n",
      "8/8, train_loss: 0.0144 step time: 0.1814\n",
      "epoch 532 average loss: 0.0152\n",
      "time consuming of epoch 532 is: 1.6146\n",
      "----------\n",
      "epoch 533/600\n",
      "1/8, train_loss: 0.0141 step time: 0.2417\n",
      "2/8, train_loss: 0.0145 step time: 0.2063\n",
      "3/8, train_loss: 0.0160 step time: 0.2059\n",
      "4/8, train_loss: 0.0144 step time: 0.2005\n",
      "5/8, train_loss: 0.0152 step time: 0.1992\n",
      "6/8, train_loss: 0.0161 step time: 0.2006\n",
      "7/8, train_loss: 0.0159 step time: 0.1840\n",
      "8/8, train_loss: 0.0167 step time: 0.1819\n",
      "epoch 533 average loss: 0.0154\n",
      "time consuming of epoch 533 is: 1.6213\n",
      "----------\n",
      "epoch 534/600\n",
      "1/8, train_loss: 0.0138 step time: 0.2405\n",
      "2/8, train_loss: 0.0168 step time: 0.2012\n",
      "3/8, train_loss: 0.0140 step time: 0.2006\n",
      "4/8, train_loss: 0.0137 step time: 0.2012\n",
      "5/8, train_loss: 0.0169 step time: 0.1998\n",
      "6/8, train_loss: 0.0168 step time: 0.2025\n",
      "7/8, train_loss: 0.0139 step time: 0.1837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8, train_loss: 0.0154 step time: 0.1825\n",
      "epoch 534 average loss: 0.0152\n",
      "time consuming of epoch 534 is: 1.6137\n",
      "----------\n",
      "epoch 535/600\n",
      "1/8, train_loss: 0.0152 step time: 0.2409\n",
      "2/8, train_loss: 0.0130 step time: 0.2021\n",
      "3/8, train_loss: 0.0164 step time: 0.2002\n",
      "4/8, train_loss: 0.0131 step time: 0.1983\n",
      "5/8, train_loss: 0.0156 step time: 0.2041\n",
      "6/8, train_loss: 0.0134 step time: 0.1988\n",
      "7/8, train_loss: 0.0150 step time: 0.1811\n",
      "8/8, train_loss: 0.0160 step time: 0.1822\n",
      "epoch 535 average loss: 0.0147\n",
      "current epoch: 535 current mean dice: 0.9547 best mean dice: 0.9558 at epoch: 500\n",
      "time consuming of epoch 535 is: 2.3647\n",
      "----------\n",
      "epoch 536/600\n",
      "1/8, train_loss: 0.0133 step time: 0.2322\n",
      "2/8, train_loss: 0.0190 step time: 0.1963\n",
      "3/8, train_loss: 0.0138 step time: 0.1994\n",
      "4/8, train_loss: 0.0138 step time: 0.1987\n",
      "5/8, train_loss: 0.0111 step time: 0.1989\n",
      "6/8, train_loss: 0.0158 step time: 0.2024\n",
      "7/8, train_loss: 0.0165 step time: 0.1812\n",
      "8/8, train_loss: 0.0151 step time: 0.1809\n",
      "epoch 536 average loss: 0.0148\n",
      "time consuming of epoch 536 is: 1.5912\n",
      "----------\n",
      "epoch 537/600\n",
      "1/8, train_loss: 0.0170 step time: 0.2446\n",
      "2/8, train_loss: 0.0169 step time: 0.1997\n",
      "3/8, train_loss: 0.0152 step time: 0.2004\n",
      "4/8, train_loss: 0.0126 step time: 0.1980\n",
      "5/8, train_loss: 0.0127 step time: 0.2000\n",
      "6/8, train_loss: 0.0154 step time: 0.1998\n",
      "7/8, train_loss: 0.0157 step time: 0.1824\n",
      "8/8, train_loss: 0.0143 step time: 0.1822\n",
      "epoch 537 average loss: 0.0150\n",
      "time consuming of epoch 537 is: 1.6086\n",
      "----------\n",
      "epoch 538/600\n",
      "1/8, train_loss: 0.0165 step time: 0.2398\n",
      "2/8, train_loss: 0.0150 step time: 0.2014\n",
      "3/8, train_loss: 0.0141 step time: 0.2002\n",
      "4/8, train_loss: 0.0164 step time: 0.1988\n",
      "5/8, train_loss: 0.0144 step time: 0.2018\n",
      "6/8, train_loss: 0.0137 step time: 0.2017\n",
      "7/8, train_loss: 0.0129 step time: 0.1819\n",
      "8/8, train_loss: 0.0194 step time: 0.1822\n",
      "epoch 538 average loss: 0.0153\n",
      "time consuming of epoch 538 is: 1.6095\n",
      "----------\n",
      "epoch 539/600\n",
      "1/8, train_loss: 0.0141 step time: 0.2411\n",
      "2/8, train_loss: 0.0149 step time: 0.2032\n",
      "3/8, train_loss: 0.0158 step time: 0.2003\n",
      "4/8, train_loss: 0.0146 step time: 0.1980\n",
      "5/8, train_loss: 0.0142 step time: 0.2017\n",
      "6/8, train_loss: 0.0153 step time: 0.1990\n",
      "7/8, train_loss: 0.0170 step time: 0.1823\n",
      "8/8, train_loss: 0.0171 step time: 0.1822\n",
      "epoch 539 average loss: 0.0154\n",
      "time consuming of epoch 539 is: 1.6094\n",
      "----------\n",
      "epoch 540/600\n",
      "1/8, train_loss: 0.0163 step time: 0.2365\n",
      "2/8, train_loss: 0.0139 step time: 0.1967\n",
      "3/8, train_loss: 0.0145 step time: 0.1987\n",
      "4/8, train_loss: 0.0173 step time: 0.1978\n",
      "5/8, train_loss: 0.0147 step time: 0.2008\n",
      "6/8, train_loss: 0.0167 step time: 0.1967\n",
      "7/8, train_loss: 0.0148 step time: 0.1813\n",
      "8/8, train_loss: 0.0161 step time: 0.1830\n",
      "epoch 540 average loss: 0.0155\n",
      "current epoch: 540 current mean dice: 0.9521 best mean dice: 0.9558 at epoch: 500\n",
      "time consuming of epoch 540 is: 2.3468\n",
      "----------\n",
      "epoch 541/600\n",
      "1/8, train_loss: 0.0148 step time: 0.2319\n",
      "2/8, train_loss: 0.0146 step time: 0.2025\n",
      "3/8, train_loss: 0.0144 step time: 0.2009\n",
      "4/8, train_loss: 0.0134 step time: 0.1986\n",
      "5/8, train_loss: 0.0176 step time: 0.2011\n",
      "6/8, train_loss: 0.0190 step time: 0.2038\n",
      "7/8, train_loss: 0.0150 step time: 0.1825\n",
      "8/8, train_loss: 0.0156 step time: 0.1823\n",
      "epoch 541 average loss: 0.0156\n",
      "time consuming of epoch 541 is: 1.6049\n",
      "----------\n",
      "epoch 542/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2396\n",
      "2/8, train_loss: 0.0137 step time: 0.2044\n",
      "3/8, train_loss: 0.0161 step time: 0.1988\n",
      "4/8, train_loss: 0.0153 step time: 0.1975\n",
      "5/8, train_loss: 0.0164 step time: 0.2003\n",
      "6/8, train_loss: 0.0148 step time: 0.2059\n",
      "7/8, train_loss: 0.0161 step time: 0.1848\n",
      "8/8, train_loss: 0.0165 step time: 0.1834\n",
      "epoch 542 average loss: 0.0152\n",
      "time consuming of epoch 542 is: 1.6161\n",
      "----------\n",
      "epoch 543/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2390\n",
      "2/8, train_loss: 0.0159 step time: 0.2054\n",
      "3/8, train_loss: 0.0151 step time: 0.2013\n",
      "4/8, train_loss: 0.0162 step time: 0.1987\n",
      "5/8, train_loss: 0.0151 step time: 0.1957\n",
      "6/8, train_loss: 0.0151 step time: 0.2046\n",
      "7/8, train_loss: 0.0115 step time: 0.1823\n",
      "8/8, train_loss: 0.0166 step time: 0.1817\n",
      "epoch 543 average loss: 0.0151\n",
      "time consuming of epoch 543 is: 1.6101\n",
      "----------\n",
      "epoch 544/600\n",
      "1/8, train_loss: 0.0153 step time: 0.2389\n",
      "2/8, train_loss: 0.0178 step time: 0.2019\n",
      "3/8, train_loss: 0.0131 step time: 0.1994\n",
      "4/8, train_loss: 0.0157 step time: 0.2010\n",
      "5/8, train_loss: 0.0156 step time: 0.1991\n",
      "6/8, train_loss: 0.0141 step time: 0.2000\n",
      "7/8, train_loss: 0.0169 step time: 0.1813\n",
      "8/8, train_loss: 0.0151 step time: 0.1820\n",
      "epoch 544 average loss: 0.0154\n",
      "time consuming of epoch 544 is: 1.6048\n",
      "----------\n",
      "epoch 545/600\n",
      "1/8, train_loss: 0.0165 step time: 0.2365\n",
      "2/8, train_loss: 0.0160 step time: 0.2020\n",
      "3/8, train_loss: 0.0159 step time: 0.2018\n",
      "4/8, train_loss: 0.0149 step time: 0.2005\n",
      "5/8, train_loss: 0.0126 step time: 0.1997\n",
      "6/8, train_loss: 0.0137 step time: 0.1984\n",
      "7/8, train_loss: 0.0146 step time: 0.1809\n",
      "8/8, train_loss: 0.0217 step time: 0.1829\n",
      "epoch 545 average loss: 0.0157\n",
      "current epoch: 545 current mean dice: 0.9489 best mean dice: 0.9558 at epoch: 500\n",
      "time consuming of epoch 545 is: 2.3694\n",
      "----------\n",
      "epoch 546/600\n",
      "1/8, train_loss: 0.0146 step time: 0.2316\n",
      "2/8, train_loss: 0.0133 step time: 0.1941\n",
      "3/8, train_loss: 0.0146 step time: 0.1945\n",
      "4/8, train_loss: 0.0180 step time: 0.1954\n",
      "5/8, train_loss: 0.0145 step time: 0.1951\n",
      "6/8, train_loss: 0.0145 step time: 0.1920\n",
      "7/8, train_loss: 0.0154 step time: 0.1829\n",
      "8/8, train_loss: 0.0131 step time: 0.1801\n",
      "epoch 546 average loss: 0.0148\n",
      "time consuming of epoch 546 is: 1.5670\n",
      "----------\n",
      "epoch 547/600\n",
      "1/8, train_loss: 0.0160 step time: 0.2394\n",
      "2/8, train_loss: 0.0151 step time: 0.1979\n",
      "3/8, train_loss: 0.0157 step time: 0.2038\n",
      "4/8, train_loss: 0.0128 step time: 0.2044\n",
      "5/8, train_loss: 0.0156 step time: 0.2060\n",
      "6/8, train_loss: 0.0189 step time: 0.2003\n",
      "7/8, train_loss: 0.0180 step time: 0.1828\n",
      "8/8, train_loss: 0.0145 step time: 0.1831\n",
      "epoch 547 average loss: 0.0158\n",
      "time consuming of epoch 547 is: 1.6188\n",
      "----------\n",
      "epoch 548/600\n",
      "1/8, train_loss: 0.0191 step time: 0.2427\n",
      "2/8, train_loss: 0.0149 step time: 0.2063\n",
      "3/8, train_loss: 0.0156 step time: 0.1999\n",
      "4/8, train_loss: 0.0168 step time: 0.2026\n",
      "5/8, train_loss: 0.0144 step time: 0.2023\n",
      "6/8, train_loss: 0.0140 step time: 0.2002\n",
      "7/8, train_loss: 0.0150 step time: 0.1835\n",
      "8/8, train_loss: 0.0130 step time: 0.1825\n",
      "epoch 548 average loss: 0.0154\n",
      "time consuming of epoch 548 is: 1.6216\n",
      "----------\n",
      "epoch 549/600\n",
      "1/8, train_loss: 0.0152 step time: 0.2389\n",
      "2/8, train_loss: 0.0156 step time: 0.2061\n",
      "3/8, train_loss: 0.0153 step time: 0.1984\n",
      "4/8, train_loss: 0.0159 step time: 0.1988\n",
      "5/8, train_loss: 0.0134 step time: 0.2046\n",
      "6/8, train_loss: 0.0143 step time: 0.2048\n",
      "7/8, train_loss: 0.0134 step time: 0.1819\n",
      "8/8, train_loss: 0.0171 step time: 0.1905\n",
      "epoch 549 average loss: 0.0150\n",
      "time consuming of epoch 549 is: 1.6257\n",
      "----------\n",
      "epoch 550/600\n",
      "1/8, train_loss: 0.0142 step time: 0.2700\n",
      "2/8, train_loss: 0.0153 step time: 0.1986\n",
      "3/8, train_loss: 0.0147 step time: 0.1980\n",
      "4/8, train_loss: 0.0116 step time: 0.1984\n",
      "5/8, train_loss: 0.0159 step time: 0.1994\n",
      "6/8, train_loss: 0.0157 step time: 0.1954\n",
      "7/8, train_loss: 0.0145 step time: 0.1816\n",
      "8/8, train_loss: 0.0158 step time: 0.1844\n",
      "epoch 550 average loss: 0.0147\n",
      "current epoch: 550 current mean dice: 0.9538 best mean dice: 0.9558 at epoch: 500\n",
      "time consuming of epoch 550 is: 2.3838\n",
      "----------\n",
      "epoch 551/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2352\n",
      "2/8, train_loss: 0.0141 step time: 0.2017\n",
      "3/8, train_loss: 0.0146 step time: 0.2044\n",
      "4/8, train_loss: 0.0165 step time: 0.2001\n",
      "5/8, train_loss: 0.0156 step time: 0.1985\n",
      "6/8, train_loss: 0.0137 step time: 0.2006\n",
      "7/8, train_loss: 0.0154 step time: 0.1842\n",
      "8/8, train_loss: 0.0163 step time: 0.1824\n",
      "epoch 551 average loss: 0.0149\n",
      "time consuming of epoch 551 is: 1.6082\n",
      "----------\n",
      "epoch 552/600\n",
      "1/8, train_loss: 0.0154 step time: 0.2406\n",
      "2/8, train_loss: 0.0144 step time: 0.1989\n",
      "3/8, train_loss: 0.0144 step time: 0.2016\n",
      "4/8, train_loss: 0.0131 step time: 0.2000\n",
      "5/8, train_loss: 0.0140 step time: 0.2033\n",
      "6/8, train_loss: 0.0156 step time: 0.2051\n",
      "7/8, train_loss: 0.0150 step time: 0.1838\n",
      "8/8, train_loss: 0.0140 step time: 0.1819\n",
      "epoch 552 average loss: 0.0145\n",
      "time consuming of epoch 552 is: 1.6168\n",
      "----------\n",
      "epoch 553/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0158 step time: 0.2369\n",
      "2/8, train_loss: 0.0150 step time: 0.2030\n",
      "3/8, train_loss: 0.0145 step time: 0.1996\n",
      "4/8, train_loss: 0.0146 step time: 0.2000\n",
      "5/8, train_loss: 0.0132 step time: 0.2005\n",
      "6/8, train_loss: 0.0177 step time: 0.2016\n",
      "7/8, train_loss: 0.0176 step time: 0.1825\n",
      "8/8, train_loss: 0.0159 step time: 0.1834\n",
      "epoch 553 average loss: 0.0155\n",
      "time consuming of epoch 553 is: 1.6089\n",
      "----------\n",
      "epoch 554/600\n",
      "1/8, train_loss: 0.0170 step time: 0.2386\n",
      "2/8, train_loss: 0.0151 step time: 0.2032\n",
      "3/8, train_loss: 0.0130 step time: 0.2003\n",
      "4/8, train_loss: 0.0156 step time: 0.2015\n",
      "5/8, train_loss: 0.0136 step time: 0.1995\n",
      "6/8, train_loss: 0.0171 step time: 0.2018\n",
      "7/8, train_loss: 0.0177 step time: 0.1828\n",
      "8/8, train_loss: 0.0159 step time: 0.1825\n",
      "epoch 554 average loss: 0.0156\n",
      "time consuming of epoch 554 is: 1.6117\n",
      "----------\n",
      "epoch 555/600\n",
      "1/8, train_loss: 0.0219 step time: 0.2382\n",
      "2/8, train_loss: 0.0147 step time: 0.2000\n",
      "3/8, train_loss: 0.0163 step time: 0.2013\n",
      "4/8, train_loss: 0.0157 step time: 0.2001\n",
      "5/8, train_loss: 0.0144 step time: 0.2003\n",
      "6/8, train_loss: 0.0151 step time: 0.2006\n",
      "7/8, train_loss: 0.0114 step time: 0.1837\n",
      "8/8, train_loss: 0.0157 step time: 0.1821\n",
      "epoch 555 average loss: 0.0157\n",
      "current epoch: 555 current mean dice: 0.9389 best mean dice: 0.9558 at epoch: 500\n",
      "time consuming of epoch 555 is: 2.3629\n",
      "----------\n",
      "epoch 556/600\n",
      "1/8, train_loss: 0.0150 step time: 0.2382\n",
      "2/8, train_loss: 0.0153 step time: 0.1981\n",
      "3/8, train_loss: 0.0157 step time: 0.1989\n",
      "4/8, train_loss: 0.0143 step time: 0.1986\n",
      "5/8, train_loss: 0.0128 step time: 0.1979\n",
      "6/8, train_loss: 0.0131 step time: 0.1977\n",
      "7/8, train_loss: 0.0180 step time: 0.1819\n",
      "8/8, train_loss: 0.0170 step time: 0.1814\n",
      "epoch 556 average loss: 0.0151\n",
      "time consuming of epoch 556 is: 1.5938\n",
      "----------\n",
      "epoch 557/600\n",
      "1/8, train_loss: 0.0144 step time: 0.2403\n",
      "2/8, train_loss: 0.0193 step time: 0.2037\n",
      "3/8, train_loss: 0.0143 step time: 0.1994\n",
      "4/8, train_loss: 0.0178 step time: 0.1994\n",
      "5/8, train_loss: 0.0150 step time: 0.1997\n",
      "6/8, train_loss: 0.0148 step time: 0.1985\n",
      "7/8, train_loss: 0.0163 step time: 0.1825\n",
      "8/8, train_loss: 0.0112 step time: 0.1822\n",
      "epoch 557 average loss: 0.0154\n",
      "time consuming of epoch 557 is: 1.6072\n",
      "----------\n",
      "epoch 558/600\n",
      "1/8, train_loss: 0.0168 step time: 0.2376\n",
      "2/8, train_loss: 0.0138 step time: 0.2018\n",
      "3/8, train_loss: 0.0145 step time: 0.2026\n",
      "4/8, train_loss: 0.0158 step time: 0.2003\n",
      "5/8, train_loss: 0.0144 step time: 0.2002\n",
      "6/8, train_loss: 0.0170 step time: 0.2006\n",
      "7/8, train_loss: 0.0150 step time: 0.1827\n",
      "8/8, train_loss: 0.0143 step time: 0.1826\n",
      "epoch 558 average loss: 0.0152\n",
      "time consuming of epoch 558 is: 1.6099\n",
      "----------\n",
      "epoch 559/600\n",
      "1/8, train_loss: 0.0165 step time: 0.2413\n",
      "2/8, train_loss: 0.0137 step time: 0.2002\n",
      "3/8, train_loss: 0.0177 step time: 0.2018\n",
      "4/8, train_loss: 0.0151 step time: 0.1987\n",
      "5/8, train_loss: 0.0168 step time: 0.2036\n",
      "6/8, train_loss: 0.0109 step time: 0.2039\n",
      "7/8, train_loss: 0.0179 step time: 0.1830\n",
      "8/8, train_loss: 0.0153 step time: 0.1828\n",
      "epoch 559 average loss: 0.0155\n",
      "time consuming of epoch 559 is: 1.6170\n",
      "----------\n",
      "epoch 560/600\n",
      "1/8, train_loss: 0.0142 step time: 0.2386\n",
      "2/8, train_loss: 0.0143 step time: 0.2024\n",
      "3/8, train_loss: 0.0173 step time: 0.2001\n",
      "4/8, train_loss: 0.0152 step time: 0.2018\n",
      "5/8, train_loss: 0.0161 step time: 0.2006\n",
      "6/8, train_loss: 0.0149 step time: 0.2033\n",
      "7/8, train_loss: 0.0162 step time: 0.1847\n",
      "8/8, train_loss: 0.0126 step time: 0.1828\n",
      "epoch 560 average loss: 0.0151\n",
      "current epoch: 560 current mean dice: 0.9542 best mean dice: 0.9558 at epoch: 500\n",
      "time consuming of epoch 560 is: 2.3706\n",
      "----------\n",
      "epoch 561/600\n",
      "1/8, train_loss: 0.0197 step time: 0.2351\n",
      "2/8, train_loss: 0.0152 step time: 0.1964\n",
      "3/8, train_loss: 0.0153 step time: 0.2032\n",
      "4/8, train_loss: 0.0166 step time: 0.2050\n",
      "5/8, train_loss: 0.0140 step time: 0.2053\n",
      "6/8, train_loss: 0.0154 step time: 0.2040\n",
      "7/8, train_loss: 0.0131 step time: 0.1838\n",
      "8/8, train_loss: 0.0156 step time: 0.1826\n",
      "epoch 561 average loss: 0.0156\n",
      "time consuming of epoch 561 is: 1.6166\n",
      "----------\n",
      "epoch 562/600\n",
      "1/8, train_loss: 0.0166 step time: 0.2382\n",
      "2/8, train_loss: 0.0138 step time: 0.1977\n",
      "3/8, train_loss: 0.0152 step time: 0.1975\n",
      "4/8, train_loss: 0.0134 step time: 0.1997\n",
      "5/8, train_loss: 0.0145 step time: 0.1995\n",
      "6/8, train_loss: 0.0163 step time: 0.1994\n",
      "7/8, train_loss: 0.0163 step time: 0.1843\n",
      "8/8, train_loss: 0.0172 step time: 0.1823\n",
      "epoch 562 average loss: 0.0154\n",
      "time consuming of epoch 562 is: 1.6000\n",
      "----------\n",
      "epoch 563/600\n",
      "1/8, train_loss: 0.0140 step time: 0.2395\n",
      "2/8, train_loss: 0.0155 step time: 0.2034\n",
      "3/8, train_loss: 0.0158 step time: 0.2047\n",
      "4/8, train_loss: 0.0155 step time: 0.2022\n",
      "5/8, train_loss: 0.0147 step time: 0.2096\n",
      "6/8, train_loss: 0.0149 step time: 0.2100\n",
      "7/8, train_loss: 0.0154 step time: 0.1818\n",
      "8/8, train_loss: 0.0184 step time: 0.1813\n",
      "epoch 563 average loss: 0.0155\n",
      "time consuming of epoch 563 is: 1.6340\n",
      "----------\n",
      "epoch 564/600\n",
      "1/8, train_loss: 0.0164 step time: 0.2407\n",
      "2/8, train_loss: 0.0130 step time: 0.2031\n",
      "3/8, train_loss: 0.0152 step time: 0.1986\n",
      "4/8, train_loss: 0.0153 step time: 0.2044\n",
      "5/8, train_loss: 0.0155 step time: 0.2002\n",
      "6/8, train_loss: 0.0140 step time: 0.2000\n",
      "7/8, train_loss: 0.0166 step time: 0.1854\n",
      "8/8, train_loss: 0.0165 step time: 0.1810\n",
      "epoch 564 average loss: 0.0153\n",
      "time consuming of epoch 564 is: 1.6147\n",
      "----------\n",
      "epoch 565/600\n",
      "1/8, train_loss: 0.0145 step time: 0.2388\n",
      "2/8, train_loss: 0.0149 step time: 0.2004\n",
      "3/8, train_loss: 0.0157 step time: 0.2033\n",
      "4/8, train_loss: 0.0165 step time: 0.2002\n",
      "5/8, train_loss: 0.0117 step time: 0.1983\n",
      "6/8, train_loss: 0.0138 step time: 0.2004\n",
      "7/8, train_loss: 0.0148 step time: 0.1826\n",
      "8/8, train_loss: 0.0162 step time: 0.1822\n",
      "epoch 565 average loss: 0.0148\n",
      "saved new best metric model\n",
      "current epoch: 565 current mean dice: 0.9562 best mean dice: 0.9562 at epoch: 565\n",
      "time consuming of epoch 565 is: 2.5032\n",
      "----------\n",
      "epoch 566/600\n",
      "1/8, train_loss: 0.0139 step time: 0.2381\n",
      "2/8, train_loss: 0.0142 step time: 0.1971\n",
      "3/8, train_loss: 0.0183 step time: 0.2001\n",
      "4/8, train_loss: 0.0145 step time: 0.1961\n",
      "5/8, train_loss: 0.0147 step time: 0.1996\n",
      "6/8, train_loss: 0.0148 step time: 0.1987\n",
      "7/8, train_loss: 0.0159 step time: 0.1836\n",
      "8/8, train_loss: 0.0149 step time: 0.1807\n",
      "epoch 566 average loss: 0.0152\n",
      "time consuming of epoch 566 is: 1.5953\n",
      "----------\n",
      "epoch 567/600\n",
      "1/8, train_loss: 0.0129 step time: 0.2400\n",
      "2/8, train_loss: 0.0153 step time: 0.2044\n",
      "3/8, train_loss: 0.0146 step time: 0.1980\n",
      "4/8, train_loss: 0.0154 step time: 0.2042\n",
      "5/8, train_loss: 0.0130 step time: 0.2006\n",
      "6/8, train_loss: 0.0150 step time: 0.2038\n",
      "7/8, train_loss: 0.0149 step time: 0.1837\n",
      "8/8, train_loss: 0.0138 step time: 0.1822\n",
      "epoch 567 average loss: 0.0144\n",
      "time consuming of epoch 567 is: 1.6184\n",
      "----------\n",
      "epoch 568/600\n",
      "1/8, train_loss: 0.0136 step time: 0.2420\n",
      "2/8, train_loss: 0.0109 step time: 0.2027\n",
      "3/8, train_loss: 0.0169 step time: 0.2024\n",
      "4/8, train_loss: 0.0129 step time: 0.2012\n",
      "5/8, train_loss: 0.0150 step time: 0.2011\n",
      "6/8, train_loss: 0.0157 step time: 0.2021\n",
      "7/8, train_loss: 0.0123 step time: 0.1840\n",
      "8/8, train_loss: 0.0150 step time: 0.1846\n",
      "epoch 568 average loss: 0.0141\n",
      "time consuming of epoch 568 is: 1.6220\n",
      "----------\n",
      "epoch 569/600\n",
      "1/8, train_loss: 0.0164 step time: 0.2425\n",
      "2/8, train_loss: 0.0128 step time: 0.2017\n",
      "3/8, train_loss: 0.0166 step time: 0.2011\n",
      "4/8, train_loss: 0.0200 step time: 0.1992\n",
      "5/8, train_loss: 0.0114 step time: 0.2031\n",
      "6/8, train_loss: 0.0160 step time: 0.1999\n",
      "7/8, train_loss: 0.0136 step time: 0.1830\n",
      "8/8, train_loss: 0.0137 step time: 0.1830\n",
      "epoch 569 average loss: 0.0151\n",
      "time consuming of epoch 569 is: 1.6148\n",
      "----------\n",
      "epoch 570/600\n",
      "1/8, train_loss: 0.0138 step time: 0.2397\n",
      "2/8, train_loss: 0.0138 step time: 0.2029\n",
      "3/8, train_loss: 0.0149 step time: 0.1991\n",
      "4/8, train_loss: 0.0154 step time: 0.1992\n",
      "5/8, train_loss: 0.0166 step time: 0.2004\n",
      "6/8, train_loss: 0.0148 step time: 0.2039\n",
      "7/8, train_loss: 0.0132 step time: 0.1837\n",
      "8/8, train_loss: 0.0151 step time: 0.1822\n",
      "epoch 570 average loss: 0.0147\n",
      "current epoch: 570 current mean dice: 0.9558 best mean dice: 0.9562 at epoch: 565\n",
      "time consuming of epoch 570 is: 2.3679\n",
      "----------\n",
      "epoch 571/600\n",
      "1/8, train_loss: 0.0123 step time: 0.2316\n",
      "2/8, train_loss: 0.0150 step time: 0.2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8, train_loss: 0.0161 step time: 0.2005\n",
      "4/8, train_loss: 0.0142 step time: 0.1988\n",
      "5/8, train_loss: 0.0141 step time: 0.1946\n",
      "6/8, train_loss: 0.0139 step time: 0.1944\n",
      "7/8, train_loss: 0.0169 step time: 0.1858\n",
      "8/8, train_loss: 0.0148 step time: 0.1829\n",
      "epoch 571 average loss: 0.0147\n",
      "time consuming of epoch 571 is: 1.5897\n",
      "----------\n",
      "epoch 572/600\n",
      "1/8, train_loss: 0.0142 step time: 0.2333\n",
      "2/8, train_loss: 0.0170 step time: 0.2032\n",
      "3/8, train_loss: 0.0166 step time: 0.2012\n",
      "4/8, train_loss: 0.0146 step time: 0.2000\n",
      "5/8, train_loss: 0.0128 step time: 0.1999\n",
      "6/8, train_loss: 0.0118 step time: 0.1989\n",
      "7/8, train_loss: 0.0149 step time: 0.1852\n",
      "8/8, train_loss: 0.0150 step time: 0.1824\n",
      "epoch 572 average loss: 0.0146\n",
      "time consuming of epoch 572 is: 1.6058\n",
      "----------\n",
      "epoch 573/600\n",
      "1/8, train_loss: 0.0129 step time: 0.2418\n",
      "2/8, train_loss: 0.0122 step time: 0.2041\n",
      "3/8, train_loss: 0.0165 step time: 0.2003\n",
      "4/8, train_loss: 0.0138 step time: 0.2000\n",
      "5/8, train_loss: 0.0172 step time: 0.1997\n",
      "6/8, train_loss: 0.0155 step time: 0.2036\n",
      "7/8, train_loss: 0.0142 step time: 0.1843\n",
      "8/8, train_loss: 0.0156 step time: 0.1829\n",
      "epoch 573 average loss: 0.0147\n",
      "time consuming of epoch 573 is: 1.6180\n",
      "----------\n",
      "epoch 574/600\n",
      "1/8, train_loss: 0.0141 step time: 0.2397\n",
      "2/8, train_loss: 0.0154 step time: 0.2006\n",
      "3/8, train_loss: 0.0168 step time: 0.2016\n",
      "4/8, train_loss: 0.0138 step time: 0.2003\n",
      "5/8, train_loss: 0.0138 step time: 0.2011\n",
      "6/8, train_loss: 0.0136 step time: 0.1990\n",
      "7/8, train_loss: 0.0142 step time: 0.1826\n",
      "8/8, train_loss: 0.0177 step time: 0.1841\n",
      "epoch 574 average loss: 0.0149\n",
      "time consuming of epoch 574 is: 1.6103\n",
      "----------\n",
      "epoch 575/600\n",
      "1/8, train_loss: 0.0133 step time: 0.2393\n",
      "2/8, train_loss: 0.0151 step time: 0.2001\n",
      "3/8, train_loss: 0.0136 step time: 0.1999\n",
      "4/8, train_loss: 0.0201 step time: 0.2020\n",
      "5/8, train_loss: 0.0135 step time: 0.1990\n",
      "6/8, train_loss: 0.0133 step time: 0.2021\n",
      "7/8, train_loss: 0.0137 step time: 0.1828\n",
      "8/8, train_loss: 0.0192 step time: 0.1829\n",
      "epoch 575 average loss: 0.0152\n",
      "current epoch: 575 current mean dice: 0.9555 best mean dice: 0.9562 at epoch: 565\n",
      "time consuming of epoch 575 is: 2.3663\n",
      "----------\n",
      "epoch 576/600\n",
      "1/8, train_loss: 0.0139 step time: 0.2391\n",
      "2/8, train_loss: 0.0188 step time: 0.2001\n",
      "3/8, train_loss: 0.0146 step time: 0.1990\n",
      "4/8, train_loss: 0.0153 step time: 0.2041\n",
      "5/8, train_loss: 0.0170 step time: 0.2018\n",
      "6/8, train_loss: 0.0138 step time: 0.1974\n",
      "7/8, train_loss: 0.0154 step time: 0.1818\n",
      "8/8, train_loss: 0.0123 step time: 0.1802\n",
      "epoch 576 average loss: 0.0151\n",
      "time consuming of epoch 576 is: 1.6046\n",
      "----------\n",
      "epoch 577/600\n",
      "1/8, train_loss: 0.0135 step time: 0.2409\n",
      "2/8, train_loss: 0.0119 step time: 0.1999\n",
      "3/8, train_loss: 0.0147 step time: 0.2012\n",
      "4/8, train_loss: 0.0135 step time: 0.1995\n",
      "5/8, train_loss: 0.0165 step time: 0.2056\n",
      "6/8, train_loss: 0.0139 step time: 0.2034\n",
      "7/8, train_loss: 0.0145 step time: 0.1853\n",
      "8/8, train_loss: 0.0181 step time: 0.1846\n",
      "epoch 577 average loss: 0.0146\n",
      "time consuming of epoch 577 is: 1.6216\n",
      "----------\n",
      "epoch 578/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2390\n",
      "2/8, train_loss: 0.0164 step time: 0.2037\n",
      "3/8, train_loss: 0.0178 step time: 0.1989\n",
      "4/8, train_loss: 0.0143 step time: 0.2007\n",
      "5/8, train_loss: 0.0097 step time: 0.1998\n",
      "6/8, train_loss: 0.0144 step time: 0.2011\n",
      "7/8, train_loss: 0.0157 step time: 0.1815\n",
      "8/8, train_loss: 0.0141 step time: 0.1815\n",
      "epoch 578 average loss: 0.0144\n",
      "time consuming of epoch 578 is: 1.6076\n",
      "----------\n",
      "epoch 579/600\n",
      "1/8, train_loss: 0.0160 step time: 0.2411\n",
      "2/8, train_loss: 0.0139 step time: 0.1999\n",
      "3/8, train_loss: 0.0121 step time: 0.2014\n",
      "4/8, train_loss: 0.0141 step time: 0.1994\n",
      "5/8, train_loss: 0.0148 step time: 0.2016\n",
      "6/8, train_loss: 0.0165 step time: 0.2018\n",
      "7/8, train_loss: 0.0154 step time: 0.1825\n",
      "8/8, train_loss: 0.0132 step time: 0.1810\n",
      "epoch 579 average loss: 0.0145\n",
      "time consuming of epoch 579 is: 1.6098\n",
      "----------\n",
      "epoch 580/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2432\n",
      "2/8, train_loss: 0.0157 step time: 0.2000\n",
      "3/8, train_loss: 0.0150 step time: 0.1981\n",
      "4/8, train_loss: 0.0170 step time: 0.1981\n",
      "5/8, train_loss: 0.0154 step time: 0.1971\n",
      "6/8, train_loss: 0.0136 step time: 0.1984\n",
      "7/8, train_loss: 0.0115 step time: 0.1812\n",
      "8/8, train_loss: 0.0139 step time: 0.1840\n",
      "epoch 580 average loss: 0.0146\n",
      "saved new best metric model\n",
      "current epoch: 580 current mean dice: 0.9564 best mean dice: 0.9564 at epoch: 580\n",
      "time consuming of epoch 580 is: 2.4964\n",
      "----------\n",
      "epoch 581/600\n",
      "1/8, train_loss: 0.0141 step time: 0.2351\n",
      "2/8, train_loss: 0.0133 step time: 0.1970\n",
      "3/8, train_loss: 0.0147 step time: 0.1957\n",
      "4/8, train_loss: 0.0137 step time: 0.1957\n",
      "5/8, train_loss: 0.0133 step time: 0.1982\n",
      "6/8, train_loss: 0.0155 step time: 0.1963\n",
      "7/8, train_loss: 0.0161 step time: 0.1823\n",
      "8/8, train_loss: 0.0139 step time: 0.1841\n",
      "epoch 581 average loss: 0.0143\n",
      "time consuming of epoch 581 is: 1.5856\n",
      "----------\n",
      "epoch 582/600\n",
      "1/8, train_loss: 0.0153 step time: 0.2400\n",
      "2/8, train_loss: 0.0160 step time: 0.2039\n",
      "3/8, train_loss: 0.0136 step time: 0.2001\n",
      "4/8, train_loss: 0.0152 step time: 0.2008\n",
      "5/8, train_loss: 0.0141 step time: 0.2001\n",
      "6/8, train_loss: 0.0146 step time: 0.2001\n",
      "7/8, train_loss: 0.0142 step time: 0.1832\n",
      "8/8, train_loss: 0.0162 step time: 0.1842\n",
      "epoch 582 average loss: 0.0149\n",
      "time consuming of epoch 582 is: 1.6141\n",
      "----------\n",
      "epoch 583/600\n",
      "1/8, train_loss: 0.0126 step time: 0.2395\n",
      "2/8, train_loss: 0.0142 step time: 0.2026\n",
      "3/8, train_loss: 0.0157 step time: 0.2024\n",
      "4/8, train_loss: 0.0142 step time: 0.2020\n",
      "5/8, train_loss: 0.0156 step time: 0.2001\n",
      "6/8, train_loss: 0.0148 step time: 0.2018\n",
      "7/8, train_loss: 0.0161 step time: 0.1829\n",
      "8/8, train_loss: 0.0148 step time: 0.1834\n",
      "epoch 583 average loss: 0.0147\n",
      "time consuming of epoch 583 is: 1.6161\n",
      "----------\n",
      "epoch 584/600\n",
      "1/8, train_loss: 0.0180 step time: 0.2380\n",
      "2/8, train_loss: 0.0130 step time: 0.2035\n",
      "3/8, train_loss: 0.0168 step time: 0.2023\n",
      "4/8, train_loss: 0.0139 step time: 0.2025\n",
      "5/8, train_loss: 0.0144 step time: 0.2015\n",
      "6/8, train_loss: 0.0104 step time: 0.2037\n",
      "7/8, train_loss: 0.0134 step time: 0.1824\n",
      "8/8, train_loss: 0.0177 step time: 0.1838\n",
      "epoch 584 average loss: 0.0147\n",
      "time consuming of epoch 584 is: 1.6192\n",
      "----------\n",
      "epoch 585/600\n",
      "1/8, train_loss: 0.0130 step time: 0.2476\n",
      "2/8, train_loss: 0.0147 step time: 0.2035\n",
      "3/8, train_loss: 0.0132 step time: 0.1993\n",
      "4/8, train_loss: 0.0141 step time: 0.2015\n",
      "5/8, train_loss: 0.0131 step time: 0.2023\n",
      "6/8, train_loss: 0.0139 step time: 0.2013\n",
      "7/8, train_loss: 0.0153 step time: 0.1811\n",
      "8/8, train_loss: 0.0152 step time: 0.1834\n",
      "epoch 585 average loss: 0.0140\n",
      "current epoch: 585 current mean dice: 0.9559 best mean dice: 0.9564 at epoch: 580\n",
      "time consuming of epoch 585 is: 2.3772\n",
      "----------\n",
      "epoch 586/600\n",
      "1/8, train_loss: 0.0134 step time: 0.2399\n",
      "2/8, train_loss: 0.0197 step time: 0.2023\n",
      "3/8, train_loss: 0.0153 step time: 0.1992\n",
      "4/8, train_loss: 0.0121 step time: 0.2003\n",
      "5/8, train_loss: 0.0166 step time: 0.2028\n",
      "6/8, train_loss: 0.0143 step time: 0.1994\n",
      "7/8, train_loss: 0.0153 step time: 0.1834\n",
      "8/8, train_loss: 0.0161 step time: 0.1842\n",
      "epoch 586 average loss: 0.0153\n",
      "time consuming of epoch 586 is: 1.6125\n",
      "----------\n",
      "epoch 587/600\n",
      "1/8, train_loss: 0.0146 step time: 0.2376\n",
      "2/8, train_loss: 0.0130 step time: 0.2015\n",
      "3/8, train_loss: 0.0131 step time: 0.2006\n",
      "4/8, train_loss: 0.0150 step time: 0.1999\n",
      "5/8, train_loss: 0.0131 step time: 0.2021\n",
      "6/8, train_loss: 0.0146 step time: 0.1987\n",
      "7/8, train_loss: 0.0157 step time: 0.1845\n",
      "8/8, train_loss: 0.0178 step time: 0.1836\n",
      "epoch 587 average loss: 0.0146\n",
      "time consuming of epoch 587 is: 1.6104\n",
      "----------\n",
      "epoch 588/600\n",
      "1/8, train_loss: 0.0143 step time: 0.2365\n",
      "2/8, train_loss: 0.0168 step time: 0.1956\n",
      "3/8, train_loss: 0.0176 step time: 0.1961\n",
      "4/8, train_loss: 0.0142 step time: 0.1944\n",
      "5/8, train_loss: 0.0130 step time: 0.1975\n",
      "6/8, train_loss: 0.0140 step time: 0.1963\n",
      "7/8, train_loss: 0.0140 step time: 0.1816\n",
      "8/8, train_loss: 0.0139 step time: 0.1831\n",
      "epoch 588 average loss: 0.0147\n",
      "time consuming of epoch 588 is: 1.5824\n",
      "----------\n",
      "epoch 589/600\n",
      "1/8, train_loss: 0.0162 step time: 0.2289\n",
      "2/8, train_loss: 0.0158 step time: 0.1970\n",
      "3/8, train_loss: 0.0108 step time: 0.2002\n",
      "4/8, train_loss: 0.0127 step time: 0.2001\n",
      "5/8, train_loss: 0.0133 step time: 0.1994\n",
      "6/8, train_loss: 0.0161 step time: 0.1990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/8, train_loss: 0.0170 step time: 0.1824\n",
      "8/8, train_loss: 0.0121 step time: 0.1848\n",
      "epoch 589 average loss: 0.0143\n",
      "time consuming of epoch 589 is: 1.5930\n",
      "----------\n",
      "epoch 590/600\n",
      "1/8, train_loss: 0.0162 step time: 0.2403\n",
      "2/8, train_loss: 0.0135 step time: 0.2021\n",
      "3/8, train_loss: 0.0123 step time: 0.1987\n",
      "4/8, train_loss: 0.0162 step time: 0.2044\n",
      "5/8, train_loss: 0.0139 step time: 0.1976\n",
      "6/8, train_loss: 0.0148 step time: 0.2037\n",
      "7/8, train_loss: 0.0126 step time: 0.1828\n",
      "8/8, train_loss: 0.0146 step time: 0.1838\n",
      "epoch 590 average loss: 0.0143\n",
      "saved new best metric model\n",
      "current epoch: 590 current mean dice: 0.9565 best mean dice: 0.9565 at epoch: 590\n",
      "time consuming of epoch 590 is: 2.5106\n",
      "----------\n",
      "epoch 591/600\n",
      "1/8, train_loss: 0.0142 step time: 0.2406\n",
      "2/8, train_loss: 0.0162 step time: 0.1978\n",
      "3/8, train_loss: 0.0137 step time: 0.2022\n",
      "4/8, train_loss: 0.0175 step time: 0.2072\n",
      "5/8, train_loss: 0.0133 step time: 0.2036\n",
      "6/8, train_loss: 0.0159 step time: 0.2019\n",
      "7/8, train_loss: 0.0134 step time: 0.1825\n",
      "8/8, train_loss: 0.0159 step time: 0.1823\n",
      "epoch 591 average loss: 0.0150\n",
      "time consuming of epoch 591 is: 1.6193\n",
      "----------\n",
      "epoch 592/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2376\n",
      "2/8, train_loss: 0.0162 step time: 0.1977\n",
      "3/8, train_loss: 0.0151 step time: 0.1945\n",
      "4/8, train_loss: 0.0164 step time: 0.1970\n",
      "5/8, train_loss: 0.0149 step time: 0.1980\n",
      "6/8, train_loss: 0.0141 step time: 0.1971\n",
      "7/8, train_loss: 0.0120 step time: 0.1841\n",
      "8/8, train_loss: 0.0123 step time: 0.1827\n",
      "epoch 592 average loss: 0.0145\n",
      "time consuming of epoch 592 is: 1.5905\n",
      "----------\n",
      "epoch 593/600\n",
      "1/8, train_loss: 0.0116 step time: 0.2312\n",
      "2/8, train_loss: 0.0132 step time: 0.1996\n",
      "3/8, train_loss: 0.0163 step time: 0.1956\n",
      "4/8, train_loss: 0.0147 step time: 0.1946\n",
      "5/8, train_loss: 0.0154 step time: 0.1949\n",
      "6/8, train_loss: 0.0155 step time: 0.1966\n",
      "7/8, train_loss: 0.0161 step time: 0.1823\n",
      "8/8, train_loss: 0.0164 step time: 0.1832\n",
      "epoch 593 average loss: 0.0149\n",
      "time consuming of epoch 593 is: 1.5793\n",
      "----------\n",
      "epoch 594/600\n",
      "1/8, train_loss: 0.0156 step time: 0.2324\n",
      "2/8, train_loss: 0.0104 step time: 0.1983\n",
      "3/8, train_loss: 0.0132 step time: 0.1970\n",
      "4/8, train_loss: 0.0170 step time: 0.1996\n",
      "5/8, train_loss: 0.0151 step time: 0.2017\n",
      "6/8, train_loss: 0.0164 step time: 0.1987\n",
      "7/8, train_loss: 0.0135 step time: 0.1817\n",
      "8/8, train_loss: 0.0147 step time: 0.1829\n",
      "epoch 594 average loss: 0.0145\n",
      "time consuming of epoch 594 is: 1.5937\n",
      "----------\n",
      "epoch 595/600\n",
      "1/8, train_loss: 0.0164 step time: 0.2395\n",
      "2/8, train_loss: 0.0164 step time: 0.2021\n",
      "3/8, train_loss: 0.0166 step time: 0.2031\n",
      "4/8, train_loss: 0.0144 step time: 0.2016\n",
      "5/8, train_loss: 0.0137 step time: 0.1997\n",
      "6/8, train_loss: 0.0138 step time: 0.2035\n",
      "7/8, train_loss: 0.0121 step time: 0.1843\n",
      "8/8, train_loss: 0.0133 step time: 0.1807\n",
      "epoch 595 average loss: 0.0146\n",
      "current epoch: 595 current mean dice: 0.9558 best mean dice: 0.9565 at epoch: 590\n",
      "time consuming of epoch 595 is: 2.3698\n",
      "----------\n",
      "epoch 596/600\n",
      "1/8, train_loss: 0.0111 step time: 0.2382\n",
      "2/8, train_loss: 0.0170 step time: 0.2021\n",
      "3/8, train_loss: 0.0142 step time: 0.1993\n",
      "4/8, train_loss: 0.0191 step time: 0.1989\n",
      "5/8, train_loss: 0.0150 step time: 0.1990\n",
      "6/8, train_loss: 0.0106 step time: 0.2012\n",
      "7/8, train_loss: 0.0196 step time: 0.1814\n",
      "8/8, train_loss: 0.0152 step time: 0.1807\n",
      "epoch 596 average loss: 0.0152\n",
      "time consuming of epoch 596 is: 1.6020\n",
      "----------\n",
      "epoch 597/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2346\n",
      "2/8, train_loss: 0.0154 step time: 0.1961\n",
      "3/8, train_loss: 0.0141 step time: 0.1977\n",
      "4/8, train_loss: 0.0161 step time: 0.1984\n",
      "5/8, train_loss: 0.0119 step time: 0.1982\n",
      "6/8, train_loss: 0.0156 step time: 0.1989\n",
      "7/8, train_loss: 0.0145 step time: 0.1796\n",
      "8/8, train_loss: 0.0110 step time: 0.1795\n",
      "epoch 597 average loss: 0.0142\n",
      "time consuming of epoch 597 is: 1.5842\n",
      "----------\n",
      "epoch 598/600\n",
      "1/8, train_loss: 0.0124 step time: 0.2461\n",
      "2/8, train_loss: 0.0150 step time: 0.2093\n",
      "3/8, train_loss: 0.0150 step time: 0.2041\n",
      "4/8, train_loss: 0.0149 step time: 0.2025\n",
      "5/8, train_loss: 0.0167 step time: 0.1994\n",
      "6/8, train_loss: 0.0134 step time: 0.2026\n",
      "7/8, train_loss: 0.0141 step time: 0.1841\n",
      "8/8, train_loss: 0.0145 step time: 0.1829\n",
      "epoch 598 average loss: 0.0145\n",
      "time consuming of epoch 598 is: 1.6322\n",
      "----------\n",
      "epoch 599/600\n",
      "1/8, train_loss: 0.0150 step time: 0.2395\n",
      "2/8, train_loss: 0.0138 step time: 0.2050\n",
      "3/8, train_loss: 0.0164 step time: 0.2003\n",
      "4/8, train_loss: 0.0143 step time: 0.2027\n",
      "5/8, train_loss: 0.0143 step time: 0.1999\n",
      "6/8, train_loss: 0.0148 step time: 0.2011\n",
      "7/8, train_loss: 0.0138 step time: 0.1844\n",
      "8/8, train_loss: 0.0179 step time: 0.1828\n",
      "epoch 599 average loss: 0.0150\n",
      "time consuming of epoch 599 is: 1.6174\n",
      "----------\n",
      "epoch 600/600\n",
      "1/8, train_loss: 0.0153 step time: 0.2409\n",
      "2/8, train_loss: 0.0153 step time: 0.2019\n",
      "3/8, train_loss: 0.0108 step time: 0.1990\n",
      "4/8, train_loss: 0.0163 step time: 0.2033\n",
      "5/8, train_loss: 0.0153 step time: 0.1995\n",
      "6/8, train_loss: 0.0152 step time: 0.2009\n",
      "7/8, train_loss: 0.0123 step time: 0.1821\n",
      "8/8, train_loss: 0.0149 step time: 0.1836\n",
      "epoch 600 average loss: 0.0144\n",
      "saved new best metric model\n",
      "current epoch: 600 current mean dice: 0.9571 best mean dice: 0.9571 at epoch: 600\n",
      "time consuming of epoch 600 is: 2.5110\n",
      "train completed, best_metric: 0.9571 at epoch: 600 total time: 1061.2309\n",
      "----------\n",
      "epoch 1/600\n",
      "1/8, train_loss: 0.0135 step time: 0.2364\n",
      "2/8, train_loss: 0.0150 step time: 0.2024\n",
      "3/8, train_loss: 0.0156 step time: 0.1979\n",
      "4/8, train_loss: 0.0126 step time: 0.2010\n",
      "5/8, train_loss: 0.0133 step time: 0.1993\n",
      "6/8, train_loss: 0.0139 step time: 0.1994\n",
      "7/8, train_loss: 0.0132 step time: 0.1810\n",
      "8/8, train_loss: 0.0149 step time: 0.1814\n",
      "epoch 1 average loss: 0.0140\n",
      "time consuming of epoch 1 is: 1.5999\n",
      "----------\n",
      "epoch 2/600\n",
      "1/8, train_loss: 0.0187 step time: 0.2404\n",
      "2/8, train_loss: 0.0163 step time: 0.2054\n",
      "3/8, train_loss: 0.0139 step time: 0.2016\n",
      "4/8, train_loss: 0.0117 step time: 0.2002\n",
      "5/8, train_loss: 0.0146 step time: 0.2016\n",
      "6/8, train_loss: 0.0169 step time: 0.1991\n",
      "7/8, train_loss: 0.0140 step time: 0.1831\n",
      "8/8, train_loss: 0.0127 step time: 0.1839\n",
      "epoch 2 average loss: 0.0148\n",
      "time consuming of epoch 2 is: 1.6165\n",
      "----------\n",
      "epoch 3/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2413\n",
      "2/8, train_loss: 0.0123 step time: 0.2031\n",
      "3/8, train_loss: 0.0152 step time: 0.2045\n",
      "4/8, train_loss: 0.0155 step time: 0.1992\n",
      "5/8, train_loss: 0.0148 step time: 0.2015\n",
      "6/8, train_loss: 0.0155 step time: 0.2005\n",
      "7/8, train_loss: 0.0133 step time: 0.1847\n",
      "8/8, train_loss: 0.0139 step time: 0.1827\n",
      "epoch 3 average loss: 0.0144\n",
      "time consuming of epoch 3 is: 1.6193\n",
      "----------\n",
      "epoch 4/600\n",
      "1/8, train_loss: 0.0152 step time: 0.2426\n",
      "2/8, train_loss: 0.0141 step time: 0.2048\n",
      "3/8, train_loss: 0.0136 step time: 0.2053\n",
      "4/8, train_loss: 0.0138 step time: 0.2028\n",
      "5/8, train_loss: 0.0146 step time: 0.1992\n",
      "6/8, train_loss: 0.0136 step time: 0.2020\n",
      "7/8, train_loss: 0.0136 step time: 0.1836\n",
      "8/8, train_loss: 0.0164 step time: 0.1829\n",
      "epoch 4 average loss: 0.0144\n",
      "time consuming of epoch 4 is: 1.6250\n",
      "----------\n",
      "epoch 5/600\n",
      "1/8, train_loss: 0.0133 step time: 0.2383\n",
      "2/8, train_loss: 0.0127 step time: 0.2031\n",
      "3/8, train_loss: 0.0147 step time: 0.2023\n",
      "4/8, train_loss: 0.0142 step time: 0.2019\n",
      "5/8, train_loss: 0.0163 step time: 0.2022\n",
      "6/8, train_loss: 0.0164 step time: 0.2019\n",
      "7/8, train_loss: 0.0109 step time: 0.1827\n",
      "8/8, train_loss: 0.0131 step time: 0.1824\n",
      "epoch 5 average loss: 0.0139\n",
      "saved new best metric model\n",
      "current epoch: 5 current mean dice: 0.9569 best mean dice: 0.9569 at epoch: 5\n",
      "time consuming of epoch 5 is: 2.5791\n",
      "----------\n",
      "epoch 6/600\n",
      "1/8, train_loss: 0.0145 step time: 0.2313\n",
      "2/8, train_loss: 0.0151 step time: 0.2003\n",
      "3/8, train_loss: 0.0139 step time: 0.1995\n",
      "4/8, train_loss: 0.0128 step time: 0.1999\n",
      "5/8, train_loss: 0.0145 step time: 0.2045\n",
      "6/8, train_loss: 0.0129 step time: 0.1991\n",
      "7/8, train_loss: 0.0150 step time: 0.1839\n",
      "8/8, train_loss: 0.0151 step time: 0.1828\n",
      "epoch 6 average loss: 0.0142\n",
      "time consuming of epoch 6 is: 1.6026\n",
      "----------\n",
      "epoch 7/600\n",
      "1/8, train_loss: 0.0120 step time: 0.2421\n",
      "2/8, train_loss: 0.0138 step time: 0.2006\n",
      "3/8, train_loss: 0.0136 step time: 0.2010\n",
      "4/8, train_loss: 0.0139 step time: 0.1994\n",
      "5/8, train_loss: 0.0138 step time: 0.2006\n",
      "6/8, train_loss: 0.0142 step time: 0.2040\n",
      "7/8, train_loss: 0.0131 step time: 0.1824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8, train_loss: 0.0161 step time: 0.1825\n",
      "epoch 7 average loss: 0.0138\n",
      "time consuming of epoch 7 is: 1.6140\n",
      "----------\n",
      "epoch 8/600\n",
      "1/8, train_loss: 0.0139 step time: 0.2372\n",
      "2/8, train_loss: 0.0162 step time: 0.1971\n",
      "3/8, train_loss: 0.0135 step time: 0.1971\n",
      "4/8, train_loss: 0.0138 step time: 0.1976\n",
      "5/8, train_loss: 0.0131 step time: 0.1973\n",
      "6/8, train_loss: 0.0153 step time: 0.2002\n",
      "7/8, train_loss: 0.0138 step time: 0.1828\n",
      "8/8, train_loss: 0.0132 step time: 0.1832\n",
      "epoch 8 average loss: 0.0141\n",
      "time consuming of epoch 8 is: 1.5940\n",
      "----------\n",
      "epoch 9/600\n",
      "1/8, train_loss: 0.0159 step time: 0.2383\n",
      "2/8, train_loss: 0.0139 step time: 0.1970\n",
      "3/8, train_loss: 0.0130 step time: 0.1969\n",
      "4/8, train_loss: 0.0144 step time: 0.1953\n",
      "5/8, train_loss: 0.0154 step time: 0.1993\n",
      "6/8, train_loss: 0.0156 step time: 0.1986\n",
      "7/8, train_loss: 0.0128 step time: 0.1823\n",
      "8/8, train_loss: 0.0136 step time: 0.1828\n",
      "epoch 9 average loss: 0.0143\n",
      "time consuming of epoch 9 is: 1.5918\n",
      "----------\n",
      "epoch 10/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2420\n",
      "2/8, train_loss: 0.0149 step time: 0.2044\n",
      "3/8, train_loss: 0.0136 step time: 0.2002\n",
      "4/8, train_loss: 0.0131 step time: 0.1999\n",
      "5/8, train_loss: 0.0132 step time: 0.2035\n",
      "6/8, train_loss: 0.0150 step time: 0.1975\n",
      "7/8, train_loss: 0.0148 step time: 0.1831\n",
      "8/8, train_loss: 0.0136 step time: 0.1826\n",
      "epoch 10 average loss: 0.0139\n",
      "current epoch: 10 current mean dice: 0.9563 best mean dice: 0.9569 at epoch: 5\n",
      "time consuming of epoch 10 is: 2.3713\n",
      "----------\n",
      "epoch 11/600\n",
      "1/8, train_loss: 0.0124 step time: 0.2407\n",
      "2/8, train_loss: 0.0160 step time: 0.1995\n",
      "3/8, train_loss: 0.0151 step time: 0.2001\n",
      "4/8, train_loss: 0.0115 step time: 0.1982\n",
      "5/8, train_loss: 0.0175 step time: 0.1989\n",
      "6/8, train_loss: 0.0130 step time: 0.2006\n",
      "7/8, train_loss: 0.0162 step time: 0.1825\n",
      "8/8, train_loss: 0.0160 step time: 0.1818\n",
      "epoch 11 average loss: 0.0147\n",
      "time consuming of epoch 11 is: 1.6036\n",
      "----------\n",
      "epoch 12/600\n",
      "1/8, train_loss: 0.0133 step time: 0.2390\n",
      "2/8, train_loss: 0.0160 step time: 0.2038\n",
      "3/8, train_loss: 0.0147 step time: 0.2021\n",
      "4/8, train_loss: 0.0136 step time: 0.1985\n",
      "5/8, train_loss: 0.0178 step time: 0.1964\n",
      "6/8, train_loss: 0.0129 step time: 0.1964\n",
      "7/8, train_loss: 0.0137 step time: 0.1831\n",
      "8/8, train_loss: 0.0155 step time: 0.1855\n",
      "epoch 12 average loss: 0.0147\n",
      "time consuming of epoch 12 is: 1.6062\n",
      "----------\n",
      "epoch 13/600\n",
      "1/8, train_loss: 0.0108 step time: 0.2414\n",
      "2/8, train_loss: 0.0133 step time: 0.2016\n",
      "3/8, train_loss: 0.0140 step time: 0.2018\n",
      "4/8, train_loss: 0.0134 step time: 0.2018\n",
      "5/8, train_loss: 0.0128 step time: 0.1999\n",
      "6/8, train_loss: 0.0183 step time: 0.2017\n",
      "7/8, train_loss: 0.0169 step time: 0.1831\n",
      "8/8, train_loss: 0.0140 step time: 0.1825\n",
      "epoch 13 average loss: 0.0142\n",
      "time consuming of epoch 13 is: 1.6152\n",
      "----------\n",
      "epoch 14/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2419\n",
      "2/8, train_loss: 0.0148 step time: 0.2052\n",
      "3/8, train_loss: 0.0144 step time: 0.1997\n",
      "4/8, train_loss: 0.0113 step time: 0.1997\n",
      "5/8, train_loss: 0.0134 step time: 0.1994\n",
      "6/8, train_loss: 0.0141 step time: 0.2011\n",
      "7/8, train_loss: 0.0175 step time: 0.1836\n",
      "8/8, train_loss: 0.0128 step time: 0.1825\n",
      "epoch 14 average loss: 0.0139\n",
      "time consuming of epoch 14 is: 1.6143\n",
      "----------\n",
      "epoch 15/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2387\n",
      "2/8, train_loss: 0.0140 step time: 0.2043\n",
      "3/8, train_loss: 0.0143 step time: 0.2023\n",
      "4/8, train_loss: 0.0138 step time: 0.2003\n",
      "5/8, train_loss: 0.0119 step time: 0.2017\n",
      "6/8, train_loss: 0.0134 step time: 0.2003\n",
      "7/8, train_loss: 0.0154 step time: 0.1832\n",
      "8/8, train_loss: 0.0131 step time: 0.1846\n",
      "epoch 15 average loss: 0.0139\n",
      "current epoch: 15 current mean dice: 0.9569 best mean dice: 0.9569 at epoch: 5\n",
      "time consuming of epoch 15 is: 2.3748\n",
      "----------\n",
      "epoch 16/600\n",
      "1/8, train_loss: 0.0157 step time: 0.2377\n",
      "2/8, train_loss: 0.0125 step time: 0.1987\n",
      "3/8, train_loss: 0.0129 step time: 0.1972\n",
      "4/8, train_loss: 0.0119 step time: 0.2026\n",
      "5/8, train_loss: 0.0166 step time: 0.1989\n",
      "6/8, train_loss: 0.0145 step time: 0.1988\n",
      "7/8, train_loss: 0.0110 step time: 0.1837\n",
      "8/8, train_loss: 0.0159 step time: 0.1813\n",
      "epoch 16 average loss: 0.0139\n",
      "time consuming of epoch 16 is: 1.6002\n",
      "----------\n",
      "epoch 17/600\n",
      "1/8, train_loss: 0.0153 step time: 0.2393\n",
      "2/8, train_loss: 0.0125 step time: 0.2033\n",
      "3/8, train_loss: 0.0136 step time: 0.2011\n",
      "4/8, train_loss: 0.0145 step time: 0.2034\n",
      "5/8, train_loss: 0.0132 step time: 0.1987\n",
      "6/8, train_loss: 0.0147 step time: 0.2021\n",
      "7/8, train_loss: 0.0152 step time: 0.1826\n",
      "8/8, train_loss: 0.0147 step time: 0.1830\n",
      "epoch 17 average loss: 0.0142\n",
      "time consuming of epoch 17 is: 1.6149\n",
      "----------\n",
      "epoch 18/600\n",
      "1/8, train_loss: 0.0134 step time: 0.2371\n",
      "2/8, train_loss: 0.0164 step time: 0.2023\n",
      "3/8, train_loss: 0.0163 step time: 0.2030\n",
      "4/8, train_loss: 0.0131 step time: 0.2005\n",
      "5/8, train_loss: 0.0104 step time: 0.2020\n",
      "6/8, train_loss: 0.0150 step time: 0.2030\n",
      "7/8, train_loss: 0.0143 step time: 0.1855\n",
      "8/8, train_loss: 0.0142 step time: 0.1812\n",
      "epoch 18 average loss: 0.0142\n",
      "time consuming of epoch 18 is: 1.6160\n",
      "----------\n",
      "epoch 19/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2329\n",
      "2/8, train_loss: 0.0155 step time: 0.2066\n",
      "3/8, train_loss: 0.0140 step time: 0.2097\n",
      "4/8, train_loss: 0.0140 step time: 0.2084\n",
      "5/8, train_loss: 0.0153 step time: 0.2085\n",
      "6/8, train_loss: 0.0123 step time: 0.2086\n",
      "7/8, train_loss: 0.0123 step time: 0.1809\n",
      "8/8, train_loss: 0.0136 step time: 0.1819\n",
      "epoch 19 average loss: 0.0140\n",
      "time consuming of epoch 19 is: 1.6389\n",
      "----------\n",
      "epoch 20/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2395\n",
      "2/8, train_loss: 0.0177 step time: 0.2032\n",
      "3/8, train_loss: 0.0128 step time: 0.2024\n",
      "4/8, train_loss: 0.0141 step time: 0.2018\n",
      "5/8, train_loss: 0.0139 step time: 0.1982\n",
      "6/8, train_loss: 0.0160 step time: 0.2028\n",
      "7/8, train_loss: 0.0129 step time: 0.1826\n",
      "8/8, train_loss: 0.0142 step time: 0.1825\n",
      "epoch 20 average loss: 0.0143\n",
      "current epoch: 20 current mean dice: 0.9569 best mean dice: 0.9569 at epoch: 5\n",
      "time consuming of epoch 20 is: 2.3662\n",
      "----------\n",
      "epoch 21/600\n",
      "1/8, train_loss: 0.0156 step time: 0.2324\n",
      "2/8, train_loss: 0.0118 step time: 0.1912\n",
      "3/8, train_loss: 0.0147 step time: 0.1915\n",
      "4/8, train_loss: 0.0132 step time: 0.1916\n",
      "5/8, train_loss: 0.0144 step time: 0.1931\n",
      "6/8, train_loss: 0.0148 step time: 0.1905\n",
      "7/8, train_loss: 0.0148 step time: 0.1814\n",
      "8/8, train_loss: 0.0121 step time: 0.1808\n",
      "epoch 21 average loss: 0.0139\n",
      "time consuming of epoch 21 is: 1.5535\n",
      "----------\n",
      "epoch 22/600\n",
      "1/8, train_loss: 0.0169 step time: 0.2387\n",
      "2/8, train_loss: 0.0150 step time: 0.2042\n",
      "3/8, train_loss: 0.0131 step time: 0.1975\n",
      "4/8, train_loss: 0.0135 step time: 0.2012\n",
      "5/8, train_loss: 0.0132 step time: 0.2002\n",
      "6/8, train_loss: 0.0149 step time: 0.2026\n",
      "7/8, train_loss: 0.0160 step time: 0.1828\n",
      "8/8, train_loss: 0.0145 step time: 0.1816\n",
      "epoch 22 average loss: 0.0146\n",
      "time consuming of epoch 22 is: 1.6099\n",
      "----------\n",
      "epoch 23/600\n",
      "1/8, train_loss: 0.0103 step time: 0.2393\n",
      "2/8, train_loss: 0.0146 step time: 0.1997\n",
      "3/8, train_loss: 0.0141 step time: 0.2018\n",
      "4/8, train_loss: 0.0143 step time: 0.2038\n",
      "5/8, train_loss: 0.0190 step time: 0.2016\n",
      "6/8, train_loss: 0.0135 step time: 0.2015\n",
      "7/8, train_loss: 0.0133 step time: 0.1831\n",
      "8/8, train_loss: 0.0151 step time: 0.1825\n",
      "epoch 23 average loss: 0.0143\n",
      "time consuming of epoch 23 is: 1.6146\n",
      "----------\n",
      "epoch 24/600\n",
      "1/8, train_loss: 0.0128 step time: 0.2387\n",
      "2/8, train_loss: 0.0134 step time: 0.2038\n",
      "3/8, train_loss: 0.0143 step time: 0.1991\n",
      "4/8, train_loss: 0.0113 step time: 0.2043\n",
      "5/8, train_loss: 0.0184 step time: 0.1993\n",
      "6/8, train_loss: 0.0110 step time: 0.2003\n",
      "7/8, train_loss: 0.0133 step time: 0.1817\n",
      "8/8, train_loss: 0.0180 step time: 0.1833\n",
      "epoch 24 average loss: 0.0141\n",
      "time consuming of epoch 24 is: 1.6120\n",
      "----------\n",
      "epoch 25/600\n",
      "1/8, train_loss: 0.0141 step time: 0.2400\n",
      "2/8, train_loss: 0.0147 step time: 0.1993\n",
      "3/8, train_loss: 0.0154 step time: 0.1996\n",
      "4/8, train_loss: 0.0118 step time: 0.2034\n",
      "5/8, train_loss: 0.0167 step time: 0.2026\n",
      "6/8, train_loss: 0.0141 step time: 0.2021\n",
      "7/8, train_loss: 0.0147 step time: 0.1827\n",
      "8/8, train_loss: 0.0157 step time: 0.1824\n",
      "epoch 25 average loss: 0.0147\n",
      "current epoch: 25 current mean dice: 0.9536 best mean dice: 0.9569 at epoch: 5\n",
      "time consuming of epoch 25 is: 2.3710\n",
      "----------\n",
      "epoch 26/600\n",
      "1/8, train_loss: 0.0135 step time: 0.2374\n",
      "2/8, train_loss: 0.0183 step time: 0.2005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8, train_loss: 0.0155 step time: 0.1998\n",
      "4/8, train_loss: 0.0146 step time: 0.2044\n",
      "5/8, train_loss: 0.0154 step time: 0.2003\n",
      "6/8, train_loss: 0.0144 step time: 0.2009\n",
      "7/8, train_loss: 0.0145 step time: 0.1833\n",
      "8/8, train_loss: 0.0126 step time: 0.1827\n",
      "epoch 26 average loss: 0.0148\n",
      "time consuming of epoch 26 is: 1.6104\n",
      "----------\n",
      "epoch 27/600\n",
      "1/8, train_loss: 0.0146 step time: 0.2429\n",
      "2/8, train_loss: 0.0171 step time: 0.2047\n",
      "3/8, train_loss: 0.0116 step time: 0.2027\n",
      "4/8, train_loss: 0.0167 step time: 0.1998\n",
      "5/8, train_loss: 0.0135 step time: 0.1991\n",
      "6/8, train_loss: 0.0173 step time: 0.2005\n",
      "7/8, train_loss: 0.0123 step time: 0.1825\n",
      "8/8, train_loss: 0.0133 step time: 0.1807\n",
      "epoch 27 average loss: 0.0146\n",
      "time consuming of epoch 27 is: 1.6140\n",
      "----------\n",
      "epoch 28/600\n",
      "1/8, train_loss: 0.0191 step time: 0.2341\n",
      "2/8, train_loss: 0.0137 step time: 0.1988\n",
      "3/8, train_loss: 0.0135 step time: 0.1993\n",
      "4/8, train_loss: 0.0145 step time: 0.2017\n",
      "5/8, train_loss: 0.0136 step time: 0.1994\n",
      "6/8, train_loss: 0.0140 step time: 0.2025\n",
      "7/8, train_loss: 0.0144 step time: 0.1845\n",
      "8/8, train_loss: 0.0127 step time: 0.1823\n",
      "epoch 28 average loss: 0.0144\n",
      "time consuming of epoch 28 is: 1.6037\n",
      "----------\n",
      "epoch 29/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2383\n",
      "2/8, train_loss: 0.0128 step time: 0.1987\n",
      "3/8, train_loss: 0.0158 step time: 0.1999\n",
      "4/8, train_loss: 0.0121 step time: 0.1989\n",
      "5/8, train_loss: 0.0194 step time: 0.2042\n",
      "6/8, train_loss: 0.0119 step time: 0.1993\n",
      "7/8, train_loss: 0.0121 step time: 0.1810\n",
      "8/8, train_loss: 0.0148 step time: 0.1813\n",
      "epoch 29 average loss: 0.0139\n",
      "time consuming of epoch 29 is: 1.6025\n",
      "----------\n",
      "epoch 30/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2384\n",
      "2/8, train_loss: 0.0140 step time: 0.1971\n",
      "3/8, train_loss: 0.0122 step time: 0.1992\n",
      "4/8, train_loss: 0.0127 step time: 0.2002\n",
      "5/8, train_loss: 0.0149 step time: 0.2000\n",
      "6/8, train_loss: 0.0148 step time: 0.1990\n",
      "7/8, train_loss: 0.0157 step time: 0.1827\n",
      "8/8, train_loss: 0.0138 step time: 0.1834\n",
      "epoch 30 average loss: 0.0142\n",
      "current epoch: 30 current mean dice: 0.9566 best mean dice: 0.9569 at epoch: 5\n",
      "time consuming of epoch 30 is: 2.3563\n",
      "----------\n",
      "epoch 31/600\n",
      "1/8, train_loss: 0.0158 step time: 0.2339\n",
      "2/8, train_loss: 0.0139 step time: 0.1953\n",
      "3/8, train_loss: 0.0141 step time: 0.1909\n",
      "4/8, train_loss: 0.0145 step time: 0.1957\n",
      "5/8, train_loss: 0.0145 step time: 0.1906\n",
      "6/8, train_loss: 0.0127 step time: 0.1906\n",
      "7/8, train_loss: 0.0115 step time: 0.1808\n",
      "8/8, train_loss: 0.0163 step time: 0.1811\n",
      "epoch 31 average loss: 0.0142\n",
      "time consuming of epoch 31 is: 1.5599\n",
      "----------\n",
      "epoch 32/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2431\n",
      "2/8, train_loss: 0.0149 step time: 0.2031\n",
      "3/8, train_loss: 0.0129 step time: 0.2014\n",
      "4/8, train_loss: 0.0135 step time: 0.2018\n",
      "5/8, train_loss: 0.0139 step time: 0.1989\n",
      "6/8, train_loss: 0.0153 step time: 0.2002\n",
      "7/8, train_loss: 0.0133 step time: 0.1835\n",
      "8/8, train_loss: 0.0146 step time: 0.1822\n",
      "epoch 32 average loss: 0.0140\n",
      "time consuming of epoch 32 is: 1.6157\n",
      "----------\n",
      "epoch 33/600\n",
      "1/8, train_loss: 0.0150 step time: 0.2388\n",
      "2/8, train_loss: 0.0132 step time: 0.1977\n",
      "3/8, train_loss: 0.0137 step time: 0.2014\n",
      "4/8, train_loss: 0.0146 step time: 0.2004\n",
      "5/8, train_loss: 0.0126 step time: 0.2030\n",
      "6/8, train_loss: 0.0128 step time: 0.1995\n",
      "7/8, train_loss: 0.0130 step time: 0.1828\n",
      "8/8, train_loss: 0.0152 step time: 0.1821\n",
      "epoch 33 average loss: 0.0138\n",
      "time consuming of epoch 33 is: 1.6073\n",
      "----------\n",
      "epoch 34/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2419\n",
      "2/8, train_loss: 0.0121 step time: 0.2032\n",
      "3/8, train_loss: 0.0124 step time: 0.2011\n",
      "4/8, train_loss: 0.0160 step time: 0.1996\n",
      "5/8, train_loss: 0.0149 step time: 0.2004\n",
      "6/8, train_loss: 0.0130 step time: 0.2023\n",
      "7/8, train_loss: 0.0150 step time: 0.1818\n",
      "8/8, train_loss: 0.0141 step time: 0.1830\n",
      "epoch 34 average loss: 0.0139\n",
      "time consuming of epoch 34 is: 1.6149\n",
      "----------\n",
      "epoch 35/600\n",
      "1/8, train_loss: 0.0162 step time: 0.2401\n",
      "2/8, train_loss: 0.0141 step time: 0.1975\n",
      "3/8, train_loss: 0.0145 step time: 0.2011\n",
      "4/8, train_loss: 0.0154 step time: 0.1987\n",
      "5/8, train_loss: 0.0120 step time: 0.2021\n",
      "6/8, train_loss: 0.0131 step time: 0.1998\n",
      "7/8, train_loss: 0.0145 step time: 0.1829\n",
      "8/8, train_loss: 0.0133 step time: 0.1837\n",
      "epoch 35 average loss: 0.0141\n",
      "current epoch: 35 current mean dice: 0.9561 best mean dice: 0.9569 at epoch: 5\n",
      "time consuming of epoch 35 is: 2.3631\n",
      "----------\n",
      "epoch 36/600\n",
      "1/8, train_loss: 0.0138 step time: 0.2377\n",
      "2/8, train_loss: 0.0121 step time: 0.1984\n",
      "3/8, train_loss: 0.0186 step time: 0.1992\n",
      "4/8, train_loss: 0.0138 step time: 0.2000\n",
      "5/8, train_loss: 0.0109 step time: 0.1973\n",
      "6/8, train_loss: 0.0169 step time: 0.1991\n",
      "7/8, train_loss: 0.0123 step time: 0.1813\n",
      "8/8, train_loss: 0.0122 step time: 0.1820\n",
      "epoch 36 average loss: 0.0138\n",
      "time consuming of epoch 36 is: 1.5960\n",
      "----------\n",
      "epoch 37/600\n",
      "1/8, train_loss: 0.0128 step time: 0.2462\n",
      "2/8, train_loss: 0.0143 step time: 0.2005\n",
      "3/8, train_loss: 0.0125 step time: 0.2010\n",
      "4/8, train_loss: 0.0134 step time: 0.1995\n",
      "5/8, train_loss: 0.0150 step time: 0.2002\n",
      "6/8, train_loss: 0.0154 step time: 0.1989\n",
      "7/8, train_loss: 0.0154 step time: 0.1835\n",
      "8/8, train_loss: 0.0127 step time: 0.1816\n",
      "epoch 37 average loss: 0.0139\n",
      "time consuming of epoch 37 is: 1.6127\n",
      "----------\n",
      "epoch 38/600\n",
      "1/8, train_loss: 0.0130 step time: 0.2413\n",
      "2/8, train_loss: 0.0141 step time: 0.2020\n",
      "3/8, train_loss: 0.0164 step time: 0.1987\n",
      "4/8, train_loss: 0.0122 step time: 0.2017\n",
      "5/8, train_loss: 0.0132 step time: 0.2006\n",
      "6/8, train_loss: 0.0154 step time: 0.2004\n",
      "7/8, train_loss: 0.0097 step time: 0.1830\n",
      "8/8, train_loss: 0.0140 step time: 0.1816\n",
      "epoch 38 average loss: 0.0135\n",
      "time consuming of epoch 38 is: 1.6108\n",
      "----------\n",
      "epoch 39/600\n",
      "1/8, train_loss: 0.0146 step time: 0.2411\n",
      "2/8, train_loss: 0.0124 step time: 0.2028\n",
      "3/8, train_loss: 0.0108 step time: 0.2020\n",
      "4/8, train_loss: 0.0125 step time: 0.2021\n",
      "5/8, train_loss: 0.0157 step time: 0.2010\n",
      "6/8, train_loss: 0.0140 step time: 0.2021\n",
      "7/8, train_loss: 0.0167 step time: 0.1827\n",
      "8/8, train_loss: 0.0132 step time: 0.1824\n",
      "epoch 39 average loss: 0.0137\n",
      "time consuming of epoch 39 is: 1.6177\n",
      "----------\n",
      "epoch 40/600\n",
      "1/8, train_loss: 0.0122 step time: 0.2415\n",
      "2/8, train_loss: 0.0148 step time: 0.2026\n",
      "3/8, train_loss: 0.0138 step time: 0.2003\n",
      "4/8, train_loss: 0.0133 step time: 0.2061\n",
      "5/8, train_loss: 0.0170 step time: 0.2035\n",
      "6/8, train_loss: 0.0150 step time: 0.2137\n",
      "7/8, train_loss: 0.0118 step time: 0.1824\n",
      "8/8, train_loss: 0.0142 step time: 0.1823\n",
      "epoch 40 average loss: 0.0140\n",
      "current epoch: 40 current mean dice: 0.9565 best mean dice: 0.9569 at epoch: 5\n",
      "time consuming of epoch 40 is: 2.3898\n",
      "----------\n",
      "epoch 41/600\n",
      "1/8, train_loss: 0.0133 step time: 0.2369\n",
      "2/8, train_loss: 0.0126 step time: 0.1998\n",
      "3/8, train_loss: 0.0132 step time: 0.1997\n",
      "4/8, train_loss: 0.0146 step time: 0.2021\n",
      "5/8, train_loss: 0.0153 step time: 0.1993\n",
      "6/8, train_loss: 0.0150 step time: 0.2009\n",
      "7/8, train_loss: 0.0149 step time: 0.1822\n",
      "8/8, train_loss: 0.0146 step time: 0.1815\n",
      "epoch 41 average loss: 0.0142\n",
      "time consuming of epoch 41 is: 1.6036\n",
      "----------\n",
      "epoch 42/600\n",
      "1/8, train_loss: 0.0127 step time: 0.2359\n",
      "2/8, train_loss: 0.0138 step time: 0.2028\n",
      "3/8, train_loss: 0.0134 step time: 0.1996\n",
      "4/8, train_loss: 0.0135 step time: 0.2014\n",
      "5/8, train_loss: 0.0143 step time: 0.2010\n",
      "6/8, train_loss: 0.0153 step time: 0.1990\n",
      "7/8, train_loss: 0.0142 step time: 0.1822\n",
      "8/8, train_loss: 0.0136 step time: 0.1826\n",
      "epoch 42 average loss: 0.0139\n",
      "time consuming of epoch 42 is: 1.6061\n",
      "----------\n",
      "epoch 43/600\n",
      "1/8, train_loss: 0.0160 step time: 0.2390\n",
      "2/8, train_loss: 0.0165 step time: 0.2043\n",
      "3/8, train_loss: 0.0144 step time: 0.1982\n",
      "4/8, train_loss: 0.0179 step time: 0.2006\n",
      "5/8, train_loss: 0.0126 step time: 0.1988\n",
      "6/8, train_loss: 0.0128 step time: 0.2018\n",
      "7/8, train_loss: 0.0125 step time: 0.1831\n",
      "8/8, train_loss: 0.0143 step time: 0.1819\n",
      "epoch 43 average loss: 0.0146\n",
      "time consuming of epoch 43 is: 1.6094\n",
      "----------\n",
      "epoch 44/600\n",
      "1/8, train_loss: 0.0138 step time: 0.2386\n",
      "2/8, train_loss: 0.0134 step time: 0.2011\n",
      "3/8, train_loss: 0.0167 step time: 0.1993\n",
      "4/8, train_loss: 0.0163 step time: 0.1999\n",
      "5/8, train_loss: 0.0124 step time: 0.1984\n",
      "6/8, train_loss: 0.0173 step time: 0.2049\n",
      "7/8, train_loss: 0.0138 step time: 0.1819\n",
      "8/8, train_loss: 0.0150 step time: 0.1816\n",
      "epoch 44 average loss: 0.0148\n",
      "time consuming of epoch 44 is: 1.6074\n",
      "----------\n",
      "epoch 45/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0135 step time: 0.2423\n",
      "2/8, train_loss: 0.0135 step time: 0.2029\n",
      "3/8, train_loss: 0.0122 step time: 0.2000\n",
      "4/8, train_loss: 0.0149 step time: 0.2014\n",
      "5/8, train_loss: 0.0158 step time: 0.2002\n",
      "6/8, train_loss: 0.0164 step time: 0.2016\n",
      "7/8, train_loss: 0.0144 step time: 0.1832\n",
      "8/8, train_loss: 0.0176 step time: 0.1822\n",
      "epoch 45 average loss: 0.0148\n",
      "current epoch: 45 current mean dice: 0.9564 best mean dice: 0.9569 at epoch: 5\n",
      "time consuming of epoch 45 is: 2.3724\n",
      "----------\n",
      "epoch 46/600\n",
      "1/8, train_loss: 0.0150 step time: 0.2390\n",
      "2/8, train_loss: 0.0165 step time: 0.1988\n",
      "3/8, train_loss: 0.0151 step time: 0.1998\n",
      "4/8, train_loss: 0.0150 step time: 0.2009\n",
      "5/8, train_loss: 0.0135 step time: 0.1982\n",
      "6/8, train_loss: 0.0121 step time: 0.2026\n",
      "7/8, train_loss: 0.0129 step time: 0.1832\n",
      "8/8, train_loss: 0.0115 step time: 0.1818\n",
      "epoch 46 average loss: 0.0139\n",
      "time consuming of epoch 46 is: 1.6057\n",
      "----------\n",
      "epoch 47/600\n",
      "1/8, train_loss: 0.0150 step time: 0.2384\n",
      "2/8, train_loss: 0.0122 step time: 0.1998\n",
      "3/8, train_loss: 0.0157 step time: 0.2031\n",
      "4/8, train_loss: 0.0137 step time: 0.1983\n",
      "5/8, train_loss: 0.0153 step time: 0.2050\n",
      "6/8, train_loss: 0.0152 step time: 0.1987\n",
      "7/8, train_loss: 0.0169 step time: 0.1824\n",
      "8/8, train_loss: 0.0152 step time: 0.1834\n",
      "epoch 47 average loss: 0.0149\n",
      "time consuming of epoch 47 is: 1.6106\n",
      "----------\n",
      "epoch 48/600\n",
      "1/8, train_loss: 0.0145 step time: 0.2461\n",
      "2/8, train_loss: 0.0146 step time: 0.2001\n",
      "3/8, train_loss: 0.0140 step time: 0.2015\n",
      "4/8, train_loss: 0.0128 step time: 0.1991\n",
      "5/8, train_loss: 0.0143 step time: 0.2012\n",
      "6/8, train_loss: 0.0117 step time: 0.2031\n",
      "7/8, train_loss: 0.0153 step time: 0.1824\n",
      "8/8, train_loss: 0.0166 step time: 0.1820\n",
      "epoch 48 average loss: 0.0142\n",
      "time consuming of epoch 48 is: 1.6168\n",
      "----------\n",
      "epoch 49/600\n",
      "1/8, train_loss: 0.0145 step time: 0.2441\n",
      "2/8, train_loss: 0.0123 step time: 0.2042\n",
      "3/8, train_loss: 0.0131 step time: 0.2019\n",
      "4/8, train_loss: 0.0122 step time: 0.1998\n",
      "5/8, train_loss: 0.0136 step time: 0.1934\n",
      "6/8, train_loss: 0.0160 step time: 0.2058\n",
      "7/8, train_loss: 0.0243 step time: 0.1834\n",
      "8/8, train_loss: 0.0132 step time: 0.1819\n",
      "epoch 49 average loss: 0.0149\n",
      "time consuming of epoch 49 is: 1.6162\n",
      "----------\n",
      "epoch 50/600\n",
      "1/8, train_loss: 0.0190 step time: 0.2372\n",
      "2/8, train_loss: 0.0141 step time: 0.2020\n",
      "3/8, train_loss: 0.0149 step time: 0.1985\n",
      "4/8, train_loss: 0.0145 step time: 0.1945\n",
      "5/8, train_loss: 0.0175 step time: 0.1926\n",
      "6/8, train_loss: 0.0156 step time: 0.1933\n",
      "7/8, train_loss: 0.0114 step time: 0.1833\n",
      "8/8, train_loss: 0.0152 step time: 0.1836\n",
      "epoch 50 average loss: 0.0153\n",
      "current epoch: 50 current mean dice: 0.9551 best mean dice: 0.9569 at epoch: 5\n",
      "time consuming of epoch 50 is: 2.3424\n",
      "----------\n",
      "epoch 51/600\n",
      "1/8, train_loss: 0.0156 step time: 0.2385\n",
      "2/8, train_loss: 0.0160 step time: 0.1981\n",
      "3/8, train_loss: 0.0121 step time: 0.1976\n",
      "4/8, train_loss: 0.0147 step time: 0.2022\n",
      "5/8, train_loss: 0.0152 step time: 0.1968\n",
      "6/8, train_loss: 0.0142 step time: 0.2014\n",
      "7/8, train_loss: 0.0175 step time: 0.1813\n",
      "8/8, train_loss: 0.0147 step time: 0.1836\n",
      "epoch 51 average loss: 0.0150\n",
      "time consuming of epoch 51 is: 1.6007\n",
      "----------\n",
      "epoch 52/600\n",
      "1/8, train_loss: 0.0136 step time: 0.2394\n",
      "2/8, train_loss: 0.0112 step time: 0.2000\n",
      "3/8, train_loss: 0.0170 step time: 0.2002\n",
      "4/8, train_loss: 0.0147 step time: 0.1997\n",
      "5/8, train_loss: 0.0151 step time: 0.2017\n",
      "6/8, train_loss: 0.0147 step time: 0.1987\n",
      "7/8, train_loss: 0.0145 step time: 0.1819\n",
      "8/8, train_loss: 0.0132 step time: 0.1833\n",
      "epoch 52 average loss: 0.0143\n",
      "time consuming of epoch 52 is: 1.6062\n",
      "----------\n",
      "epoch 53/600\n",
      "1/8, train_loss: 0.0121 step time: 0.2403\n",
      "2/8, train_loss: 0.0139 step time: 0.1994\n",
      "3/8, train_loss: 0.0180 step time: 0.1962\n",
      "4/8, train_loss: 0.0125 step time: 0.1962\n",
      "5/8, train_loss: 0.0155 step time: 0.1985\n",
      "6/8, train_loss: 0.0169 step time: 0.2030\n",
      "7/8, train_loss: 0.0138 step time: 0.1897\n",
      "8/8, train_loss: 0.0148 step time: 0.1850\n",
      "epoch 53 average loss: 0.0147\n",
      "time consuming of epoch 53 is: 1.6100\n",
      "----------\n",
      "epoch 54/600\n",
      "1/8, train_loss: 0.0152 step time: 0.2441\n",
      "2/8, train_loss: 0.0098 step time: 0.1992\n",
      "3/8, train_loss: 0.0129 step time: 0.2018\n",
      "4/8, train_loss: 0.0126 step time: 0.2054\n",
      "5/8, train_loss: 0.0128 step time: 0.2001\n",
      "6/8, train_loss: 0.0159 step time: 0.2009\n",
      "7/8, train_loss: 0.0122 step time: 0.1826\n",
      "8/8, train_loss: 0.0141 step time: 0.1820\n",
      "epoch 54 average loss: 0.0132\n",
      "time consuming of epoch 54 is: 1.6174\n",
      "----------\n",
      "epoch 55/600\n",
      "1/8, train_loss: 0.0148 step time: 0.2354\n",
      "2/8, train_loss: 0.0146 step time: 0.1967\n",
      "3/8, train_loss: 0.0126 step time: 0.1985\n",
      "4/8, train_loss: 0.0145 step time: 0.1979\n",
      "5/8, train_loss: 0.0156 step time: 0.1980\n",
      "6/8, train_loss: 0.0155 step time: 0.2027\n",
      "7/8, train_loss: 0.0134 step time: 0.1842\n",
      "8/8, train_loss: 0.0127 step time: 0.1819\n",
      "epoch 55 average loss: 0.0142\n",
      "saved new best metric model\n",
      "current epoch: 55 current mean dice: 0.9570 best mean dice: 0.9570 at epoch: 55\n",
      "time consuming of epoch 55 is: 2.4883\n",
      "----------\n",
      "epoch 56/600\n",
      "1/8, train_loss: 0.0172 step time: 0.2291\n",
      "2/8, train_loss: 0.0141 step time: 0.1982\n",
      "3/8, train_loss: 0.0128 step time: 0.1965\n",
      "4/8, train_loss: 0.0154 step time: 0.1948\n",
      "5/8, train_loss: 0.0133 step time: 0.1974\n",
      "6/8, train_loss: 0.0130 step time: 0.1969\n",
      "7/8, train_loss: 0.0144 step time: 0.1824\n",
      "8/8, train_loss: 0.0118 step time: 0.1805\n",
      "epoch 56 average loss: 0.0140\n",
      "time consuming of epoch 56 is: 1.5770\n",
      "----------\n",
      "epoch 57/600\n",
      "1/8, train_loss: 0.0140 step time: 0.2386\n",
      "2/8, train_loss: 0.0087 step time: 0.1980\n",
      "3/8, train_loss: 0.0136 step time: 0.2026\n",
      "4/8, train_loss: 0.0140 step time: 0.1983\n",
      "5/8, train_loss: 0.0157 step time: 0.1978\n",
      "6/8, train_loss: 0.0128 step time: 0.2526\n",
      "7/8, train_loss: 0.0162 step time: 0.1826\n",
      "8/8, train_loss: 0.0176 step time: 0.1821\n",
      "epoch 57 average loss: 0.0141\n",
      "time consuming of epoch 57 is: 1.6539\n",
      "----------\n",
      "epoch 58/600\n",
      "1/8, train_loss: 0.0203 step time: 0.2411\n",
      "2/8, train_loss: 0.0142 step time: 0.2021\n",
      "3/8, train_loss: 0.0178 step time: 0.1998\n",
      "4/8, train_loss: 0.0165 step time: 0.2008\n",
      "5/8, train_loss: 0.0134 step time: 0.2006\n",
      "6/8, train_loss: 0.0114 step time: 0.1994\n",
      "7/8, train_loss: 0.0130 step time: 0.1808\n",
      "8/8, train_loss: 0.0136 step time: 0.1825\n",
      "epoch 58 average loss: 0.0150\n",
      "time consuming of epoch 58 is: 1.6087\n",
      "----------\n",
      "epoch 59/600\n",
      "1/8, train_loss: 0.0161 step time: 0.2403\n",
      "2/8, train_loss: 0.0131 step time: 0.2019\n",
      "3/8, train_loss: 0.0157 step time: 0.2025\n",
      "4/8, train_loss: 0.0122 step time: 0.2024\n",
      "5/8, train_loss: 0.0134 step time: 0.1966\n",
      "6/8, train_loss: 0.0155 step time: 0.2022\n",
      "7/8, train_loss: 0.0116 step time: 0.1820\n",
      "8/8, train_loss: 0.0163 step time: 0.1847\n",
      "epoch 59 average loss: 0.0142\n",
      "time consuming of epoch 59 is: 1.6142\n",
      "----------\n",
      "epoch 60/600\n",
      "1/8, train_loss: 0.0171 step time: 0.2393\n",
      "2/8, train_loss: 0.0142 step time: 0.2118\n",
      "3/8, train_loss: 0.0134 step time: 0.1995\n",
      "4/8, train_loss: 0.0132 step time: 0.2119\n",
      "5/8, train_loss: 0.0146 step time: 0.2066\n",
      "6/8, train_loss: 0.0155 step time: 0.2014\n",
      "7/8, train_loss: 0.0131 step time: 0.1833\n",
      "8/8, train_loss: 0.0133 step time: 0.1806\n",
      "epoch 60 average loss: 0.0143\n",
      "saved new best metric model\n",
      "current epoch: 60 current mean dice: 0.9575 best mean dice: 0.9575 at epoch: 60\n",
      "time consuming of epoch 60 is: 2.5346\n",
      "----------\n",
      "epoch 61/600\n",
      "1/8, train_loss: 0.0132 step time: 0.2282\n",
      "2/8, train_loss: 0.0130 step time: 0.1994\n",
      "3/8, train_loss: 0.0143 step time: 0.1999\n",
      "4/8, train_loss: 0.0122 step time: 0.2000\n",
      "5/8, train_loss: 0.0141 step time: 0.1997\n",
      "6/8, train_loss: 0.0208 step time: 0.1991\n",
      "7/8, train_loss: 0.0142 step time: 0.1812\n",
      "8/8, train_loss: 0.0142 step time: 0.1821\n",
      "epoch 61 average loss: 0.0145\n",
      "time consuming of epoch 61 is: 1.5908\n",
      "----------\n",
      "epoch 62/600\n",
      "1/8, train_loss: 0.0129 step time: 0.2408\n",
      "2/8, train_loss: 0.0137 step time: 0.2035\n",
      "3/8, train_loss: 0.0162 step time: 0.1981\n",
      "4/8, train_loss: 0.0132 step time: 0.1977\n",
      "5/8, train_loss: 0.0140 step time: 0.1971\n",
      "6/8, train_loss: 0.0134 step time: 0.1995\n",
      "7/8, train_loss: 0.0148 step time: 0.1838\n",
      "8/8, train_loss: 0.0110 step time: 0.1839\n",
      "epoch 62 average loss: 0.0137\n",
      "time consuming of epoch 62 is: 1.6062\n",
      "----------\n",
      "epoch 63/600\n",
      "1/8, train_loss: 0.0140 step time: 0.2406\n",
      "2/8, train_loss: 0.0126 step time: 0.2012\n",
      "3/8, train_loss: 0.0137 step time: 0.2027\n",
      "4/8, train_loss: 0.0129 step time: 0.1996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8, train_loss: 0.0133 step time: 0.1996\n",
      "6/8, train_loss: 0.0182 step time: 0.2036\n",
      "7/8, train_loss: 0.0116 step time: 0.1833\n",
      "8/8, train_loss: 0.0153 step time: 0.1823\n",
      "epoch 63 average loss: 0.0140\n",
      "time consuming of epoch 63 is: 1.6144\n",
      "----------\n",
      "epoch 64/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2431\n",
      "2/8, train_loss: 0.0146 step time: 0.2018\n",
      "3/8, train_loss: 0.0138 step time: 0.1988\n",
      "4/8, train_loss: 0.0129 step time: 0.2006\n",
      "5/8, train_loss: 0.0143 step time: 0.2033\n",
      "6/8, train_loss: 0.0162 step time: 0.2012\n",
      "7/8, train_loss: 0.0161 step time: 0.1823\n",
      "8/8, train_loss: 0.0129 step time: 0.1823\n",
      "epoch 64 average loss: 0.0141\n",
      "time consuming of epoch 64 is: 1.6151\n",
      "----------\n",
      "epoch 65/600\n",
      "1/8, train_loss: 0.0132 step time: 0.2391\n",
      "2/8, train_loss: 0.0139 step time: 0.2004\n",
      "3/8, train_loss: 0.0151 step time: 0.2000\n",
      "4/8, train_loss: 0.0163 step time: 0.1989\n",
      "5/8, train_loss: 0.0116 step time: 0.1982\n",
      "6/8, train_loss: 0.0132 step time: 0.2003\n",
      "7/8, train_loss: 0.0181 step time: 0.1813\n",
      "8/8, train_loss: 0.0142 step time: 0.1803\n",
      "epoch 65 average loss: 0.0144\n",
      "current epoch: 65 current mean dice: 0.9565 best mean dice: 0.9575 at epoch: 60\n",
      "time consuming of epoch 65 is: 2.3543\n",
      "----------\n",
      "epoch 66/600\n",
      "1/8, train_loss: 0.0160 step time: 0.2402\n",
      "2/8, train_loss: 0.0133 step time: 0.2026\n",
      "3/8, train_loss: 0.0130 step time: 0.2016\n",
      "4/8, train_loss: 0.0151 step time: 0.1980\n",
      "5/8, train_loss: 0.0150 step time: 0.2031\n",
      "6/8, train_loss: 0.0116 step time: 0.1995\n",
      "7/8, train_loss: 0.0130 step time: 0.1832\n",
      "8/8, train_loss: 0.0151 step time: 0.1823\n",
      "epoch 66 average loss: 0.0140\n",
      "time consuming of epoch 66 is: 1.6116\n",
      "----------\n",
      "epoch 67/600\n",
      "1/8, train_loss: 0.0132 step time: 0.2410\n",
      "2/8, train_loss: 0.0136 step time: 0.2032\n",
      "3/8, train_loss: 0.0136 step time: 0.2003\n",
      "4/8, train_loss: 0.0152 step time: 0.2012\n",
      "5/8, train_loss: 0.0134 step time: 0.2019\n",
      "6/8, train_loss: 0.0121 step time: 0.2041\n",
      "7/8, train_loss: 0.0129 step time: 0.1838\n",
      "8/8, train_loss: 0.0156 step time: 0.1818\n",
      "epoch 67 average loss: 0.0137\n",
      "time consuming of epoch 67 is: 1.6186\n",
      "----------\n",
      "epoch 68/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2409\n",
      "2/8, train_loss: 0.0157 step time: 0.2044\n",
      "3/8, train_loss: 0.0134 step time: 0.2039\n",
      "4/8, train_loss: 0.0126 step time: 0.2035\n",
      "5/8, train_loss: 0.0128 step time: 0.2015\n",
      "6/8, train_loss: 0.0123 step time: 0.2012\n",
      "7/8, train_loss: 0.0158 step time: 0.1808\n",
      "8/8, train_loss: 0.0123 step time: 0.1811\n",
      "epoch 68 average loss: 0.0136\n",
      "time consuming of epoch 68 is: 1.6190\n",
      "----------\n",
      "epoch 69/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2369\n",
      "2/8, train_loss: 0.0135 step time: 0.2000\n",
      "3/8, train_loss: 0.0152 step time: 0.1985\n",
      "4/8, train_loss: 0.0144 step time: 0.1983\n",
      "5/8, train_loss: 0.0126 step time: 0.2020\n",
      "6/8, train_loss: 0.0123 step time: 0.2018\n",
      "7/8, train_loss: 0.0130 step time: 0.1819\n",
      "8/8, train_loss: 0.0118 step time: 0.1844\n",
      "epoch 69 average loss: 0.0133\n",
      "time consuming of epoch 69 is: 1.6053\n",
      "----------\n",
      "epoch 70/600\n",
      "1/8, train_loss: 0.0124 step time: 0.2406\n",
      "2/8, train_loss: 0.0140 step time: 0.2043\n",
      "3/8, train_loss: 0.0120 step time: 0.2043\n",
      "4/8, train_loss: 0.0143 step time: 0.1998\n",
      "5/8, train_loss: 0.0143 step time: 0.2018\n",
      "6/8, train_loss: 0.0118 step time: 0.1993\n",
      "7/8, train_loss: 0.0177 step time: 0.1816\n",
      "8/8, train_loss: 0.0150 step time: 0.1826\n",
      "epoch 70 average loss: 0.0139\n",
      "current epoch: 70 current mean dice: 0.9565 best mean dice: 0.9575 at epoch: 60\n",
      "time consuming of epoch 70 is: 2.3703\n",
      "----------\n",
      "epoch 71/600\n",
      "1/8, train_loss: 0.0145 step time: 0.2369\n",
      "2/8, train_loss: 0.0155 step time: 0.1966\n",
      "3/8, train_loss: 0.0127 step time: 0.2033\n",
      "4/8, train_loss: 0.0136 step time: 0.1968\n",
      "5/8, train_loss: 0.0119 step time: 0.1996\n",
      "6/8, train_loss: 0.0137 step time: 0.2024\n",
      "7/8, train_loss: 0.0139 step time: 0.1818\n",
      "8/8, train_loss: 0.0125 step time: 0.1831\n",
      "epoch 71 average loss: 0.0135\n",
      "time consuming of epoch 71 is: 1.6017\n",
      "----------\n",
      "epoch 72/600\n",
      "1/8, train_loss: 0.0120 step time: 0.2431\n",
      "2/8, train_loss: 0.0119 step time: 0.2050\n",
      "3/8, train_loss: 0.0130 step time: 0.2040\n",
      "4/8, train_loss: 0.0140 step time: 0.2019\n",
      "5/8, train_loss: 0.0149 step time: 0.1997\n",
      "6/8, train_loss: 0.0163 step time: 0.2061\n",
      "7/8, train_loss: 0.0136 step time: 0.1830\n",
      "8/8, train_loss: 0.0160 step time: 0.1837\n",
      "epoch 72 average loss: 0.0140\n",
      "time consuming of epoch 72 is: 1.6283\n",
      "----------\n",
      "epoch 73/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2396\n",
      "2/8, train_loss: 0.0133 step time: 0.2056\n",
      "3/8, train_loss: 0.0132 step time: 0.1999\n",
      "4/8, train_loss: 0.0111 step time: 0.1998\n",
      "5/8, train_loss: 0.0122 step time: 0.1994\n",
      "6/8, train_loss: 0.0110 step time: 0.2018\n",
      "7/8, train_loss: 0.0152 step time: 0.1820\n",
      "8/8, train_loss: 0.0142 step time: 0.1817\n",
      "epoch 73 average loss: 0.0128\n",
      "time consuming of epoch 73 is: 1.6111\n",
      "----------\n",
      "epoch 74/600\n",
      "1/8, train_loss: 0.0155 step time: 0.2392\n",
      "2/8, train_loss: 0.0132 step time: 0.1993\n",
      "3/8, train_loss: 0.0155 step time: 0.2026\n",
      "4/8, train_loss: 0.0114 step time: 0.2019\n",
      "5/8, train_loss: 0.0130 step time: 0.2037\n",
      "6/8, train_loss: 0.0127 step time: 0.2017\n",
      "7/8, train_loss: 0.0140 step time: 0.1849\n",
      "8/8, train_loss: 0.0145 step time: 0.1832\n",
      "epoch 74 average loss: 0.0137\n",
      "time consuming of epoch 74 is: 1.6179\n",
      "----------\n",
      "epoch 75/600\n",
      "1/8, train_loss: 0.0139 step time: 0.2411\n",
      "2/8, train_loss: 0.0168 step time: 0.2021\n",
      "3/8, train_loss: 0.0155 step time: 0.2004\n",
      "4/8, train_loss: 0.0153 step time: 0.2005\n",
      "5/8, train_loss: 0.0120 step time: 0.2005\n",
      "6/8, train_loss: 0.0114 step time: 0.2004\n",
      "7/8, train_loss: 0.0127 step time: 0.1828\n",
      "8/8, train_loss: 0.0141 step time: 0.1823\n",
      "epoch 75 average loss: 0.0140\n",
      "saved new best metric model\n",
      "current epoch: 75 current mean dice: 0.9576 best mean dice: 0.9576 at epoch: 75\n",
      "time consuming of epoch 75 is: 2.5109\n",
      "----------\n",
      "epoch 76/600\n",
      "1/8, train_loss: 0.0140 step time: 0.2379\n",
      "2/8, train_loss: 0.0114 step time: 0.1998\n",
      "3/8, train_loss: 0.0174 step time: 0.1998\n",
      "4/8, train_loss: 0.0134 step time: 0.1997\n",
      "5/8, train_loss: 0.0154 step time: 0.2008\n",
      "6/8, train_loss: 0.0135 step time: 0.1997\n",
      "7/8, train_loss: 0.0139 step time: 0.1823\n",
      "8/8, train_loss: 0.0138 step time: 0.1816\n",
      "epoch 76 average loss: 0.0141\n",
      "time consuming of epoch 76 is: 1.6028\n",
      "----------\n",
      "epoch 77/600\n",
      "1/8, train_loss: 0.0123 step time: 0.2405\n",
      "2/8, train_loss: 0.0150 step time: 0.1987\n",
      "3/8, train_loss: 0.0108 step time: 0.2017\n",
      "4/8, train_loss: 0.0128 step time: 0.2024\n",
      "5/8, train_loss: 0.0162 step time: 0.1954\n",
      "6/8, train_loss: 0.0149 step time: 0.1991\n",
      "7/8, train_loss: 0.0160 step time: 0.1848\n",
      "8/8, train_loss: 0.0125 step time: 0.1824\n",
      "epoch 77 average loss: 0.0138\n",
      "time consuming of epoch 77 is: 1.6065\n",
      "----------\n",
      "epoch 78/600\n",
      "1/8, train_loss: 0.0161 step time: 0.2400\n",
      "2/8, train_loss: 0.0128 step time: 0.2024\n",
      "3/8, train_loss: 0.0143 step time: 0.2005\n",
      "4/8, train_loss: 0.0122 step time: 0.1999\n",
      "5/8, train_loss: 0.0145 step time: 0.2001\n",
      "6/8, train_loss: 0.0133 step time: 0.2022\n",
      "7/8, train_loss: 0.0149 step time: 0.1829\n",
      "8/8, train_loss: 0.0145 step time: 0.1830\n",
      "epoch 78 average loss: 0.0141\n",
      "time consuming of epoch 78 is: 1.6123\n",
      "----------\n",
      "epoch 79/600\n",
      "1/8, train_loss: 0.0122 step time: 0.2417\n",
      "2/8, train_loss: 0.0125 step time: 0.2040\n",
      "3/8, train_loss: 0.0119 step time: 0.2003\n",
      "4/8, train_loss: 0.0159 step time: 0.2033\n",
      "5/8, train_loss: 0.0154 step time: 0.1995\n",
      "6/8, train_loss: 0.0152 step time: 0.2005\n",
      "7/8, train_loss: 0.0132 step time: 0.1825\n",
      "8/8, train_loss: 0.0150 step time: 0.1847\n",
      "epoch 79 average loss: 0.0139\n",
      "time consuming of epoch 79 is: 1.6181\n",
      "----------\n",
      "epoch 80/600\n",
      "1/8, train_loss: 0.0142 step time: 0.2393\n",
      "2/8, train_loss: 0.0128 step time: 0.2029\n",
      "3/8, train_loss: 0.0154 step time: 0.2017\n",
      "4/8, train_loss: 0.0116 step time: 0.1998\n",
      "5/8, train_loss: 0.0152 step time: 0.2001\n",
      "6/8, train_loss: 0.0139 step time: 0.1996\n",
      "7/8, train_loss: 0.0149 step time: 0.1831\n",
      "8/8, train_loss: 0.0105 step time: 0.1822\n",
      "epoch 80 average loss: 0.0136\n",
      "current epoch: 80 current mean dice: 0.9575 best mean dice: 0.9576 at epoch: 75\n",
      "time consuming of epoch 80 is: 2.3645\n",
      "----------\n",
      "epoch 81/600\n",
      "1/8, train_loss: 0.0134 step time: 0.2404\n",
      "2/8, train_loss: 0.0143 step time: 0.1938\n",
      "3/8, train_loss: 0.0121 step time: 0.1943\n",
      "4/8, train_loss: 0.0138 step time: 0.1935\n",
      "5/8, train_loss: 0.0138 step time: 0.1943\n",
      "6/8, train_loss: 0.0138 step time: 0.1942\n",
      "7/8, train_loss: 0.0133 step time: 0.1820\n",
      "8/8, train_loss: 0.0135 step time: 0.1827\n",
      "epoch 81 average loss: 0.0135\n",
      "time consuming of epoch 81 is: 1.5763\n",
      "----------\n",
      "epoch 82/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0151 step time: 0.2411\n",
      "2/8, train_loss: 0.0111 step time: 0.1994\n",
      "3/8, train_loss: 0.0124 step time: 0.2000\n",
      "4/8, train_loss: 0.0157 step time: 0.2027\n",
      "5/8, train_loss: 0.0129 step time: 0.1982\n",
      "6/8, train_loss: 0.0149 step time: 0.2011\n",
      "7/8, train_loss: 0.0148 step time: 0.1820\n",
      "8/8, train_loss: 0.0134 step time: 0.1817\n",
      "epoch 82 average loss: 0.0138\n",
      "time consuming of epoch 82 is: 1.6077\n",
      "----------\n",
      "epoch 83/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2416\n",
      "2/8, train_loss: 0.0145 step time: 0.2001\n",
      "3/8, train_loss: 0.0144 step time: 0.2067\n",
      "4/8, train_loss: 0.0139 step time: 0.1972\n",
      "5/8, train_loss: 0.0122 step time: 0.2017\n",
      "6/8, train_loss: 0.0132 step time: 0.1977\n",
      "7/8, train_loss: 0.0121 step time: 0.1816\n",
      "8/8, train_loss: 0.0126 step time: 0.1807\n",
      "epoch 83 average loss: 0.0133\n",
      "time consuming of epoch 83 is: 1.6087\n",
      "----------\n",
      "epoch 84/600\n",
      "1/8, train_loss: 0.0132 step time: 0.2362\n",
      "2/8, train_loss: 0.0114 step time: 0.1979\n",
      "3/8, train_loss: 0.0144 step time: 0.1999\n",
      "4/8, train_loss: 0.0134 step time: 0.1986\n",
      "5/8, train_loss: 0.0135 step time: 0.1985\n",
      "6/8, train_loss: 0.0142 step time: 0.1976\n",
      "7/8, train_loss: 0.0143 step time: 0.1826\n",
      "8/8, train_loss: 0.0130 step time: 0.1822\n",
      "epoch 84 average loss: 0.0134\n",
      "time consuming of epoch 84 is: 1.5949\n",
      "----------\n",
      "epoch 85/600\n",
      "1/8, train_loss: 0.0144 step time: 0.2400\n",
      "2/8, train_loss: 0.0148 step time: 0.1996\n",
      "3/8, train_loss: 0.0121 step time: 0.1990\n",
      "4/8, train_loss: 0.0152 step time: 0.1991\n",
      "5/8, train_loss: 0.0127 step time: 0.2009\n",
      "6/8, train_loss: 0.0148 step time: 0.1990\n",
      "7/8, train_loss: 0.0127 step time: 0.1846\n",
      "8/8, train_loss: 0.0133 step time: 0.1815\n",
      "epoch 85 average loss: 0.0138\n",
      "current epoch: 85 current mean dice: 0.9565 best mean dice: 0.9576 at epoch: 75\n",
      "time consuming of epoch 85 is: 2.3607\n",
      "----------\n",
      "epoch 86/600\n",
      "1/8, train_loss: 0.0120 step time: 0.2319\n",
      "2/8, train_loss: 0.0131 step time: 0.1965\n",
      "3/8, train_loss: 0.0146 step time: 0.1922\n",
      "4/8, train_loss: 0.0136 step time: 0.1932\n",
      "5/8, train_loss: 0.0117 step time: 0.1932\n",
      "6/8, train_loss: 0.0117 step time: 0.1928\n",
      "7/8, train_loss: 0.0132 step time: 0.1823\n",
      "8/8, train_loss: 0.0159 step time: 0.1825\n",
      "epoch 86 average loss: 0.0132\n",
      "time consuming of epoch 86 is: 1.5658\n",
      "----------\n",
      "epoch 87/600\n",
      "1/8, train_loss: 0.0123 step time: 0.2392\n",
      "2/8, train_loss: 0.0138 step time: 0.2027\n",
      "3/8, train_loss: 0.0134 step time: 0.2024\n",
      "4/8, train_loss: 0.0132 step time: 0.1999\n",
      "5/8, train_loss: 0.0146 step time: 0.2007\n",
      "6/8, train_loss: 0.0121 step time: 0.2020\n",
      "7/8, train_loss: 0.0158 step time: 0.1826\n",
      "8/8, train_loss: 0.0135 step time: 0.1816\n",
      "epoch 87 average loss: 0.0136\n",
      "time consuming of epoch 87 is: 1.6128\n",
      "----------\n",
      "epoch 88/600\n",
      "1/8, train_loss: 0.0133 step time: 0.2384\n",
      "2/8, train_loss: 0.0130 step time: 0.1969\n",
      "3/8, train_loss: 0.0131 step time: 0.1967\n",
      "4/8, train_loss: 0.0152 step time: 0.2015\n",
      "5/8, train_loss: 0.0123 step time: 0.1994\n",
      "6/8, train_loss: 0.0142 step time: 0.2011\n",
      "7/8, train_loss: 0.0159 step time: 0.1835\n",
      "8/8, train_loss: 0.0131 step time: 0.1829\n",
      "epoch 88 average loss: 0.0137\n",
      "time consuming of epoch 88 is: 1.6018\n",
      "----------\n",
      "epoch 89/600\n",
      "1/8, train_loss: 0.0172 step time: 0.2392\n",
      "2/8, train_loss: 0.0132 step time: 0.2014\n",
      "3/8, train_loss: 0.0118 step time: 0.1987\n",
      "4/8, train_loss: 0.0136 step time: 0.2000\n",
      "5/8, train_loss: 0.0135 step time: 0.1984\n",
      "6/8, train_loss: 0.0138 step time: 0.2017\n",
      "7/8, train_loss: 0.0121 step time: 0.1827\n",
      "8/8, train_loss: 0.0169 step time: 0.1815\n",
      "epoch 89 average loss: 0.0140\n",
      "time consuming of epoch 89 is: 1.6055\n",
      "----------\n",
      "epoch 90/600\n",
      "1/8, train_loss: 0.0138 step time: 0.2423\n",
      "2/8, train_loss: 0.0135 step time: 0.2026\n",
      "3/8, train_loss: 0.0129 step time: 0.1998\n",
      "4/8, train_loss: 0.0115 step time: 0.1995\n",
      "5/8, train_loss: 0.0180 step time: 0.1976\n",
      "6/8, train_loss: 0.0103 step time: 0.2026\n",
      "7/8, train_loss: 0.0138 step time: 0.1824\n",
      "8/8, train_loss: 0.0132 step time: 0.1833\n",
      "epoch 90 average loss: 0.0134\n",
      "current epoch: 90 current mean dice: 0.9572 best mean dice: 0.9576 at epoch: 75\n",
      "time consuming of epoch 90 is: 2.3665\n",
      "----------\n",
      "epoch 91/600\n",
      "1/8, train_loss: 0.0111 step time: 0.2424\n",
      "2/8, train_loss: 0.0122 step time: 0.2020\n",
      "3/8, train_loss: 0.0147 step time: 0.1990\n",
      "4/8, train_loss: 0.0167 step time: 0.2014\n",
      "5/8, train_loss: 0.0142 step time: 0.2005\n",
      "6/8, train_loss: 0.0132 step time: 0.1988\n",
      "7/8, train_loss: 0.0143 step time: 0.1833\n",
      "8/8, train_loss: 0.0129 step time: 0.1822\n",
      "epoch 91 average loss: 0.0137\n",
      "time consuming of epoch 91 is: 1.6107\n",
      "----------\n",
      "epoch 92/600\n",
      "1/8, train_loss: 0.0122 step time: 0.2425\n",
      "2/8, train_loss: 0.0106 step time: 0.1983\n",
      "3/8, train_loss: 0.0121 step time: 0.2040\n",
      "4/8, train_loss: 0.0127 step time: 0.1994\n",
      "5/8, train_loss: 0.0149 step time: 0.2006\n",
      "6/8, train_loss: 0.0151 step time: 0.2021\n",
      "7/8, train_loss: 0.0108 step time: 0.1840\n",
      "8/8, train_loss: 0.0149 step time: 0.1840\n",
      "epoch 92 average loss: 0.0129\n",
      "time consuming of epoch 92 is: 1.6166\n",
      "----------\n",
      "epoch 93/600\n",
      "1/8, train_loss: 0.0154 step time: 0.2399\n",
      "2/8, train_loss: 0.0143 step time: 0.2028\n",
      "3/8, train_loss: 0.0139 step time: 0.1974\n",
      "4/8, train_loss: 0.0146 step time: 0.1985\n",
      "5/8, train_loss: 0.0126 step time: 0.1998\n",
      "6/8, train_loss: 0.0134 step time: 0.1991\n",
      "7/8, train_loss: 0.0119 step time: 0.1829\n",
      "8/8, train_loss: 0.0123 step time: 0.1826\n",
      "epoch 93 average loss: 0.0136\n",
      "time consuming of epoch 93 is: 1.6046\n",
      "----------\n",
      "epoch 94/600\n",
      "1/8, train_loss: 0.0144 step time: 0.2397\n",
      "2/8, train_loss: 0.0134 step time: 0.2026\n",
      "3/8, train_loss: 0.0126 step time: 0.2034\n",
      "4/8, train_loss: 0.0142 step time: 0.1994\n",
      "5/8, train_loss: 0.0143 step time: 0.2011\n",
      "6/8, train_loss: 0.0140 step time: 0.1997\n",
      "7/8, train_loss: 0.0130 step time: 0.1834\n",
      "8/8, train_loss: 0.0130 step time: 0.1838\n",
      "epoch 94 average loss: 0.0136\n",
      "time consuming of epoch 94 is: 1.6144\n",
      "----------\n",
      "epoch 95/600\n",
      "1/8, train_loss: 0.0167 step time: 0.2393\n",
      "2/8, train_loss: 0.0131 step time: 0.2022\n",
      "3/8, train_loss: 0.0141 step time: 0.2024\n",
      "4/8, train_loss: 0.0140 step time: 0.1997\n",
      "5/8, train_loss: 0.0127 step time: 0.2015\n",
      "6/8, train_loss: 0.0118 step time: 0.2001\n",
      "7/8, train_loss: 0.0141 step time: 0.1834\n",
      "8/8, train_loss: 0.0122 step time: 0.1827\n",
      "epoch 95 average loss: 0.0136\n",
      "saved new best metric model\n",
      "current epoch: 95 current mean dice: 0.9580 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 95 is: 2.5098\n",
      "----------\n",
      "epoch 96/600\n",
      "1/8, train_loss: 0.0138 step time: 0.2392\n",
      "2/8, train_loss: 0.0134 step time: 0.2103\n",
      "3/8, train_loss: 0.0126 step time: 0.1987\n",
      "4/8, train_loss: 0.0161 step time: 0.1994\n",
      "5/8, train_loss: 0.0144 step time: 0.2045\n",
      "6/8, train_loss: 0.0147 step time: 0.1996\n",
      "7/8, train_loss: 0.0129 step time: 0.1847\n",
      "8/8, train_loss: 0.0156 step time: 0.1825\n",
      "epoch 96 average loss: 0.0142\n",
      "time consuming of epoch 96 is: 1.6202\n",
      "----------\n",
      "epoch 97/600\n",
      "1/8, train_loss: 0.0129 step time: 0.2327\n",
      "2/8, train_loss: 0.0120 step time: 0.1967\n",
      "3/8, train_loss: 0.0148 step time: 0.1994\n",
      "4/8, train_loss: 0.0133 step time: 0.2022\n",
      "5/8, train_loss: 0.0139 step time: 0.1990\n",
      "6/8, train_loss: 0.0143 step time: 0.2008\n",
      "7/8, train_loss: 0.0137 step time: 0.1840\n",
      "8/8, train_loss: 0.0149 step time: 0.1824\n",
      "epoch 97 average loss: 0.0137\n",
      "time consuming of epoch 97 is: 1.5985\n",
      "----------\n",
      "epoch 98/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2426\n",
      "2/8, train_loss: 0.0131 step time: 0.2042\n",
      "3/8, train_loss: 0.0145 step time: 0.2096\n",
      "4/8, train_loss: 0.0125 step time: 0.2067\n",
      "5/8, train_loss: 0.0143 step time: 0.1988\n",
      "6/8, train_loss: 0.0128 step time: 0.2048\n",
      "7/8, train_loss: 0.0125 step time: 0.1839\n",
      "8/8, train_loss: 0.0120 step time: 0.1825\n",
      "epoch 98 average loss: 0.0134\n",
      "time consuming of epoch 98 is: 1.6349\n",
      "----------\n",
      "epoch 99/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2405\n",
      "2/8, train_loss: 0.0112 step time: 0.2031\n",
      "3/8, train_loss: 0.0122 step time: 0.2028\n",
      "4/8, train_loss: 0.0136 step time: 0.1990\n",
      "5/8, train_loss: 0.0139 step time: 0.2004\n",
      "6/8, train_loss: 0.0151 step time: 0.1993\n",
      "7/8, train_loss: 0.0131 step time: 0.1838\n",
      "8/8, train_loss: 0.0153 step time: 0.1849\n",
      "epoch 99 average loss: 0.0135\n",
      "time consuming of epoch 99 is: 1.6155\n",
      "----------\n",
      "epoch 100/600\n",
      "1/8, train_loss: 0.0124 step time: 0.2512\n",
      "2/8, train_loss: 0.0131 step time: 0.1959\n",
      "3/8, train_loss: 0.0159 step time: 0.2007\n",
      "4/8, train_loss: 0.0131 step time: 0.1977\n",
      "5/8, train_loss: 0.0144 step time: 0.1983\n",
      "6/8, train_loss: 0.0136 step time: 0.2015\n",
      "7/8, train_loss: 0.0138 step time: 0.1827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8, train_loss: 0.0122 step time: 0.1827\n",
      "epoch 100 average loss: 0.0136\n",
      "current epoch: 100 current mean dice: 0.9575 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 100 is: 2.3680\n",
      "----------\n",
      "epoch 101/600\n",
      "1/8, train_loss: 0.0138 step time: 0.2361\n",
      "2/8, train_loss: 0.0126 step time: 0.2029\n",
      "3/8, train_loss: 0.0150 step time: 0.1982\n",
      "4/8, train_loss: 0.0158 step time: 0.2006\n",
      "5/8, train_loss: 0.0110 step time: 0.1975\n",
      "6/8, train_loss: 0.0149 step time: 0.2005\n",
      "7/8, train_loss: 0.0155 step time: 0.1844\n",
      "8/8, train_loss: 0.0123 step time: 0.1831\n",
      "epoch 101 average loss: 0.0139\n",
      "time consuming of epoch 101 is: 1.6044\n",
      "----------\n",
      "epoch 102/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2376\n",
      "2/8, train_loss: 0.0132 step time: 0.2033\n",
      "3/8, train_loss: 0.0137 step time: 0.1990\n",
      "4/8, train_loss: 0.0113 step time: 0.2003\n",
      "5/8, train_loss: 0.0143 step time: 0.1986\n",
      "6/8, train_loss: 0.0107 step time: 0.1979\n",
      "7/8, train_loss: 0.0155 step time: 0.1827\n",
      "8/8, train_loss: 0.0154 step time: 0.1829\n",
      "epoch 102 average loss: 0.0133\n",
      "time consuming of epoch 102 is: 1.6037\n",
      "----------\n",
      "epoch 103/600\n",
      "1/8, train_loss: 0.0146 step time: 0.2393\n",
      "2/8, train_loss: 0.0159 step time: 0.2060\n",
      "3/8, train_loss: 0.0105 step time: 0.1979\n",
      "4/8, train_loss: 0.0138 step time: 0.2023\n",
      "5/8, train_loss: 0.0140 step time: 0.1976\n",
      "6/8, train_loss: 0.0129 step time: 0.1997\n",
      "7/8, train_loss: 0.0132 step time: 0.1842\n",
      "8/8, train_loss: 0.0131 step time: 0.1825\n",
      "epoch 103 average loss: 0.0135\n",
      "time consuming of epoch 103 is: 1.6112\n",
      "----------\n",
      "epoch 104/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2394\n",
      "2/8, train_loss: 0.0145 step time: 0.2026\n",
      "3/8, train_loss: 0.0141 step time: 0.1997\n",
      "4/8, train_loss: 0.0150 step time: 0.2002\n",
      "5/8, train_loss: 0.0120 step time: 0.2017\n",
      "6/8, train_loss: 0.0133 step time: 0.1996\n",
      "7/8, train_loss: 0.0106 step time: 0.1828\n",
      "8/8, train_loss: 0.0160 step time: 0.1838\n",
      "epoch 104 average loss: 0.0135\n",
      "time consuming of epoch 104 is: 1.6110\n",
      "----------\n",
      "epoch 105/600\n",
      "1/8, train_loss: 0.0124 step time: 0.2403\n",
      "2/8, train_loss: 0.0144 step time: 0.1998\n",
      "3/8, train_loss: 0.0132 step time: 0.2028\n",
      "4/8, train_loss: 0.0151 step time: 0.2003\n",
      "5/8, train_loss: 0.0129 step time: 0.2003\n",
      "6/8, train_loss: 0.0150 step time: 0.2006\n",
      "7/8, train_loss: 0.0118 step time: 0.1839\n",
      "8/8, train_loss: 0.0129 step time: 0.1817\n",
      "epoch 105 average loss: 0.0135\n",
      "current epoch: 105 current mean dice: 0.9571 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 105 is: 2.3651\n",
      "----------\n",
      "epoch 106/600\n",
      "1/8, train_loss: 0.0115 step time: 0.2338\n",
      "2/8, train_loss: 0.0130 step time: 0.1976\n",
      "3/8, train_loss: 0.0126 step time: 0.2000\n",
      "4/8, train_loss: 0.0140 step time: 0.2039\n",
      "5/8, train_loss: 0.0096 step time: 0.2042\n",
      "6/8, train_loss: 0.0144 step time: 0.2022\n",
      "7/8, train_loss: 0.0134 step time: 0.1838\n",
      "8/8, train_loss: 0.0136 step time: 0.1838\n",
      "epoch 106 average loss: 0.0128\n",
      "time consuming of epoch 106 is: 1.6104\n",
      "----------\n",
      "epoch 107/600\n",
      "1/8, train_loss: 0.0146 step time: 0.2421\n",
      "2/8, train_loss: 0.0132 step time: 0.2034\n",
      "3/8, train_loss: 0.0127 step time: 0.2045\n",
      "4/8, train_loss: 0.0128 step time: 0.2020\n",
      "5/8, train_loss: 0.0128 step time: 0.2029\n",
      "6/8, train_loss: 0.0101 step time: 0.1975\n",
      "7/8, train_loss: 0.0145 step time: 0.1827\n",
      "8/8, train_loss: 0.0165 step time: 0.1812\n",
      "epoch 107 average loss: 0.0134\n",
      "time consuming of epoch 107 is: 1.6178\n",
      "----------\n",
      "epoch 108/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2392\n",
      "2/8, train_loss: 0.0131 step time: 0.1992\n",
      "3/8, train_loss: 0.0123 step time: 0.2021\n",
      "4/8, train_loss: 0.0120 step time: 0.2058\n",
      "5/8, train_loss: 0.0164 step time: 0.2043\n",
      "6/8, train_loss: 0.0151 step time: 0.2018\n",
      "7/8, train_loss: 0.0108 step time: 0.1825\n",
      "8/8, train_loss: 0.0136 step time: 0.1828\n",
      "epoch 108 average loss: 0.0134\n",
      "time consuming of epoch 108 is: 1.6189\n",
      "----------\n",
      "epoch 109/600\n",
      "1/8, train_loss: 0.0134 step time: 0.2397\n",
      "2/8, train_loss: 0.0221 step time: 0.1999\n",
      "3/8, train_loss: 0.0120 step time: 0.2013\n",
      "4/8, train_loss: 0.0128 step time: 0.2015\n",
      "5/8, train_loss: 0.0124 step time: 0.2063\n",
      "6/8, train_loss: 0.0133 step time: 0.1996\n",
      "7/8, train_loss: 0.0153 step time: 0.1823\n",
      "8/8, train_loss: 0.0183 step time: 0.1825\n",
      "epoch 109 average loss: 0.0150\n",
      "time consuming of epoch 109 is: 1.6145\n",
      "----------\n",
      "epoch 110/600\n",
      "1/8, train_loss: 0.0135 step time: 0.2395\n",
      "2/8, train_loss: 0.0156 step time: 0.2013\n",
      "3/8, train_loss: 0.0168 step time: 0.2016\n",
      "4/8, train_loss: 0.0140 step time: 0.1996\n",
      "5/8, train_loss: 0.0153 step time: 0.2020\n",
      "6/8, train_loss: 0.0146 step time: 0.2051\n",
      "7/8, train_loss: 0.0137 step time: 0.1812\n",
      "8/8, train_loss: 0.0217 step time: 0.1817\n",
      "epoch 110 average loss: 0.0156\n",
      "current epoch: 110 current mean dice: 0.9391 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 110 is: 2.3684\n",
      "----------\n",
      "epoch 111/600\n",
      "1/8, train_loss: 0.0156 step time: 0.2374\n",
      "2/8, train_loss: 0.0172 step time: 0.1980\n",
      "3/8, train_loss: 0.0141 step time: 0.2047\n",
      "4/8, train_loss: 0.0153 step time: 0.1989\n",
      "5/8, train_loss: 0.0150 step time: 0.2017\n",
      "6/8, train_loss: 0.0158 step time: 0.2023\n",
      "7/8, train_loss: 0.0132 step time: 0.1827\n",
      "8/8, train_loss: 0.0165 step time: 0.1820\n",
      "epoch 111 average loss: 0.0153\n",
      "time consuming of epoch 111 is: 1.6087\n",
      "----------\n",
      "epoch 112/600\n",
      "1/8, train_loss: 0.0144 step time: 0.2404\n",
      "2/8, train_loss: 0.0150 step time: 0.1977\n",
      "3/8, train_loss: 0.0133 step time: 0.2016\n",
      "4/8, train_loss: 0.0195 step time: 0.1978\n",
      "5/8, train_loss: 0.0163 step time: 0.1952\n",
      "6/8, train_loss: 0.0149 step time: 0.1964\n",
      "7/8, train_loss: 0.0143 step time: 0.1818\n",
      "8/8, train_loss: 0.0180 step time: 0.1846\n",
      "epoch 112 average loss: 0.0157\n",
      "time consuming of epoch 112 is: 1.5969\n",
      "----------\n",
      "epoch 113/600\n",
      "1/8, train_loss: 0.0214 step time: 0.2440\n",
      "2/8, train_loss: 0.0165 step time: 0.2038\n",
      "3/8, train_loss: 0.0153 step time: 0.1997\n",
      "4/8, train_loss: 0.0151 step time: 0.2018\n",
      "5/8, train_loss: 0.0144 step time: 0.2031\n",
      "6/8, train_loss: 0.0149 step time: 0.2016\n",
      "7/8, train_loss: 0.0185 step time: 0.1825\n",
      "8/8, train_loss: 0.0141 step time: 0.1827\n",
      "epoch 113 average loss: 0.0163\n",
      "time consuming of epoch 113 is: 1.6207\n",
      "----------\n",
      "epoch 114/600\n",
      "1/8, train_loss: 0.0134 step time: 0.2392\n",
      "2/8, train_loss: 0.0165 step time: 0.2020\n",
      "3/8, train_loss: 0.0144 step time: 0.2000\n",
      "4/8, train_loss: 0.0133 step time: 0.1947\n",
      "5/8, train_loss: 0.0182 step time: 0.1932\n",
      "6/8, train_loss: 0.0172 step time: 0.1932\n",
      "7/8, train_loss: 0.0144 step time: 0.1828\n",
      "8/8, train_loss: 0.0147 step time: 0.1822\n",
      "epoch 114 average loss: 0.0153\n",
      "time consuming of epoch 114 is: 1.5889\n",
      "----------\n",
      "epoch 115/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2383\n",
      "2/8, train_loss: 0.0117 step time: 0.2029\n",
      "3/8, train_loss: 0.0138 step time: 0.2045\n",
      "4/8, train_loss: 0.0155 step time: 0.1982\n",
      "5/8, train_loss: 0.0168 step time: 0.1998\n",
      "6/8, train_loss: 0.0140 step time: 0.2019\n",
      "7/8, train_loss: 0.0155 step time: 0.1817\n",
      "8/8, train_loss: 0.0144 step time: 0.1839\n",
      "epoch 115 average loss: 0.0146\n",
      "current epoch: 115 current mean dice: 0.9545 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 115 is: 2.3698\n",
      "----------\n",
      "epoch 116/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2404\n",
      "2/8, train_loss: 0.0140 step time: 0.1989\n",
      "3/8, train_loss: 0.0136 step time: 0.1986\n",
      "4/8, train_loss: 0.0137 step time: 0.2017\n",
      "5/8, train_loss: 0.0150 step time: 0.1977\n",
      "6/8, train_loss: 0.0182 step time: 0.2013\n",
      "7/8, train_loss: 0.0158 step time: 0.1818\n",
      "8/8, train_loss: 0.0141 step time: 0.1818\n",
      "epoch 116 average loss: 0.0149\n",
      "time consuming of epoch 116 is: 1.6034\n",
      "----------\n",
      "epoch 117/600\n",
      "1/8, train_loss: 0.0138 step time: 0.2381\n",
      "2/8, train_loss: 0.0165 step time: 0.2048\n",
      "3/8, train_loss: 0.0153 step time: 0.2048\n",
      "4/8, train_loss: 0.0147 step time: 0.2042\n",
      "5/8, train_loss: 0.0142 step time: 0.1998\n",
      "6/8, train_loss: 0.0161 step time: 0.2005\n",
      "7/8, train_loss: 0.0118 step time: 0.1823\n",
      "8/8, train_loss: 0.0168 step time: 0.1820\n",
      "epoch 117 average loss: 0.0149\n",
      "time consuming of epoch 117 is: 1.6180\n",
      "----------\n",
      "epoch 118/600\n",
      "1/8, train_loss: 0.0138 step time: 0.2385\n",
      "2/8, train_loss: 0.0163 step time: 0.2026\n",
      "3/8, train_loss: 0.0154 step time: 0.2016\n",
      "4/8, train_loss: 0.0140 step time: 0.1993\n",
      "5/8, train_loss: 0.0149 step time: 0.2023\n",
      "6/8, train_loss: 0.0144 step time: 0.2034\n",
      "7/8, train_loss: 0.0123 step time: 0.1833\n",
      "8/8, train_loss: 0.0163 step time: 0.1834\n",
      "epoch 118 average loss: 0.0147\n",
      "time consuming of epoch 118 is: 1.6163\n",
      "----------\n",
      "epoch 119/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0147 step time: 0.2376\n",
      "2/8, train_loss: 0.0150 step time: 0.1988\n",
      "3/8, train_loss: 0.0132 step time: 0.1988\n",
      "4/8, train_loss: 0.0134 step time: 0.1949\n",
      "5/8, train_loss: 0.0133 step time: 0.1988\n",
      "6/8, train_loss: 0.0163 step time: 0.1963\n",
      "7/8, train_loss: 0.0155 step time: 0.1791\n",
      "8/8, train_loss: 0.0147 step time: 0.1822\n",
      "epoch 119 average loss: 0.0145\n",
      "time consuming of epoch 119 is: 1.5881\n",
      "----------\n",
      "epoch 120/600\n",
      "1/8, train_loss: 0.0127 step time: 0.2434\n",
      "2/8, train_loss: 0.0149 step time: 0.2016\n",
      "3/8, train_loss: 0.0166 step time: 0.1993\n",
      "4/8, train_loss: 0.0147 step time: 0.2010\n",
      "5/8, train_loss: 0.0143 step time: 0.1990\n",
      "6/8, train_loss: 0.0131 step time: 0.1999\n",
      "7/8, train_loss: 0.0118 step time: 0.1860\n",
      "8/8, train_loss: 0.0139 step time: 0.1861\n",
      "epoch 120 average loss: 0.0140\n",
      "current epoch: 120 current mean dice: 0.9557 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 120 is: 2.3748\n",
      "----------\n",
      "epoch 121/600\n",
      "1/8, train_loss: 0.0148 step time: 0.2364\n",
      "2/8, train_loss: 0.0134 step time: 0.2056\n",
      "3/8, train_loss: 0.0135 step time: 0.2019\n",
      "4/8, train_loss: 0.0130 step time: 0.2025\n",
      "5/8, train_loss: 0.0116 step time: 0.1991\n",
      "6/8, train_loss: 0.0136 step time: 0.2051\n",
      "7/8, train_loss: 0.0127 step time: 0.1813\n",
      "8/8, train_loss: 0.0141 step time: 0.1818\n",
      "epoch 121 average loss: 0.0133\n",
      "time consuming of epoch 121 is: 1.6148\n",
      "----------\n",
      "epoch 122/600\n",
      "1/8, train_loss: 0.0143 step time: 0.2412\n",
      "2/8, train_loss: 0.0138 step time: 0.2028\n",
      "3/8, train_loss: 0.0144 step time: 0.2048\n",
      "4/8, train_loss: 0.0140 step time: 0.2014\n",
      "5/8, train_loss: 0.0145 step time: 0.1999\n",
      "6/8, train_loss: 0.0136 step time: 0.2004\n",
      "7/8, train_loss: 0.0113 step time: 0.1827\n",
      "8/8, train_loss: 0.0145 step time: 0.1837\n",
      "epoch 122 average loss: 0.0138\n",
      "time consuming of epoch 122 is: 1.6184\n",
      "----------\n",
      "epoch 123/600\n",
      "1/8, train_loss: 0.0127 step time: 0.2393\n",
      "2/8, train_loss: 0.0114 step time: 0.2041\n",
      "3/8, train_loss: 0.0153 step time: 0.2000\n",
      "4/8, train_loss: 0.0128 step time: 0.2009\n",
      "5/8, train_loss: 0.0137 step time: 0.2038\n",
      "6/8, train_loss: 0.0129 step time: 0.2036\n",
      "7/8, train_loss: 0.0128 step time: 0.1819\n",
      "8/8, train_loss: 0.0138 step time: 0.1815\n",
      "epoch 123 average loss: 0.0132\n",
      "time consuming of epoch 123 is: 1.6169\n",
      "----------\n",
      "epoch 124/600\n",
      "1/8, train_loss: 0.0120 step time: 0.2396\n",
      "2/8, train_loss: 0.0160 step time: 0.1991\n",
      "3/8, train_loss: 0.0133 step time: 0.1992\n",
      "4/8, train_loss: 0.0122 step time: 0.2027\n",
      "5/8, train_loss: 0.0131 step time: 0.2030\n",
      "6/8, train_loss: 0.0136 step time: 0.1993\n",
      "7/8, train_loss: 0.0138 step time: 0.1828\n",
      "8/8, train_loss: 0.0144 step time: 0.1824\n",
      "epoch 124 average loss: 0.0135\n",
      "time consuming of epoch 124 is: 1.6095\n",
      "----------\n",
      "epoch 125/600\n",
      "1/8, train_loss: 0.0136 step time: 0.2419\n",
      "2/8, train_loss: 0.0131 step time: 0.2039\n",
      "3/8, train_loss: 0.0114 step time: 0.1986\n",
      "4/8, train_loss: 0.0140 step time: 0.2004\n",
      "5/8, train_loss: 0.0139 step time: 0.1999\n",
      "6/8, train_loss: 0.0117 step time: 0.2009\n",
      "7/8, train_loss: 0.0147 step time: 0.1844\n",
      "8/8, train_loss: 0.0155 step time: 0.1845\n",
      "epoch 125 average loss: 0.0135\n",
      "current epoch: 125 current mean dice: 0.9563 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 125 is: 2.3710\n",
      "----------\n",
      "epoch 126/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2373\n",
      "2/8, train_loss: 0.0139 step time: 0.2001\n",
      "3/8, train_loss: 0.0120 step time: 0.1988\n",
      "4/8, train_loss: 0.0151 step time: 0.2001\n",
      "5/8, train_loss: 0.0140 step time: 0.1983\n",
      "6/8, train_loss: 0.0139 step time: 0.1993\n",
      "7/8, train_loss: 0.0141 step time: 0.1819\n",
      "8/8, train_loss: 0.0149 step time: 0.1813\n",
      "epoch 126 average loss: 0.0135\n",
      "time consuming of epoch 126 is: 1.5980\n",
      "----------\n",
      "epoch 127/600\n",
      "1/8, train_loss: 0.0144 step time: 0.2413\n",
      "2/8, train_loss: 0.0120 step time: 0.2022\n",
      "3/8, train_loss: 0.0156 step time: 0.2000\n",
      "4/8, train_loss: 0.0114 step time: 0.2038\n",
      "5/8, train_loss: 0.0145 step time: 0.2003\n",
      "6/8, train_loss: 0.0193 step time: 0.2005\n",
      "7/8, train_loss: 0.0143 step time: 0.1831\n",
      "8/8, train_loss: 0.0131 step time: 0.1826\n",
      "epoch 127 average loss: 0.0143\n",
      "time consuming of epoch 127 is: 1.6154\n",
      "----------\n",
      "epoch 128/600\n",
      "1/8, train_loss: 0.0117 step time: 0.2405\n",
      "2/8, train_loss: 0.0146 step time: 0.2014\n",
      "3/8, train_loss: 0.0161 step time: 0.2049\n",
      "4/8, train_loss: 0.0142 step time: 0.2043\n",
      "5/8, train_loss: 0.0174 step time: 0.2049\n",
      "6/8, train_loss: 0.0145 step time: 0.1995\n",
      "7/8, train_loss: 0.0139 step time: 0.1843\n",
      "8/8, train_loss: 0.0151 step time: 0.1825\n",
      "epoch 128 average loss: 0.0147\n",
      "time consuming of epoch 128 is: 1.6238\n",
      "----------\n",
      "epoch 129/600\n",
      "1/8, train_loss: 0.0141 step time: 0.2400\n",
      "2/8, train_loss: 0.0145 step time: 0.1978\n",
      "3/8, train_loss: 0.0117 step time: 0.1973\n",
      "4/8, train_loss: 0.0142 step time: 0.1968\n",
      "5/8, train_loss: 0.0147 step time: 0.1972\n",
      "6/8, train_loss: 0.0141 step time: 0.1957\n",
      "7/8, train_loss: 0.0126 step time: 0.1851\n",
      "8/8, train_loss: 0.0128 step time: 0.1812\n",
      "epoch 129 average loss: 0.0136\n",
      "time consuming of epoch 129 is: 1.5927\n",
      "----------\n",
      "epoch 130/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2319\n",
      "2/8, train_loss: 0.0142 step time: 0.1970\n",
      "3/8, train_loss: 0.0140 step time: 0.1975\n",
      "4/8, train_loss: 0.0112 step time: 0.1952\n",
      "5/8, train_loss: 0.0144 step time: 0.1950\n",
      "6/8, train_loss: 0.0122 step time: 0.1960\n",
      "7/8, train_loss: 0.0122 step time: 0.1824\n",
      "8/8, train_loss: 0.0157 step time: 0.1829\n",
      "epoch 130 average loss: 0.0134\n",
      "current epoch: 130 current mean dice: 0.9567 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 130 is: 2.3347\n",
      "----------\n",
      "epoch 131/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2414\n",
      "2/8, train_loss: 0.0131 step time: 0.2033\n",
      "3/8, train_loss: 0.0124 step time: 0.2028\n",
      "4/8, train_loss: 0.0126 step time: 0.1980\n",
      "5/8, train_loss: 0.0152 step time: 0.2003\n",
      "6/8, train_loss: 0.0159 step time: 0.1975\n",
      "7/8, train_loss: 0.0141 step time: 0.1814\n",
      "8/8, train_loss: 0.0153 step time: 0.1816\n",
      "epoch 131 average loss: 0.0142\n",
      "time consuming of epoch 131 is: 1.6074\n",
      "----------\n",
      "epoch 132/600\n",
      "1/8, train_loss: 0.0114 step time: 0.2409\n",
      "2/8, train_loss: 0.0165 step time: 0.2047\n",
      "3/8, train_loss: 0.0141 step time: 0.2022\n",
      "4/8, train_loss: 0.0131 step time: 0.2016\n",
      "5/8, train_loss: 0.0157 step time: 0.2000\n",
      "6/8, train_loss: 0.0148 step time: 0.2027\n",
      "7/8, train_loss: 0.0120 step time: 0.1831\n",
      "8/8, train_loss: 0.0140 step time: 0.1849\n",
      "epoch 132 average loss: 0.0140\n",
      "time consuming of epoch 132 is: 1.6213\n",
      "----------\n",
      "epoch 133/600\n",
      "1/8, train_loss: 0.0154 step time: 0.2415\n",
      "2/8, train_loss: 0.0127 step time: 0.2049\n",
      "3/8, train_loss: 0.0119 step time: 0.2005\n",
      "4/8, train_loss: 0.0113 step time: 0.1997\n",
      "5/8, train_loss: 0.0146 step time: 0.2020\n",
      "6/8, train_loss: 0.0143 step time: 0.2018\n",
      "7/8, train_loss: 0.0144 step time: 0.1827\n",
      "8/8, train_loss: 0.0150 step time: 0.1826\n",
      "epoch 133 average loss: 0.0137\n",
      "time consuming of epoch 133 is: 1.6172\n",
      "----------\n",
      "epoch 134/600\n",
      "1/8, train_loss: 0.0144 step time: 0.2416\n",
      "2/8, train_loss: 0.0135 step time: 0.2034\n",
      "3/8, train_loss: 0.0132 step time: 0.1986\n",
      "4/8, train_loss: 0.0109 step time: 0.2012\n",
      "5/8, train_loss: 0.0147 step time: 0.2024\n",
      "6/8, train_loss: 0.0150 step time: 0.2000\n",
      "7/8, train_loss: 0.0143 step time: 0.1835\n",
      "8/8, train_loss: 0.0134 step time: 0.1840\n",
      "epoch 134 average loss: 0.0137\n",
      "time consuming of epoch 134 is: 1.6164\n",
      "----------\n",
      "epoch 135/600\n",
      "1/8, train_loss: 0.0127 step time: 0.2438\n",
      "2/8, train_loss: 0.0155 step time: 0.1997\n",
      "3/8, train_loss: 0.0160 step time: 0.2002\n",
      "4/8, train_loss: 0.0129 step time: 0.2004\n",
      "5/8, train_loss: 0.0139 step time: 0.2035\n",
      "6/8, train_loss: 0.0126 step time: 0.2011\n",
      "7/8, train_loss: 0.0148 step time: 0.1838\n",
      "8/8, train_loss: 0.0137 step time: 0.1827\n",
      "epoch 135 average loss: 0.0140\n",
      "current epoch: 135 current mean dice: 0.9539 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 135 is: 2.3720\n",
      "----------\n",
      "epoch 136/600\n",
      "1/8, train_loss: 0.0141 step time: 0.2377\n",
      "2/8, train_loss: 0.0121 step time: 0.1998\n",
      "3/8, train_loss: 0.0148 step time: 0.2020\n",
      "4/8, train_loss: 0.0163 step time: 0.2023\n",
      "5/8, train_loss: 0.0146 step time: 0.2034\n",
      "6/8, train_loss: 0.0119 step time: 0.2009\n",
      "7/8, train_loss: 0.0147 step time: 0.1847\n",
      "8/8, train_loss: 0.0185 step time: 0.1843\n",
      "epoch 136 average loss: 0.0146\n",
      "time consuming of epoch 136 is: 1.6163\n",
      "----------\n",
      "epoch 137/600\n",
      "1/8, train_loss: 0.0130 step time: 0.2401\n",
      "2/8, train_loss: 0.0111 step time: 0.1974\n",
      "3/8, train_loss: 0.0137 step time: 0.1960\n",
      "4/8, train_loss: 0.0142 step time: 0.1950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8, train_loss: 0.0119 step time: 0.2011\n",
      "6/8, train_loss: 0.0151 step time: 0.2010\n",
      "7/8, train_loss: 0.0137 step time: 0.1844\n",
      "8/8, train_loss: 0.0162 step time: 0.1836\n",
      "epoch 137 average loss: 0.0136\n",
      "time consuming of epoch 137 is: 1.6000\n",
      "----------\n",
      "epoch 138/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2422\n",
      "2/8, train_loss: 0.0122 step time: 0.2006\n",
      "3/8, train_loss: 0.0124 step time: 0.2022\n",
      "4/8, train_loss: 0.0161 step time: 0.2018\n",
      "5/8, train_loss: 0.0139 step time: 0.1990\n",
      "6/8, train_loss: 0.0142 step time: 0.2015\n",
      "7/8, train_loss: 0.0125 step time: 0.1826\n",
      "8/8, train_loss: 0.0151 step time: 0.1827\n",
      "epoch 138 average loss: 0.0136\n",
      "time consuming of epoch 138 is: 1.6144\n",
      "----------\n",
      "epoch 139/600\n",
      "1/8, train_loss: 0.0121 step time: 0.2413\n",
      "2/8, train_loss: 0.0115 step time: 0.2019\n",
      "3/8, train_loss: 0.0136 step time: 0.1997\n",
      "4/8, train_loss: 0.0151 step time: 0.2003\n",
      "5/8, train_loss: 0.0143 step time: 0.2041\n",
      "6/8, train_loss: 0.0148 step time: 0.1992\n",
      "7/8, train_loss: 0.0120 step time: 0.1824\n",
      "8/8, train_loss: 0.0135 step time: 0.1816\n",
      "epoch 139 average loss: 0.0133\n",
      "time consuming of epoch 139 is: 1.6118\n",
      "----------\n",
      "epoch 140/600\n",
      "1/8, train_loss: 0.0153 step time: 0.2406\n",
      "2/8, train_loss: 0.0137 step time: 0.2013\n",
      "3/8, train_loss: 0.0138 step time: 0.2031\n",
      "4/8, train_loss: 0.0121 step time: 0.2028\n",
      "5/8, train_loss: 0.0122 step time: 0.2028\n",
      "6/8, train_loss: 0.0128 step time: 0.2001\n",
      "7/8, train_loss: 0.0134 step time: 0.1832\n",
      "8/8, train_loss: 0.0130 step time: 0.1844\n",
      "epoch 140 average loss: 0.0133\n",
      "current epoch: 140 current mean dice: 0.9565 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 140 is: 2.3741\n",
      "----------\n",
      "epoch 141/600\n",
      "1/8, train_loss: 0.0113 step time: 0.2412\n",
      "2/8, train_loss: 0.0117 step time: 0.1982\n",
      "3/8, train_loss: 0.0148 step time: 0.2000\n",
      "4/8, train_loss: 0.0121 step time: 0.2015\n",
      "5/8, train_loss: 0.0137 step time: 0.1993\n",
      "6/8, train_loss: 0.0148 step time: 0.1997\n",
      "7/8, train_loss: 0.0148 step time: 0.1819\n",
      "8/8, train_loss: 0.0125 step time: 0.1823\n",
      "epoch 141 average loss: 0.0132\n",
      "time consuming of epoch 141 is: 1.6056\n",
      "----------\n",
      "epoch 142/600\n",
      "1/8, train_loss: 0.0141 step time: 0.2386\n",
      "2/8, train_loss: 0.0109 step time: 0.2049\n",
      "3/8, train_loss: 0.0125 step time: 0.1980\n",
      "4/8, train_loss: 0.0131 step time: 0.2005\n",
      "5/8, train_loss: 0.0136 step time: 0.2000\n",
      "6/8, train_loss: 0.0125 step time: 0.1988\n",
      "7/8, train_loss: 0.0123 step time: 0.1812\n",
      "8/8, train_loss: 0.0139 step time: 0.1808\n",
      "epoch 142 average loss: 0.0129\n",
      "time consuming of epoch 142 is: 1.6045\n",
      "----------\n",
      "epoch 143/600\n",
      "1/8, train_loss: 0.0150 step time: 0.2388\n",
      "2/8, train_loss: 0.0127 step time: 0.2002\n",
      "3/8, train_loss: 0.0105 step time: 0.2024\n",
      "4/8, train_loss: 0.0127 step time: 0.1993\n",
      "5/8, train_loss: 0.0155 step time: 0.1983\n",
      "6/8, train_loss: 0.0115 step time: 0.1994\n",
      "7/8, train_loss: 0.0143 step time: 0.1822\n",
      "8/8, train_loss: 0.0131 step time: 0.1835\n",
      "epoch 143 average loss: 0.0131\n",
      "time consuming of epoch 143 is: 1.6055\n",
      "----------\n",
      "epoch 144/600\n",
      "1/8, train_loss: 0.0142 step time: 0.2399\n",
      "2/8, train_loss: 0.0118 step time: 0.2018\n",
      "3/8, train_loss: 0.0146 step time: 0.1974\n",
      "4/8, train_loss: 0.0150 step time: 0.2024\n",
      "5/8, train_loss: 0.0137 step time: 0.2003\n",
      "6/8, train_loss: 0.0147 step time: 0.2013\n",
      "7/8, train_loss: 0.0138 step time: 0.1833\n",
      "8/8, train_loss: 0.0111 step time: 0.1846\n",
      "epoch 144 average loss: 0.0136\n",
      "time consuming of epoch 144 is: 1.6130\n",
      "----------\n",
      "epoch 145/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2408\n",
      "2/8, train_loss: 0.0129 step time: 0.1988\n",
      "3/8, train_loss: 0.0140 step time: 0.1981\n",
      "4/8, train_loss: 0.0114 step time: 0.1949\n",
      "5/8, train_loss: 0.0115 step time: 0.1937\n",
      "6/8, train_loss: 0.0149 step time: 0.1976\n",
      "7/8, train_loss: 0.0150 step time: 0.1822\n",
      "8/8, train_loss: 0.0113 step time: 0.1833\n",
      "epoch 145 average loss: 0.0130\n",
      "current epoch: 145 current mean dice: 0.9563 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 145 is: 2.3472\n",
      "----------\n",
      "epoch 146/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2361\n",
      "2/8, train_loss: 0.0122 step time: 0.1975\n",
      "3/8, train_loss: 0.0139 step time: 0.1951\n",
      "4/8, train_loss: 0.0136 step time: 0.1944\n",
      "5/8, train_loss: 0.0127 step time: 0.1949\n",
      "6/8, train_loss: 0.0118 step time: 0.1936\n",
      "7/8, train_loss: 0.0156 step time: 0.1813\n",
      "8/8, train_loss: 0.0150 step time: 0.1825\n",
      "epoch 146 average loss: 0.0135\n",
      "time consuming of epoch 146 is: 1.5765\n",
      "----------\n",
      "epoch 147/600\n",
      "1/8, train_loss: 0.0111 step time: 0.2304\n",
      "2/8, train_loss: 0.0134 step time: 0.1949\n",
      "3/8, train_loss: 0.0142 step time: 0.1957\n",
      "4/8, train_loss: 0.0130 step time: 0.1943\n",
      "5/8, train_loss: 0.0113 step time: 0.1965\n",
      "6/8, train_loss: 0.0133 step time: 0.2038\n",
      "7/8, train_loss: 0.0140 step time: 0.1834\n",
      "8/8, train_loss: 0.0148 step time: 0.1811\n",
      "epoch 147 average loss: 0.0131\n",
      "time consuming of epoch 147 is: 1.5815\n",
      "----------\n",
      "epoch 148/600\n",
      "1/8, train_loss: 0.0144 step time: 0.2386\n",
      "2/8, train_loss: 0.0138 step time: 0.1991\n",
      "3/8, train_loss: 0.0135 step time: 0.2018\n",
      "4/8, train_loss: 0.0137 step time: 0.2015\n",
      "5/8, train_loss: 0.0121 step time: 0.1983\n",
      "6/8, train_loss: 0.0122 step time: 0.2000\n",
      "7/8, train_loss: 0.0130 step time: 0.1830\n",
      "8/8, train_loss: 0.0139 step time: 0.1820\n",
      "epoch 148 average loss: 0.0133\n",
      "time consuming of epoch 148 is: 1.6057\n",
      "----------\n",
      "epoch 149/600\n",
      "1/8, train_loss: 0.0147 step time: 0.2782\n",
      "2/8, train_loss: 0.0124 step time: 0.2043\n",
      "3/8, train_loss: 0.0128 step time: 0.2011\n",
      "4/8, train_loss: 0.0140 step time: 0.2037\n",
      "5/8, train_loss: 0.0137 step time: 0.1993\n",
      "6/8, train_loss: 0.0146 step time: 0.2060\n",
      "7/8, train_loss: 0.0114 step time: 0.1829\n",
      "8/8, train_loss: 0.0215 step time: 0.1824\n",
      "epoch 149 average loss: 0.0144\n",
      "time consuming of epoch 149 is: 1.6598\n",
      "----------\n",
      "epoch 150/600\n",
      "1/8, train_loss: 0.0129 step time: 0.2321\n",
      "2/8, train_loss: 0.0153 step time: 0.2004\n",
      "3/8, train_loss: 0.0140 step time: 0.1969\n",
      "4/8, train_loss: 0.0204 step time: 0.1947\n",
      "5/8, train_loss: 0.0270 step time: 0.1983\n",
      "6/8, train_loss: 0.0176 step time: 0.1962\n",
      "7/8, train_loss: 0.0243 step time: 0.1835\n",
      "8/8, train_loss: 0.0346 step time: 0.1842\n",
      "epoch 150 average loss: 0.0207\n",
      "current epoch: 150 current mean dice: 0.9190 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 150 is: 2.3445\n",
      "----------\n",
      "epoch 151/600\n",
      "1/8, train_loss: 0.0183 step time: 0.2378\n",
      "2/8, train_loss: 0.0199 step time: 0.1997\n",
      "3/8, train_loss: 0.0186 step time: 0.2005\n",
      "4/8, train_loss: 0.0295 step time: 0.1974\n",
      "5/8, train_loss: 0.0160 step time: 0.2012\n",
      "6/8, train_loss: 0.0680 step time: 0.1990\n",
      "7/8, train_loss: 0.0221 step time: 0.1840\n",
      "8/8, train_loss: 0.1066 step time: 0.1813\n",
      "epoch 151 average loss: 0.0373\n",
      "time consuming of epoch 151 is: 1.6024\n",
      "----------\n",
      "epoch 152/600\n",
      "1/8, train_loss: 0.0371 step time: 0.2372\n",
      "2/8, train_loss: 0.1709 step time: 0.2057\n",
      "3/8, train_loss: 0.0895 step time: 0.2113\n",
      "4/8, train_loss: 0.0737 step time: 0.2287\n",
      "5/8, train_loss: 0.0432 step time: 0.2189\n",
      "6/8, train_loss: 0.0345 step time: 0.2053\n",
      "7/8, train_loss: 0.0334 step time: 0.1847\n",
      "8/8, train_loss: 0.0320 step time: 0.1830\n",
      "epoch 152 average loss: 0.0643\n",
      "time consuming of epoch 152 is: 1.6763\n",
      "----------\n",
      "epoch 153/600\n",
      "1/8, train_loss: 0.0528 step time: 0.2322\n",
      "2/8, train_loss: 0.0409 step time: 0.1966\n",
      "3/8, train_loss: 0.0378 step time: 0.1927\n",
      "4/8, train_loss: 0.1317 step time: 0.1983\n",
      "5/8, train_loss: 0.0336 step time: 0.1987\n",
      "6/8, train_loss: 0.0542 step time: 0.1942\n",
      "7/8, train_loss: 0.0319 step time: 0.1824\n",
      "8/8, train_loss: 0.0796 step time: 0.1823\n",
      "epoch 153 average loss: 0.0578\n",
      "time consuming of epoch 153 is: 1.5790\n",
      "----------\n",
      "epoch 154/600\n",
      "1/8, train_loss: 0.1314 step time: 0.2315\n",
      "2/8, train_loss: 0.0374 step time: 0.1969\n",
      "3/8, train_loss: 0.0554 step time: 0.1975\n",
      "4/8, train_loss: 0.1202 step time: 0.1959\n",
      "5/8, train_loss: 0.0298 step time: 0.2078\n",
      "6/8, train_loss: 0.0568 step time: 0.1998\n",
      "7/8, train_loss: 0.0563 step time: 0.1835\n",
      "8/8, train_loss: 0.0409 step time: 0.1824\n",
      "epoch 154 average loss: 0.0660\n",
      "time consuming of epoch 154 is: 1.5966\n",
      "----------\n",
      "epoch 155/600\n",
      "1/8, train_loss: 0.1273 step time: 0.2403\n",
      "2/8, train_loss: 0.0391 step time: 0.1999\n",
      "3/8, train_loss: 0.0610 step time: 0.1999\n",
      "4/8, train_loss: 0.1013 step time: 0.2001\n",
      "5/8, train_loss: 0.0324 step time: 0.1995\n",
      "6/8, train_loss: 0.0754 step time: 0.1994\n",
      "7/8, train_loss: 0.0479 step time: 0.1831\n",
      "8/8, train_loss: 0.0455 step time: 0.1846\n",
      "epoch 155 average loss: 0.0663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 155 current mean dice: 0.9085 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 155 is: 2.3640\n",
      "----------\n",
      "epoch 156/600\n",
      "1/8, train_loss: 0.0247 step time: 0.2350\n",
      "2/8, train_loss: 0.0265 step time: 0.1989\n",
      "3/8, train_loss: 0.0492 step time: 0.1986\n",
      "4/8, train_loss: 0.0273 step time: 0.1975\n",
      "5/8, train_loss: 0.0266 step time: 0.1999\n",
      "6/8, train_loss: 0.0688 step time: 0.1996\n",
      "7/8, train_loss: 0.0301 step time: 0.1811\n",
      "8/8, train_loss: 0.0409 step time: 0.1837\n",
      "epoch 156 average loss: 0.0368\n",
      "time consuming of epoch 156 is: 1.5955\n",
      "----------\n",
      "epoch 157/600\n",
      "1/8, train_loss: 0.0279 step time: 0.2433\n",
      "2/8, train_loss: 0.1259 step time: 0.2001\n",
      "3/8, train_loss: 0.0324 step time: 0.1989\n",
      "4/8, train_loss: 0.0270 step time: 0.2059\n",
      "5/8, train_loss: 0.0489 step time: 0.2027\n",
      "6/8, train_loss: 0.0405 step time: 0.1991\n",
      "7/8, train_loss: 0.0289 step time: 0.1834\n",
      "8/8, train_loss: 0.0466 step time: 0.1825\n",
      "epoch 157 average loss: 0.0473\n",
      "time consuming of epoch 157 is: 1.6170\n",
      "----------\n",
      "epoch 158/600\n",
      "1/8, train_loss: 0.0325 step time: 0.2390\n",
      "2/8, train_loss: 0.0268 step time: 0.2024\n",
      "3/8, train_loss: 0.0400 step time: 0.2001\n",
      "4/8, train_loss: 0.0366 step time: 0.1991\n",
      "5/8, train_loss: 0.0307 step time: 0.2016\n",
      "6/8, train_loss: 0.0303 step time: 0.2025\n",
      "7/8, train_loss: 0.0332 step time: 0.1830\n",
      "8/8, train_loss: 0.0470 step time: 0.1819\n",
      "epoch 158 average loss: 0.0346\n",
      "time consuming of epoch 158 is: 1.6112\n",
      "----------\n",
      "epoch 159/600\n",
      "1/8, train_loss: 0.0323 step time: 0.2433\n",
      "2/8, train_loss: 0.0330 step time: 0.2019\n",
      "3/8, train_loss: 0.0312 step time: 0.2002\n",
      "4/8, train_loss: 0.0362 step time: 0.2023\n",
      "5/8, train_loss: 0.0333 step time: 0.2031\n",
      "6/8, train_loss: 0.0355 step time: 0.1996\n",
      "7/8, train_loss: 0.0312 step time: 0.1829\n",
      "8/8, train_loss: 0.0260 step time: 0.1814\n",
      "epoch 159 average loss: 0.0323\n",
      "time consuming of epoch 159 is: 1.6162\n",
      "----------\n",
      "epoch 160/600\n",
      "1/8, train_loss: 0.0234 step time: 0.2398\n",
      "2/8, train_loss: 0.0248 step time: 0.1958\n",
      "3/8, train_loss: 0.0263 step time: 0.1987\n",
      "4/8, train_loss: 0.0289 step time: 0.1971\n",
      "5/8, train_loss: 0.0629 step time: 0.2017\n",
      "6/8, train_loss: 0.0223 step time: 0.1990\n",
      "7/8, train_loss: 0.0286 step time: 0.1846\n",
      "8/8, train_loss: 0.0285 step time: 0.1845\n",
      "epoch 160 average loss: 0.0307\n",
      "current epoch: 160 current mean dice: 0.7800 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 160 is: 2.3591\n",
      "----------\n",
      "epoch 161/600\n",
      "1/8, train_loss: 0.0284 step time: 0.2389\n",
      "2/8, train_loss: 0.0474 step time: 0.1993\n",
      "3/8, train_loss: 0.0389 step time: 0.2023\n",
      "4/8, train_loss: 0.0378 step time: 0.2022\n",
      "5/8, train_loss: 0.0302 step time: 0.2018\n",
      "6/8, train_loss: 0.0320 step time: 0.1983\n",
      "7/8, train_loss: 0.0268 step time: 0.1819\n",
      "8/8, train_loss: 0.0239 step time: 0.1813\n",
      "epoch 161 average loss: 0.0332\n",
      "time consuming of epoch 161 is: 1.6071\n",
      "----------\n",
      "epoch 162/600\n",
      "1/8, train_loss: 0.0224 step time: 0.2390\n",
      "2/8, train_loss: 0.0259 step time: 0.2004\n",
      "3/8, train_loss: 0.0444 step time: 0.2008\n",
      "4/8, train_loss: 0.0256 step time: 0.2011\n",
      "5/8, train_loss: 0.0244 step time: 0.2017\n",
      "6/8, train_loss: 0.0317 step time: 0.2003\n",
      "7/8, train_loss: 0.0305 step time: 0.1837\n",
      "8/8, train_loss: 0.0253 step time: 0.1813\n",
      "epoch 162 average loss: 0.0288\n",
      "time consuming of epoch 162 is: 1.6098\n",
      "----------\n",
      "epoch 163/600\n",
      "1/8, train_loss: 0.0319 step time: 0.2446\n",
      "2/8, train_loss: 0.0353 step time: 0.2060\n",
      "3/8, train_loss: 0.0273 step time: 0.1982\n",
      "4/8, train_loss: 0.0272 step time: 0.2001\n",
      "5/8, train_loss: 0.0270 step time: 0.2022\n",
      "6/8, train_loss: 0.0310 step time: 0.1995\n",
      "7/8, train_loss: 0.0415 step time: 0.1834\n",
      "8/8, train_loss: 0.0210 step time: 0.1838\n",
      "epoch 163 average loss: 0.0303\n",
      "time consuming of epoch 163 is: 1.6189\n",
      "----------\n",
      "epoch 164/600\n",
      "1/8, train_loss: 0.0243 step time: 0.2390\n",
      "2/8, train_loss: 0.0194 step time: 0.2041\n",
      "3/8, train_loss: 0.0291 step time: 0.1977\n",
      "4/8, train_loss: 0.0321 step time: 0.2021\n",
      "5/8, train_loss: 0.0239 step time: 0.2044\n",
      "6/8, train_loss: 0.0216 step time: 0.2042\n",
      "7/8, train_loss: 0.0404 step time: 0.1842\n",
      "8/8, train_loss: 0.0228 step time: 0.1821\n",
      "epoch 164 average loss: 0.0267\n",
      "time consuming of epoch 164 is: 1.6191\n",
      "----------\n",
      "epoch 165/600\n",
      "1/8, train_loss: 0.0280 step time: 0.2385\n",
      "2/8, train_loss: 0.0203 step time: 0.2012\n",
      "3/8, train_loss: 0.0354 step time: 0.2049\n",
      "4/8, train_loss: 0.0299 step time: 0.2021\n",
      "5/8, train_loss: 0.0393 step time: 0.1988\n",
      "6/8, train_loss: 0.0186 step time: 0.2009\n",
      "7/8, train_loss: 0.0192 step time: 0.1830\n",
      "8/8, train_loss: 0.0346 step time: 0.1838\n",
      "epoch 165 average loss: 0.0282\n",
      "current epoch: 165 current mean dice: 0.9368 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 165 is: 2.3717\n",
      "----------\n",
      "epoch 166/600\n",
      "1/8, train_loss: 0.0230 step time: 0.2352\n",
      "2/8, train_loss: 0.0195 step time: 0.1992\n",
      "3/8, train_loss: 0.0201 step time: 0.2023\n",
      "4/8, train_loss: 0.0242 step time: 0.2000\n",
      "5/8, train_loss: 0.0219 step time: 0.2001\n",
      "6/8, train_loss: 0.0247 step time: 0.1986\n",
      "7/8, train_loss: 0.0202 step time: 0.1814\n",
      "8/8, train_loss: 0.0178 step time: 0.1817\n",
      "epoch 166 average loss: 0.0214\n",
      "time consuming of epoch 166 is: 1.5997\n",
      "----------\n",
      "epoch 167/600\n",
      "1/8, train_loss: 0.0262 step time: 0.2369\n",
      "2/8, train_loss: 0.0180 step time: 0.2018\n",
      "3/8, train_loss: 0.0218 step time: 0.1986\n",
      "4/8, train_loss: 0.0234 step time: 0.2008\n",
      "5/8, train_loss: 0.0182 step time: 0.2018\n",
      "6/8, train_loss: 0.0231 step time: 0.1991\n",
      "7/8, train_loss: 0.0258 step time: 0.1833\n",
      "8/8, train_loss: 0.0172 step time: 0.1823\n",
      "epoch 167 average loss: 0.0217\n",
      "time consuming of epoch 167 is: 1.6062\n",
      "----------\n",
      "epoch 168/600\n",
      "1/8, train_loss: 0.0214 step time: 0.2415\n",
      "2/8, train_loss: 0.0193 step time: 0.2019\n",
      "3/8, train_loss: 0.0394 step time: 0.1988\n",
      "4/8, train_loss: 0.0169 step time: 0.2014\n",
      "5/8, train_loss: 0.0185 step time: 0.1997\n",
      "6/8, train_loss: 0.0195 step time: 0.2005\n",
      "7/8, train_loss: 0.0196 step time: 0.1830\n",
      "8/8, train_loss: 0.0538 step time: 0.1832\n",
      "epoch 168 average loss: 0.0260\n",
      "time consuming of epoch 168 is: 1.6115\n",
      "----------\n",
      "epoch 169/600\n",
      "1/8, train_loss: 0.0233 step time: 0.2389\n",
      "2/8, train_loss: 0.0287 step time: 0.1996\n",
      "3/8, train_loss: 0.0237 step time: 0.2015\n",
      "4/8, train_loss: 0.0221 step time: 0.2016\n",
      "5/8, train_loss: 0.0230 step time: 0.2009\n",
      "6/8, train_loss: 0.0291 step time: 0.2053\n",
      "7/8, train_loss: 0.0188 step time: 0.1843\n",
      "8/8, train_loss: 0.0206 step time: 0.1821\n",
      "epoch 169 average loss: 0.0237\n",
      "time consuming of epoch 169 is: 1.6157\n",
      "----------\n",
      "epoch 170/600\n",
      "1/8, train_loss: 0.0226 step time: 0.2393\n",
      "2/8, train_loss: 0.0217 step time: 0.2032\n",
      "3/8, train_loss: 0.0186 step time: 0.2016\n",
      "4/8, train_loss: 0.0221 step time: 0.2006\n",
      "5/8, train_loss: 0.0239 step time: 0.1994\n",
      "6/8, train_loss: 0.0243 step time: 0.2003\n",
      "7/8, train_loss: 0.0199 step time: 0.1840\n",
      "8/8, train_loss: 0.0223 step time: 0.1824\n",
      "epoch 170 average loss: 0.0219\n",
      "current epoch: 170 current mean dice: 0.9486 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 170 is: 2.3682\n",
      "----------\n",
      "epoch 171/600\n",
      "1/8, train_loss: 0.0227 step time: 0.2364\n",
      "2/8, train_loss: 0.0142 step time: 0.1993\n",
      "3/8, train_loss: 0.0197 step time: 0.1981\n",
      "4/8, train_loss: 0.0201 step time: 0.1998\n",
      "5/8, train_loss: 0.0264 step time: 0.2012\n",
      "6/8, train_loss: 0.0200 step time: 0.1978\n",
      "7/8, train_loss: 0.0218 step time: 0.1826\n",
      "8/8, train_loss: 0.0178 step time: 0.1815\n",
      "epoch 171 average loss: 0.0203\n",
      "time consuming of epoch 171 is: 1.5978\n",
      "----------\n",
      "epoch 172/600\n",
      "1/8, train_loss: 0.0209 step time: 0.2451\n",
      "2/8, train_loss: 0.0197 step time: 0.2026\n",
      "3/8, train_loss: 0.0177 step time: 0.2001\n",
      "4/8, train_loss: 0.0199 step time: 0.2007\n",
      "5/8, train_loss: 0.0158 step time: 0.2002\n",
      "6/8, train_loss: 0.0334 step time: 0.2010\n",
      "7/8, train_loss: 0.0197 step time: 0.1820\n",
      "8/8, train_loss: 0.0181 step time: 0.1823\n",
      "epoch 172 average loss: 0.0207\n",
      "time consuming of epoch 172 is: 1.6155\n",
      "----------\n",
      "epoch 173/600\n",
      "1/8, train_loss: 0.0168 step time: 0.2407\n",
      "2/8, train_loss: 0.0186 step time: 0.2039\n",
      "3/8, train_loss: 0.0171 step time: 0.2003\n",
      "4/8, train_loss: 0.0184 step time: 0.2007\n",
      "5/8, train_loss: 0.0216 step time: 0.1998\n",
      "6/8, train_loss: 0.0190 step time: 0.2021\n",
      "7/8, train_loss: 0.0199 step time: 0.1853\n",
      "8/8, train_loss: 0.0160 step time: 0.1834\n",
      "epoch 173 average loss: 0.0184\n",
      "time consuming of epoch 173 is: 1.6178\n",
      "----------\n",
      "epoch 174/600\n",
      "1/8, train_loss: 0.0174 step time: 0.2379\n",
      "2/8, train_loss: 0.0156 step time: 0.2026\n",
      "3/8, train_loss: 0.0203 step time: 0.2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/8, train_loss: 0.0291 step time: 0.2032\n",
      "5/8, train_loss: 0.0201 step time: 0.1991\n",
      "6/8, train_loss: 0.0191 step time: 0.2001\n",
      "7/8, train_loss: 0.0215 step time: 0.1848\n",
      "8/8, train_loss: 0.0187 step time: 0.1821\n",
      "epoch 174 average loss: 0.0203\n",
      "time consuming of epoch 174 is: 1.6115\n",
      "----------\n",
      "epoch 175/600\n",
      "1/8, train_loss: 0.0174 step time: 0.2403\n",
      "2/8, train_loss: 0.0182 step time: 0.2004\n",
      "3/8, train_loss: 0.0175 step time: 0.2011\n",
      "4/8, train_loss: 0.0167 step time: 0.2015\n",
      "5/8, train_loss: 0.0300 step time: 0.1986\n",
      "6/8, train_loss: 0.0157 step time: 0.2004\n",
      "7/8, train_loss: 0.0159 step time: 0.1824\n",
      "8/8, train_loss: 0.0190 step time: 0.1824\n",
      "epoch 175 average loss: 0.0188\n",
      "current epoch: 175 current mean dice: 0.9518 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 175 is: 2.3651\n",
      "----------\n",
      "epoch 176/600\n",
      "1/8, train_loss: 0.0251 step time: 0.2390\n",
      "2/8, train_loss: 0.0149 step time: 0.1990\n",
      "3/8, train_loss: 0.0244 step time: 0.2003\n",
      "4/8, train_loss: 0.0172 step time: 0.2000\n",
      "5/8, train_loss: 0.0142 step time: 0.1978\n",
      "6/8, train_loss: 0.0167 step time: 0.1966\n",
      "7/8, train_loss: 0.0172 step time: 0.1823\n",
      "8/8, train_loss: 0.0162 step time: 0.1829\n",
      "epoch 176 average loss: 0.0182\n",
      "time consuming of epoch 176 is: 1.5990\n",
      "----------\n",
      "epoch 177/600\n",
      "1/8, train_loss: 0.0168 step time: 0.2421\n",
      "2/8, train_loss: 0.0180 step time: 0.2020\n",
      "3/8, train_loss: 0.0199 step time: 0.2037\n",
      "4/8, train_loss: 0.0188 step time: 0.1998\n",
      "5/8, train_loss: 0.0183 step time: 0.2027\n",
      "6/8, train_loss: 0.0186 step time: 0.1982\n",
      "7/8, train_loss: 0.0163 step time: 0.1828\n",
      "8/8, train_loss: 0.0170 step time: 0.1819\n",
      "epoch 177 average loss: 0.0179\n",
      "time consuming of epoch 177 is: 1.6148\n",
      "----------\n",
      "epoch 178/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2390\n",
      "2/8, train_loss: 0.0169 step time: 0.1998\n",
      "3/8, train_loss: 0.0177 step time: 0.2027\n",
      "4/8, train_loss: 0.0143 step time: 0.1995\n",
      "5/8, train_loss: 0.0163 step time: 0.1996\n",
      "6/8, train_loss: 0.0196 step time: 0.1986\n",
      "7/8, train_loss: 0.0189 step time: 0.1838\n",
      "8/8, train_loss: 0.0175 step time: 0.1837\n",
      "epoch 178 average loss: 0.0170\n",
      "time consuming of epoch 178 is: 1.6081\n",
      "----------\n",
      "epoch 179/600\n",
      "1/8, train_loss: 0.0189 step time: 0.2387\n",
      "2/8, train_loss: 0.0174 step time: 0.2024\n",
      "3/8, train_loss: 0.0178 step time: 0.2014\n",
      "4/8, train_loss: 0.0203 step time: 0.2015\n",
      "5/8, train_loss: 0.0218 step time: 0.2031\n",
      "6/8, train_loss: 0.0170 step time: 0.1998\n",
      "7/8, train_loss: 0.0150 step time: 0.1824\n",
      "8/8, train_loss: 0.0179 step time: 0.1840\n",
      "epoch 179 average loss: 0.0183\n",
      "time consuming of epoch 179 is: 1.6152\n",
      "----------\n",
      "epoch 180/600\n",
      "1/8, train_loss: 0.0221 step time: 0.2375\n",
      "2/8, train_loss: 0.0191 step time: 0.2020\n",
      "3/8, train_loss: 0.0218 step time: 0.1998\n",
      "4/8, train_loss: 0.0161 step time: 0.2024\n",
      "5/8, train_loss: 0.0154 step time: 0.1993\n",
      "6/8, train_loss: 0.0141 step time: 0.1996\n",
      "7/8, train_loss: 0.0159 step time: 0.1828\n",
      "8/8, train_loss: 0.0180 step time: 0.1821\n",
      "epoch 180 average loss: 0.0178\n",
      "current epoch: 180 current mean dice: 0.9508 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 180 is: 2.3623\n",
      "----------\n",
      "epoch 181/600\n",
      "1/8, train_loss: 0.0230 step time: 0.2403\n",
      "2/8, train_loss: 0.0149 step time: 0.2028\n",
      "3/8, train_loss: 0.0210 step time: 0.1993\n",
      "4/8, train_loss: 0.0175 step time: 0.2021\n",
      "5/8, train_loss: 0.0137 step time: 0.2048\n",
      "6/8, train_loss: 0.0154 step time: 0.2001\n",
      "7/8, train_loss: 0.0170 step time: 0.1829\n",
      "8/8, train_loss: 0.0160 step time: 0.1820\n",
      "epoch 181 average loss: 0.0173\n",
      "time consuming of epoch 181 is: 1.6153\n",
      "----------\n",
      "epoch 182/600\n",
      "1/8, train_loss: 0.0175 step time: 0.2393\n",
      "2/8, train_loss: 0.0182 step time: 0.2041\n",
      "3/8, train_loss: 0.0176 step time: 0.2050\n",
      "4/8, train_loss: 0.0155 step time: 0.2005\n",
      "5/8, train_loss: 0.0183 step time: 0.2045\n",
      "6/8, train_loss: 0.0169 step time: 0.2029\n",
      "7/8, train_loss: 0.0168 step time: 0.1827\n",
      "8/8, train_loss: 0.0164 step time: 0.1834\n",
      "epoch 182 average loss: 0.0171\n",
      "time consuming of epoch 182 is: 1.6236\n",
      "----------\n",
      "epoch 183/600\n",
      "1/8, train_loss: 0.0162 step time: 0.2404\n",
      "2/8, train_loss: 0.0187 step time: 0.2031\n",
      "3/8, train_loss: 0.0182 step time: 0.1923\n",
      "4/8, train_loss: 0.0176 step time: 0.1933\n",
      "5/8, train_loss: 0.0225 step time: 0.1935\n",
      "6/8, train_loss: 0.0161 step time: 0.1971\n",
      "7/8, train_loss: 0.0147 step time: 0.1836\n",
      "8/8, train_loss: 0.0219 step time: 0.1849\n",
      "epoch 183 average loss: 0.0182\n",
      "time consuming of epoch 183 is: 1.5897\n",
      "----------\n",
      "epoch 184/600\n",
      "1/8, train_loss: 0.0171 step time: 0.2330\n",
      "2/8, train_loss: 0.0131 step time: 0.1974\n",
      "3/8, train_loss: 0.0166 step time: 0.2010\n",
      "4/8, train_loss: 0.0200 step time: 0.2085\n",
      "5/8, train_loss: 0.0187 step time: 0.2003\n",
      "6/8, train_loss: 0.0168 step time: 0.2026\n",
      "7/8, train_loss: 0.0183 step time: 0.1826\n",
      "8/8, train_loss: 0.0156 step time: 0.1841\n",
      "epoch 184 average loss: 0.0170\n",
      "time consuming of epoch 184 is: 1.6109\n",
      "----------\n",
      "epoch 185/600\n",
      "1/8, train_loss: 0.0174 step time: 0.2385\n",
      "2/8, train_loss: 0.0214 step time: 0.2027\n",
      "3/8, train_loss: 0.0169 step time: 0.2026\n",
      "4/8, train_loss: 0.0182 step time: 0.1991\n",
      "5/8, train_loss: 0.0170 step time: 0.2053\n",
      "6/8, train_loss: 0.0150 step time: 0.1985\n",
      "7/8, train_loss: 0.0181 step time: 0.1817\n",
      "8/8, train_loss: 0.0175 step time: 0.1827\n",
      "epoch 185 average loss: 0.0177\n",
      "current epoch: 185 current mean dice: 0.9488 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 185 is: 2.3673\n",
      "----------\n",
      "epoch 186/600\n",
      "1/8, train_loss: 0.0173 step time: 0.2400\n",
      "2/8, train_loss: 0.0149 step time: 0.1996\n",
      "3/8, train_loss: 0.0201 step time: 0.1976\n",
      "4/8, train_loss: 0.0170 step time: 0.2026\n",
      "5/8, train_loss: 0.0227 step time: 0.1995\n",
      "6/8, train_loss: 0.0167 step time: 0.2099\n",
      "7/8, train_loss: 0.0172 step time: 0.1811\n",
      "8/8, train_loss: 0.0172 step time: 0.1795\n",
      "epoch 186 average loss: 0.0179\n",
      "time consuming of epoch 186 is: 1.6110\n",
      "----------\n",
      "epoch 187/600\n",
      "1/8, train_loss: 0.0159 step time: 0.2323\n",
      "2/8, train_loss: 0.0175 step time: 0.1951\n",
      "3/8, train_loss: 0.0143 step time: 0.2000\n",
      "4/8, train_loss: 0.0152 step time: 0.1975\n",
      "5/8, train_loss: 0.0237 step time: 0.2006\n",
      "6/8, train_loss: 0.0169 step time: 0.1963\n",
      "7/8, train_loss: 0.0159 step time: 0.1828\n",
      "8/8, train_loss: 0.0175 step time: 0.1825\n",
      "epoch 187 average loss: 0.0171\n",
      "time consuming of epoch 187 is: 1.5882\n",
      "----------\n",
      "epoch 188/600\n",
      "1/8, train_loss: 0.0162 step time: 0.2424\n",
      "2/8, train_loss: 0.0175 step time: 0.1997\n",
      "3/8, train_loss: 0.0183 step time: 0.2000\n",
      "4/8, train_loss: 0.0152 step time: 0.2018\n",
      "5/8, train_loss: 0.0192 step time: 0.2024\n",
      "6/8, train_loss: 0.0166 step time: 0.1991\n",
      "7/8, train_loss: 0.0136 step time: 0.1833\n",
      "8/8, train_loss: 0.0176 step time: 0.1814\n",
      "epoch 188 average loss: 0.0168\n",
      "time consuming of epoch 188 is: 1.6117\n",
      "----------\n",
      "epoch 189/600\n",
      "1/8, train_loss: 0.0170 step time: 0.2414\n",
      "2/8, train_loss: 0.0219 step time: 0.2030\n",
      "3/8, train_loss: 0.0174 step time: 0.2015\n",
      "4/8, train_loss: 0.0163 step time: 0.1993\n",
      "5/8, train_loss: 0.0164 step time: 0.1981\n",
      "6/8, train_loss: 0.0132 step time: 0.2017\n",
      "7/8, train_loss: 0.0171 step time: 0.1829\n",
      "8/8, train_loss: 0.0173 step time: 0.1819\n",
      "epoch 189 average loss: 0.0171\n",
      "time consuming of epoch 189 is: 1.6111\n",
      "----------\n",
      "epoch 190/600\n",
      "1/8, train_loss: 0.0165 step time: 0.2390\n",
      "2/8, train_loss: 0.0206 step time: 0.2016\n",
      "3/8, train_loss: 0.0131 step time: 0.2013\n",
      "4/8, train_loss: 0.0164 step time: 0.2005\n",
      "5/8, train_loss: 0.0154 step time: 0.2007\n",
      "6/8, train_loss: 0.0166 step time: 0.2028\n",
      "7/8, train_loss: 0.0146 step time: 0.1813\n",
      "8/8, train_loss: 0.0172 step time: 0.1805\n",
      "epoch 190 average loss: 0.0163\n",
      "current epoch: 190 current mean dice: 0.9537 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 190 is: 2.3633\n",
      "----------\n",
      "epoch 191/600\n",
      "1/8, train_loss: 0.0145 step time: 0.2390\n",
      "2/8, train_loss: 0.0157 step time: 0.1998\n",
      "3/8, train_loss: 0.0183 step time: 0.1997\n",
      "4/8, train_loss: 0.0138 step time: 0.1957\n",
      "5/8, train_loss: 0.0188 step time: 0.2006\n",
      "6/8, train_loss: 0.0160 step time: 0.1962\n",
      "7/8, train_loss: 0.0158 step time: 0.1808\n",
      "8/8, train_loss: 0.0164 step time: 0.1813\n",
      "epoch 191 average loss: 0.0162\n",
      "time consuming of epoch 191 is: 1.5942\n",
      "----------\n",
      "epoch 192/600\n",
      "1/8, train_loss: 0.0216 step time: 0.2384\n",
      "2/8, train_loss: 0.0173 step time: 0.2026\n",
      "3/8, train_loss: 0.0210 step time: 0.2034\n",
      "4/8, train_loss: 0.0141 step time: 0.2001\n",
      "5/8, train_loss: 0.0159 step time: 0.2005\n",
      "6/8, train_loss: 0.0158 step time: 0.2006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/8, train_loss: 0.0142 step time: 0.1834\n",
      "8/8, train_loss: 0.0169 step time: 0.1813\n",
      "epoch 192 average loss: 0.0171\n",
      "time consuming of epoch 192 is: 1.6117\n",
      "----------\n",
      "epoch 193/600\n",
      "1/8, train_loss: 0.0155 step time: 0.2390\n",
      "2/8, train_loss: 0.0168 step time: 0.2028\n",
      "3/8, train_loss: 0.0198 step time: 0.2033\n",
      "4/8, train_loss: 0.0170 step time: 0.2006\n",
      "5/8, train_loss: 0.0184 step time: 0.2043\n",
      "6/8, train_loss: 0.0162 step time: 0.2015\n",
      "7/8, train_loss: 0.0168 step time: 0.1836\n",
      "8/8, train_loss: 0.0179 step time: 0.1820\n",
      "epoch 193 average loss: 0.0173\n",
      "time consuming of epoch 193 is: 1.6186\n",
      "----------\n",
      "epoch 194/600\n",
      "1/8, train_loss: 0.0157 step time: 0.2426\n",
      "2/8, train_loss: 0.0166 step time: 0.2029\n",
      "3/8, train_loss: 0.0166 step time: 0.2034\n",
      "4/8, train_loss: 0.0146 step time: 0.2013\n",
      "5/8, train_loss: 0.0215 step time: 0.2001\n",
      "6/8, train_loss: 0.0173 step time: 0.2050\n",
      "7/8, train_loss: 0.0146 step time: 0.1828\n",
      "8/8, train_loss: 0.0164 step time: 0.1828\n",
      "epoch 194 average loss: 0.0166\n",
      "time consuming of epoch 194 is: 1.6224\n",
      "----------\n",
      "epoch 195/600\n",
      "1/8, train_loss: 0.0220 step time: 0.2415\n",
      "2/8, train_loss: 0.0180 step time: 0.2025\n",
      "3/8, train_loss: 0.0182 step time: 0.2016\n",
      "4/8, train_loss: 0.0167 step time: 0.1999\n",
      "5/8, train_loss: 0.0158 step time: 0.2015\n",
      "6/8, train_loss: 0.0200 step time: 0.2017\n",
      "7/8, train_loss: 0.0160 step time: 0.1828\n",
      "8/8, train_loss: 0.0176 step time: 0.1849\n",
      "epoch 195 average loss: 0.0180\n",
      "current epoch: 195 current mean dice: 0.9532 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 195 is: 2.3752\n",
      "----------\n",
      "epoch 196/600\n",
      "1/8, train_loss: 0.0212 step time: 0.2394\n",
      "2/8, train_loss: 0.0141 step time: 0.1998\n",
      "3/8, train_loss: 0.0150 step time: 0.1989\n",
      "4/8, train_loss: 0.0186 step time: 0.1989\n",
      "5/8, train_loss: 0.0168 step time: 0.2001\n",
      "6/8, train_loss: 0.0154 step time: 0.1994\n",
      "7/8, train_loss: 0.0158 step time: 0.1819\n",
      "8/8, train_loss: 0.0160 step time: 0.1816\n",
      "epoch 196 average loss: 0.0166\n",
      "time consuming of epoch 196 is: 1.6011\n",
      "----------\n",
      "epoch 197/600\n",
      "1/8, train_loss: 0.0143 step time: 0.2436\n",
      "2/8, train_loss: 0.0146 step time: 0.2019\n",
      "3/8, train_loss: 0.0177 step time: 0.2020\n",
      "4/8, train_loss: 0.0227 step time: 0.2032\n",
      "5/8, train_loss: 0.0180 step time: 0.2000\n",
      "6/8, train_loss: 0.0181 step time: 0.2022\n",
      "7/8, train_loss: 0.0174 step time: 0.1830\n",
      "8/8, train_loss: 0.0186 step time: 0.1840\n",
      "epoch 197 average loss: 0.0177\n",
      "time consuming of epoch 197 is: 1.6215\n",
      "----------\n",
      "epoch 198/600\n",
      "1/8, train_loss: 0.0184 step time: 0.2432\n",
      "2/8, train_loss: 0.0166 step time: 0.2039\n",
      "3/8, train_loss: 0.0161 step time: 0.2032\n",
      "4/8, train_loss: 0.0154 step time: 0.2000\n",
      "5/8, train_loss: 0.0191 step time: 0.1998\n",
      "6/8, train_loss: 0.0176 step time: 0.1994\n",
      "7/8, train_loss: 0.0137 step time: 0.1820\n",
      "8/8, train_loss: 0.0192 step time: 0.1825\n",
      "epoch 198 average loss: 0.0170\n",
      "time consuming of epoch 198 is: 1.6153\n",
      "----------\n",
      "epoch 199/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2370\n",
      "2/8, train_loss: 0.0185 step time: 0.2017\n",
      "3/8, train_loss: 0.0146 step time: 0.2054\n",
      "4/8, train_loss: 0.0152 step time: 0.2040\n",
      "5/8, train_loss: 0.0177 step time: 0.2042\n",
      "6/8, train_loss: 0.0142 step time: 0.2005\n",
      "7/8, train_loss: 0.0131 step time: 0.1830\n",
      "8/8, train_loss: 0.0180 step time: 0.1821\n",
      "epoch 199 average loss: 0.0158\n",
      "time consuming of epoch 199 is: 1.6193\n",
      "----------\n",
      "epoch 200/600\n",
      "1/8, train_loss: 0.0205 step time: 0.2405\n",
      "2/8, train_loss: 0.0158 step time: 0.2024\n",
      "3/8, train_loss: 0.0155 step time: 0.2002\n",
      "4/8, train_loss: 0.0141 step time: 0.2006\n",
      "5/8, train_loss: 0.0155 step time: 0.2024\n",
      "6/8, train_loss: 0.0178 step time: 0.2025\n",
      "7/8, train_loss: 0.0164 step time: 0.1824\n",
      "8/8, train_loss: 0.0124 step time: 0.1834\n",
      "epoch 200 average loss: 0.0160\n",
      "current epoch: 200 current mean dice: 0.9528 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 200 is: 2.3714\n",
      "----------\n",
      "epoch 201/600\n",
      "1/8, train_loss: 0.0145 step time: 0.2413\n",
      "2/8, train_loss: 0.0135 step time: 0.2035\n",
      "3/8, train_loss: 0.0172 step time: 0.1985\n",
      "4/8, train_loss: 0.0137 step time: 0.2003\n",
      "5/8, train_loss: 0.0167 step time: 0.2001\n",
      "6/8, train_loss: 0.0164 step time: 0.2032\n",
      "7/8, train_loss: 0.0163 step time: 0.1812\n",
      "8/8, train_loss: 0.0174 step time: 0.1829\n",
      "epoch 201 average loss: 0.0157\n",
      "time consuming of epoch 201 is: 1.6123\n",
      "----------\n",
      "epoch 202/600\n",
      "1/8, train_loss: 0.0158 step time: 0.2408\n",
      "2/8, train_loss: 0.0156 step time: 0.2001\n",
      "3/8, train_loss: 0.0209 step time: 0.2055\n",
      "4/8, train_loss: 0.0150 step time: 0.2027\n",
      "5/8, train_loss: 0.0191 step time: 0.2022\n",
      "6/8, train_loss: 0.0137 step time: 0.2001\n",
      "7/8, train_loss: 0.0163 step time: 0.1821\n",
      "8/8, train_loss: 0.0133 step time: 0.1794\n",
      "epoch 202 average loss: 0.0162\n",
      "time consuming of epoch 202 is: 1.6149\n",
      "----------\n",
      "epoch 203/600\n",
      "1/8, train_loss: 0.0158 step time: 0.2397\n",
      "2/8, train_loss: 0.0164 step time: 0.1997\n",
      "3/8, train_loss: 0.0180 step time: 0.1985\n",
      "4/8, train_loss: 0.0158 step time: 0.2028\n",
      "5/8, train_loss: 0.0193 step time: 0.2052\n",
      "6/8, train_loss: 0.0158 step time: 0.2028\n",
      "7/8, train_loss: 0.0161 step time: 0.1812\n",
      "8/8, train_loss: 0.0133 step time: 0.1819\n",
      "epoch 203 average loss: 0.0163\n",
      "time consuming of epoch 203 is: 1.6130\n",
      "----------\n",
      "epoch 204/600\n",
      "1/8, train_loss: 0.0183 step time: 0.2409\n",
      "2/8, train_loss: 0.0154 step time: 0.1990\n",
      "3/8, train_loss: 0.0184 step time: 0.1991\n",
      "4/8, train_loss: 0.0200 step time: 0.2490\n",
      "5/8, train_loss: 0.0164 step time: 0.2005\n",
      "6/8, train_loss: 0.0142 step time: 0.2004\n",
      "7/8, train_loss: 0.0155 step time: 0.1799\n",
      "8/8, train_loss: 0.0143 step time: 0.1787\n",
      "epoch 204 average loss: 0.0166\n",
      "time consuming of epoch 204 is: 1.6491\n",
      "----------\n",
      "epoch 205/600\n",
      "1/8, train_loss: 0.0153 step time: 0.2337\n",
      "2/8, train_loss: 0.0138 step time: 0.1940\n",
      "3/8, train_loss: 0.0168 step time: 0.2042\n",
      "4/8, train_loss: 0.0152 step time: 0.2027\n",
      "5/8, train_loss: 0.0168 step time: 0.1989\n",
      "6/8, train_loss: 0.0141 step time: 0.1958\n",
      "7/8, train_loss: 0.0188 step time: 0.1795\n",
      "8/8, train_loss: 0.0176 step time: 0.1789\n",
      "epoch 205 average loss: 0.0161\n",
      "current epoch: 205 current mean dice: 0.9509 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 205 is: 2.3407\n",
      "----------\n",
      "epoch 206/600\n",
      "1/8, train_loss: 0.0150 step time: 0.2356\n",
      "2/8, train_loss: 0.0151 step time: 0.1946\n",
      "3/8, train_loss: 0.0173 step time: 0.1982\n",
      "4/8, train_loss: 0.0140 step time: 0.1969\n",
      "5/8, train_loss: 0.0188 step time: 0.1985\n",
      "6/8, train_loss: 0.0202 step time: 0.1966\n",
      "7/8, train_loss: 0.0160 step time: 0.1792\n",
      "8/8, train_loss: 0.0137 step time: 0.1790\n",
      "epoch 206 average loss: 0.0163\n",
      "time consuming of epoch 206 is: 1.5798\n",
      "----------\n",
      "epoch 207/600\n",
      "1/8, train_loss: 0.0159 step time: 0.2348\n",
      "2/8, train_loss: 0.0160 step time: 0.1943\n",
      "3/8, train_loss: 0.0177 step time: 0.1969\n",
      "4/8, train_loss: 0.0175 step time: 0.2036\n",
      "5/8, train_loss: 0.0147 step time: 0.1992\n",
      "6/8, train_loss: 0.0157 step time: 0.2067\n",
      "7/8, train_loss: 0.0135 step time: 0.1824\n",
      "8/8, train_loss: 0.0186 step time: 0.1823\n",
      "epoch 207 average loss: 0.0162\n",
      "time consuming of epoch 207 is: 1.6014\n",
      "----------\n",
      "epoch 208/600\n",
      "1/8, train_loss: 0.0145 step time: 0.2418\n",
      "2/8, train_loss: 0.0163 step time: 0.1991\n",
      "3/8, train_loss: 0.0143 step time: 0.1981\n",
      "4/8, train_loss: 0.0148 step time: 0.2000\n",
      "5/8, train_loss: 0.0163 step time: 0.2100\n",
      "6/8, train_loss: 0.0197 step time: 0.2047\n",
      "7/8, train_loss: 0.0199 step time: 0.1823\n",
      "8/8, train_loss: 0.0134 step time: 0.1810\n",
      "epoch 208 average loss: 0.0161\n",
      "time consuming of epoch 208 is: 1.6187\n",
      "----------\n",
      "epoch 209/600\n",
      "1/8, train_loss: 0.0136 step time: 0.2378\n",
      "2/8, train_loss: 0.0168 step time: 0.2033\n",
      "3/8, train_loss: 0.0149 step time: 0.2013\n",
      "4/8, train_loss: 0.0166 step time: 0.2019\n",
      "5/8, train_loss: 0.0158 step time: 0.2044\n",
      "6/8, train_loss: 0.0159 step time: 0.2015\n",
      "7/8, train_loss: 0.0165 step time: 0.1830\n",
      "8/8, train_loss: 0.0178 step time: 0.1844\n",
      "epoch 209 average loss: 0.0160\n",
      "time consuming of epoch 209 is: 1.6191\n",
      "----------\n",
      "epoch 210/600\n",
      "1/8, train_loss: 0.0193 step time: 0.2384\n",
      "2/8, train_loss: 0.0150 step time: 0.2036\n",
      "3/8, train_loss: 0.0166 step time: 0.2020\n",
      "4/8, train_loss: 0.0164 step time: 0.1998\n",
      "5/8, train_loss: 0.0154 step time: 0.2020\n",
      "6/8, train_loss: 0.0154 step time: 0.1994\n",
      "7/8, train_loss: 0.0152 step time: 0.1824\n",
      "8/8, train_loss: 0.0146 step time: 0.1811\n",
      "epoch 210 average loss: 0.0160\n",
      "current epoch: 210 current mean dice: 0.9534 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 210 is: 2.3661\n",
      "----------\n",
      "epoch 211/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0169 step time: 0.2394\n",
      "2/8, train_loss: 0.0165 step time: 0.1995\n",
      "3/8, train_loss: 0.0167 step time: 0.2019\n",
      "4/8, train_loss: 0.0163 step time: 0.2001\n",
      "5/8, train_loss: 0.0120 step time: 0.1982\n",
      "6/8, train_loss: 0.0159 step time: 0.2015\n",
      "7/8, train_loss: 0.0148 step time: 0.1816\n",
      "8/8, train_loss: 0.0148 step time: 0.1815\n",
      "epoch 211 average loss: 0.0155\n",
      "time consuming of epoch 211 is: 1.6048\n",
      "----------\n",
      "epoch 212/600\n",
      "1/8, train_loss: 0.0141 step time: 0.2403\n",
      "2/8, train_loss: 0.0169 step time: 0.2036\n",
      "3/8, train_loss: 0.0171 step time: 0.2021\n",
      "4/8, train_loss: 0.0148 step time: 0.1991\n",
      "5/8, train_loss: 0.0161 step time: 0.2008\n",
      "6/8, train_loss: 0.0164 step time: 0.2019\n",
      "7/8, train_loss: 0.0157 step time: 0.1829\n",
      "8/8, train_loss: 0.0147 step time: 0.1827\n",
      "epoch 212 average loss: 0.0157\n",
      "time consuming of epoch 212 is: 1.6150\n",
      "----------\n",
      "epoch 213/600\n",
      "1/8, train_loss: 0.0176 step time: 0.2417\n",
      "2/8, train_loss: 0.0166 step time: 0.2013\n",
      "3/8, train_loss: 0.0159 step time: 0.2017\n",
      "4/8, train_loss: 0.0133 step time: 0.1982\n",
      "5/8, train_loss: 0.0147 step time: 0.2026\n",
      "6/8, train_loss: 0.0183 step time: 0.2020\n",
      "7/8, train_loss: 0.0150 step time: 0.1822\n",
      "8/8, train_loss: 0.0163 step time: 0.1839\n",
      "epoch 213 average loss: 0.0160\n",
      "time consuming of epoch 213 is: 1.6153\n",
      "----------\n",
      "epoch 214/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2374\n",
      "2/8, train_loss: 0.0142 step time: 0.1978\n",
      "3/8, train_loss: 0.0152 step time: 0.1959\n",
      "4/8, train_loss: 0.0213 step time: 0.2029\n",
      "5/8, train_loss: 0.0140 step time: 0.2017\n",
      "6/8, train_loss: 0.0155 step time: 0.1994\n",
      "7/8, train_loss: 0.0153 step time: 0.1850\n",
      "8/8, train_loss: 0.0143 step time: 0.1832\n",
      "epoch 214 average loss: 0.0156\n",
      "time consuming of epoch 214 is: 1.6046\n",
      "----------\n",
      "epoch 215/600\n",
      "1/8, train_loss: 0.0166 step time: 0.2426\n",
      "2/8, train_loss: 0.0159 step time: 0.2054\n",
      "3/8, train_loss: 0.0177 step time: 0.1983\n",
      "4/8, train_loss: 0.0177 step time: 0.2003\n",
      "5/8, train_loss: 0.0156 step time: 0.2026\n",
      "6/8, train_loss: 0.0149 step time: 0.1992\n",
      "7/8, train_loss: 0.0139 step time: 0.1822\n",
      "8/8, train_loss: 0.0141 step time: 0.1822\n",
      "epoch 215 average loss: 0.0158\n",
      "current epoch: 215 current mean dice: 0.9544 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 215 is: 2.3704\n",
      "----------\n",
      "epoch 216/600\n",
      "1/8, train_loss: 0.0150 step time: 0.2320\n",
      "2/8, train_loss: 0.0154 step time: 0.1955\n",
      "3/8, train_loss: 0.0139 step time: 0.1952\n",
      "4/8, train_loss: 0.0149 step time: 0.1980\n",
      "5/8, train_loss: 0.0131 step time: 0.1952\n",
      "6/8, train_loss: 0.0188 step time: 0.1983\n",
      "7/8, train_loss: 0.0145 step time: 0.1821\n",
      "8/8, train_loss: 0.0183 step time: 0.1826\n",
      "epoch 216 average loss: 0.0155\n",
      "time consuming of epoch 216 is: 1.5800\n",
      "----------\n",
      "epoch 217/600\n",
      "1/8, train_loss: 0.0160 step time: 0.2396\n",
      "2/8, train_loss: 0.0154 step time: 0.2047\n",
      "3/8, train_loss: 0.0130 step time: 0.1968\n",
      "4/8, train_loss: 0.0142 step time: 0.2077\n",
      "5/8, train_loss: 0.0161 step time: 0.1995\n",
      "6/8, train_loss: 0.0154 step time: 0.2035\n",
      "7/8, train_loss: 0.0162 step time: 0.1821\n",
      "8/8, train_loss: 0.0158 step time: 0.1838\n",
      "epoch 217 average loss: 0.0153\n",
      "time consuming of epoch 217 is: 1.6188\n",
      "----------\n",
      "epoch 218/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2398\n",
      "2/8, train_loss: 0.0151 step time: 0.2019\n",
      "3/8, train_loss: 0.0142 step time: 0.2011\n",
      "4/8, train_loss: 0.0151 step time: 0.2019\n",
      "5/8, train_loss: 0.0149 step time: 0.1967\n",
      "6/8, train_loss: 0.0174 step time: 0.2004\n",
      "7/8, train_loss: 0.0141 step time: 0.1837\n",
      "8/8, train_loss: 0.0154 step time: 0.1854\n",
      "epoch 218 average loss: 0.0151\n",
      "time consuming of epoch 218 is: 1.6127\n",
      "----------\n",
      "epoch 219/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2438\n",
      "2/8, train_loss: 0.0147 step time: 0.1990\n",
      "3/8, train_loss: 0.0146 step time: 0.2008\n",
      "4/8, train_loss: 0.0154 step time: 0.2037\n",
      "5/8, train_loss: 0.0154 step time: 0.2005\n",
      "6/8, train_loss: 0.0144 step time: 0.2038\n",
      "7/8, train_loss: 0.0162 step time: 0.1823\n",
      "8/8, train_loss: 0.0145 step time: 0.1816\n",
      "epoch 219 average loss: 0.0149\n",
      "time consuming of epoch 219 is: 1.6171\n",
      "----------\n",
      "epoch 220/600\n",
      "1/8, train_loss: 0.0134 step time: 0.2369\n",
      "2/8, train_loss: 0.0150 step time: 0.2037\n",
      "3/8, train_loss: 0.0139 step time: 0.2001\n",
      "4/8, train_loss: 0.0180 step time: 0.1994\n",
      "5/8, train_loss: 0.0166 step time: 0.2004\n",
      "6/8, train_loss: 0.0174 step time: 0.2009\n",
      "7/8, train_loss: 0.0144 step time: 0.1838\n",
      "8/8, train_loss: 0.0126 step time: 0.1814\n",
      "epoch 220 average loss: 0.0152\n",
      "current epoch: 220 current mean dice: 0.9542 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 220 is: 2.3624\n",
      "----------\n",
      "epoch 221/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2361\n",
      "2/8, train_loss: 0.0144 step time: 0.1999\n",
      "3/8, train_loss: 0.0128 step time: 0.2037\n",
      "4/8, train_loss: 0.0159 step time: 0.1984\n",
      "5/8, train_loss: 0.0124 step time: 0.2014\n",
      "6/8, train_loss: 0.0167 step time: 0.1929\n",
      "7/8, train_loss: 0.0193 step time: 0.1827\n",
      "8/8, train_loss: 0.0153 step time: 0.1817\n",
      "epoch 221 average loss: 0.0153\n",
      "time consuming of epoch 221 is: 1.5978\n",
      "----------\n",
      "epoch 222/600\n",
      "1/8, train_loss: 0.0146 step time: 0.2270\n",
      "2/8, train_loss: 0.0153 step time: 0.1956\n",
      "3/8, train_loss: 0.0185 step time: 0.1957\n",
      "4/8, train_loss: 0.0143 step time: 0.1935\n",
      "5/8, train_loss: 0.0139 step time: 0.1989\n",
      "6/8, train_loss: 0.0163 step time: 0.1990\n",
      "7/8, train_loss: 0.0167 step time: 0.1837\n",
      "8/8, train_loss: 0.0160 step time: 0.1829\n",
      "epoch 222 average loss: 0.0157\n",
      "time consuming of epoch 222 is: 1.5776\n",
      "----------\n",
      "epoch 223/600\n",
      "1/8, train_loss: 0.0138 step time: 0.2327\n",
      "2/8, train_loss: 0.0138 step time: 0.1958\n",
      "3/8, train_loss: 0.0152 step time: 0.1997\n",
      "4/8, train_loss: 0.0138 step time: 0.1993\n",
      "5/8, train_loss: 0.0143 step time: 0.2033\n",
      "6/8, train_loss: 0.0159 step time: 0.2038\n",
      "7/8, train_loss: 0.0171 step time: 0.1841\n",
      "8/8, train_loss: 0.0159 step time: 0.1828\n",
      "epoch 223 average loss: 0.0150\n",
      "time consuming of epoch 223 is: 1.6032\n",
      "----------\n",
      "epoch 224/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2418\n",
      "2/8, train_loss: 0.0121 step time: 0.2043\n",
      "3/8, train_loss: 0.0175 step time: 0.1993\n",
      "4/8, train_loss: 0.0152 step time: 0.2032\n",
      "5/8, train_loss: 0.0148 step time: 0.2024\n",
      "6/8, train_loss: 0.0161 step time: 0.2019\n",
      "7/8, train_loss: 0.0145 step time: 0.1823\n",
      "8/8, train_loss: 0.0150 step time: 0.1820\n",
      "epoch 224 average loss: 0.0151\n",
      "time consuming of epoch 224 is: 1.6185\n",
      "----------\n",
      "epoch 225/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2384\n",
      "2/8, train_loss: 0.0150 step time: 0.1999\n",
      "3/8, train_loss: 0.0154 step time: 0.1995\n",
      "4/8, train_loss: 0.0113 step time: 0.2037\n",
      "5/8, train_loss: 0.0177 step time: 0.2018\n",
      "6/8, train_loss: 0.0173 step time: 0.1993\n",
      "7/8, train_loss: 0.0154 step time: 0.1834\n",
      "8/8, train_loss: 0.0139 step time: 0.1827\n",
      "epoch 225 average loss: 0.0151\n",
      "current epoch: 225 current mean dice: 0.9551 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 225 is: 2.3655\n",
      "----------\n",
      "epoch 226/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2304\n",
      "2/8, train_loss: 0.0145 step time: 0.1959\n",
      "3/8, train_loss: 0.0109 step time: 0.1985\n",
      "4/8, train_loss: 0.0155 step time: 0.1971\n",
      "5/8, train_loss: 0.0160 step time: 0.1968\n",
      "6/8, train_loss: 0.0152 step time: 0.1960\n",
      "7/8, train_loss: 0.0179 step time: 0.1820\n",
      "8/8, train_loss: 0.0144 step time: 0.1813\n",
      "epoch 226 average loss: 0.0149\n",
      "time consuming of epoch 226 is: 1.5791\n",
      "----------\n",
      "epoch 227/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2385\n",
      "2/8, train_loss: 0.0130 step time: 0.1980\n",
      "3/8, train_loss: 0.0167 step time: 0.1996\n",
      "4/8, train_loss: 0.0135 step time: 0.1933\n",
      "5/8, train_loss: 0.0141 step time: 0.1964\n",
      "6/8, train_loss: 0.0147 step time: 0.1942\n",
      "7/8, train_loss: 0.0157 step time: 0.1835\n",
      "8/8, train_loss: 0.0150 step time: 0.1812\n",
      "epoch 227 average loss: 0.0147\n",
      "time consuming of epoch 227 is: 1.5861\n",
      "----------\n",
      "epoch 228/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2447\n",
      "2/8, train_loss: 0.0176 step time: 0.1996\n",
      "3/8, train_loss: 0.0155 step time: 0.1990\n",
      "4/8, train_loss: 0.0168 step time: 0.1979\n",
      "5/8, train_loss: 0.0146 step time: 0.2019\n",
      "6/8, train_loss: 0.0160 step time: 0.2051\n",
      "7/8, train_loss: 0.0132 step time: 0.1839\n",
      "8/8, train_loss: 0.0141 step time: 0.1813\n",
      "epoch 228 average loss: 0.0154\n",
      "time consuming of epoch 228 is: 1.6148\n",
      "----------\n",
      "epoch 229/600\n",
      "1/8, train_loss: 0.0117 step time: 0.2402\n",
      "2/8, train_loss: 0.0144 step time: 0.1990\n",
      "3/8, train_loss: 0.0164 step time: 0.2060\n",
      "4/8, train_loss: 0.0198 step time: 0.2057\n",
      "5/8, train_loss: 0.0136 step time: 0.1962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/8, train_loss: 0.0180 step time: 0.2001\n",
      "7/8, train_loss: 0.0151 step time: 0.1826\n",
      "8/8, train_loss: 0.0169 step time: 0.1839\n",
      "epoch 229 average loss: 0.0157\n",
      "time consuming of epoch 229 is: 1.6152\n",
      "----------\n",
      "epoch 230/600\n",
      "1/8, train_loss: 0.0147 step time: 0.2434\n",
      "2/8, train_loss: 0.0138 step time: 0.2030\n",
      "3/8, train_loss: 0.0129 step time: 0.2020\n",
      "4/8, train_loss: 0.0153 step time: 0.1987\n",
      "5/8, train_loss: 0.0171 step time: 0.1999\n",
      "6/8, train_loss: 0.0140 step time: 0.2015\n",
      "7/8, train_loss: 0.0153 step time: 0.1826\n",
      "8/8, train_loss: 0.0163 step time: 0.1829\n",
      "epoch 230 average loss: 0.0150\n",
      "current epoch: 230 current mean dice: 0.9552 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 230 is: 2.3695\n",
      "----------\n",
      "epoch 231/600\n",
      "1/8, train_loss: 0.0146 step time: 0.2462\n",
      "2/8, train_loss: 0.0157 step time: 0.2083\n",
      "3/8, train_loss: 0.0156 step time: 0.2034\n",
      "4/8, train_loss: 0.0159 step time: 0.2044\n",
      "5/8, train_loss: 0.0152 step time: 0.2016\n",
      "6/8, train_loss: 0.0154 step time: 0.2029\n",
      "7/8, train_loss: 0.0145 step time: 0.1812\n",
      "8/8, train_loss: 0.0145 step time: 0.1815\n",
      "epoch 231 average loss: 0.0152\n",
      "time consuming of epoch 231 is: 1.6308\n",
      "----------\n",
      "epoch 232/600\n",
      "1/8, train_loss: 0.0127 step time: 0.2389\n",
      "2/8, train_loss: 0.0150 step time: 0.1999\n",
      "3/8, train_loss: 0.0150 step time: 0.2003\n",
      "4/8, train_loss: 0.0151 step time: 0.2018\n",
      "5/8, train_loss: 0.0131 step time: 0.2015\n",
      "6/8, train_loss: 0.0139 step time: 0.1996\n",
      "7/8, train_loss: 0.0164 step time: 0.1833\n",
      "8/8, train_loss: 0.0142 step time: 0.1828\n",
      "epoch 232 average loss: 0.0144\n",
      "time consuming of epoch 232 is: 1.6097\n",
      "----------\n",
      "epoch 233/600\n",
      "1/8, train_loss: 0.0143 step time: 0.2421\n",
      "2/8, train_loss: 0.0127 step time: 0.2054\n",
      "3/8, train_loss: 0.0145 step time: 0.1987\n",
      "4/8, train_loss: 0.0137 step time: 0.2055\n",
      "5/8, train_loss: 0.0141 step time: 0.2031\n",
      "6/8, train_loss: 0.0161 step time: 0.1986\n",
      "7/8, train_loss: 0.0165 step time: 0.1818\n",
      "8/8, train_loss: 0.0148 step time: 0.1826\n",
      "epoch 233 average loss: 0.0146\n",
      "time consuming of epoch 233 is: 1.6195\n",
      "----------\n",
      "epoch 234/600\n",
      "1/8, train_loss: 0.0171 step time: 0.2416\n",
      "2/8, train_loss: 0.0165 step time: 0.2026\n",
      "3/8, train_loss: 0.0169 step time: 0.2003\n",
      "4/8, train_loss: 0.0129 step time: 0.2034\n",
      "5/8, train_loss: 0.0148 step time: 0.1991\n",
      "6/8, train_loss: 0.0138 step time: 0.2015\n",
      "7/8, train_loss: 0.0142 step time: 0.1820\n",
      "8/8, train_loss: 0.0147 step time: 0.1822\n",
      "epoch 234 average loss: 0.0151\n",
      "time consuming of epoch 234 is: 1.6145\n",
      "----------\n",
      "epoch 235/600\n",
      "1/8, train_loss: 0.0135 step time: 0.2391\n",
      "2/8, train_loss: 0.0181 step time: 0.2003\n",
      "3/8, train_loss: 0.0165 step time: 0.1995\n",
      "4/8, train_loss: 0.0139 step time: 0.1986\n",
      "5/8, train_loss: 0.0143 step time: 0.2001\n",
      "6/8, train_loss: 0.0159 step time: 0.1993\n",
      "7/8, train_loss: 0.0161 step time: 0.1819\n",
      "8/8, train_loss: 0.0118 step time: 0.1821\n",
      "epoch 235 average loss: 0.0150\n",
      "current epoch: 235 current mean dice: 0.9552 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 235 is: 2.3567\n",
      "----------\n",
      "epoch 236/600\n",
      "1/8, train_loss: 0.0134 step time: 0.2358\n",
      "2/8, train_loss: 0.0129 step time: 0.1984\n",
      "3/8, train_loss: 0.0153 step time: 0.2001\n",
      "4/8, train_loss: 0.0156 step time: 0.2024\n",
      "5/8, train_loss: 0.0169 step time: 0.1996\n",
      "6/8, train_loss: 0.0156 step time: 0.1989\n",
      "7/8, train_loss: 0.0142 step time: 0.1831\n",
      "8/8, train_loss: 0.0152 step time: 0.1822\n",
      "epoch 236 average loss: 0.0149\n",
      "time consuming of epoch 236 is: 1.6016\n",
      "----------\n",
      "epoch 237/600\n",
      "1/8, train_loss: 0.0168 step time: 0.2417\n",
      "2/8, train_loss: 0.0132 step time: 0.2027\n",
      "3/8, train_loss: 0.0136 step time: 0.1984\n",
      "4/8, train_loss: 0.0172 step time: 0.2014\n",
      "5/8, train_loss: 0.0146 step time: 0.2021\n",
      "6/8, train_loss: 0.0145 step time: 0.2004\n",
      "7/8, train_loss: 0.0126 step time: 0.1837\n",
      "8/8, train_loss: 0.0199 step time: 0.1818\n",
      "epoch 237 average loss: 0.0153\n",
      "time consuming of epoch 237 is: 1.6137\n",
      "----------\n",
      "epoch 238/600\n",
      "1/8, train_loss: 0.0155 step time: 0.2413\n",
      "2/8, train_loss: 0.0170 step time: 0.2021\n",
      "3/8, train_loss: 0.0136 step time: 0.1999\n",
      "4/8, train_loss: 0.0135 step time: 0.2031\n",
      "5/8, train_loss: 0.0139 step time: 0.2005\n",
      "6/8, train_loss: 0.0136 step time: 0.2020\n",
      "7/8, train_loss: 0.0155 step time: 0.1822\n",
      "8/8, train_loss: 0.0157 step time: 0.1858\n",
      "epoch 238 average loss: 0.0148\n",
      "time consuming of epoch 238 is: 1.6185\n",
      "----------\n",
      "epoch 239/600\n",
      "1/8, train_loss: 0.0136 step time: 0.2371\n",
      "2/8, train_loss: 0.0141 step time: 0.2020\n",
      "3/8, train_loss: 0.0137 step time: 0.2046\n",
      "4/8, train_loss: 0.0133 step time: 0.1997\n",
      "5/8, train_loss: 0.0145 step time: 0.1997\n",
      "6/8, train_loss: 0.0158 step time: 0.2006\n",
      "7/8, train_loss: 0.0141 step time: 0.1845\n",
      "8/8, train_loss: 0.0186 step time: 0.1807\n",
      "epoch 239 average loss: 0.0147\n",
      "time consuming of epoch 239 is: 1.6103\n",
      "----------\n",
      "epoch 240/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2399\n",
      "2/8, train_loss: 0.0136 step time: 0.2037\n",
      "3/8, train_loss: 0.0130 step time: 0.2024\n",
      "4/8, train_loss: 0.0163 step time: 0.1991\n",
      "5/8, train_loss: 0.0156 step time: 0.2004\n",
      "6/8, train_loss: 0.0171 step time: 0.2016\n",
      "7/8, train_loss: 0.0142 step time: 0.1846\n",
      "8/8, train_loss: 0.0153 step time: 0.1850\n",
      "epoch 240 average loss: 0.0148\n",
      "current epoch: 240 current mean dice: 0.9544 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 240 is: 2.3728\n",
      "----------\n",
      "epoch 241/600\n",
      "1/8, train_loss: 0.0126 step time: 0.2422\n",
      "2/8, train_loss: 0.0138 step time: 0.2003\n",
      "3/8, train_loss: 0.0141 step time: 0.2011\n",
      "4/8, train_loss: 0.0143 step time: 0.1988\n",
      "5/8, train_loss: 0.0161 step time: 0.2007\n",
      "6/8, train_loss: 0.0138 step time: 0.2002\n",
      "7/8, train_loss: 0.0150 step time: 0.1815\n",
      "8/8, train_loss: 0.0146 step time: 0.1811\n",
      "epoch 241 average loss: 0.0143\n",
      "time consuming of epoch 241 is: 1.6069\n",
      "----------\n",
      "epoch 242/600\n",
      "1/8, train_loss: 0.0146 step time: 0.2381\n",
      "2/8, train_loss: 0.0141 step time: 0.2030\n",
      "3/8, train_loss: 0.0142 step time: 0.2001\n",
      "4/8, train_loss: 0.0153 step time: 0.2006\n",
      "5/8, train_loss: 0.0145 step time: 0.1998\n",
      "6/8, train_loss: 0.0148 step time: 0.2015\n",
      "7/8, train_loss: 0.0130 step time: 0.1833\n",
      "8/8, train_loss: 0.0130 step time: 0.1808\n",
      "epoch 242 average loss: 0.0142\n",
      "time consuming of epoch 242 is: 1.6086\n",
      "----------\n",
      "epoch 243/600\n",
      "1/8, train_loss: 0.0145 step time: 0.2379\n",
      "2/8, train_loss: 0.0131 step time: 0.1992\n",
      "3/8, train_loss: 0.0111 step time: 0.2025\n",
      "4/8, train_loss: 0.0153 step time: 0.2024\n",
      "5/8, train_loss: 0.0145 step time: 0.2077\n",
      "6/8, train_loss: 0.0183 step time: 0.2028\n",
      "7/8, train_loss: 0.0142 step time: 0.1835\n",
      "8/8, train_loss: 0.0178 step time: 0.1839\n",
      "epoch 243 average loss: 0.0148\n",
      "time consuming of epoch 243 is: 1.6213\n",
      "----------\n",
      "epoch 244/600\n",
      "1/8, train_loss: 0.0159 step time: 0.2369\n",
      "2/8, train_loss: 0.0140 step time: 0.2037\n",
      "3/8, train_loss: 0.0149 step time: 0.2025\n",
      "4/8, train_loss: 0.0158 step time: 0.1974\n",
      "5/8, train_loss: 0.0150 step time: 0.1987\n",
      "6/8, train_loss: 0.0121 step time: 0.2065\n",
      "7/8, train_loss: 0.0128 step time: 0.1897\n",
      "8/8, train_loss: 0.0155 step time: 0.1846\n",
      "epoch 244 average loss: 0.0145\n",
      "time consuming of epoch 244 is: 1.6214\n",
      "----------\n",
      "epoch 245/600\n",
      "1/8, train_loss: 0.0156 step time: 0.2284\n",
      "2/8, train_loss: 0.0146 step time: 0.1978\n",
      "3/8, train_loss: 0.0142 step time: 0.1954\n",
      "4/8, train_loss: 0.0142 step time: 0.1976\n",
      "5/8, train_loss: 0.0154 step time: 0.1976\n",
      "6/8, train_loss: 0.0143 step time: 0.1964\n",
      "7/8, train_loss: 0.0136 step time: 0.1833\n",
      "8/8, train_loss: 0.0119 step time: 0.1831\n",
      "epoch 245 average loss: 0.0142\n",
      "current epoch: 245 current mean dice: 0.9547 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 245 is: 2.3380\n",
      "----------\n",
      "epoch 246/600\n",
      "1/8, train_loss: 0.0130 step time: 0.2391\n",
      "2/8, train_loss: 0.0127 step time: 0.2014\n",
      "3/8, train_loss: 0.0168 step time: 0.1992\n",
      "4/8, train_loss: 0.0148 step time: 0.1987\n",
      "5/8, train_loss: 0.0132 step time: 0.1972\n",
      "6/8, train_loss: 0.0151 step time: 0.2000\n",
      "7/8, train_loss: 0.0142 step time: 0.1834\n",
      "8/8, train_loss: 0.0153 step time: 0.1826\n",
      "epoch 246 average loss: 0.0144\n",
      "time consuming of epoch 246 is: 1.6027\n",
      "----------\n",
      "epoch 247/600\n",
      "1/8, train_loss: 0.0144 step time: 0.2389\n",
      "2/8, train_loss: 0.0160 step time: 0.2017\n",
      "3/8, train_loss: 0.0145 step time: 0.2005\n",
      "4/8, train_loss: 0.0148 step time: 0.2253\n",
      "5/8, train_loss: 0.0123 step time: 0.1983\n",
      "6/8, train_loss: 0.0144 step time: 0.2012\n",
      "7/8, train_loss: 0.0151 step time: 0.1824\n",
      "8/8, train_loss: 0.0169 step time: 0.1837\n",
      "epoch 247 average loss: 0.0148\n",
      "time consuming of epoch 247 is: 1.6335\n",
      "----------\n",
      "epoch 248/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0157 step time: 0.2301\n",
      "2/8, train_loss: 0.0164 step time: 0.1958\n",
      "3/8, train_loss: 0.0166 step time: 0.1976\n",
      "4/8, train_loss: 0.0149 step time: 0.2048\n",
      "5/8, train_loss: 0.0145 step time: 0.1974\n",
      "6/8, train_loss: 0.0161 step time: 0.1986\n",
      "7/8, train_loss: 0.0106 step time: 0.1844\n",
      "8/8, train_loss: 0.0138 step time: 0.1820\n",
      "epoch 248 average loss: 0.0148\n",
      "time consuming of epoch 248 is: 1.5926\n",
      "----------\n",
      "epoch 249/600\n",
      "1/8, train_loss: 0.0177 step time: 0.2412\n",
      "2/8, train_loss: 0.0162 step time: 0.2028\n",
      "3/8, train_loss: 0.0126 step time: 0.2018\n",
      "4/8, train_loss: 0.0141 step time: 0.2016\n",
      "5/8, train_loss: 0.0147 step time: 0.1985\n",
      "6/8, train_loss: 0.0117 step time: 0.1986\n",
      "7/8, train_loss: 0.0157 step time: 0.1827\n",
      "8/8, train_loss: 0.0157 step time: 0.1833\n",
      "epoch 249 average loss: 0.0148\n",
      "time consuming of epoch 249 is: 1.6119\n",
      "----------\n",
      "epoch 250/600\n",
      "1/8, train_loss: 0.0140 step time: 0.2390\n",
      "2/8, train_loss: 0.0145 step time: 0.1971\n",
      "3/8, train_loss: 0.0147 step time: 0.1960\n",
      "4/8, train_loss: 0.0162 step time: 0.1973\n",
      "5/8, train_loss: 0.0139 step time: 0.1983\n",
      "6/8, train_loss: 0.0160 step time: 0.1996\n",
      "7/8, train_loss: 0.0145 step time: 0.1830\n",
      "8/8, train_loss: 0.0173 step time: 0.1818\n",
      "epoch 250 average loss: 0.0151\n",
      "current epoch: 250 current mean dice: 0.9533 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 250 is: 2.3525\n",
      "----------\n",
      "epoch 251/600\n",
      "1/8, train_loss: 0.0156 step time: 0.2978\n",
      "2/8, train_loss: 0.0167 step time: 0.2054\n",
      "3/8, train_loss: 0.0182 step time: 0.1969\n",
      "4/8, train_loss: 0.0153 step time: 0.2064\n",
      "5/8, train_loss: 0.0138 step time: 0.2077\n",
      "6/8, train_loss: 0.0137 step time: 0.1984\n",
      "7/8, train_loss: 0.0146 step time: 0.1808\n",
      "8/8, train_loss: 0.0181 step time: 0.1812\n",
      "epoch 251 average loss: 0.0158\n",
      "time consuming of epoch 251 is: 1.6760\n",
      "----------\n",
      "epoch 252/600\n",
      "1/8, train_loss: 0.0140 step time: 0.2377\n",
      "2/8, train_loss: 0.0166 step time: 0.1968\n",
      "3/8, train_loss: 0.0170 step time: 0.2018\n",
      "4/8, train_loss: 0.0126 step time: 0.1989\n",
      "5/8, train_loss: 0.0137 step time: 0.1991\n",
      "6/8, train_loss: 0.0140 step time: 0.1995\n",
      "7/8, train_loss: 0.0156 step time: 0.1842\n",
      "8/8, train_loss: 0.0171 step time: 0.1814\n",
      "epoch 252 average loss: 0.0151\n",
      "time consuming of epoch 252 is: 1.6010\n",
      "----------\n",
      "epoch 253/600\n",
      "1/8, train_loss: 0.0124 step time: 0.2389\n",
      "2/8, train_loss: 0.0152 step time: 0.1980\n",
      "3/8, train_loss: 0.0150 step time: 0.2010\n",
      "4/8, train_loss: 0.0149 step time: 0.2025\n",
      "5/8, train_loss: 0.0131 step time: 0.2022\n",
      "6/8, train_loss: 0.0146 step time: 0.1994\n",
      "7/8, train_loss: 0.0144 step time: 0.1837\n",
      "8/8, train_loss: 0.0159 step time: 0.1824\n",
      "epoch 253 average loss: 0.0144\n",
      "time consuming of epoch 253 is: 1.6095\n",
      "----------\n",
      "epoch 254/600\n",
      "1/8, train_loss: 0.0146 step time: 0.2435\n",
      "2/8, train_loss: 0.0173 step time: 0.1985\n",
      "3/8, train_loss: 0.0153 step time: 0.2002\n",
      "4/8, train_loss: 0.0145 step time: 0.2018\n",
      "5/8, train_loss: 0.0163 step time: 0.2006\n",
      "6/8, train_loss: 0.0144 step time: 0.2008\n",
      "7/8, train_loss: 0.0156 step time: 0.1814\n",
      "8/8, train_loss: 0.0136 step time: 0.1820\n",
      "epoch 254 average loss: 0.0152\n",
      "time consuming of epoch 254 is: 1.6105\n",
      "----------\n",
      "epoch 255/600\n",
      "1/8, train_loss: 0.0159 step time: 0.2387\n",
      "2/8, train_loss: 0.0135 step time: 0.1965\n",
      "3/8, train_loss: 0.0153 step time: 0.1965\n",
      "4/8, train_loss: 0.0155 step time: 0.1948\n",
      "5/8, train_loss: 0.0136 step time: 0.1964\n",
      "6/8, train_loss: 0.0141 step time: 0.1981\n",
      "7/8, train_loss: 0.0145 step time: 0.1828\n",
      "8/8, train_loss: 0.0152 step time: 0.1821\n",
      "epoch 255 average loss: 0.0147\n",
      "current epoch: 255 current mean dice: 0.9532 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 255 is: 2.3437\n",
      "----------\n",
      "epoch 256/600\n",
      "1/8, train_loss: 0.0153 step time: 0.2400\n",
      "2/8, train_loss: 0.0137 step time: 0.2013\n",
      "3/8, train_loss: 0.0191 step time: 0.1988\n",
      "4/8, train_loss: 0.0149 step time: 0.2013\n",
      "5/8, train_loss: 0.0114 step time: 0.2005\n",
      "6/8, train_loss: 0.0157 step time: 0.2004\n",
      "7/8, train_loss: 0.0145 step time: 0.1832\n",
      "8/8, train_loss: 0.0140 step time: 0.1808\n",
      "epoch 256 average loss: 0.0148\n",
      "time consuming of epoch 256 is: 1.6074\n",
      "----------\n",
      "epoch 257/600\n",
      "1/8, train_loss: 0.0159 step time: 0.2384\n",
      "2/8, train_loss: 0.0137 step time: 0.2025\n",
      "3/8, train_loss: 0.0169 step time: 0.1954\n",
      "4/8, train_loss: 0.0152 step time: 0.1972\n",
      "5/8, train_loss: 0.0144 step time: 0.1989\n",
      "6/8, train_loss: 0.0135 step time: 0.2011\n",
      "7/8, train_loss: 0.0154 step time: 0.1827\n",
      "8/8, train_loss: 0.0116 step time: 0.1825\n",
      "epoch 257 average loss: 0.0146\n",
      "time consuming of epoch 257 is: 1.6002\n",
      "----------\n",
      "epoch 258/600\n",
      "1/8, train_loss: 0.0139 step time: 0.2392\n",
      "2/8, train_loss: 0.0123 step time: 0.1989\n",
      "3/8, train_loss: 0.0142 step time: 0.1988\n",
      "4/8, train_loss: 0.0159 step time: 0.2018\n",
      "5/8, train_loss: 0.0135 step time: 0.2000\n",
      "6/8, train_loss: 0.0151 step time: 0.1975\n",
      "7/8, train_loss: 0.0179 step time: 0.1824\n",
      "8/8, train_loss: 0.0145 step time: 0.1831\n",
      "epoch 258 average loss: 0.0147\n",
      "time consuming of epoch 258 is: 1.6030\n",
      "----------\n",
      "epoch 259/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2396\n",
      "2/8, train_loss: 0.0169 step time: 0.2023\n",
      "3/8, train_loss: 0.0135 step time: 0.2004\n",
      "4/8, train_loss: 0.0179 step time: 0.2010\n",
      "5/8, train_loss: 0.0143 step time: 0.1981\n",
      "6/8, train_loss: 0.0143 step time: 0.2033\n",
      "7/8, train_loss: 0.0131 step time: 0.1837\n",
      "8/8, train_loss: 0.0126 step time: 0.1829\n",
      "epoch 259 average loss: 0.0145\n",
      "time consuming of epoch 259 is: 1.6126\n",
      "----------\n",
      "epoch 260/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2363\n",
      "2/8, train_loss: 0.0143 step time: 0.1979\n",
      "3/8, train_loss: 0.0130 step time: 0.1951\n",
      "4/8, train_loss: 0.0126 step time: 0.1948\n",
      "5/8, train_loss: 0.0146 step time: 0.1955\n",
      "6/8, train_loss: 0.0154 step time: 0.2024\n",
      "7/8, train_loss: 0.0144 step time: 0.1843\n",
      "8/8, train_loss: 0.0132 step time: 0.1817\n",
      "epoch 260 average loss: 0.0141\n",
      "current epoch: 260 current mean dice: 0.9553 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 260 is: 2.3430\n",
      "----------\n",
      "epoch 261/600\n",
      "1/8, train_loss: 0.0129 step time: 0.2397\n",
      "2/8, train_loss: 0.0126 step time: 0.2039\n",
      "3/8, train_loss: 0.0114 step time: 0.1978\n",
      "4/8, train_loss: 0.0160 step time: 0.1975\n",
      "5/8, train_loss: 0.0132 step time: 0.1977\n",
      "6/8, train_loss: 0.0205 step time: 0.1974\n",
      "7/8, train_loss: 0.0131 step time: 0.1816\n",
      "8/8, train_loss: 0.0152 step time: 0.1810\n",
      "epoch 261 average loss: 0.0144\n",
      "time consuming of epoch 261 is: 1.5977\n",
      "----------\n",
      "epoch 262/600\n",
      "1/8, train_loss: 0.0165 step time: 0.2430\n",
      "2/8, train_loss: 0.0161 step time: 0.2001\n",
      "3/8, train_loss: 0.0142 step time: 0.2012\n",
      "4/8, train_loss: 0.0128 step time: 0.1991\n",
      "5/8, train_loss: 0.0178 step time: 0.2014\n",
      "6/8, train_loss: 0.0154 step time: 0.2018\n",
      "7/8, train_loss: 0.0116 step time: 0.1842\n",
      "8/8, train_loss: 0.0139 step time: 0.1822\n",
      "epoch 262 average loss: 0.0148\n",
      "time consuming of epoch 262 is: 1.6144\n",
      "----------\n",
      "epoch 263/600\n",
      "1/8, train_loss: 0.0162 step time: 0.2400\n",
      "2/8, train_loss: 0.0142 step time: 0.2034\n",
      "3/8, train_loss: 0.0141 step time: 0.1996\n",
      "4/8, train_loss: 0.0169 step time: 0.2000\n",
      "5/8, train_loss: 0.0147 step time: 0.1989\n",
      "6/8, train_loss: 0.0139 step time: 0.2010\n",
      "7/8, train_loss: 0.0145 step time: 0.1825\n",
      "8/8, train_loss: 0.0123 step time: 0.1816\n",
      "epoch 263 average loss: 0.0146\n",
      "time consuming of epoch 263 is: 1.6088\n",
      "----------\n",
      "epoch 264/600\n",
      "1/8, train_loss: 0.0141 step time: 0.2391\n",
      "2/8, train_loss: 0.0116 step time: 0.2029\n",
      "3/8, train_loss: 0.0158 step time: 0.1997\n",
      "4/8, train_loss: 0.0117 step time: 0.2018\n",
      "5/8, train_loss: 0.0130 step time: 0.2025\n",
      "6/8, train_loss: 0.0149 step time: 0.2019\n",
      "7/8, train_loss: 0.0131 step time: 0.1821\n",
      "8/8, train_loss: 0.0143 step time: 0.1823\n",
      "epoch 264 average loss: 0.0136\n",
      "time consuming of epoch 264 is: 1.6137\n",
      "----------\n",
      "epoch 265/600\n",
      "1/8, train_loss: 0.0141 step time: 0.2372\n",
      "2/8, train_loss: 0.0129 step time: 0.2017\n",
      "3/8, train_loss: 0.0123 step time: 0.2047\n",
      "4/8, train_loss: 0.0130 step time: 0.2005\n",
      "5/8, train_loss: 0.0136 step time: 0.2024\n",
      "6/8, train_loss: 0.0164 step time: 0.2004\n",
      "7/8, train_loss: 0.0152 step time: 0.1832\n",
      "8/8, train_loss: 0.0143 step time: 0.1830\n",
      "epoch 265 average loss: 0.0140\n",
      "current epoch: 265 current mean dice: 0.9559 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 265 is: 2.3711\n",
      "----------\n",
      "epoch 266/600\n",
      "1/8, train_loss: 0.0167 step time: 0.2388\n",
      "2/8, train_loss: 0.0162 step time: 0.2005\n",
      "3/8, train_loss: 0.0120 step time: 0.2003\n",
      "4/8, train_loss: 0.0140 step time: 0.1992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8, train_loss: 0.0135 step time: 0.1990\n",
      "6/8, train_loss: 0.0121 step time: 0.1982\n",
      "7/8, train_loss: 0.0153 step time: 0.1816\n",
      "8/8, train_loss: 0.0188 step time: 0.1815\n",
      "epoch 266 average loss: 0.0148\n",
      "time consuming of epoch 266 is: 1.6001\n",
      "----------\n",
      "epoch 267/600\n",
      "1/8, train_loss: 0.0132 step time: 0.2412\n",
      "2/8, train_loss: 0.0146 step time: 0.2041\n",
      "3/8, train_loss: 0.0173 step time: 0.1947\n",
      "4/8, train_loss: 0.0121 step time: 0.1969\n",
      "5/8, train_loss: 0.0135 step time: 0.1978\n",
      "6/8, train_loss: 0.0170 step time: 0.2058\n",
      "7/8, train_loss: 0.0144 step time: 0.1822\n",
      "8/8, train_loss: 0.0138 step time: 0.1835\n",
      "epoch 267 average loss: 0.0145\n",
      "time consuming of epoch 267 is: 1.6076\n",
      "----------\n",
      "epoch 268/600\n",
      "1/8, train_loss: 0.0138 step time: 0.2341\n",
      "2/8, train_loss: 0.0127 step time: 0.1941\n",
      "3/8, train_loss: 0.0118 step time: 0.1973\n",
      "4/8, train_loss: 0.0140 step time: 0.2030\n",
      "5/8, train_loss: 0.0164 step time: 0.2033\n",
      "6/8, train_loss: 0.0145 step time: 0.2023\n",
      "7/8, train_loss: 0.0141 step time: 0.1826\n",
      "8/8, train_loss: 0.0159 step time: 0.1797\n",
      "epoch 268 average loss: 0.0142\n",
      "time consuming of epoch 268 is: 1.5978\n",
      "----------\n",
      "epoch 269/600\n",
      "1/8, train_loss: 0.0143 step time: 0.2354\n",
      "2/8, train_loss: 0.0153 step time: 0.1953\n",
      "3/8, train_loss: 0.0137 step time: 0.1982\n",
      "4/8, train_loss: 0.0135 step time: 0.1991\n",
      "5/8, train_loss: 0.0142 step time: 0.1991\n",
      "6/8, train_loss: 0.0117 step time: 0.1978\n",
      "7/8, train_loss: 0.0138 step time: 0.1796\n",
      "8/8, train_loss: 0.0158 step time: 0.1797\n",
      "epoch 269 average loss: 0.0140\n",
      "time consuming of epoch 269 is: 1.5852\n",
      "----------\n",
      "epoch 270/600\n",
      "1/8, train_loss: 0.0148 step time: 0.2382\n",
      "2/8, train_loss: 0.0138 step time: 0.1952\n",
      "3/8, train_loss: 0.0128 step time: 0.1978\n",
      "4/8, train_loss: 0.0155 step time: 0.1965\n",
      "5/8, train_loss: 0.0145 step time: 0.1974\n",
      "6/8, train_loss: 0.0142 step time: 0.1977\n",
      "7/8, train_loss: 0.0137 step time: 0.1796\n",
      "8/8, train_loss: 0.0149 step time: 0.1794\n",
      "epoch 270 average loss: 0.0143\n",
      "current epoch: 270 current mean dice: 0.9561 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 270 is: 2.3355\n",
      "----------\n",
      "epoch 271/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2358\n",
      "2/8, train_loss: 0.0142 step time: 0.1955\n",
      "3/8, train_loss: 0.0152 step time: 0.1995\n",
      "4/8, train_loss: 0.0159 step time: 0.1991\n",
      "5/8, train_loss: 0.0139 step time: 0.1991\n",
      "6/8, train_loss: 0.0157 step time: 0.1953\n",
      "7/8, train_loss: 0.0112 step time: 0.1796\n",
      "8/8, train_loss: 0.0145 step time: 0.1796\n",
      "epoch 271 average loss: 0.0145\n",
      "time consuming of epoch 271 is: 1.5845\n",
      "----------\n",
      "epoch 272/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2357\n",
      "2/8, train_loss: 0.0158 step time: 0.1950\n",
      "3/8, train_loss: 0.0164 step time: 0.1988\n",
      "4/8, train_loss: 0.0136 step time: 0.2040\n",
      "5/8, train_loss: 0.0146 step time: 0.1993\n",
      "6/8, train_loss: 0.0139 step time: 0.2006\n",
      "7/8, train_loss: 0.0133 step time: 0.1839\n",
      "8/8, train_loss: 0.0142 step time: 0.1844\n",
      "epoch 272 average loss: 0.0146\n",
      "time consuming of epoch 272 is: 1.6028\n",
      "----------\n",
      "epoch 273/600\n",
      "1/8, train_loss: 0.0153 step time: 0.2412\n",
      "2/8, train_loss: 0.0151 step time: 0.2021\n",
      "3/8, train_loss: 0.0131 step time: 0.2004\n",
      "4/8, train_loss: 0.0147 step time: 0.1992\n",
      "5/8, train_loss: 0.0154 step time: 0.2012\n",
      "6/8, train_loss: 0.0143 step time: 0.2021\n",
      "7/8, train_loss: 0.0117 step time: 0.1843\n",
      "8/8, train_loss: 0.0162 step time: 0.1834\n",
      "epoch 273 average loss: 0.0145\n",
      "time consuming of epoch 273 is: 1.6153\n",
      "----------\n",
      "epoch 274/600\n",
      "1/8, train_loss: 0.0143 step time: 0.2418\n",
      "2/8, train_loss: 0.0127 step time: 0.2048\n",
      "3/8, train_loss: 0.0148 step time: 0.1989\n",
      "4/8, train_loss: 0.0129 step time: 0.2012\n",
      "5/8, train_loss: 0.0128 step time: 0.2070\n",
      "6/8, train_loss: 0.0163 step time: 0.2024\n",
      "7/8, train_loss: 0.0132 step time: 0.1830\n",
      "8/8, train_loss: 0.0144 step time: 0.1831\n",
      "epoch 274 average loss: 0.0139\n",
      "time consuming of epoch 274 is: 1.6236\n",
      "----------\n",
      "epoch 275/600\n",
      "1/8, train_loss: 0.0142 step time: 0.2387\n",
      "2/8, train_loss: 0.0125 step time: 0.2033\n",
      "3/8, train_loss: 0.0142 step time: 0.2026\n",
      "4/8, train_loss: 0.0141 step time: 0.2024\n",
      "5/8, train_loss: 0.0144 step time: 0.2031\n",
      "6/8, train_loss: 0.0147 step time: 0.2045\n",
      "7/8, train_loss: 0.0135 step time: 0.1824\n",
      "8/8, train_loss: 0.0130 step time: 0.1826\n",
      "epoch 275 average loss: 0.0138\n",
      "current epoch: 275 current mean dice: 0.9567 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 275 is: 2.3764\n",
      "----------\n",
      "epoch 276/600\n",
      "1/8, train_loss: 0.0126 step time: 0.2364\n",
      "2/8, train_loss: 0.0124 step time: 0.1982\n",
      "3/8, train_loss: 0.0141 step time: 0.2016\n",
      "4/8, train_loss: 0.0155 step time: 0.1995\n",
      "5/8, train_loss: 0.0135 step time: 0.2002\n",
      "6/8, train_loss: 0.0153 step time: 0.1983\n",
      "7/8, train_loss: 0.0123 step time: 0.1813\n",
      "8/8, train_loss: 0.0157 step time: 0.1810\n",
      "epoch 276 average loss: 0.0139\n",
      "time consuming of epoch 276 is: 1.5976\n",
      "----------\n",
      "epoch 277/600\n",
      "1/8, train_loss: 0.0148 step time: 0.2379\n",
      "2/8, train_loss: 0.0146 step time: 0.2020\n",
      "3/8, train_loss: 0.0119 step time: 0.2024\n",
      "4/8, train_loss: 0.0178 step time: 0.2017\n",
      "5/8, train_loss: 0.0132 step time: 0.2011\n",
      "6/8, train_loss: 0.0137 step time: 0.2004\n",
      "7/8, train_loss: 0.0134 step time: 0.1846\n",
      "8/8, train_loss: 0.0133 step time: 0.1832\n",
      "epoch 277 average loss: 0.0141\n",
      "time consuming of epoch 277 is: 1.6145\n",
      "----------\n",
      "epoch 278/600\n",
      "1/8, train_loss: 0.0139 step time: 0.2413\n",
      "2/8, train_loss: 0.0123 step time: 0.2026\n",
      "3/8, train_loss: 0.0133 step time: 0.2031\n",
      "4/8, train_loss: 0.0149 step time: 0.1976\n",
      "5/8, train_loss: 0.0128 step time: 0.2042\n",
      "6/8, train_loss: 0.0153 step time: 0.1981\n",
      "7/8, train_loss: 0.0129 step time: 0.1836\n",
      "8/8, train_loss: 0.0149 step time: 0.1821\n",
      "epoch 278 average loss: 0.0138\n",
      "time consuming of epoch 278 is: 1.6144\n",
      "----------\n",
      "epoch 279/600\n",
      "1/8, train_loss: 0.0134 step time: 0.2407\n",
      "2/8, train_loss: 0.0141 step time: 0.2033\n",
      "3/8, train_loss: 0.0170 step time: 0.2003\n",
      "4/8, train_loss: 0.0152 step time: 0.2026\n",
      "5/8, train_loss: 0.0144 step time: 0.1994\n",
      "6/8, train_loss: 0.0129 step time: 0.2010\n",
      "7/8, train_loss: 0.0146 step time: 0.1840\n",
      "8/8, train_loss: 0.0134 step time: 0.1825\n",
      "epoch 279 average loss: 0.0144\n",
      "time consuming of epoch 279 is: 1.6150\n",
      "----------\n",
      "epoch 280/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2427\n",
      "2/8, train_loss: 0.0134 step time: 0.2026\n",
      "3/8, train_loss: 0.0136 step time: 0.2003\n",
      "4/8, train_loss: 0.0140 step time: 0.2002\n",
      "5/8, train_loss: 0.0109 step time: 0.1989\n",
      "6/8, train_loss: 0.0136 step time: 0.2011\n",
      "7/8, train_loss: 0.0160 step time: 0.1821\n",
      "8/8, train_loss: 0.0139 step time: 0.1817\n",
      "epoch 280 average loss: 0.0136\n",
      "current epoch: 280 current mean dice: 0.9540 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 280 is: 2.3671\n",
      "----------\n",
      "epoch 281/600\n",
      "1/8, train_loss: 0.0140 step time: 0.2367\n",
      "2/8, train_loss: 0.0152 step time: 0.1971\n",
      "3/8, train_loss: 0.0116 step time: 0.2008\n",
      "4/8, train_loss: 0.0140 step time: 0.2003\n",
      "5/8, train_loss: 0.0170 step time: 0.2100\n",
      "6/8, train_loss: 0.0131 step time: 0.2039\n",
      "7/8, train_loss: 0.0163 step time: 0.1844\n",
      "8/8, train_loss: 0.0143 step time: 0.1842\n",
      "epoch 281 average loss: 0.0144\n",
      "time consuming of epoch 281 is: 1.6185\n",
      "----------\n",
      "epoch 282/600\n",
      "1/8, train_loss: 0.0158 step time: 0.2340\n",
      "2/8, train_loss: 0.0151 step time: 0.2019\n",
      "3/8, train_loss: 0.0138 step time: 0.2018\n",
      "4/8, train_loss: 0.0165 step time: 0.1982\n",
      "5/8, train_loss: 0.0152 step time: 0.1955\n",
      "6/8, train_loss: 0.0151 step time: 0.1951\n",
      "7/8, train_loss: 0.0138 step time: 0.1820\n",
      "8/8, train_loss: 0.0135 step time: 0.1830\n",
      "epoch 282 average loss: 0.0148\n",
      "time consuming of epoch 282 is: 1.5929\n",
      "----------\n",
      "epoch 283/600\n",
      "1/8, train_loss: 0.0160 step time: 0.2335\n",
      "2/8, train_loss: 0.0152 step time: 0.1996\n",
      "3/8, train_loss: 0.0134 step time: 0.1968\n",
      "4/8, train_loss: 0.0126 step time: 0.1954\n",
      "5/8, train_loss: 0.0174 step time: 0.1980\n",
      "6/8, train_loss: 0.0146 step time: 0.2014\n",
      "7/8, train_loss: 0.0134 step time: 0.1853\n",
      "8/8, train_loss: 0.0131 step time: 0.1836\n",
      "epoch 283 average loss: 0.0145\n",
      "time consuming of epoch 283 is: 1.5952\n",
      "----------\n",
      "epoch 284/600\n",
      "1/8, train_loss: 0.0171 step time: 0.2422\n",
      "2/8, train_loss: 0.0137 step time: 0.2056\n",
      "3/8, train_loss: 0.0129 step time: 0.2047\n",
      "4/8, train_loss: 0.0137 step time: 0.1993\n",
      "5/8, train_loss: 0.0150 step time: 0.2015\n",
      "6/8, train_loss: 0.0119 step time: 0.2045\n",
      "7/8, train_loss: 0.0126 step time: 0.1834\n",
      "8/8, train_loss: 0.0152 step time: 0.1837\n",
      "epoch 284 average loss: 0.0140\n",
      "time consuming of epoch 284 is: 1.6264\n",
      "----------\n",
      "epoch 285/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0114 step time: 0.2402\n",
      "2/8, train_loss: 0.0167 step time: 0.2046\n",
      "3/8, train_loss: 0.0147 step time: 0.2018\n",
      "4/8, train_loss: 0.0121 step time: 0.2032\n",
      "5/8, train_loss: 0.0134 step time: 0.2153\n",
      "6/8, train_loss: 0.0124 step time: 0.2024\n",
      "7/8, train_loss: 0.0146 step time: 0.1845\n",
      "8/8, train_loss: 0.0148 step time: 0.1825\n",
      "epoch 285 average loss: 0.0138\n",
      "current epoch: 285 current mean dice: 0.9548 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 285 is: 2.3913\n",
      "----------\n",
      "epoch 286/600\n",
      "1/8, train_loss: 0.0106 step time: 0.2381\n",
      "2/8, train_loss: 0.0144 step time: 0.1990\n",
      "3/8, train_loss: 0.0150 step time: 0.2000\n",
      "4/8, train_loss: 0.0130 step time: 0.1983\n",
      "5/8, train_loss: 0.0132 step time: 0.1993\n",
      "6/8, train_loss: 0.0121 step time: 0.2003\n",
      "7/8, train_loss: 0.0138 step time: 0.1825\n",
      "8/8, train_loss: 0.0149 step time: 0.1838\n",
      "epoch 286 average loss: 0.0134\n",
      "time consuming of epoch 286 is: 1.6026\n",
      "----------\n",
      "epoch 287/600\n",
      "1/8, train_loss: 0.0163 step time: 0.2413\n",
      "2/8, train_loss: 0.0169 step time: 0.1974\n",
      "3/8, train_loss: 0.0126 step time: 0.2003\n",
      "4/8, train_loss: 0.0139 step time: 0.1972\n",
      "5/8, train_loss: 0.0116 step time: 0.1989\n",
      "6/8, train_loss: 0.0148 step time: 0.2014\n",
      "7/8, train_loss: 0.0141 step time: 0.1826\n",
      "8/8, train_loss: 0.0116 step time: 0.1832\n",
      "epoch 287 average loss: 0.0140\n",
      "time consuming of epoch 287 is: 1.6036\n",
      "----------\n",
      "epoch 288/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2459\n",
      "2/8, train_loss: 0.0163 step time: 0.1973\n",
      "3/8, train_loss: 0.0145 step time: 0.2063\n",
      "4/8, train_loss: 0.0157 step time: 0.2019\n",
      "5/8, train_loss: 0.0147 step time: 0.1991\n",
      "6/8, train_loss: 0.0115 step time: 0.2016\n",
      "7/8, train_loss: 0.0111 step time: 0.1824\n",
      "8/8, train_loss: 0.0145 step time: 0.1810\n",
      "epoch 288 average loss: 0.0138\n",
      "time consuming of epoch 288 is: 1.6167\n",
      "----------\n",
      "epoch 289/600\n",
      "1/8, train_loss: 0.0144 step time: 0.2353\n",
      "2/8, train_loss: 0.0119 step time: 0.2009\n",
      "3/8, train_loss: 0.0152 step time: 0.1992\n",
      "4/8, train_loss: 0.0143 step time: 0.1996\n",
      "5/8, train_loss: 0.0141 step time: 0.1974\n",
      "6/8, train_loss: 0.0115 step time: 0.2007\n",
      "7/8, train_loss: 0.0128 step time: 0.1827\n",
      "8/8, train_loss: 0.0153 step time: 0.1822\n",
      "epoch 289 average loss: 0.0137\n",
      "time consuming of epoch 289 is: 1.5994\n",
      "----------\n",
      "epoch 290/600\n",
      "1/8, train_loss: 0.0122 step time: 0.2412\n",
      "2/8, train_loss: 0.0122 step time: 0.2009\n",
      "3/8, train_loss: 0.0159 step time: 0.1992\n",
      "4/8, train_loss: 0.0143 step time: 0.1991\n",
      "5/8, train_loss: 0.0138 step time: 0.1994\n",
      "6/8, train_loss: 0.0153 step time: 0.2004\n",
      "7/8, train_loss: 0.0148 step time: 0.1825\n",
      "8/8, train_loss: 0.0134 step time: 0.1827\n",
      "epoch 290 average loss: 0.0140\n",
      "current epoch: 290 current mean dice: 0.9568 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 290 is: 2.3623\n",
      "----------\n",
      "epoch 291/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2368\n",
      "2/8, train_loss: 0.0148 step time: 0.1996\n",
      "3/8, train_loss: 0.0173 step time: 0.1997\n",
      "4/8, train_loss: 0.0139 step time: 0.2020\n",
      "5/8, train_loss: 0.0115 step time: 0.2029\n",
      "6/8, train_loss: 0.0143 step time: 0.1991\n",
      "7/8, train_loss: 0.0148 step time: 0.1816\n",
      "8/8, train_loss: 0.0132 step time: 0.1813\n",
      "epoch 291 average loss: 0.0142\n",
      "time consuming of epoch 291 is: 1.6041\n",
      "----------\n",
      "epoch 292/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2403\n",
      "2/8, train_loss: 0.0151 step time: 0.1984\n",
      "3/8, train_loss: 0.0154 step time: 0.2011\n",
      "4/8, train_loss: 0.0134 step time: 0.2042\n",
      "5/8, train_loss: 0.0169 step time: 0.2012\n",
      "6/8, train_loss: 0.0138 step time: 0.1992\n",
      "7/8, train_loss: 0.0110 step time: 0.1832\n",
      "8/8, train_loss: 0.0109 step time: 0.1838\n",
      "epoch 292 average loss: 0.0136\n",
      "time consuming of epoch 292 is: 1.6128\n",
      "----------\n",
      "epoch 293/600\n",
      "1/8, train_loss: 0.0167 step time: 0.2405\n",
      "2/8, train_loss: 0.0137 step time: 0.1992\n",
      "3/8, train_loss: 0.0153 step time: 0.2010\n",
      "4/8, train_loss: 0.0135 step time: 0.1989\n",
      "5/8, train_loss: 0.0114 step time: 0.2037\n",
      "6/8, train_loss: 0.0128 step time: 0.2023\n",
      "7/8, train_loss: 0.0125 step time: 0.1828\n",
      "8/8, train_loss: 0.0124 step time: 0.1827\n",
      "epoch 293 average loss: 0.0135\n",
      "time consuming of epoch 293 is: 1.6124\n",
      "----------\n",
      "epoch 294/600\n",
      "1/8, train_loss: 0.0133 step time: 0.2403\n",
      "2/8, train_loss: 0.0131 step time: 0.2025\n",
      "3/8, train_loss: 0.0137 step time: 0.1995\n",
      "4/8, train_loss: 0.0141 step time: 0.2002\n",
      "5/8, train_loss: 0.0126 step time: 0.2018\n",
      "6/8, train_loss: 0.0161 step time: 0.2015\n",
      "7/8, train_loss: 0.0151 step time: 0.1840\n",
      "8/8, train_loss: 0.0130 step time: 0.1824\n",
      "epoch 294 average loss: 0.0139\n",
      "time consuming of epoch 294 is: 1.6137\n",
      "----------\n",
      "epoch 295/600\n",
      "1/8, train_loss: 0.0156 step time: 0.2420\n",
      "2/8, train_loss: 0.0147 step time: 0.2030\n",
      "3/8, train_loss: 0.0142 step time: 0.1999\n",
      "4/8, train_loss: 0.0156 step time: 0.2015\n",
      "5/8, train_loss: 0.0118 step time: 0.1999\n",
      "6/8, train_loss: 0.0139 step time: 0.1996\n",
      "7/8, train_loss: 0.0143 step time: 0.1814\n",
      "8/8, train_loss: 0.0136 step time: 0.1823\n",
      "epoch 295 average loss: 0.0142\n",
      "current epoch: 295 current mean dice: 0.9562 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 295 is: 2.3675\n",
      "----------\n",
      "epoch 296/600\n",
      "1/8, train_loss: 0.0150 step time: 0.2380\n",
      "2/8, train_loss: 0.0149 step time: 0.1993\n",
      "3/8, train_loss: 0.0134 step time: 0.1995\n",
      "4/8, train_loss: 0.0147 step time: 0.2051\n",
      "5/8, train_loss: 0.0125 step time: 0.1989\n",
      "6/8, train_loss: 0.0139 step time: 0.2033\n",
      "7/8, train_loss: 0.0138 step time: 0.1854\n",
      "8/8, train_loss: 0.0127 step time: 0.1828\n",
      "epoch 296 average loss: 0.0139\n",
      "time consuming of epoch 296 is: 1.6134\n",
      "----------\n",
      "epoch 297/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2412\n",
      "2/8, train_loss: 0.0142 step time: 0.2001\n",
      "3/8, train_loss: 0.0154 step time: 0.2024\n",
      "4/8, train_loss: 0.0130 step time: 0.2027\n",
      "5/8, train_loss: 0.0130 step time: 0.2073\n",
      "6/8, train_loss: 0.0153 step time: 0.2065\n",
      "7/8, train_loss: 0.0126 step time: 0.1829\n",
      "8/8, train_loss: 0.0134 step time: 0.1821\n",
      "epoch 297 average loss: 0.0138\n",
      "time consuming of epoch 297 is: 1.6267\n",
      "----------\n",
      "epoch 298/600\n",
      "1/8, train_loss: 0.0133 step time: 0.2429\n",
      "2/8, train_loss: 0.0147 step time: 0.2021\n",
      "3/8, train_loss: 0.0135 step time: 0.2010\n",
      "4/8, train_loss: 0.0122 step time: 0.1980\n",
      "5/8, train_loss: 0.0140 step time: 0.1988\n",
      "6/8, train_loss: 0.0124 step time: 0.2001\n",
      "7/8, train_loss: 0.0144 step time: 0.1833\n",
      "8/8, train_loss: 0.0139 step time: 0.1819\n",
      "epoch 298 average loss: 0.0135\n",
      "time consuming of epoch 298 is: 1.6098\n",
      "----------\n",
      "epoch 299/600\n",
      "1/8, train_loss: 0.0156 step time: 0.2394\n",
      "2/8, train_loss: 0.0102 step time: 0.2068\n",
      "3/8, train_loss: 0.0128 step time: 0.2001\n",
      "4/8, train_loss: 0.0141 step time: 0.1993\n",
      "5/8, train_loss: 0.0148 step time: 0.1986\n",
      "6/8, train_loss: 0.0153 step time: 0.2059\n",
      "7/8, train_loss: 0.0126 step time: 0.1821\n",
      "8/8, train_loss: 0.0154 step time: 0.1818\n",
      "epoch 299 average loss: 0.0139\n",
      "time consuming of epoch 299 is: 1.6154\n",
      "----------\n",
      "epoch 300/600\n",
      "1/8, train_loss: 0.0103 step time: 0.2402\n",
      "2/8, train_loss: 0.0158 step time: 0.2033\n",
      "3/8, train_loss: 0.0138 step time: 0.1976\n",
      "4/8, train_loss: 0.0159 step time: 0.2001\n",
      "5/8, train_loss: 0.0134 step time: 0.1990\n",
      "6/8, train_loss: 0.0127 step time: 0.1995\n",
      "7/8, train_loss: 0.0129 step time: 0.1815\n",
      "8/8, train_loss: 0.0132 step time: 0.1813\n",
      "epoch 300 average loss: 0.0135\n",
      "current epoch: 300 current mean dice: 0.9563 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 300 is: 2.3587\n",
      "----------\n",
      "epoch 301/600\n",
      "1/8, train_loss: 0.0126 step time: 0.2389\n",
      "2/8, train_loss: 0.0153 step time: 0.2020\n",
      "3/8, train_loss: 0.0120 step time: 0.1986\n",
      "4/8, train_loss: 0.0138 step time: 0.2041\n",
      "5/8, train_loss: 0.0135 step time: 0.2048\n",
      "6/8, train_loss: 0.0148 step time: 0.2030\n",
      "7/8, train_loss: 0.0163 step time: 0.1826\n",
      "8/8, train_loss: 0.0134 step time: 0.1841\n",
      "epoch 301 average loss: 0.0140\n",
      "time consuming of epoch 301 is: 1.6192\n",
      "----------\n",
      "epoch 302/600\n",
      "1/8, train_loss: 0.0139 step time: 0.2416\n",
      "2/8, train_loss: 0.0106 step time: 0.2038\n",
      "3/8, train_loss: 0.0139 step time: 0.2002\n",
      "4/8, train_loss: 0.0144 step time: 0.2004\n",
      "5/8, train_loss: 0.0148 step time: 0.2003\n",
      "6/8, train_loss: 0.0149 step time: 0.2030\n",
      "7/8, train_loss: 0.0132 step time: 0.1823\n",
      "8/8, train_loss: 0.0157 step time: 0.1818\n",
      "epoch 302 average loss: 0.0139\n",
      "time consuming of epoch 302 is: 1.6147\n",
      "----------\n",
      "epoch 303/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2404\n",
      "2/8, train_loss: 0.0131 step time: 0.2014\n",
      "3/8, train_loss: 0.0156 step time: 0.2027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/8, train_loss: 0.0129 step time: 0.2013\n",
      "5/8, train_loss: 0.0121 step time: 0.1991\n",
      "6/8, train_loss: 0.0152 step time: 0.1988\n",
      "7/8, train_loss: 0.0150 step time: 0.1823\n",
      "8/8, train_loss: 0.0128 step time: 0.1814\n",
      "epoch 303 average loss: 0.0137\n",
      "time consuming of epoch 303 is: 1.6085\n",
      "----------\n",
      "epoch 304/600\n",
      "1/8, train_loss: 0.0111 step time: 0.2343\n",
      "2/8, train_loss: 0.0145 step time: 0.1970\n",
      "3/8, train_loss: 0.0132 step time: 0.1985\n",
      "4/8, train_loss: 0.0119 step time: 0.1956\n",
      "5/8, train_loss: 0.0144 step time: 0.1983\n",
      "6/8, train_loss: 0.0174 step time: 0.1930\n",
      "7/8, train_loss: 0.0152 step time: 0.1825\n",
      "8/8, train_loss: 0.0154 step time: 0.1827\n",
      "epoch 304 average loss: 0.0141\n",
      "time consuming of epoch 304 is: 1.5834\n",
      "----------\n",
      "epoch 305/600\n",
      "1/8, train_loss: 0.0109 step time: 0.2318\n",
      "2/8, train_loss: 0.0142 step time: 0.1997\n",
      "3/8, train_loss: 0.0133 step time: 0.1974\n",
      "4/8, train_loss: 0.0121 step time: 0.1974\n",
      "5/8, train_loss: 0.0125 step time: 0.1982\n",
      "6/8, train_loss: 0.0145 step time: 0.1975\n",
      "7/8, train_loss: 0.0136 step time: 0.1837\n",
      "8/8, train_loss: 0.0134 step time: 0.1820\n",
      "epoch 305 average loss: 0.0131\n",
      "current epoch: 305 current mean dice: 0.9561 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 305 is: 2.3445\n",
      "----------\n",
      "epoch 306/600\n",
      "1/8, train_loss: 0.0119 step time: 0.2348\n",
      "2/8, train_loss: 0.0130 step time: 0.1970\n",
      "3/8, train_loss: 0.0114 step time: 0.1997\n",
      "4/8, train_loss: 0.0130 step time: 0.1984\n",
      "5/8, train_loss: 0.0136 step time: 0.2005\n",
      "6/8, train_loss: 0.0149 step time: 0.1987\n",
      "7/8, train_loss: 0.0156 step time: 0.1814\n",
      "8/8, train_loss: 0.0123 step time: 0.1837\n",
      "epoch 306 average loss: 0.0132\n",
      "time consuming of epoch 306 is: 1.5953\n",
      "----------\n",
      "epoch 307/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2393\n",
      "2/8, train_loss: 0.0144 step time: 0.2026\n",
      "3/8, train_loss: 0.0126 step time: 0.1994\n",
      "4/8, train_loss: 0.0106 step time: 0.1997\n",
      "5/8, train_loss: 0.0140 step time: 0.2005\n",
      "6/8, train_loss: 0.0147 step time: 0.2012\n",
      "7/8, train_loss: 0.0149 step time: 0.1821\n",
      "8/8, train_loss: 0.0132 step time: 0.1831\n",
      "epoch 307 average loss: 0.0134\n",
      "time consuming of epoch 307 is: 1.6094\n",
      "----------\n",
      "epoch 308/600\n",
      "1/8, train_loss: 0.0119 step time: 0.2366\n",
      "2/8, train_loss: 0.0143 step time: 0.2018\n",
      "3/8, train_loss: 0.0143 step time: 0.1998\n",
      "4/8, train_loss: 0.0144 step time: 0.1990\n",
      "5/8, train_loss: 0.0147 step time: 0.2002\n",
      "6/8, train_loss: 0.0107 step time: 0.1968\n",
      "7/8, train_loss: 0.0128 step time: 0.1822\n",
      "8/8, train_loss: 0.0140 step time: 0.1822\n",
      "epoch 308 average loss: 0.0134\n",
      "time consuming of epoch 308 is: 1.6000\n",
      "----------\n",
      "epoch 309/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2360\n",
      "2/8, train_loss: 0.0117 step time: 0.1994\n",
      "3/8, train_loss: 0.0142 step time: 0.2030\n",
      "4/8, train_loss: 0.0158 step time: 0.1985\n",
      "5/8, train_loss: 0.0127 step time: 0.1994\n",
      "6/8, train_loss: 0.0129 step time: 0.2025\n",
      "7/8, train_loss: 0.0137 step time: 0.1828\n",
      "8/8, train_loss: 0.0144 step time: 0.1818\n",
      "epoch 309 average loss: 0.0135\n",
      "time consuming of epoch 309 is: 1.6049\n",
      "----------\n",
      "epoch 310/600\n",
      "1/8, train_loss: 0.0159 step time: 0.2426\n",
      "2/8, train_loss: 0.0139 step time: 0.2050\n",
      "3/8, train_loss: 0.0153 step time: 0.2014\n",
      "4/8, train_loss: 0.0132 step time: 0.2002\n",
      "5/8, train_loss: 0.0136 step time: 0.2011\n",
      "6/8, train_loss: 0.0119 step time: 0.2013\n",
      "7/8, train_loss: 0.0127 step time: 0.1842\n",
      "8/8, train_loss: 0.0127 step time: 0.1827\n",
      "epoch 310 average loss: 0.0136\n",
      "current epoch: 310 current mean dice: 0.9558 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 310 is: 2.3759\n",
      "----------\n",
      "epoch 311/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2378\n",
      "2/8, train_loss: 0.0102 step time: 0.1978\n",
      "3/8, train_loss: 0.0134 step time: 0.1981\n",
      "4/8, train_loss: 0.0138 step time: 0.2014\n",
      "5/8, train_loss: 0.0134 step time: 0.2001\n",
      "6/8, train_loss: 0.0150 step time: 0.2017\n",
      "7/8, train_loss: 0.0153 step time: 0.1815\n",
      "8/8, train_loss: 0.0136 step time: 0.1814\n",
      "epoch 311 average loss: 0.0137\n",
      "time consuming of epoch 311 is: 1.6010\n",
      "----------\n",
      "epoch 312/600\n",
      "1/8, train_loss: 0.0142 step time: 0.2358\n",
      "2/8, train_loss: 0.0145 step time: 0.1996\n",
      "3/8, train_loss: 0.0143 step time: 0.2018\n",
      "4/8, train_loss: 0.0146 step time: 0.1979\n",
      "5/8, train_loss: 0.0149 step time: 0.1985\n",
      "6/8, train_loss: 0.0131 step time: 0.1999\n",
      "7/8, train_loss: 0.0147 step time: 0.1847\n",
      "8/8, train_loss: 0.0113 step time: 0.1823\n",
      "epoch 312 average loss: 0.0140\n",
      "time consuming of epoch 312 is: 1.6019\n",
      "----------\n",
      "epoch 313/600\n",
      "1/8, train_loss: 0.0113 step time: 0.2403\n",
      "2/8, train_loss: 0.0129 step time: 0.1998\n",
      "3/8, train_loss: 0.0141 step time: 0.2020\n",
      "4/8, train_loss: 0.0141 step time: 0.2003\n",
      "5/8, train_loss: 0.0151 step time: 0.2028\n",
      "6/8, train_loss: 0.0132 step time: 0.1992\n",
      "7/8, train_loss: 0.0122 step time: 0.1828\n",
      "8/8, train_loss: 0.0151 step time: 0.1830\n",
      "epoch 313 average loss: 0.0135\n",
      "time consuming of epoch 313 is: 1.6118\n",
      "----------\n",
      "epoch 314/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2390\n",
      "2/8, train_loss: 0.0172 step time: 0.2035\n",
      "3/8, train_loss: 0.0117 step time: 0.2005\n",
      "4/8, train_loss: 0.0137 step time: 0.1993\n",
      "5/8, train_loss: 0.0140 step time: 0.1999\n",
      "6/8, train_loss: 0.0134 step time: 0.2001\n",
      "7/8, train_loss: 0.0135 step time: 0.1815\n",
      "8/8, train_loss: 0.0130 step time: 0.1819\n",
      "epoch 314 average loss: 0.0136\n",
      "time consuming of epoch 314 is: 1.6071\n",
      "----------\n",
      "epoch 315/600\n",
      "1/8, train_loss: 0.0133 step time: 0.2364\n",
      "2/8, train_loss: 0.0162 step time: 0.1993\n",
      "3/8, train_loss: 0.0114 step time: 0.2007\n",
      "4/8, train_loss: 0.0142 step time: 0.2005\n",
      "5/8, train_loss: 0.0125 step time: 0.2003\n",
      "6/8, train_loss: 0.0140 step time: 0.2048\n",
      "7/8, train_loss: 0.0125 step time: 0.1837\n",
      "8/8, train_loss: 0.0128 step time: 0.1847\n",
      "epoch 315 average loss: 0.0134\n",
      "current epoch: 315 current mean dice: 0.9571 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 315 is: 2.3679\n",
      "----------\n",
      "epoch 316/600\n",
      "1/8, train_loss: 0.0139 step time: 0.2378\n",
      "2/8, train_loss: 0.0120 step time: 0.1958\n",
      "3/8, train_loss: 0.0156 step time: 0.1944\n",
      "4/8, train_loss: 0.0163 step time: 0.1943\n",
      "5/8, train_loss: 0.0105 step time: 0.1971\n",
      "6/8, train_loss: 0.0122 step time: 0.1956\n",
      "7/8, train_loss: 0.0121 step time: 0.1850\n",
      "8/8, train_loss: 0.0153 step time: 0.1828\n",
      "epoch 316 average loss: 0.0135\n",
      "time consuming of epoch 316 is: 1.5839\n",
      "----------\n",
      "epoch 317/600\n",
      "1/8, train_loss: 0.0129 step time: 0.2414\n",
      "2/8, train_loss: 0.0123 step time: 0.2031\n",
      "3/8, train_loss: 0.0157 step time: 0.2039\n",
      "4/8, train_loss: 0.0138 step time: 0.2072\n",
      "5/8, train_loss: 0.0137 step time: 0.2004\n",
      "6/8, train_loss: 0.0131 step time: 0.2019\n",
      "7/8, train_loss: 0.0123 step time: 0.1825\n",
      "8/8, train_loss: 0.0137 step time: 0.1821\n",
      "epoch 317 average loss: 0.0134\n",
      "time consuming of epoch 317 is: 1.6242\n",
      "----------\n",
      "epoch 318/600\n",
      "1/8, train_loss: 0.0169 step time: 0.2397\n",
      "2/8, train_loss: 0.0137 step time: 0.2022\n",
      "3/8, train_loss: 0.0136 step time: 0.2014\n",
      "4/8, train_loss: 0.0101 step time: 0.1999\n",
      "5/8, train_loss: 0.0153 step time: 0.2001\n",
      "6/8, train_loss: 0.0149 step time: 0.1994\n",
      "7/8, train_loss: 0.0141 step time: 0.1815\n",
      "8/8, train_loss: 0.0141 step time: 0.1821\n",
      "epoch 318 average loss: 0.0141\n",
      "time consuming of epoch 318 is: 1.6078\n",
      "----------\n",
      "epoch 319/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2406\n",
      "2/8, train_loss: 0.0132 step time: 0.2026\n",
      "3/8, train_loss: 0.0154 step time: 0.2013\n",
      "4/8, train_loss: 0.0137 step time: 0.2004\n",
      "5/8, train_loss: 0.0159 step time: 0.2009\n",
      "6/8, train_loss: 0.0126 step time: 0.2014\n",
      "7/8, train_loss: 0.0119 step time: 0.1845\n",
      "8/8, train_loss: 0.0153 step time: 0.1824\n",
      "epoch 319 average loss: 0.0137\n",
      "time consuming of epoch 319 is: 1.6155\n",
      "----------\n",
      "epoch 320/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2424\n",
      "2/8, train_loss: 0.0154 step time: 0.2032\n",
      "3/8, train_loss: 0.0131 step time: 0.1994\n",
      "4/8, train_loss: 0.0122 step time: 0.1973\n",
      "5/8, train_loss: 0.0150 step time: 0.1970\n",
      "6/8, train_loss: 0.0120 step time: 0.1995\n",
      "7/8, train_loss: 0.0140 step time: 0.1827\n",
      "8/8, train_loss: 0.0150 step time: 0.1822\n",
      "epoch 320 average loss: 0.0139\n",
      "current epoch: 320 current mean dice: 0.9570 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 320 is: 2.3605\n",
      "----------\n",
      "epoch 321/600\n",
      "1/8, train_loss: 0.0134 step time: 0.2371\n",
      "2/8, train_loss: 0.0157 step time: 0.1980\n",
      "3/8, train_loss: 0.0157 step time: 0.2020\n",
      "4/8, train_loss: 0.0151 step time: 0.1983\n",
      "5/8, train_loss: 0.0117 step time: 0.1994\n",
      "6/8, train_loss: 0.0133 step time: 0.1995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/8, train_loss: 0.0108 step time: 0.1838\n",
      "8/8, train_loss: 0.0151 step time: 0.1814\n",
      "epoch 321 average loss: 0.0139\n",
      "time consuming of epoch 321 is: 1.6007\n",
      "----------\n",
      "epoch 322/600\n",
      "1/8, train_loss: 0.0145 step time: 0.2408\n",
      "2/8, train_loss: 0.0112 step time: 0.2004\n",
      "3/8, train_loss: 0.0143 step time: 0.2031\n",
      "4/8, train_loss: 0.0141 step time: 0.2006\n",
      "5/8, train_loss: 0.0144 step time: 0.2011\n",
      "6/8, train_loss: 0.0141 step time: 0.2003\n",
      "7/8, train_loss: 0.0146 step time: 0.1831\n",
      "8/8, train_loss: 0.0132 step time: 0.1827\n",
      "epoch 322 average loss: 0.0138\n",
      "time consuming of epoch 322 is: 1.6135\n",
      "----------\n",
      "epoch 323/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2405\n",
      "2/8, train_loss: 0.0146 step time: 0.2025\n",
      "3/8, train_loss: 0.0167 step time: 0.2021\n",
      "4/8, train_loss: 0.0119 step time: 0.1977\n",
      "5/8, train_loss: 0.0120 step time: 0.2003\n",
      "6/8, train_loss: 0.0154 step time: 0.2005\n",
      "7/8, train_loss: 0.0126 step time: 0.1830\n",
      "8/8, train_loss: 0.0148 step time: 0.1826\n",
      "epoch 323 average loss: 0.0139\n",
      "time consuming of epoch 323 is: 1.6109\n",
      "----------\n",
      "epoch 324/600\n",
      "1/8, train_loss: 0.0112 step time: 0.2399\n",
      "2/8, train_loss: 0.0104 step time: 0.2030\n",
      "3/8, train_loss: 0.0135 step time: 0.1996\n",
      "4/8, train_loss: 0.0149 step time: 0.2000\n",
      "5/8, train_loss: 0.0150 step time: 0.1957\n",
      "6/8, train_loss: 0.0135 step time: 0.1985\n",
      "7/8, train_loss: 0.0119 step time: 0.1822\n",
      "8/8, train_loss: 0.0138 step time: 0.1819\n",
      "epoch 324 average loss: 0.0130\n",
      "time consuming of epoch 324 is: 1.6021\n",
      "----------\n",
      "epoch 325/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2412\n",
      "2/8, train_loss: 0.0129 step time: 0.1984\n",
      "3/8, train_loss: 0.0131 step time: 0.1976\n",
      "4/8, train_loss: 0.0158 step time: 0.1967\n",
      "5/8, train_loss: 0.0124 step time: 0.1962\n",
      "6/8, train_loss: 0.0156 step time: 0.1960\n",
      "7/8, train_loss: 0.0124 step time: 0.1822\n",
      "8/8, train_loss: 0.0141 step time: 0.1818\n",
      "epoch 325 average loss: 0.0137\n",
      "current epoch: 325 current mean dice: 0.9572 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 325 is: 2.3452\n",
      "----------\n",
      "epoch 326/600\n",
      "1/8, train_loss: 0.0123 step time: 0.2372\n",
      "2/8, train_loss: 0.0114 step time: 0.1981\n",
      "3/8, train_loss: 0.0119 step time: 0.2001\n",
      "4/8, train_loss: 0.0115 step time: 0.2011\n",
      "5/8, train_loss: 0.0129 step time: 0.1995\n",
      "6/8, train_loss: 0.0142 step time: 0.1993\n",
      "7/8, train_loss: 0.0160 step time: 0.1844\n",
      "8/8, train_loss: 0.0133 step time: 0.1803\n",
      "epoch 326 average loss: 0.0129\n",
      "time consuming of epoch 326 is: 1.6013\n",
      "----------\n",
      "epoch 327/600\n",
      "1/8, train_loss: 0.0135 step time: 0.2403\n",
      "2/8, train_loss: 0.0139 step time: 0.1996\n",
      "3/8, train_loss: 0.0127 step time: 0.1998\n",
      "4/8, train_loss: 0.0124 step time: 0.2000\n",
      "5/8, train_loss: 0.0134 step time: 0.2008\n",
      "6/8, train_loss: 0.0148 step time: 0.1998\n",
      "7/8, train_loss: 0.0138 step time: 0.1827\n",
      "8/8, train_loss: 0.0134 step time: 0.1823\n",
      "epoch 327 average loss: 0.0135\n",
      "time consuming of epoch 327 is: 1.6065\n",
      "----------\n",
      "epoch 328/600\n",
      "1/8, train_loss: 0.0119 step time: 0.2442\n",
      "2/8, train_loss: 0.0146 step time: 0.2033\n",
      "3/8, train_loss: 0.0135 step time: 0.1994\n",
      "4/8, train_loss: 0.0159 step time: 0.2025\n",
      "5/8, train_loss: 0.0132 step time: 0.1995\n",
      "6/8, train_loss: 0.0141 step time: 0.2015\n",
      "7/8, train_loss: 0.0116 step time: 0.1839\n",
      "8/8, train_loss: 0.0111 step time: 0.1823\n",
      "epoch 328 average loss: 0.0132\n",
      "time consuming of epoch 328 is: 1.6180\n",
      "----------\n",
      "epoch 329/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2401\n",
      "2/8, train_loss: 0.0152 step time: 0.2020\n",
      "3/8, train_loss: 0.0118 step time: 0.1988\n",
      "4/8, train_loss: 0.0134 step time: 0.2000\n",
      "5/8, train_loss: 0.0121 step time: 0.2018\n",
      "6/8, train_loss: 0.0134 step time: 0.1996\n",
      "7/8, train_loss: 0.0120 step time: 0.1844\n",
      "8/8, train_loss: 0.0132 step time: 0.1825\n",
      "epoch 329 average loss: 0.0130\n",
      "time consuming of epoch 329 is: 1.6108\n",
      "----------\n",
      "epoch 330/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2414\n",
      "2/8, train_loss: 0.0116 step time: 0.2035\n",
      "3/8, train_loss: 0.0138 step time: 0.2017\n",
      "4/8, train_loss: 0.0134 step time: 0.1979\n",
      "5/8, train_loss: 0.0130 step time: 0.2013\n",
      "6/8, train_loss: 0.0132 step time: 0.1994\n",
      "7/8, train_loss: 0.0154 step time: 0.1838\n",
      "8/8, train_loss: 0.0138 step time: 0.1840\n",
      "epoch 330 average loss: 0.0132\n",
      "current epoch: 330 current mean dice: 0.9567 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 330 is: 2.3716\n",
      "----------\n",
      "epoch 331/600\n",
      "1/8, train_loss: 0.0136 step time: 0.2379\n",
      "2/8, train_loss: 0.0134 step time: 0.2016\n",
      "3/8, train_loss: 0.0121 step time: 0.1985\n",
      "4/8, train_loss: 0.0121 step time: 0.1991\n",
      "5/8, train_loss: 0.0124 step time: 0.1995\n",
      "6/8, train_loss: 0.0134 step time: 0.2002\n",
      "7/8, train_loss: 0.0152 step time: 0.1817\n",
      "8/8, train_loss: 0.0151 step time: 0.1817\n",
      "epoch 331 average loss: 0.0134\n",
      "time consuming of epoch 331 is: 1.6013\n",
      "----------\n",
      "epoch 332/600\n",
      "1/8, train_loss: 0.0130 step time: 0.2403\n",
      "2/8, train_loss: 0.0152 step time: 0.2031\n",
      "3/8, train_loss: 0.0123 step time: 0.1997\n",
      "4/8, train_loss: 0.0144 step time: 0.2016\n",
      "5/8, train_loss: 0.0144 step time: 0.2003\n",
      "6/8, train_loss: 0.0151 step time: 0.2013\n",
      "7/8, train_loss: 0.0137 step time: 0.1830\n",
      "8/8, train_loss: 0.0139 step time: 0.1826\n",
      "epoch 332 average loss: 0.0140\n",
      "time consuming of epoch 332 is: 1.6134\n",
      "----------\n",
      "epoch 333/600\n",
      "1/8, train_loss: 0.0115 step time: 0.2364\n",
      "2/8, train_loss: 0.0128 step time: 0.1996\n",
      "3/8, train_loss: 0.0129 step time: 0.2030\n",
      "4/8, train_loss: 0.0168 step time: 0.1997\n",
      "5/8, train_loss: 0.0130 step time: 0.2020\n",
      "6/8, train_loss: 0.0132 step time: 0.2029\n",
      "7/8, train_loss: 0.0105 step time: 0.1826\n",
      "8/8, train_loss: 0.0127 step time: 0.1827\n",
      "epoch 333 average loss: 0.0129\n",
      "time consuming of epoch 333 is: 1.6104\n",
      "----------\n",
      "epoch 334/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2393\n",
      "2/8, train_loss: 0.0118 step time: 0.2005\n",
      "3/8, train_loss: 0.0149 step time: 0.2014\n",
      "4/8, train_loss: 0.0125 step time: 0.1992\n",
      "5/8, train_loss: 0.0115 step time: 0.2013\n",
      "6/8, train_loss: 0.0130 step time: 0.1994\n",
      "7/8, train_loss: 0.0147 step time: 0.1834\n",
      "8/8, train_loss: 0.0112 step time: 0.1839\n",
      "epoch 334 average loss: 0.0131\n",
      "time consuming of epoch 334 is: 1.6096\n",
      "----------\n",
      "epoch 335/600\n",
      "1/8, train_loss: 0.0159 step time: 0.2385\n",
      "2/8, train_loss: 0.0103 step time: 0.2025\n",
      "3/8, train_loss: 0.0123 step time: 0.2002\n",
      "4/8, train_loss: 0.0126 step time: 0.2015\n",
      "5/8, train_loss: 0.0130 step time: 0.2000\n",
      "6/8, train_loss: 0.0126 step time: 0.2014\n",
      "7/8, train_loss: 0.0138 step time: 0.1841\n",
      "8/8, train_loss: 0.0154 step time: 0.1823\n",
      "epoch 335 average loss: 0.0132\n",
      "current epoch: 335 current mean dice: 0.9576 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 335 is: 2.3672\n",
      "----------\n",
      "epoch 336/600\n",
      "1/8, train_loss: 0.0142 step time: 0.2391\n",
      "2/8, train_loss: 0.0137 step time: 0.2001\n",
      "3/8, train_loss: 0.0137 step time: 0.2009\n",
      "4/8, train_loss: 0.0123 step time: 0.1974\n",
      "5/8, train_loss: 0.0156 step time: 0.2013\n",
      "6/8, train_loss: 0.0133 step time: 0.2005\n",
      "7/8, train_loss: 0.0127 step time: 0.1846\n",
      "8/8, train_loss: 0.0140 step time: 0.1832\n",
      "epoch 336 average loss: 0.0137\n",
      "time consuming of epoch 336 is: 1.6083\n",
      "----------\n",
      "epoch 337/600\n",
      "1/8, train_loss: 0.0122 step time: 0.2403\n",
      "2/8, train_loss: 0.0129 step time: 0.1965\n",
      "3/8, train_loss: 0.0161 step time: 0.1966\n",
      "4/8, train_loss: 0.0114 step time: 0.1943\n",
      "5/8, train_loss: 0.0137 step time: 0.1966\n",
      "6/8, train_loss: 0.0131 step time: 0.1958\n",
      "7/8, train_loss: 0.0198 step time: 0.1823\n",
      "8/8, train_loss: 0.0147 step time: 0.1822\n",
      "epoch 337 average loss: 0.0142\n",
      "time consuming of epoch 337 is: 1.5863\n",
      "----------\n",
      "epoch 338/600\n",
      "1/8, train_loss: 0.0128 step time: 0.2345\n",
      "2/8, train_loss: 0.0121 step time: 0.2004\n",
      "3/8, train_loss: 0.0155 step time: 0.1975\n",
      "4/8, train_loss: 0.0157 step time: 0.1950\n",
      "5/8, train_loss: 0.0155 step time: 0.1951\n",
      "6/8, train_loss: 0.0163 step time: 0.1959\n",
      "7/8, train_loss: 0.0149 step time: 0.1819\n",
      "8/8, train_loss: 0.0158 step time: 0.1816\n",
      "epoch 338 average loss: 0.0148\n",
      "time consuming of epoch 338 is: 1.5833\n",
      "----------\n",
      "epoch 339/600\n",
      "1/8, train_loss: 0.0162 step time: 0.2379\n",
      "2/8, train_loss: 0.0129 step time: 0.2019\n",
      "3/8, train_loss: 0.0224 step time: 0.1993\n",
      "4/8, train_loss: 0.0137 step time: 0.2019\n",
      "5/8, train_loss: 0.0147 step time: 0.2006\n",
      "6/8, train_loss: 0.0177 step time: 0.2010\n",
      "7/8, train_loss: 0.0170 step time: 0.1825\n",
      "8/8, train_loss: 0.0139 step time: 0.1822\n",
      "epoch 339 average loss: 0.0161\n",
      "time consuming of epoch 339 is: 1.6088\n",
      "----------\n",
      "epoch 340/600\n",
      "1/8, train_loss: 0.0158 step time: 0.2412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/8, train_loss: 0.0219 step time: 0.2044\n",
      "3/8, train_loss: 0.0134 step time: 0.2020\n",
      "4/8, train_loss: 0.0153 step time: 0.2016\n",
      "5/8, train_loss: 0.0190 step time: 0.1992\n",
      "6/8, train_loss: 0.0153 step time: 0.2012\n",
      "7/8, train_loss: 0.0140 step time: 0.1820\n",
      "8/8, train_loss: 0.0153 step time: 0.1821\n",
      "epoch 340 average loss: 0.0163\n",
      "current epoch: 340 current mean dice: 0.9420 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 340 is: 2.3715\n",
      "----------\n",
      "epoch 341/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2339\n",
      "2/8, train_loss: 0.0164 step time: 0.1944\n",
      "3/8, train_loss: 0.0250 step time: 0.1953\n",
      "4/8, train_loss: 0.0138 step time: 0.1943\n",
      "5/8, train_loss: 0.0145 step time: 0.1990\n",
      "6/8, train_loss: 0.0191 step time: 0.1931\n",
      "7/8, train_loss: 0.0147 step time: 0.1814\n",
      "8/8, train_loss: 0.0175 step time: 0.1816\n",
      "epoch 341 average loss: 0.0170\n",
      "time consuming of epoch 341 is: 1.5742\n",
      "----------\n",
      "epoch 342/600\n",
      "1/8, train_loss: 0.0149 step time: 0.2364\n",
      "2/8, train_loss: 0.0149 step time: 0.2038\n",
      "3/8, train_loss: 0.0189 step time: 0.1996\n",
      "4/8, train_loss: 0.0172 step time: 0.2004\n",
      "5/8, train_loss: 0.0161 step time: 0.2017\n",
      "6/8, train_loss: 0.0149 step time: 0.2029\n",
      "7/8, train_loss: 0.0114 step time: 0.1829\n",
      "8/8, train_loss: 0.0140 step time: 0.1823\n",
      "epoch 342 average loss: 0.0153\n",
      "time consuming of epoch 342 is: 1.6116\n",
      "----------\n",
      "epoch 343/600\n",
      "1/8, train_loss: 0.0147 step time: 0.2419\n",
      "2/8, train_loss: 0.0145 step time: 0.2002\n",
      "3/8, train_loss: 0.0149 step time: 0.2214\n",
      "4/8, train_loss: 0.0145 step time: 0.2330\n",
      "5/8, train_loss: 0.0158 step time: 0.1952\n",
      "6/8, train_loss: 0.0170 step time: 0.1962\n",
      "7/8, train_loss: 0.0132 step time: 0.1795\n",
      "8/8, train_loss: 0.0189 step time: 0.1794\n",
      "epoch 343 average loss: 0.0154\n",
      "time consuming of epoch 343 is: 1.6484\n",
      "----------\n",
      "epoch 344/600\n",
      "1/8, train_loss: 0.0152 step time: 0.2327\n",
      "2/8, train_loss: 0.0212 step time: 0.1953\n",
      "3/8, train_loss: 0.0124 step time: 0.1966\n",
      "4/8, train_loss: 0.0141 step time: 0.1978\n",
      "5/8, train_loss: 0.0161 step time: 0.1971\n",
      "6/8, train_loss: 0.0204 step time: 0.1977\n",
      "7/8, train_loss: 0.0178 step time: 0.1791\n",
      "8/8, train_loss: 0.0128 step time: 0.1791\n",
      "epoch 344 average loss: 0.0162\n",
      "time consuming of epoch 344 is: 1.5764\n",
      "----------\n",
      "epoch 345/600\n",
      "1/8, train_loss: 0.0156 step time: 0.2326\n",
      "2/8, train_loss: 0.0168 step time: 0.1955\n",
      "3/8, train_loss: 0.0142 step time: 0.1971\n",
      "4/8, train_loss: 0.0167 step time: 0.1977\n",
      "5/8, train_loss: 0.0140 step time: 0.1980\n",
      "6/8, train_loss: 0.0133 step time: 0.1979\n",
      "7/8, train_loss: 0.0137 step time: 0.1795\n",
      "8/8, train_loss: 0.0154 step time: 0.1792\n",
      "epoch 345 average loss: 0.0150\n",
      "current epoch: 345 current mean dice: 0.9538 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 345 is: 2.3303\n",
      "----------\n",
      "epoch 346/600\n",
      "1/8, train_loss: 0.0135 step time: 0.2622\n",
      "2/8, train_loss: 0.0124 step time: 0.1957\n",
      "3/8, train_loss: 0.0162 step time: 0.1927\n",
      "4/8, train_loss: 0.0124 step time: 0.1944\n",
      "5/8, train_loss: 0.0143 step time: 0.2023\n",
      "6/8, train_loss: 0.0146 step time: 0.2021\n",
      "7/8, train_loss: 0.0168 step time: 0.1819\n",
      "8/8, train_loss: 0.0120 step time: 0.1831\n",
      "epoch 346 average loss: 0.0140\n",
      "time consuming of epoch 346 is: 1.6159\n",
      "----------\n",
      "epoch 347/600\n",
      "1/8, train_loss: 0.0150 step time: 0.2410\n",
      "2/8, train_loss: 0.0141 step time: 0.2059\n",
      "3/8, train_loss: 0.0132 step time: 0.1993\n",
      "4/8, train_loss: 0.0144 step time: 0.2001\n",
      "5/8, train_loss: 0.0126 step time: 0.1985\n",
      "6/8, train_loss: 0.0167 step time: 0.1987\n",
      "7/8, train_loss: 0.0135 step time: 0.1826\n",
      "8/8, train_loss: 0.0139 step time: 0.1832\n",
      "epoch 347 average loss: 0.0142\n",
      "time consuming of epoch 347 is: 1.6106\n",
      "----------\n",
      "epoch 348/600\n",
      "1/8, train_loss: 0.0134 step time: 0.2404\n",
      "2/8, train_loss: 0.0146 step time: 0.2019\n",
      "3/8, train_loss: 0.0155 step time: 0.1996\n",
      "4/8, train_loss: 0.0154 step time: 0.2015\n",
      "5/8, train_loss: 0.0120 step time: 0.1997\n",
      "6/8, train_loss: 0.0127 step time: 0.2029\n",
      "7/8, train_loss: 0.0143 step time: 0.1825\n",
      "8/8, train_loss: 0.0119 step time: 0.1835\n",
      "epoch 348 average loss: 0.0137\n",
      "time consuming of epoch 348 is: 1.6135\n",
      "----------\n",
      "epoch 349/600\n",
      "1/8, train_loss: 0.0162 step time: 0.2378\n",
      "2/8, train_loss: 0.0110 step time: 0.2036\n",
      "3/8, train_loss: 0.0142 step time: 0.1991\n",
      "4/8, train_loss: 0.0129 step time: 0.2003\n",
      "5/8, train_loss: 0.0130 step time: 0.1980\n",
      "6/8, train_loss: 0.0165 step time: 0.2002\n",
      "7/8, train_loss: 0.0156 step time: 0.1944\n",
      "8/8, train_loss: 0.0131 step time: 0.1818\n",
      "epoch 349 average loss: 0.0141\n",
      "time consuming of epoch 349 is: 1.6167\n",
      "----------\n",
      "epoch 350/600\n",
      "1/8, train_loss: 0.0113 step time: 0.2478\n",
      "2/8, train_loss: 0.0138 step time: 0.2190\n",
      "3/8, train_loss: 0.0138 step time: 0.2004\n",
      "4/8, train_loss: 0.0117 step time: 0.2717\n",
      "5/8, train_loss: 0.0153 step time: 0.1998\n",
      "6/8, train_loss: 0.0139 step time: 0.2089\n",
      "7/8, train_loss: 0.0110 step time: 0.1811\n",
      "8/8, train_loss: 0.0141 step time: 0.1805\n",
      "epoch 350 average loss: 0.0131\n",
      "current epoch: 350 current mean dice: 0.9557 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 350 is: 2.4629\n",
      "----------\n",
      "epoch 351/600\n",
      "1/8, train_loss: 0.0162 step time: 0.2356\n",
      "2/8, train_loss: 0.0135 step time: 0.1980\n",
      "3/8, train_loss: 0.0131 step time: 0.2013\n",
      "4/8, train_loss: 0.0132 step time: 0.1983\n",
      "5/8, train_loss: 0.0117 step time: 0.2036\n",
      "6/8, train_loss: 0.0120 step time: 0.1992\n",
      "7/8, train_loss: 0.0145 step time: 0.1838\n",
      "8/8, train_loss: 0.0115 step time: 0.1823\n",
      "epoch 351 average loss: 0.0132\n",
      "time consuming of epoch 351 is: 1.6031\n",
      "----------\n",
      "epoch 352/600\n",
      "1/8, train_loss: 0.0134 step time: 0.2411\n",
      "2/8, train_loss: 0.0141 step time: 0.2016\n",
      "3/8, train_loss: 0.0129 step time: 0.2079\n",
      "4/8, train_loss: 0.0101 step time: 0.2043\n",
      "5/8, train_loss: 0.0143 step time: 0.1969\n",
      "6/8, train_loss: 0.0166 step time: 0.1958\n",
      "7/8, train_loss: 0.0123 step time: 0.1791\n",
      "8/8, train_loss: 0.0133 step time: 0.1791\n",
      "epoch 352 average loss: 0.0134\n",
      "time consuming of epoch 352 is: 1.6070\n",
      "----------\n",
      "epoch 353/600\n",
      "1/8, train_loss: 0.0130 step time: 0.2337\n",
      "2/8, train_loss: 0.0137 step time: 0.1924\n",
      "3/8, train_loss: 0.0146 step time: 0.1959\n",
      "4/8, train_loss: 0.0130 step time: 0.1963\n",
      "5/8, train_loss: 0.0129 step time: 0.1960\n",
      "6/8, train_loss: 0.0141 step time: 0.1966\n",
      "7/8, train_loss: 0.0144 step time: 0.1789\n",
      "8/8, train_loss: 0.0115 step time: 0.1791\n",
      "epoch 353 average loss: 0.0134\n",
      "time consuming of epoch 353 is: 1.5701\n",
      "----------\n",
      "epoch 354/600\n",
      "1/8, train_loss: 0.0169 step time: 0.2342\n",
      "2/8, train_loss: 0.0129 step time: 0.1954\n",
      "3/8, train_loss: 0.0146 step time: 0.2000\n",
      "4/8, train_loss: 0.0147 step time: 0.2029\n",
      "5/8, train_loss: 0.0134 step time: 0.2019\n",
      "6/8, train_loss: 0.0127 step time: 0.2012\n",
      "7/8, train_loss: 0.0118 step time: 0.1833\n",
      "8/8, train_loss: 0.0138 step time: 0.1822\n",
      "epoch 354 average loss: 0.0138\n",
      "time consuming of epoch 354 is: 1.6023\n",
      "----------\n",
      "epoch 355/600\n",
      "1/8, train_loss: 0.0139 step time: 0.2398\n",
      "2/8, train_loss: 0.0142 step time: 0.1994\n",
      "3/8, train_loss: 0.0136 step time: 0.2013\n",
      "4/8, train_loss: 0.0123 step time: 0.2015\n",
      "5/8, train_loss: 0.0141 step time: 0.1985\n",
      "6/8, train_loss: 0.0117 step time: 0.2002\n",
      "7/8, train_loss: 0.0172 step time: 0.1828\n",
      "8/8, train_loss: 0.0138 step time: 0.1819\n",
      "epoch 355 average loss: 0.0139\n",
      "current epoch: 355 current mean dice: 0.9558 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 355 is: 2.3626\n",
      "----------\n",
      "epoch 356/600\n",
      "1/8, train_loss: 0.0111 step time: 0.2389\n",
      "2/8, train_loss: 0.0135 step time: 0.1965\n",
      "3/8, train_loss: 0.0139 step time: 0.2015\n",
      "4/8, train_loss: 0.0137 step time: 0.1981\n",
      "5/8, train_loss: 0.0117 step time: 0.2002\n",
      "6/8, train_loss: 0.0146 step time: 0.1991\n",
      "7/8, train_loss: 0.0156 step time: 0.1833\n",
      "8/8, train_loss: 0.0148 step time: 0.1804\n",
      "epoch 356 average loss: 0.0136\n",
      "time consuming of epoch 356 is: 1.5990\n",
      "----------\n",
      "epoch 357/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2401\n",
      "2/8, train_loss: 0.0141 step time: 0.1999\n",
      "3/8, train_loss: 0.0121 step time: 0.2006\n",
      "4/8, train_loss: 0.0120 step time: 0.1984\n",
      "5/8, train_loss: 0.0152 step time: 0.1984\n",
      "6/8, train_loss: 0.0130 step time: 0.1999\n",
      "7/8, train_loss: 0.0189 step time: 0.1848\n",
      "8/8, train_loss: 0.0146 step time: 0.1835\n",
      "epoch 357 average loss: 0.0142\n",
      "time consuming of epoch 357 is: 1.6069\n",
      "----------\n",
      "epoch 358/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2435\n",
      "2/8, train_loss: 0.0118 step time: 0.2031\n",
      "3/8, train_loss: 0.0117 step time: 0.1991\n",
      "4/8, train_loss: 0.0143 step time: 0.2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8, train_loss: 0.0149 step time: 0.2040\n",
      "6/8, train_loss: 0.0115 step time: 0.2017\n",
      "7/8, train_loss: 0.0174 step time: 0.1834\n",
      "8/8, train_loss: 0.0151 step time: 0.1823\n",
      "epoch 358 average loss: 0.0136\n",
      "time consuming of epoch 358 is: 1.6209\n",
      "----------\n",
      "epoch 359/600\n",
      "1/8, train_loss: 0.0138 step time: 0.2407\n",
      "2/8, train_loss: 0.0104 step time: 0.2018\n",
      "3/8, train_loss: 0.0109 step time: 0.2012\n",
      "4/8, train_loss: 0.0140 step time: 0.2039\n",
      "5/8, train_loss: 0.0122 step time: 0.2015\n",
      "6/8, train_loss: 0.0130 step time: 0.2015\n",
      "7/8, train_loss: 0.0125 step time: 0.1846\n",
      "8/8, train_loss: 0.0140 step time: 0.1839\n",
      "epoch 359 average loss: 0.0126\n",
      "time consuming of epoch 359 is: 1.6205\n",
      "----------\n",
      "epoch 360/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2410\n",
      "2/8, train_loss: 0.0165 step time: 0.2005\n",
      "3/8, train_loss: 0.0139 step time: 0.2025\n",
      "4/8, train_loss: 0.0154 step time: 0.2017\n",
      "5/8, train_loss: 0.0113 step time: 0.1975\n",
      "6/8, train_loss: 0.0170 step time: 0.1999\n",
      "7/8, train_loss: 0.0140 step time: 0.1822\n",
      "8/8, train_loss: 0.0120 step time: 0.1845\n",
      "epoch 360 average loss: 0.0140\n",
      "current epoch: 360 current mean dice: 0.9560 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 360 is: 2.3665\n",
      "----------\n",
      "epoch 361/600\n",
      "1/8, train_loss: 0.0135 step time: 0.2400\n",
      "2/8, train_loss: 0.0149 step time: 0.1987\n",
      "3/8, train_loss: 0.0148 step time: 0.2029\n",
      "4/8, train_loss: 0.0119 step time: 0.1994\n",
      "5/8, train_loss: 0.0139 step time: 0.1994\n",
      "6/8, train_loss: 0.0128 step time: 0.1992\n",
      "7/8, train_loss: 0.0109 step time: 0.1817\n",
      "8/8, train_loss: 0.0155 step time: 0.1810\n",
      "epoch 361 average loss: 0.0135\n",
      "time consuming of epoch 361 is: 1.6035\n",
      "----------\n",
      "epoch 362/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2488\n",
      "2/8, train_loss: 0.0127 step time: 0.2042\n",
      "3/8, train_loss: 0.0132 step time: 0.2002\n",
      "4/8, train_loss: 0.0135 step time: 0.2021\n",
      "5/8, train_loss: 0.0132 step time: 0.1997\n",
      "6/8, train_loss: 0.0165 step time: 0.2029\n",
      "7/8, train_loss: 0.0156 step time: 0.1827\n",
      "8/8, train_loss: 0.0137 step time: 0.1829\n",
      "epoch 362 average loss: 0.0139\n",
      "time consuming of epoch 362 is: 1.6250\n",
      "----------\n",
      "epoch 363/600\n",
      "1/8, train_loss: 0.0117 step time: 0.2393\n",
      "2/8, train_loss: 0.0132 step time: 0.2019\n",
      "3/8, train_loss: 0.0129 step time: 0.2022\n",
      "4/8, train_loss: 0.0131 step time: 0.2000\n",
      "5/8, train_loss: 0.0147 step time: 0.2012\n",
      "6/8, train_loss: 0.0144 step time: 0.2020\n",
      "7/8, train_loss: 0.0120 step time: 0.1828\n",
      "8/8, train_loss: 0.0125 step time: 0.1814\n",
      "epoch 363 average loss: 0.0130\n",
      "time consuming of epoch 363 is: 1.6121\n",
      "----------\n",
      "epoch 364/600\n",
      "1/8, train_loss: 0.0147 step time: 0.2408\n",
      "2/8, train_loss: 0.0137 step time: 0.2034\n",
      "3/8, train_loss: 0.0116 step time: 0.1993\n",
      "4/8, train_loss: 0.0115 step time: 0.2016\n",
      "5/8, train_loss: 0.0140 step time: 0.1996\n",
      "6/8, train_loss: 0.0118 step time: 0.2027\n",
      "7/8, train_loss: 0.0143 step time: 0.1826\n",
      "8/8, train_loss: 0.0170 step time: 0.1820\n",
      "epoch 364 average loss: 0.0136\n",
      "time consuming of epoch 364 is: 1.6133\n",
      "----------\n",
      "epoch 365/600\n",
      "1/8, train_loss: 0.0134 step time: 0.2424\n",
      "2/8, train_loss: 0.0121 step time: 0.2035\n",
      "3/8, train_loss: 0.0138 step time: 0.1993\n",
      "4/8, train_loss: 0.0148 step time: 0.2017\n",
      "5/8, train_loss: 0.0124 step time: 0.1997\n",
      "6/8, train_loss: 0.0122 step time: 0.2014\n",
      "7/8, train_loss: 0.0121 step time: 0.1834\n",
      "8/8, train_loss: 0.0123 step time: 0.1821\n",
      "epoch 365 average loss: 0.0129\n",
      "current epoch: 365 current mean dice: 0.9561 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 365 is: 2.3715\n",
      "----------\n",
      "epoch 366/600\n",
      "1/8, train_loss: 0.0114 step time: 0.2404\n",
      "2/8, train_loss: 0.0161 step time: 0.2012\n",
      "3/8, train_loss: 0.0132 step time: 0.1981\n",
      "4/8, train_loss: 0.0137 step time: 0.1998\n",
      "5/8, train_loss: 0.0110 step time: 0.2005\n",
      "6/8, train_loss: 0.0124 step time: 0.1995\n",
      "7/8, train_loss: 0.0131 step time: 0.1815\n",
      "8/8, train_loss: 0.0095 step time: 0.1805\n",
      "epoch 366 average loss: 0.0126\n",
      "time consuming of epoch 366 is: 1.6028\n",
      "----------\n",
      "epoch 367/600\n",
      "1/8, train_loss: 0.0103 step time: 0.2381\n",
      "2/8, train_loss: 0.0122 step time: 0.2041\n",
      "3/8, train_loss: 0.0151 step time: 0.2032\n",
      "4/8, train_loss: 0.0145 step time: 0.2000\n",
      "5/8, train_loss: 0.0134 step time: 0.1999\n",
      "6/8, train_loss: 0.0116 step time: 0.1996\n",
      "7/8, train_loss: 0.0127 step time: 0.1829\n",
      "8/8, train_loss: 0.0120 step time: 0.1828\n",
      "epoch 367 average loss: 0.0127\n",
      "time consuming of epoch 367 is: 1.6118\n",
      "----------\n",
      "epoch 368/600\n",
      "1/8, train_loss: 0.0150 step time: 0.2393\n",
      "2/8, train_loss: 0.0122 step time: 0.2026\n",
      "3/8, train_loss: 0.0138 step time: 0.2002\n",
      "4/8, train_loss: 0.0123 step time: 0.1994\n",
      "5/8, train_loss: 0.0140 step time: 0.1995\n",
      "6/8, train_loss: 0.0118 step time: 0.2004\n",
      "7/8, train_loss: 0.0126 step time: 0.1820\n",
      "8/8, train_loss: 0.0145 step time: 0.1873\n",
      "epoch 368 average loss: 0.0133\n",
      "time consuming of epoch 368 is: 1.6122\n",
      "----------\n",
      "epoch 369/600\n",
      "1/8, train_loss: 0.0138 step time: 0.2386\n",
      "2/8, train_loss: 0.0109 step time: 0.2029\n",
      "3/8, train_loss: 0.0134 step time: 0.1983\n",
      "4/8, train_loss: 0.0131 step time: 0.1998\n",
      "5/8, train_loss: 0.0135 step time: 0.2019\n",
      "6/8, train_loss: 0.0112 step time: 0.2002\n",
      "7/8, train_loss: 0.0148 step time: 0.1798\n",
      "8/8, train_loss: 0.0144 step time: 0.1790\n",
      "epoch 369 average loss: 0.0131\n",
      "time consuming of epoch 369 is: 1.6019\n",
      "----------\n",
      "epoch 370/600\n",
      "1/8, train_loss: 0.0132 step time: 0.2324\n",
      "2/8, train_loss: 0.0133 step time: 0.1947\n",
      "3/8, train_loss: 0.0119 step time: 0.1967\n",
      "4/8, train_loss: 0.0144 step time: 0.1978\n",
      "5/8, train_loss: 0.0112 step time: 0.1985\n",
      "6/8, train_loss: 0.0123 step time: 0.1966\n",
      "7/8, train_loss: 0.0135 step time: 0.1789\n",
      "8/8, train_loss: 0.0129 step time: 0.1791\n",
      "epoch 370 average loss: 0.0128\n",
      "current epoch: 370 current mean dice: 0.9570 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 370 is: 2.3275\n",
      "----------\n",
      "epoch 371/600\n",
      "1/8, train_loss: 0.0123 step time: 0.2341\n",
      "2/8, train_loss: 0.0120 step time: 0.1951\n",
      "3/8, train_loss: 0.0126 step time: 0.2005\n",
      "4/8, train_loss: 0.0139 step time: 0.1956\n",
      "5/8, train_loss: 0.0120 step time: 0.1983\n",
      "6/8, train_loss: 0.0115 step time: 0.1976\n",
      "7/8, train_loss: 0.0150 step time: 0.1794\n",
      "8/8, train_loss: 0.0123 step time: 0.1792\n",
      "epoch 371 average loss: 0.0127\n",
      "time consuming of epoch 371 is: 1.5809\n",
      "----------\n",
      "epoch 372/600\n",
      "1/8, train_loss: 0.0148 step time: 0.2329\n",
      "2/8, train_loss: 0.0128 step time: 0.1947\n",
      "3/8, train_loss: 0.0133 step time: 0.1984\n",
      "4/8, train_loss: 0.0111 step time: 0.1976\n",
      "5/8, train_loss: 0.0129 step time: 0.1980\n",
      "6/8, train_loss: 0.0120 step time: 0.1981\n",
      "7/8, train_loss: 0.0166 step time: 0.1794\n",
      "8/8, train_loss: 0.0136 step time: 0.1792\n",
      "epoch 372 average loss: 0.0134\n",
      "time consuming of epoch 372 is: 1.5794\n",
      "----------\n",
      "epoch 373/600\n",
      "1/8, train_loss: 0.0109 step time: 0.2484\n",
      "2/8, train_loss: 0.0130 step time: 0.2052\n",
      "3/8, train_loss: 0.0127 step time: 0.2047\n",
      "4/8, train_loss: 0.0116 step time: 0.2030\n",
      "5/8, train_loss: 0.0139 step time: 0.2015\n",
      "6/8, train_loss: 0.0125 step time: 0.2028\n",
      "7/8, train_loss: 0.0157 step time: 0.1841\n",
      "8/8, train_loss: 0.0158 step time: 0.1837\n",
      "epoch 373 average loss: 0.0133\n",
      "time consuming of epoch 373 is: 1.6347\n",
      "----------\n",
      "epoch 374/600\n",
      "1/8, train_loss: 0.0126 step time: 0.2400\n",
      "2/8, train_loss: 0.0137 step time: 0.2018\n",
      "3/8, train_loss: 0.0134 step time: 0.1990\n",
      "4/8, train_loss: 0.0135 step time: 0.2018\n",
      "5/8, train_loss: 0.0122 step time: 0.2009\n",
      "6/8, train_loss: 0.0156 step time: 0.2024\n",
      "7/8, train_loss: 0.0116 step time: 0.1835\n",
      "8/8, train_loss: 0.0134 step time: 0.1826\n",
      "epoch 374 average loss: 0.0133\n",
      "time consuming of epoch 374 is: 1.6134\n",
      "----------\n",
      "epoch 375/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2451\n",
      "2/8, train_loss: 0.0111 step time: 0.2040\n",
      "3/8, train_loss: 0.0138 step time: 0.2013\n",
      "4/8, train_loss: 0.0123 step time: 0.2021\n",
      "5/8, train_loss: 0.0143 step time: 0.2032\n",
      "6/8, train_loss: 0.0155 step time: 0.1998\n",
      "7/8, train_loss: 0.0121 step time: 0.1846\n",
      "8/8, train_loss: 0.0137 step time: 0.1834\n",
      "epoch 375 average loss: 0.0129\n",
      "current epoch: 375 current mean dice: 0.9545 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 375 is: 2.3858\n",
      "----------\n",
      "epoch 376/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2467\n",
      "2/8, train_loss: 0.0132 step time: 0.1948\n",
      "3/8, train_loss: 0.0142 step time: 0.1960\n",
      "4/8, train_loss: 0.0139 step time: 0.1994\n",
      "5/8, train_loss: 0.0134 step time: 0.1985\n",
      "6/8, train_loss: 0.0147 step time: 0.1953\n",
      "7/8, train_loss: 0.0132 step time: 0.1825\n",
      "8/8, train_loss: 0.0114 step time: 0.1821\n",
      "epoch 376 average loss: 0.0131\n",
      "time consuming of epoch 376 is: 1.5966\n",
      "----------\n",
      "epoch 377/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0132 step time: 0.2430\n",
      "2/8, train_loss: 0.0133 step time: 0.2017\n",
      "3/8, train_loss: 0.0127 step time: 0.1984\n",
      "4/8, train_loss: 0.0136 step time: 0.2015\n",
      "5/8, train_loss: 0.0115 step time: 0.2020\n",
      "6/8, train_loss: 0.0146 step time: 0.1981\n",
      "7/8, train_loss: 0.0120 step time: 0.1819\n",
      "8/8, train_loss: 0.0154 step time: 0.1821\n",
      "epoch 377 average loss: 0.0133\n",
      "time consuming of epoch 377 is: 1.6101\n",
      "----------\n",
      "epoch 378/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2383\n",
      "2/8, train_loss: 0.0110 step time: 0.2019\n",
      "3/8, train_loss: 0.0128 step time: 0.1989\n",
      "4/8, train_loss: 0.0145 step time: 0.2009\n",
      "5/8, train_loss: 0.0141 step time: 0.1985\n",
      "6/8, train_loss: 0.0151 step time: 0.1993\n",
      "7/8, train_loss: 0.0142 step time: 0.1825\n",
      "8/8, train_loss: 0.0117 step time: 0.1827\n",
      "epoch 378 average loss: 0.0131\n",
      "time consuming of epoch 378 is: 1.6043\n",
      "----------\n",
      "epoch 379/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2406\n",
      "2/8, train_loss: 0.0134 step time: 0.1994\n",
      "3/8, train_loss: 0.0137 step time: 0.2034\n",
      "4/8, train_loss: 0.0115 step time: 0.2003\n",
      "5/8, train_loss: 0.0109 step time: 0.1985\n",
      "6/8, train_loss: 0.0129 step time: 0.1936\n",
      "7/8, train_loss: 0.0125 step time: 0.1821\n",
      "8/8, train_loss: 0.0132 step time: 0.1823\n",
      "epoch 379 average loss: 0.0129\n",
      "time consuming of epoch 379 is: 1.6019\n",
      "----------\n",
      "epoch 380/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2409\n",
      "2/8, train_loss: 0.0127 step time: 0.2039\n",
      "3/8, train_loss: 0.0125 step time: 0.1988\n",
      "4/8, train_loss: 0.0117 step time: 0.2072\n",
      "5/8, train_loss: 0.0156 step time: 0.2015\n",
      "6/8, train_loss: 0.0121 step time: 0.2020\n",
      "7/8, train_loss: 0.0137 step time: 0.1811\n",
      "8/8, train_loss: 0.0118 step time: 0.1814\n",
      "epoch 380 average loss: 0.0129\n",
      "current epoch: 380 current mean dice: 0.9574 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 380 is: 2.3727\n",
      "----------\n",
      "epoch 381/600\n",
      "1/8, train_loss: 0.0124 step time: 0.2375\n",
      "2/8, train_loss: 0.0142 step time: 0.1971\n",
      "3/8, train_loss: 0.0120 step time: 0.1993\n",
      "4/8, train_loss: 0.0097 step time: 0.1987\n",
      "5/8, train_loss: 0.0181 step time: 0.1998\n",
      "6/8, train_loss: 0.0123 step time: 0.2002\n",
      "7/8, train_loss: 0.0131 step time: 0.1815\n",
      "8/8, train_loss: 0.0136 step time: 0.1818\n",
      "epoch 381 average loss: 0.0132\n",
      "time consuming of epoch 381 is: 1.5968\n",
      "----------\n",
      "epoch 382/600\n",
      "1/8, train_loss: 0.0141 step time: 0.2394\n",
      "2/8, train_loss: 0.0141 step time: 0.2015\n",
      "3/8, train_loss: 0.0138 step time: 0.2033\n",
      "4/8, train_loss: 0.0112 step time: 0.1987\n",
      "5/8, train_loss: 0.0125 step time: 0.2010\n",
      "6/8, train_loss: 0.0112 step time: 0.1992\n",
      "7/8, train_loss: 0.0124 step time: 0.1831\n",
      "8/8, train_loss: 0.0140 step time: 0.1827\n",
      "epoch 382 average loss: 0.0129\n",
      "time consuming of epoch 382 is: 1.6103\n",
      "----------\n",
      "epoch 383/600\n",
      "1/8, train_loss: 0.0152 step time: 0.2431\n",
      "2/8, train_loss: 0.0127 step time: 0.2046\n",
      "3/8, train_loss: 0.0151 step time: 0.1979\n",
      "4/8, train_loss: 0.0134 step time: 0.2010\n",
      "5/8, train_loss: 0.0117 step time: 0.2107\n",
      "6/8, train_loss: 0.0099 step time: 0.1999\n",
      "7/8, train_loss: 0.0114 step time: 0.1841\n",
      "8/8, train_loss: 0.0131 step time: 0.1821\n",
      "epoch 383 average loss: 0.0128\n",
      "time consuming of epoch 383 is: 1.6247\n",
      "----------\n",
      "epoch 384/600\n",
      "1/8, train_loss: 0.0122 step time: 0.2399\n",
      "2/8, train_loss: 0.0130 step time: 0.2012\n",
      "3/8, train_loss: 0.0106 step time: 0.1996\n",
      "4/8, train_loss: 0.0131 step time: 0.2007\n",
      "5/8, train_loss: 0.0148 step time: 0.2010\n",
      "6/8, train_loss: 0.0126 step time: 0.2015\n",
      "7/8, train_loss: 0.0125 step time: 0.1830\n",
      "8/8, train_loss: 0.0123 step time: 0.1829\n",
      "epoch 384 average loss: 0.0126\n",
      "time consuming of epoch 384 is: 1.6117\n",
      "----------\n",
      "epoch 385/600\n",
      "1/8, train_loss: 0.0119 step time: 0.2423\n",
      "2/8, train_loss: 0.0164 step time: 0.2040\n",
      "3/8, train_loss: 0.0122 step time: 0.1990\n",
      "4/8, train_loss: 0.0105 step time: 0.2013\n",
      "5/8, train_loss: 0.0119 step time: 0.2001\n",
      "6/8, train_loss: 0.0133 step time: 0.2022\n",
      "7/8, train_loss: 0.0118 step time: 0.1841\n",
      "8/8, train_loss: 0.0159 step time: 0.1834\n",
      "epoch 385 average loss: 0.0130\n",
      "current epoch: 385 current mean dice: 0.9563 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 385 is: 2.3741\n",
      "----------\n",
      "epoch 386/600\n",
      "1/8, train_loss: 0.0146 step time: 0.2407\n",
      "2/8, train_loss: 0.0126 step time: 0.2000\n",
      "3/8, train_loss: 0.0105 step time: 0.2004\n",
      "4/8, train_loss: 0.0136 step time: 0.1984\n",
      "5/8, train_loss: 0.0121 step time: 0.2014\n",
      "6/8, train_loss: 0.0134 step time: 0.2026\n",
      "7/8, train_loss: 0.0125 step time: 0.1819\n",
      "8/8, train_loss: 0.0130 step time: 0.1817\n",
      "epoch 386 average loss: 0.0128\n",
      "time consuming of epoch 386 is: 1.6083\n",
      "----------\n",
      "epoch 387/600\n",
      "1/8, train_loss: 0.0155 step time: 0.2402\n",
      "2/8, train_loss: 0.0121 step time: 0.2046\n",
      "3/8, train_loss: 0.0131 step time: 0.2043\n",
      "4/8, train_loss: 0.0131 step time: 0.2008\n",
      "5/8, train_loss: 0.0126 step time: 0.2023\n",
      "6/8, train_loss: 0.0115 step time: 0.2026\n",
      "7/8, train_loss: 0.0108 step time: 0.1842\n",
      "8/8, train_loss: 0.0127 step time: 0.1841\n",
      "epoch 387 average loss: 0.0127\n",
      "time consuming of epoch 387 is: 1.6247\n",
      "----------\n",
      "epoch 388/600\n",
      "1/8, train_loss: 0.0147 step time: 0.2378\n",
      "2/8, train_loss: 0.0141 step time: 0.2070\n",
      "3/8, train_loss: 0.0115 step time: 0.1985\n",
      "4/8, train_loss: 0.0122 step time: 0.2026\n",
      "5/8, train_loss: 0.0153 step time: 0.2013\n",
      "6/8, train_loss: 0.0131 step time: 0.2036\n",
      "7/8, train_loss: 0.0135 step time: 0.1820\n",
      "8/8, train_loss: 0.0115 step time: 0.1835\n",
      "epoch 388 average loss: 0.0132\n",
      "time consuming of epoch 388 is: 1.6178\n",
      "----------\n",
      "epoch 389/600\n",
      "1/8, train_loss: 0.0155 step time: 0.2405\n",
      "2/8, train_loss: 0.0129 step time: 0.1964\n",
      "3/8, train_loss: 0.0155 step time: 0.2016\n",
      "4/8, train_loss: 0.0101 step time: 0.1995\n",
      "5/8, train_loss: 0.0128 step time: 0.2002\n",
      "6/8, train_loss: 0.0132 step time: 0.1992\n",
      "7/8, train_loss: 0.0123 step time: 0.1843\n",
      "8/8, train_loss: 0.0120 step time: 0.1827\n",
      "epoch 389 average loss: 0.0130\n",
      "time consuming of epoch 389 is: 1.6057\n",
      "----------\n",
      "epoch 390/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2411\n",
      "2/8, train_loss: 0.0133 step time: 0.1997\n",
      "3/8, train_loss: 0.0112 step time: 0.2005\n",
      "4/8, train_loss: 0.0124 step time: 0.2018\n",
      "5/8, train_loss: 0.0133 step time: 0.2000\n",
      "6/8, train_loss: 0.0124 step time: 0.1995\n",
      "7/8, train_loss: 0.0109 step time: 0.1815\n",
      "8/8, train_loss: 0.0121 step time: 0.1828\n",
      "epoch 390 average loss: 0.0124\n",
      "current epoch: 390 current mean dice: 0.9570 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 390 is: 2.3635\n",
      "----------\n",
      "epoch 391/600\n",
      "1/8, train_loss: 0.0140 step time: 0.2354\n",
      "2/8, train_loss: 0.0120 step time: 0.1979\n",
      "3/8, train_loss: 0.0134 step time: 0.1993\n",
      "4/8, train_loss: 0.0102 step time: 0.2001\n",
      "5/8, train_loss: 0.0126 step time: 0.1992\n",
      "6/8, train_loss: 0.0133 step time: 0.2000\n",
      "7/8, train_loss: 0.0132 step time: 0.1827\n",
      "8/8, train_loss: 0.0121 step time: 0.1812\n",
      "epoch 391 average loss: 0.0126\n",
      "time consuming of epoch 391 is: 1.5969\n",
      "----------\n",
      "epoch 392/600\n",
      "1/8, train_loss: 0.0117 step time: 0.2407\n",
      "2/8, train_loss: 0.0129 step time: 0.2019\n",
      "3/8, train_loss: 0.0146 step time: 0.1993\n",
      "4/8, train_loss: 0.0109 step time: 0.2015\n",
      "5/8, train_loss: 0.0099 step time: 0.2037\n",
      "6/8, train_loss: 0.0133 step time: 0.1993\n",
      "7/8, train_loss: 0.0125 step time: 0.1821\n",
      "8/8, train_loss: 0.0121 step time: 0.1824\n",
      "epoch 392 average loss: 0.0122\n",
      "time consuming of epoch 392 is: 1.6121\n",
      "----------\n",
      "epoch 393/600\n",
      "1/8, train_loss: 0.0146 step time: 0.2421\n",
      "2/8, train_loss: 0.0116 step time: 0.2037\n",
      "3/8, train_loss: 0.0133 step time: 0.2000\n",
      "4/8, train_loss: 0.0144 step time: 0.2022\n",
      "5/8, train_loss: 0.0111 step time: 0.1985\n",
      "6/8, train_loss: 0.0116 step time: 0.2010\n",
      "7/8, train_loss: 0.0120 step time: 0.1820\n",
      "8/8, train_loss: 0.0126 step time: 0.1835\n",
      "epoch 393 average loss: 0.0126\n",
      "time consuming of epoch 393 is: 1.6143\n",
      "----------\n",
      "epoch 394/600\n",
      "1/8, train_loss: 0.0133 step time: 0.2420\n",
      "2/8, train_loss: 0.0138 step time: 0.2010\n",
      "3/8, train_loss: 0.0145 step time: 0.1992\n",
      "4/8, train_loss: 0.0110 step time: 0.1990\n",
      "5/8, train_loss: 0.0116 step time: 0.1986\n",
      "6/8, train_loss: 0.0130 step time: 0.1991\n",
      "7/8, train_loss: 0.0131 step time: 0.1827\n",
      "8/8, train_loss: 0.0110 step time: 0.1824\n",
      "epoch 394 average loss: 0.0127\n",
      "time consuming of epoch 394 is: 1.6058\n",
      "----------\n",
      "epoch 395/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2410\n",
      "2/8, train_loss: 0.0160 step time: 0.2022\n",
      "3/8, train_loss: 0.0114 step time: 0.1993\n",
      "4/8, train_loss: 0.0138 step time: 0.2016\n",
      "5/8, train_loss: 0.0137 step time: 0.1991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/8, train_loss: 0.0120 step time: 0.2024\n",
      "7/8, train_loss: 0.0137 step time: 0.1816\n",
      "8/8, train_loss: 0.0132 step time: 0.1818\n",
      "epoch 395 average loss: 0.0130\n",
      "current epoch: 395 current mean dice: 0.9568 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 395 is: 2.3662\n",
      "----------\n",
      "epoch 396/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2363\n",
      "2/8, train_loss: 0.0135 step time: 0.2054\n",
      "3/8, train_loss: 0.0126 step time: 0.1976\n",
      "4/8, train_loss: 0.0099 step time: 0.1995\n",
      "5/8, train_loss: 0.0130 step time: 0.2004\n",
      "6/8, train_loss: 0.0136 step time: 0.2009\n",
      "7/8, train_loss: 0.0124 step time: 0.1823\n",
      "8/8, train_loss: 0.0132 step time: 0.1850\n",
      "epoch 396 average loss: 0.0125\n",
      "time consuming of epoch 396 is: 1.6086\n",
      "----------\n",
      "epoch 397/600\n",
      "1/8, train_loss: 0.0136 step time: 0.2378\n",
      "2/8, train_loss: 0.0133 step time: 0.2009\n",
      "3/8, train_loss: 0.0104 step time: 0.1981\n",
      "4/8, train_loss: 0.0121 step time: 0.1994\n",
      "5/8, train_loss: 0.0112 step time: 0.2009\n",
      "6/8, train_loss: 0.0139 step time: 0.1994\n",
      "7/8, train_loss: 0.0112 step time: 0.1829\n",
      "8/8, train_loss: 0.0115 step time: 0.1827\n",
      "epoch 397 average loss: 0.0122\n",
      "time consuming of epoch 397 is: 1.6037\n",
      "----------\n",
      "epoch 398/600\n",
      "1/8, train_loss: 0.0154 step time: 0.2406\n",
      "2/8, train_loss: 0.0115 step time: 0.1976\n",
      "3/8, train_loss: 0.0110 step time: 0.2069\n",
      "4/8, train_loss: 0.0167 step time: 0.2030\n",
      "5/8, train_loss: 0.0127 step time: 0.2024\n",
      "6/8, train_loss: 0.0133 step time: 0.2013\n",
      "7/8, train_loss: 0.0114 step time: 0.1813\n",
      "8/8, train_loss: 0.0123 step time: 0.1833\n",
      "epoch 398 average loss: 0.0130\n",
      "time consuming of epoch 398 is: 1.6180\n",
      "----------\n",
      "epoch 399/600\n",
      "1/8, train_loss: 0.0132 step time: 0.2384\n",
      "2/8, train_loss: 0.0132 step time: 0.1981\n",
      "3/8, train_loss: 0.0119 step time: 0.2033\n",
      "4/8, train_loss: 0.0127 step time: 0.2009\n",
      "5/8, train_loss: 0.0127 step time: 0.1980\n",
      "6/8, train_loss: 0.0105 step time: 0.2007\n",
      "7/8, train_loss: 0.0162 step time: 0.1812\n",
      "8/8, train_loss: 0.0103 step time: 0.1814\n",
      "epoch 399 average loss: 0.0126\n",
      "time consuming of epoch 399 is: 1.6035\n",
      "----------\n",
      "epoch 400/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2345\n",
      "2/8, train_loss: 0.0111 step time: 0.2016\n",
      "3/8, train_loss: 0.0173 step time: 0.1989\n",
      "4/8, train_loss: 0.0124 step time: 0.2029\n",
      "5/8, train_loss: 0.0113 step time: 0.1985\n",
      "6/8, train_loss: 0.0124 step time: 0.1996\n",
      "7/8, train_loss: 0.0130 step time: 0.1828\n",
      "8/8, train_loss: 0.0134 step time: 0.1819\n",
      "epoch 400 average loss: 0.0127\n",
      "current epoch: 400 current mean dice: 0.9579 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 400 is: 2.3582\n",
      "----------\n",
      "epoch 401/600\n",
      "1/8, train_loss: 0.0135 step time: 0.2340\n",
      "2/8, train_loss: 0.0136 step time: 0.1955\n",
      "3/8, train_loss: 0.0107 step time: 0.1963\n",
      "4/8, train_loss: 0.0124 step time: 0.1981\n",
      "5/8, train_loss: 0.0135 step time: 0.2054\n",
      "6/8, train_loss: 0.0132 step time: 0.1990\n",
      "7/8, train_loss: 0.0135 step time: 0.1813\n",
      "8/8, train_loss: 0.0115 step time: 0.1835\n",
      "epoch 401 average loss: 0.0127\n",
      "time consuming of epoch 401 is: 1.5944\n",
      "----------\n",
      "epoch 402/600\n",
      "1/8, train_loss: 0.0128 step time: 0.2420\n",
      "2/8, train_loss: 0.0106 step time: 0.2040\n",
      "3/8, train_loss: 0.0132 step time: 0.1992\n",
      "4/8, train_loss: 0.0152 step time: 0.1992\n",
      "5/8, train_loss: 0.0105 step time: 0.2015\n",
      "6/8, train_loss: 0.0136 step time: 0.2002\n",
      "7/8, train_loss: 0.0115 step time: 0.1826\n",
      "8/8, train_loss: 0.0135 step time: 0.1852\n",
      "epoch 402 average loss: 0.0126\n",
      "time consuming of epoch 402 is: 1.6151\n",
      "----------\n",
      "epoch 403/600\n",
      "1/8, train_loss: 0.0148 step time: 0.2401\n",
      "2/8, train_loss: 0.0154 step time: 0.2001\n",
      "3/8, train_loss: 0.0112 step time: 0.2022\n",
      "4/8, train_loss: 0.0137 step time: 0.2012\n",
      "5/8, train_loss: 0.0110 step time: 0.2018\n",
      "6/8, train_loss: 0.0135 step time: 0.1993\n",
      "7/8, train_loss: 0.0105 step time: 0.1859\n",
      "8/8, train_loss: 0.0105 step time: 0.1832\n",
      "epoch 403 average loss: 0.0126\n",
      "time consuming of epoch 403 is: 1.6151\n",
      "----------\n",
      "epoch 404/600\n",
      "1/8, train_loss: 0.0106 step time: 0.2423\n",
      "2/8, train_loss: 0.0102 step time: 0.2032\n",
      "3/8, train_loss: 0.0124 step time: 0.1987\n",
      "4/8, train_loss: 0.0117 step time: 0.2040\n",
      "5/8, train_loss: 0.0134 step time: 0.1985\n",
      "6/8, train_loss: 0.0147 step time: 0.2020\n",
      "7/8, train_loss: 0.0116 step time: 0.1823\n",
      "8/8, train_loss: 0.0151 step time: 0.1814\n",
      "epoch 404 average loss: 0.0124\n",
      "time consuming of epoch 404 is: 1.6141\n",
      "----------\n",
      "epoch 405/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2421\n",
      "2/8, train_loss: 0.0125 step time: 0.2019\n",
      "3/8, train_loss: 0.0122 step time: 0.2025\n",
      "4/8, train_loss: 0.0142 step time: 0.1995\n",
      "5/8, train_loss: 0.0133 step time: 0.2018\n",
      "6/8, train_loss: 0.0095 step time: 0.2020\n",
      "7/8, train_loss: 0.0121 step time: 0.1832\n",
      "8/8, train_loss: 0.0118 step time: 0.1845\n",
      "epoch 405 average loss: 0.0121\n",
      "current epoch: 405 current mean dice: 0.9576 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 405 is: 2.3735\n",
      "----------\n",
      "epoch 406/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2416\n",
      "2/8, train_loss: 0.0113 step time: 0.2051\n",
      "3/8, train_loss: 0.0115 step time: 0.1980\n",
      "4/8, train_loss: 0.0127 step time: 0.1995\n",
      "5/8, train_loss: 0.0128 step time: 0.2052\n",
      "6/8, train_loss: 0.0125 step time: 0.2034\n",
      "7/8, train_loss: 0.0129 step time: 0.1841\n",
      "8/8, train_loss: 0.0121 step time: 0.1834\n",
      "epoch 406 average loss: 0.0122\n",
      "time consuming of epoch 406 is: 1.6215\n",
      "----------\n",
      "epoch 407/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2433\n",
      "2/8, train_loss: 0.0124 step time: 0.2035\n",
      "3/8, train_loss: 0.0143 step time: 0.1999\n",
      "4/8, train_loss: 0.0130 step time: 0.2003\n",
      "5/8, train_loss: 0.0112 step time: 0.2008\n",
      "6/8, train_loss: 0.0113 step time: 0.2026\n",
      "7/8, train_loss: 0.0124 step time: 0.1823\n",
      "8/8, train_loss: 0.0142 step time: 0.1822\n",
      "epoch 407 average loss: 0.0125\n",
      "time consuming of epoch 407 is: 1.6164\n",
      "----------\n",
      "epoch 408/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2403\n",
      "2/8, train_loss: 0.0161 step time: 0.1998\n",
      "3/8, train_loss: 0.0108 step time: 0.1998\n",
      "4/8, train_loss: 0.0127 step time: 0.1995\n",
      "5/8, train_loss: 0.0123 step time: 0.2007\n",
      "6/8, train_loss: 0.0123 step time: 0.1974\n",
      "7/8, train_loss: 0.0136 step time: 0.1817\n",
      "8/8, train_loss: 0.0123 step time: 0.1808\n",
      "epoch 408 average loss: 0.0126\n",
      "time consuming of epoch 408 is: 1.6018\n",
      "----------\n",
      "epoch 409/600\n",
      "1/8, train_loss: 0.0112 step time: 0.2392\n",
      "2/8, train_loss: 0.0137 step time: 0.2067\n",
      "3/8, train_loss: 0.0132 step time: 0.2002\n",
      "4/8, train_loss: 0.0108 step time: 0.2010\n",
      "5/8, train_loss: 0.0115 step time: 0.1974\n",
      "6/8, train_loss: 0.0134 step time: 0.1995\n",
      "7/8, train_loss: 0.0121 step time: 0.1821\n",
      "8/8, train_loss: 0.0140 step time: 0.1820\n",
      "epoch 409 average loss: 0.0125\n",
      "time consuming of epoch 409 is: 1.6095\n",
      "----------\n",
      "epoch 410/600\n",
      "1/8, train_loss: 0.0124 step time: 0.2390\n",
      "2/8, train_loss: 0.0121 step time: 0.2023\n",
      "3/8, train_loss: 0.0148 step time: 0.2005\n",
      "4/8, train_loss: 0.0163 step time: 0.2024\n",
      "5/8, train_loss: 0.0101 step time: 0.2019\n",
      "6/8, train_loss: 0.0133 step time: 0.1986\n",
      "7/8, train_loss: 0.0159 step time: 0.1843\n",
      "8/8, train_loss: 0.0103 step time: 0.1818\n",
      "epoch 410 average loss: 0.0131\n",
      "current epoch: 410 current mean dice: 0.9578 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 410 is: 2.3666\n",
      "----------\n",
      "epoch 411/600\n",
      "1/8, train_loss: 0.0117 step time: 0.2361\n",
      "2/8, train_loss: 0.0129 step time: 0.1976\n",
      "3/8, train_loss: 0.0114 step time: 0.1998\n",
      "4/8, train_loss: 0.0122 step time: 0.1993\n",
      "5/8, train_loss: 0.0125 step time: 0.1994\n",
      "6/8, train_loss: 0.0113 step time: 0.2020\n",
      "7/8, train_loss: 0.0123 step time: 0.1813\n",
      "8/8, train_loss: 0.0156 step time: 0.1828\n",
      "epoch 411 average loss: 0.0125\n",
      "time consuming of epoch 411 is: 1.5994\n",
      "----------\n",
      "epoch 412/600\n",
      "1/8, train_loss: 0.0109 step time: 0.2399\n",
      "2/8, train_loss: 0.0120 step time: 0.2019\n",
      "3/8, train_loss: 0.0127 step time: 0.1987\n",
      "4/8, train_loss: 0.0125 step time: 0.2005\n",
      "5/8, train_loss: 0.0137 step time: 0.2019\n",
      "6/8, train_loss: 0.0139 step time: 0.2000\n",
      "7/8, train_loss: 0.0129 step time: 0.1826\n",
      "8/8, train_loss: 0.0117 step time: 0.1825\n",
      "epoch 412 average loss: 0.0125\n",
      "time consuming of epoch 412 is: 1.6098\n",
      "----------\n",
      "epoch 413/600\n",
      "1/8, train_loss: 0.0156 step time: 0.2453\n",
      "2/8, train_loss: 0.0136 step time: 0.2094\n",
      "3/8, train_loss: 0.0112 step time: 0.1992\n",
      "4/8, train_loss: 0.0124 step time: 0.2054\n",
      "5/8, train_loss: 0.0103 step time: 0.1985\n",
      "6/8, train_loss: 0.0117 step time: 0.2006\n",
      "7/8, train_loss: 0.0124 step time: 0.1825\n",
      "8/8, train_loss: 0.0138 step time: 0.1823\n",
      "epoch 413 average loss: 0.0126\n",
      "time consuming of epoch 413 is: 1.6248\n",
      "----------\n",
      "epoch 414/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0127 step time: 0.2401\n",
      "2/8, train_loss: 0.0150 step time: 0.1998\n",
      "3/8, train_loss: 0.0137 step time: 0.1993\n",
      "4/8, train_loss: 0.0121 step time: 0.2016\n",
      "5/8, train_loss: 0.0089 step time: 0.1982\n",
      "6/8, train_loss: 0.0120 step time: 0.1992\n",
      "7/8, train_loss: 0.0140 step time: 0.1819\n",
      "8/8, train_loss: 0.0110 step time: 0.1814\n",
      "epoch 414 average loss: 0.0124\n",
      "time consuming of epoch 414 is: 1.6030\n",
      "----------\n",
      "epoch 415/600\n",
      "1/8, train_loss: 0.0143 step time: 0.2406\n",
      "2/8, train_loss: 0.0119 step time: 0.2041\n",
      "3/8, train_loss: 0.0132 step time: 0.2005\n",
      "4/8, train_loss: 0.0114 step time: 0.2053\n",
      "5/8, train_loss: 0.0115 step time: 0.2005\n",
      "6/8, train_loss: 0.0144 step time: 0.2030\n",
      "7/8, train_loss: 0.0112 step time: 0.1845\n",
      "8/8, train_loss: 0.0113 step time: 0.1844\n",
      "epoch 415 average loss: 0.0124\n",
      "current epoch: 415 current mean dice: 0.9575 best mean dice: 0.9580 at epoch: 95\n",
      "time consuming of epoch 415 is: 2.3807\n",
      "----------\n",
      "epoch 416/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2361\n",
      "2/8, train_loss: 0.0127 step time: 0.1981\n",
      "3/8, train_loss: 0.0150 step time: 0.1996\n",
      "4/8, train_loss: 0.0122 step time: 0.2053\n",
      "5/8, train_loss: 0.0107 step time: 0.1962\n",
      "6/8, train_loss: 0.0115 step time: 0.1981\n",
      "7/8, train_loss: 0.0124 step time: 0.1813\n",
      "8/8, train_loss: 0.0117 step time: 0.1813\n",
      "epoch 416 average loss: 0.0124\n",
      "time consuming of epoch 416 is: 1.5972\n",
      "----------\n",
      "epoch 417/600\n",
      "1/8, train_loss: 0.0134 step time: 0.2408\n",
      "2/8, train_loss: 0.0111 step time: 0.2045\n",
      "3/8, train_loss: 0.0123 step time: 0.2040\n",
      "4/8, train_loss: 0.0122 step time: 0.1992\n",
      "5/8, train_loss: 0.0142 step time: 0.1987\n",
      "6/8, train_loss: 0.0111 step time: 0.2064\n",
      "7/8, train_loss: 0.0124 step time: 0.1826\n",
      "8/8, train_loss: 0.0137 step time: 0.1824\n",
      "epoch 417 average loss: 0.0126\n",
      "time consuming of epoch 417 is: 1.6199\n",
      "----------\n",
      "epoch 418/600\n",
      "1/8, train_loss: 0.0128 step time: 0.2382\n",
      "2/8, train_loss: 0.0116 step time: 0.2018\n",
      "3/8, train_loss: 0.0110 step time: 0.2034\n",
      "4/8, train_loss: 0.0141 step time: 0.2017\n",
      "5/8, train_loss: 0.0111 step time: 0.1995\n",
      "6/8, train_loss: 0.0143 step time: 0.2011\n",
      "7/8, train_loss: 0.0125 step time: 0.1829\n",
      "8/8, train_loss: 0.0114 step time: 0.1822\n",
      "epoch 418 average loss: 0.0123\n",
      "time consuming of epoch 418 is: 1.6125\n",
      "----------\n",
      "epoch 419/600\n",
      "1/8, train_loss: 0.0123 step time: 0.2364\n",
      "2/8, train_loss: 0.0131 step time: 0.2020\n",
      "3/8, train_loss: 0.0117 step time: 0.2012\n",
      "4/8, train_loss: 0.0101 step time: 0.1991\n",
      "5/8, train_loss: 0.0136 step time: 0.2037\n",
      "6/8, train_loss: 0.0122 step time: 0.1996\n",
      "7/8, train_loss: 0.0107 step time: 0.1843\n",
      "8/8, train_loss: 0.0115 step time: 0.1820\n",
      "epoch 419 average loss: 0.0119\n",
      "time consuming of epoch 419 is: 1.6102\n",
      "----------\n",
      "epoch 420/600\n",
      "1/8, train_loss: 0.0152 step time: 0.2363\n",
      "2/8, train_loss: 0.0162 step time: 0.1982\n",
      "3/8, train_loss: 0.0104 step time: 0.1974\n",
      "4/8, train_loss: 0.0121 step time: 0.1987\n",
      "5/8, train_loss: 0.0113 step time: 0.2008\n",
      "6/8, train_loss: 0.0128 step time: 0.1953\n",
      "7/8, train_loss: 0.0122 step time: 0.1847\n",
      "8/8, train_loss: 0.0134 step time: 0.1815\n",
      "epoch 420 average loss: 0.0129\n",
      "saved new best metric model\n",
      "current epoch: 420 current mean dice: 0.9580 best mean dice: 0.9580 at epoch: 420\n",
      "time consuming of epoch 420 is: 2.4882\n",
      "----------\n",
      "epoch 421/600\n",
      "1/8, train_loss: 0.0136 step time: 0.2374\n",
      "2/8, train_loss: 0.0105 step time: 0.1997\n",
      "3/8, train_loss: 0.0103 step time: 0.1998\n",
      "4/8, train_loss: 0.0134 step time: 0.1997\n",
      "5/8, train_loss: 0.0140 step time: 0.1996\n",
      "6/8, train_loss: 0.0128 step time: 0.2024\n",
      "7/8, train_loss: 0.0110 step time: 0.1805\n",
      "8/8, train_loss: 0.0135 step time: 0.1809\n",
      "epoch 421 average loss: 0.0124\n",
      "time consuming of epoch 421 is: 1.6012\n",
      "----------\n",
      "epoch 422/600\n",
      "1/8, train_loss: 0.0132 step time: 0.2370\n",
      "2/8, train_loss: 0.0125 step time: 0.2087\n",
      "3/8, train_loss: 0.0115 step time: 0.2052\n",
      "4/8, train_loss: 0.0119 step time: 0.2061\n",
      "5/8, train_loss: 0.0125 step time: 0.1999\n",
      "6/8, train_loss: 0.0116 step time: 0.2041\n",
      "7/8, train_loss: 0.0130 step time: 0.1829\n",
      "8/8, train_loss: 0.0144 step time: 0.1822\n",
      "epoch 422 average loss: 0.0126\n",
      "time consuming of epoch 422 is: 1.6275\n",
      "----------\n",
      "epoch 423/600\n",
      "1/8, train_loss: 0.0146 step time: 0.2422\n",
      "2/8, train_loss: 0.0137 step time: 0.2023\n",
      "3/8, train_loss: 0.0104 step time: 0.2016\n",
      "4/8, train_loss: 0.0127 step time: 0.1994\n",
      "5/8, train_loss: 0.0138 step time: 0.2002\n",
      "6/8, train_loss: 0.0124 step time: 0.2016\n",
      "7/8, train_loss: 0.0149 step time: 0.1824\n",
      "8/8, train_loss: 0.0093 step time: 0.1812\n",
      "epoch 423 average loss: 0.0127\n",
      "time consuming of epoch 423 is: 1.6125\n",
      "----------\n",
      "epoch 424/600\n",
      "1/8, train_loss: 0.0134 step time: 0.2382\n",
      "2/8, train_loss: 0.0132 step time: 0.2024\n",
      "3/8, train_loss: 0.0122 step time: 0.2079\n",
      "4/8, train_loss: 0.0104 step time: 0.2018\n",
      "5/8, train_loss: 0.0126 step time: 0.2020\n",
      "6/8, train_loss: 0.0136 step time: 0.1981\n",
      "7/8, train_loss: 0.0138 step time: 0.1844\n",
      "8/8, train_loss: 0.0121 step time: 0.1814\n",
      "epoch 424 average loss: 0.0127\n",
      "time consuming of epoch 424 is: 1.6176\n",
      "----------\n",
      "epoch 425/600\n",
      "1/8, train_loss: 0.0127 step time: 0.2401\n",
      "2/8, train_loss: 0.0141 step time: 0.2030\n",
      "3/8, train_loss: 0.0148 step time: 0.2013\n",
      "4/8, train_loss: 0.0112 step time: 0.1995\n",
      "5/8, train_loss: 0.0113 step time: 0.2029\n",
      "6/8, train_loss: 0.0123 step time: 0.1993\n",
      "7/8, train_loss: 0.0118 step time: 0.1835\n",
      "8/8, train_loss: 0.0103 step time: 0.1827\n",
      "epoch 425 average loss: 0.0123\n",
      "saved new best metric model\n",
      "current epoch: 425 current mean dice: 0.9587 best mean dice: 0.9587 at epoch: 425\n",
      "time consuming of epoch 425 is: 2.5081\n",
      "----------\n",
      "epoch 426/600\n",
      "1/8, train_loss: 0.0115 step time: 0.2404\n",
      "2/8, train_loss: 0.0143 step time: 0.1992\n",
      "3/8, train_loss: 0.0102 step time: 0.1991\n",
      "4/8, train_loss: 0.0117 step time: 0.1970\n",
      "5/8, train_loss: 0.0153 step time: 0.2011\n",
      "6/8, train_loss: 0.0113 step time: 0.2000\n",
      "7/8, train_loss: 0.0119 step time: 0.1841\n",
      "8/8, train_loss: 0.0146 step time: 0.1813\n",
      "epoch 426 average loss: 0.0126\n",
      "time consuming of epoch 426 is: 1.6033\n",
      "----------\n",
      "epoch 427/600\n",
      "1/8, train_loss: 0.0122 step time: 0.2375\n",
      "2/8, train_loss: 0.0109 step time: 0.2033\n",
      "3/8, train_loss: 0.0146 step time: 0.2011\n",
      "4/8, train_loss: 0.0116 step time: 0.1979\n",
      "5/8, train_loss: 0.0111 step time: 0.2015\n",
      "6/8, train_loss: 0.0132 step time: 0.1998\n",
      "7/8, train_loss: 0.0121 step time: 0.1850\n",
      "8/8, train_loss: 0.0129 step time: 0.1843\n",
      "epoch 427 average loss: 0.0123\n",
      "time consuming of epoch 427 is: 1.6118\n",
      "----------\n",
      "epoch 428/600\n",
      "1/8, train_loss: 0.0126 step time: 0.2388\n",
      "2/8, train_loss: 0.0126 step time: 0.2003\n",
      "3/8, train_loss: 0.0112 step time: 0.1958\n",
      "4/8, train_loss: 0.0113 step time: 0.2002\n",
      "5/8, train_loss: 0.0121 step time: 0.2016\n",
      "6/8, train_loss: 0.0116 step time: 0.2034\n",
      "7/8, train_loss: 0.0128 step time: 0.1814\n",
      "8/8, train_loss: 0.0134 step time: 0.1821\n",
      "epoch 428 average loss: 0.0122\n",
      "time consuming of epoch 428 is: 1.6049\n",
      "----------\n",
      "epoch 429/600\n",
      "1/8, train_loss: 0.0135 step time: 0.2413\n",
      "2/8, train_loss: 0.0146 step time: 0.2019\n",
      "3/8, train_loss: 0.0101 step time: 0.2019\n",
      "4/8, train_loss: 0.0130 step time: 0.2024\n",
      "5/8, train_loss: 0.0124 step time: 0.1991\n",
      "6/8, train_loss: 0.0146 step time: 0.2000\n",
      "7/8, train_loss: 0.0111 step time: 0.1808\n",
      "8/8, train_loss: 0.0109 step time: 0.1795\n",
      "epoch 429 average loss: 0.0125\n",
      "time consuming of epoch 429 is: 1.6083\n",
      "----------\n",
      "epoch 430/600\n",
      "1/8, train_loss: 0.0117 step time: 0.2373\n",
      "2/8, train_loss: 0.0126 step time: 0.1961\n",
      "3/8, train_loss: 0.0136 step time: 0.1996\n",
      "4/8, train_loss: 0.0163 step time: 0.1972\n",
      "5/8, train_loss: 0.0146 step time: 0.1965\n",
      "6/8, train_loss: 0.0110 step time: 0.1995\n",
      "7/8, train_loss: 0.0121 step time: 0.1804\n",
      "8/8, train_loss: 0.0133 step time: 0.1801\n",
      "epoch 430 average loss: 0.0131\n",
      "current epoch: 430 current mean dice: 0.9583 best mean dice: 0.9587 at epoch: 425\n",
      "time consuming of epoch 430 is: 2.3405\n",
      "----------\n",
      "epoch 431/600\n",
      "1/8, train_loss: 0.0119 step time: 0.2317\n",
      "2/8, train_loss: 0.0097 step time: 0.1996\n",
      "3/8, train_loss: 0.0135 step time: 0.1974\n",
      "4/8, train_loss: 0.0148 step time: 0.1941\n",
      "5/8, train_loss: 0.0141 step time: 0.1960\n",
      "6/8, train_loss: 0.0125 step time: 0.1940\n",
      "7/8, train_loss: 0.0123 step time: 0.1815\n",
      "8/8, train_loss: 0.0112 step time: 0.1823\n",
      "epoch 431 average loss: 0.0125\n",
      "time consuming of epoch 431 is: 1.5777\n",
      "----------\n",
      "epoch 432/600\n",
      "1/8, train_loss: 0.0117 step time: 0.2440\n",
      "2/8, train_loss: 0.0117 step time: 0.2033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8, train_loss: 0.0120 step time: 0.2025\n",
      "4/8, train_loss: 0.0147 step time: 0.2005\n",
      "5/8, train_loss: 0.0123 step time: 0.2017\n",
      "6/8, train_loss: 0.0132 step time: 0.1994\n",
      "7/8, train_loss: 0.0121 step time: 0.1827\n",
      "8/8, train_loss: 0.0103 step time: 0.1815\n",
      "epoch 432 average loss: 0.0123\n",
      "time consuming of epoch 432 is: 1.6170\n",
      "----------\n",
      "epoch 433/600\n",
      "1/8, train_loss: 0.0117 step time: 0.2476\n",
      "2/8, train_loss: 0.0137 step time: 0.2052\n",
      "3/8, train_loss: 0.0133 step time: 0.2001\n",
      "4/8, train_loss: 0.0119 step time: 0.2011\n",
      "5/8, train_loss: 0.0112 step time: 0.1997\n",
      "6/8, train_loss: 0.0118 step time: 0.1980\n",
      "7/8, train_loss: 0.0120 step time: 0.1820\n",
      "8/8, train_loss: 0.0132 step time: 0.1815\n",
      "epoch 433 average loss: 0.0123\n",
      "time consuming of epoch 433 is: 1.6166\n",
      "----------\n",
      "epoch 434/600\n",
      "1/8, train_loss: 0.0128 step time: 0.2385\n",
      "2/8, train_loss: 0.0113 step time: 0.1976\n",
      "3/8, train_loss: 0.0119 step time: 0.2000\n",
      "4/8, train_loss: 0.0118 step time: 0.1983\n",
      "5/8, train_loss: 0.0119 step time: 0.2017\n",
      "6/8, train_loss: 0.0111 step time: 0.1998\n",
      "7/8, train_loss: 0.0117 step time: 0.1829\n",
      "8/8, train_loss: 0.0114 step time: 0.1825\n",
      "epoch 434 average loss: 0.0118\n",
      "time consuming of epoch 434 is: 1.6025\n",
      "----------\n",
      "epoch 435/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2410\n",
      "2/8, train_loss: 0.0142 step time: 0.1995\n",
      "3/8, train_loss: 0.0138 step time: 0.2023\n",
      "4/8, train_loss: 0.0124 step time: 0.1989\n",
      "5/8, train_loss: 0.0110 step time: 0.2041\n",
      "6/8, train_loss: 0.0156 step time: 0.2041\n",
      "7/8, train_loss: 0.0112 step time: 0.1839\n",
      "8/8, train_loss: 0.0105 step time: 0.1818\n",
      "epoch 435 average loss: 0.0124\n",
      "current epoch: 435 current mean dice: 0.9572 best mean dice: 0.9587 at epoch: 425\n",
      "time consuming of epoch 435 is: 2.3731\n",
      "----------\n",
      "epoch 436/600\n",
      "1/8, train_loss: 0.0111 step time: 0.2333\n",
      "2/8, train_loss: 0.0115 step time: 0.2037\n",
      "3/8, train_loss: 0.0134 step time: 0.1921\n",
      "4/8, train_loss: 0.0130 step time: 0.1985\n",
      "5/8, train_loss: 0.0118 step time: 0.1978\n",
      "6/8, train_loss: 0.0119 step time: 0.2013\n",
      "7/8, train_loss: 0.0103 step time: 0.1855\n",
      "8/8, train_loss: 0.0151 step time: 0.1822\n",
      "epoch 436 average loss: 0.0122\n",
      "time consuming of epoch 436 is: 1.5956\n",
      "----------\n",
      "epoch 437/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2290\n",
      "2/8, train_loss: 0.0107 step time: 0.1953\n",
      "3/8, train_loss: 0.0110 step time: 0.1978\n",
      "4/8, train_loss: 0.0125 step time: 0.1999\n",
      "5/8, train_loss: 0.0146 step time: 0.1993\n",
      "6/8, train_loss: 0.0154 step time: 0.2026\n",
      "7/8, train_loss: 0.0111 step time: 0.1846\n",
      "8/8, train_loss: 0.0135 step time: 0.1827\n",
      "epoch 437 average loss: 0.0124\n",
      "time consuming of epoch 437 is: 1.5924\n",
      "----------\n",
      "epoch 438/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2408\n",
      "2/8, train_loss: 0.0125 step time: 0.2028\n",
      "3/8, train_loss: 0.0131 step time: 0.2013\n",
      "4/8, train_loss: 0.0135 step time: 0.1984\n",
      "5/8, train_loss: 0.0111 step time: 0.2011\n",
      "6/8, train_loss: 0.0163 step time: 0.2005\n",
      "7/8, train_loss: 0.0122 step time: 0.1821\n",
      "8/8, train_loss: 0.0107 step time: 0.1848\n",
      "epoch 438 average loss: 0.0125\n",
      "time consuming of epoch 438 is: 1.6132\n",
      "----------\n",
      "epoch 439/600\n",
      "1/8, train_loss: 0.0108 step time: 0.2402\n",
      "2/8, train_loss: 0.0117 step time: 0.1999\n",
      "3/8, train_loss: 0.0110 step time: 0.1987\n",
      "4/8, train_loss: 0.0114 step time: 0.2036\n",
      "5/8, train_loss: 0.0127 step time: 0.2063\n",
      "6/8, train_loss: 0.0109 step time: 0.2024\n",
      "7/8, train_loss: 0.0130 step time: 0.1810\n",
      "8/8, train_loss: 0.0143 step time: 0.1804\n",
      "epoch 439 average loss: 0.0120\n",
      "time consuming of epoch 439 is: 1.6138\n",
      "----------\n",
      "epoch 440/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2450\n",
      "2/8, train_loss: 0.0140 step time: 0.2011\n",
      "3/8, train_loss: 0.0137 step time: 0.2023\n",
      "4/8, train_loss: 0.0133 step time: 0.2031\n",
      "5/8, train_loss: 0.0107 step time: 0.1983\n",
      "6/8, train_loss: 0.0119 step time: 0.2033\n",
      "7/8, train_loss: 0.0116 step time: 0.1865\n",
      "8/8, train_loss: 0.0118 step time: 0.1858\n",
      "epoch 440 average loss: 0.0124\n",
      "current epoch: 440 current mean dice: 0.9582 best mean dice: 0.9587 at epoch: 425\n",
      "time consuming of epoch 440 is: 2.3816\n",
      "----------\n",
      "epoch 441/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2375\n",
      "2/8, train_loss: 0.0136 step time: 0.2026\n",
      "3/8, train_loss: 0.0140 step time: 0.1985\n",
      "4/8, train_loss: 0.0124 step time: 0.2022\n",
      "5/8, train_loss: 0.0132 step time: 0.1986\n",
      "6/8, train_loss: 0.0127 step time: 0.1989\n",
      "7/8, train_loss: 0.0104 step time: 0.1827\n",
      "8/8, train_loss: 0.0115 step time: 0.1824\n",
      "epoch 441 average loss: 0.0123\n",
      "time consuming of epoch 441 is: 1.6045\n",
      "----------\n",
      "epoch 442/600\n",
      "1/8, train_loss: 0.0130 step time: 0.2402\n",
      "2/8, train_loss: 0.0116 step time: 0.2006\n",
      "3/8, train_loss: 0.0102 step time: 0.2000\n",
      "4/8, train_loss: 0.0126 step time: 0.2018\n",
      "5/8, train_loss: 0.0120 step time: 0.1994\n",
      "6/8, train_loss: 0.0112 step time: 0.2003\n",
      "7/8, train_loss: 0.0143 step time: 0.1829\n",
      "8/8, train_loss: 0.0129 step time: 0.1827\n",
      "epoch 442 average loss: 0.0122\n",
      "time consuming of epoch 442 is: 1.6091\n",
      "----------\n",
      "epoch 443/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2396\n",
      "2/8, train_loss: 0.0144 step time: 0.2025\n",
      "3/8, train_loss: 0.0114 step time: 0.1994\n",
      "4/8, train_loss: 0.0117 step time: 0.2010\n",
      "5/8, train_loss: 0.0135 step time: 0.2006\n",
      "6/8, train_loss: 0.0116 step time: 0.2013\n",
      "7/8, train_loss: 0.0111 step time: 0.1851\n",
      "8/8, train_loss: 0.0137 step time: 0.1836\n",
      "epoch 443 average loss: 0.0125\n",
      "time consuming of epoch 443 is: 1.6148\n",
      "----------\n",
      "epoch 444/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2425\n",
      "2/8, train_loss: 0.0130 step time: 0.2020\n",
      "3/8, train_loss: 0.0121 step time: 0.2043\n",
      "4/8, train_loss: 0.0145 step time: 0.1983\n",
      "5/8, train_loss: 0.0128 step time: 0.2011\n",
      "6/8, train_loss: 0.0117 step time: 0.2017\n",
      "7/8, train_loss: 0.0119 step time: 0.1827\n",
      "8/8, train_loss: 0.0126 step time: 0.1831\n",
      "epoch 444 average loss: 0.0126\n",
      "time consuming of epoch 444 is: 1.6170\n",
      "----------\n",
      "epoch 445/600\n",
      "1/8, train_loss: 0.0117 step time: 0.2398\n",
      "2/8, train_loss: 0.0123 step time: 0.2020\n",
      "3/8, train_loss: 0.0110 step time: 0.2033\n",
      "4/8, train_loss: 0.0145 step time: 0.1997\n",
      "5/8, train_loss: 0.0103 step time: 0.2023\n",
      "6/8, train_loss: 0.0104 step time: 0.1981\n",
      "7/8, train_loss: 0.0115 step time: 0.1821\n",
      "8/8, train_loss: 0.0140 step time: 0.1828\n",
      "epoch 445 average loss: 0.0120\n",
      "current epoch: 445 current mean dice: 0.9585 best mean dice: 0.9587 at epoch: 425\n",
      "time consuming of epoch 445 is: 2.3667\n",
      "----------\n",
      "epoch 446/600\n",
      "1/8, train_loss: 0.0115 step time: 0.2361\n",
      "2/8, train_loss: 0.0116 step time: 0.1993\n",
      "3/8, train_loss: 0.0125 step time: 0.2057\n",
      "4/8, train_loss: 0.0118 step time: 0.1989\n",
      "5/8, train_loss: 0.0129 step time: 0.1991\n",
      "6/8, train_loss: 0.0128 step time: 0.1985\n",
      "7/8, train_loss: 0.0131 step time: 0.1812\n",
      "8/8, train_loss: 0.0118 step time: 0.1818\n",
      "epoch 446 average loss: 0.0123\n",
      "time consuming of epoch 446 is: 1.6018\n",
      "----------\n",
      "epoch 447/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2405\n",
      "2/8, train_loss: 0.0137 step time: 0.2004\n",
      "3/8, train_loss: 0.0124 step time: 0.1983\n",
      "4/8, train_loss: 0.0132 step time: 0.2004\n",
      "5/8, train_loss: 0.0122 step time: 0.2025\n",
      "6/8, train_loss: 0.0133 step time: 0.2057\n",
      "7/8, train_loss: 0.0100 step time: 0.1814\n",
      "8/8, train_loss: 0.0141 step time: 0.1843\n",
      "epoch 447 average loss: 0.0124\n",
      "time consuming of epoch 447 is: 1.6150\n",
      "----------\n",
      "epoch 448/600\n",
      "1/8, train_loss: 0.0152 step time: 0.2408\n",
      "2/8, train_loss: 0.0135 step time: 0.2042\n",
      "3/8, train_loss: 0.0105 step time: 0.2035\n",
      "4/8, train_loss: 0.0120 step time: 0.2016\n",
      "5/8, train_loss: 0.0136 step time: 0.1985\n",
      "6/8, train_loss: 0.0131 step time: 0.2053\n",
      "7/8, train_loss: 0.0106 step time: 0.1821\n",
      "8/8, train_loss: 0.0135 step time: 0.1832\n",
      "epoch 448 average loss: 0.0128\n",
      "time consuming of epoch 448 is: 1.6206\n",
      "----------\n",
      "epoch 449/600\n",
      "1/8, train_loss: 0.0129 step time: 0.2385\n",
      "2/8, train_loss: 0.0126 step time: 0.2021\n",
      "3/8, train_loss: 0.0126 step time: 0.2020\n",
      "4/8, train_loss: 0.0122 step time: 0.2002\n",
      "5/8, train_loss: 0.0100 step time: 0.1994\n",
      "6/8, train_loss: 0.0129 step time: 0.2031\n",
      "7/8, train_loss: 0.0140 step time: 0.1824\n",
      "8/8, train_loss: 0.0110 step time: 0.1822\n",
      "epoch 449 average loss: 0.0123\n",
      "time consuming of epoch 449 is: 1.6115\n",
      "----------\n",
      "epoch 450/600\n",
      "1/8, train_loss: 0.0119 step time: 0.2412\n",
      "2/8, train_loss: 0.0103 step time: 0.2000\n",
      "3/8, train_loss: 0.0112 step time: 0.2010\n",
      "4/8, train_loss: 0.0135 step time: 0.2016\n",
      "5/8, train_loss: 0.0117 step time: 0.2019\n",
      "6/8, train_loss: 0.0103 step time: 0.2030\n",
      "7/8, train_loss: 0.0115 step time: 0.1817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8, train_loss: 0.0113 step time: 0.1837\n",
      "epoch 450 average loss: 0.0115\n",
      "current epoch: 450 current mean dice: 0.9585 best mean dice: 0.9587 at epoch: 425\n",
      "time consuming of epoch 450 is: 2.3716\n",
      "----------\n",
      "epoch 451/600\n",
      "1/8, train_loss: 0.0115 step time: 0.2360\n",
      "2/8, train_loss: 0.0134 step time: 0.1947\n",
      "3/8, train_loss: 0.0128 step time: 0.2023\n",
      "4/8, train_loss: 0.0106 step time: 0.1986\n",
      "5/8, train_loss: 0.0121 step time: 0.1985\n",
      "6/8, train_loss: 0.0115 step time: 0.2005\n",
      "7/8, train_loss: 0.0130 step time: 0.1822\n",
      "8/8, train_loss: 0.0105 step time: 0.1814\n",
      "epoch 451 average loss: 0.0119\n",
      "time consuming of epoch 451 is: 1.5952\n",
      "----------\n",
      "epoch 452/600\n",
      "1/8, train_loss: 0.0112 step time: 0.2369\n",
      "2/8, train_loss: 0.0121 step time: 0.2001\n",
      "3/8, train_loss: 0.0120 step time: 0.2021\n",
      "4/8, train_loss: 0.0122 step time: 0.2045\n",
      "5/8, train_loss: 0.0127 step time: 0.2048\n",
      "6/8, train_loss: 0.0107 step time: 0.2027\n",
      "7/8, train_loss: 0.0144 step time: 0.1832\n",
      "8/8, train_loss: 0.0122 step time: 0.1837\n",
      "epoch 452 average loss: 0.0122\n",
      "time consuming of epoch 452 is: 1.6195\n",
      "----------\n",
      "epoch 453/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2443\n",
      "2/8, train_loss: 0.0109 step time: 0.2031\n",
      "3/8, train_loss: 0.0113 step time: 0.1989\n",
      "4/8, train_loss: 0.0143 step time: 0.2023\n",
      "5/8, train_loss: 0.0123 step time: 0.2011\n",
      "6/8, train_loss: 0.0147 step time: 0.2029\n",
      "7/8, train_loss: 0.0109 step time: 0.1862\n",
      "8/8, train_loss: 0.0133 step time: 0.1828\n",
      "epoch 453 average loss: 0.0123\n",
      "time consuming of epoch 453 is: 1.6229\n",
      "----------\n",
      "epoch 454/600\n",
      "1/8, train_loss: 0.0122 step time: 0.2414\n",
      "2/8, train_loss: 0.0106 step time: 0.2032\n",
      "3/8, train_loss: 0.0111 step time: 0.2003\n",
      "4/8, train_loss: 0.0173 step time: 0.2023\n",
      "5/8, train_loss: 0.0132 step time: 0.2041\n",
      "6/8, train_loss: 0.0115 step time: 0.2031\n",
      "7/8, train_loss: 0.0106 step time: 0.1830\n",
      "8/8, train_loss: 0.0128 step time: 0.1818\n",
      "epoch 454 average loss: 0.0124\n",
      "time consuming of epoch 454 is: 1.6209\n",
      "----------\n",
      "epoch 455/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2430\n",
      "2/8, train_loss: 0.0142 step time: 0.2020\n",
      "3/8, train_loss: 0.0115 step time: 0.1970\n",
      "4/8, train_loss: 0.0118 step time: 0.1913\n",
      "5/8, train_loss: 0.0105 step time: 0.1928\n",
      "6/8, train_loss: 0.0116 step time: 0.1918\n",
      "7/8, train_loss: 0.0127 step time: 0.1813\n",
      "8/8, train_loss: 0.0130 step time: 0.1828\n",
      "epoch 455 average loss: 0.0123\n",
      "saved new best metric model\n",
      "current epoch: 455 current mean dice: 0.9590 best mean dice: 0.9590 at epoch: 455\n",
      "time consuming of epoch 455 is: 2.4812\n",
      "----------\n",
      "epoch 456/600\n",
      "1/8, train_loss: 0.0119 step time: 0.2306\n",
      "2/8, train_loss: 0.0117 step time: 0.1999\n",
      "3/8, train_loss: 0.0119 step time: 0.2026\n",
      "4/8, train_loss: 0.0137 step time: 0.2017\n",
      "5/8, train_loss: 0.0120 step time: 0.1988\n",
      "6/8, train_loss: 0.0113 step time: 0.1982\n",
      "7/8, train_loss: 0.0103 step time: 0.1827\n",
      "8/8, train_loss: 0.0124 step time: 0.1835\n",
      "epoch 456 average loss: 0.0119\n",
      "time consuming of epoch 456 is: 1.5993\n",
      "----------\n",
      "epoch 457/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2395\n",
      "2/8, train_loss: 0.0112 step time: 0.1977\n",
      "3/8, train_loss: 0.0107 step time: 0.1972\n",
      "4/8, train_loss: 0.0110 step time: 0.1965\n",
      "5/8, train_loss: 0.0106 step time: 0.1961\n",
      "6/8, train_loss: 0.0112 step time: 0.1975\n",
      "7/8, train_loss: 0.0108 step time: 0.1831\n",
      "8/8, train_loss: 0.0146 step time: 0.1818\n",
      "epoch 457 average loss: 0.0116\n",
      "time consuming of epoch 457 is: 1.5910\n",
      "----------\n",
      "epoch 458/600\n",
      "1/8, train_loss: 0.0127 step time: 0.2416\n",
      "2/8, train_loss: 0.0126 step time: 0.2018\n",
      "3/8, train_loss: 0.0140 step time: 0.2004\n",
      "4/8, train_loss: 0.0123 step time: 0.2009\n",
      "5/8, train_loss: 0.0115 step time: 0.2006\n",
      "6/8, train_loss: 0.0119 step time: 0.2001\n",
      "7/8, train_loss: 0.0108 step time: 0.1826\n",
      "8/8, train_loss: 0.0110 step time: 0.1838\n",
      "epoch 458 average loss: 0.0121\n",
      "time consuming of epoch 458 is: 1.6134\n",
      "----------\n",
      "epoch 459/600\n",
      "1/8, train_loss: 0.0124 step time: 0.2383\n",
      "2/8, train_loss: 0.0116 step time: 0.1998\n",
      "3/8, train_loss: 0.0116 step time: 0.1988\n",
      "4/8, train_loss: 0.0122 step time: 0.2022\n",
      "5/8, train_loss: 0.0115 step time: 0.2037\n",
      "6/8, train_loss: 0.0168 step time: 0.2000\n",
      "7/8, train_loss: 0.0124 step time: 0.1849\n",
      "8/8, train_loss: 0.0117 step time: 0.1822\n",
      "epoch 459 average loss: 0.0125\n",
      "time consuming of epoch 459 is: 1.6112\n",
      "----------\n",
      "epoch 460/600\n",
      "1/8, train_loss: 0.0100 step time: 0.2365\n",
      "2/8, train_loss: 0.0155 step time: 0.1981\n",
      "3/8, train_loss: 0.0127 step time: 0.1994\n",
      "4/8, train_loss: 0.0100 step time: 0.1973\n",
      "5/8, train_loss: 0.0119 step time: 0.1973\n",
      "6/8, train_loss: 0.0126 step time: 0.1968\n",
      "7/8, train_loss: 0.0111 step time: 0.1836\n",
      "8/8, train_loss: 0.0117 step time: 0.1832\n",
      "epoch 460 average loss: 0.0119\n",
      "current epoch: 460 current mean dice: 0.9589 best mean dice: 0.9590 at epoch: 455\n",
      "time consuming of epoch 460 is: 2.3494\n",
      "----------\n",
      "epoch 461/600\n",
      "1/8, train_loss: 0.0126 step time: 0.2415\n",
      "2/8, train_loss: 0.0117 step time: 0.2032\n",
      "3/8, train_loss: 0.0118 step time: 0.1982\n",
      "4/8, train_loss: 0.0148 step time: 0.1991\n",
      "5/8, train_loss: 0.0103 step time: 0.1981\n",
      "6/8, train_loss: 0.0098 step time: 0.2015\n",
      "7/8, train_loss: 0.0118 step time: 0.1812\n",
      "8/8, train_loss: 0.0133 step time: 0.1814\n",
      "epoch 461 average loss: 0.0120\n",
      "time consuming of epoch 461 is: 1.6052\n",
      "----------\n",
      "epoch 462/600\n",
      "1/8, train_loss: 0.0120 step time: 0.2410\n",
      "2/8, train_loss: 0.0127 step time: 0.2033\n",
      "3/8, train_loss: 0.0110 step time: 0.2032\n",
      "4/8, train_loss: 0.0112 step time: 0.1990\n",
      "5/8, train_loss: 0.0119 step time: 0.2069\n",
      "6/8, train_loss: 0.0117 step time: 0.2025\n",
      "7/8, train_loss: 0.0125 step time: 0.1829\n",
      "8/8, train_loss: 0.0139 step time: 0.1825\n",
      "epoch 462 average loss: 0.0121\n",
      "time consuming of epoch 462 is: 1.6226\n",
      "----------\n",
      "epoch 463/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2380\n",
      "2/8, train_loss: 0.0109 step time: 0.2012\n",
      "3/8, train_loss: 0.0146 step time: 0.2019\n",
      "4/8, train_loss: 0.0105 step time: 0.1979\n",
      "5/8, train_loss: 0.0132 step time: 0.2020\n",
      "6/8, train_loss: 0.0135 step time: 0.1974\n",
      "7/8, train_loss: 0.0137 step time: 0.1827\n",
      "8/8, train_loss: 0.0100 step time: 0.1826\n",
      "epoch 463 average loss: 0.0121\n",
      "time consuming of epoch 463 is: 1.6055\n",
      "----------\n",
      "epoch 464/600\n",
      "1/8, train_loss: 0.0127 step time: 0.2361\n",
      "2/8, train_loss: 0.0121 step time: 0.2002\n",
      "3/8, train_loss: 0.0131 step time: 0.1999\n",
      "4/8, train_loss: 0.0101 step time: 0.1989\n",
      "5/8, train_loss: 0.0103 step time: 0.2061\n",
      "6/8, train_loss: 0.0118 step time: 0.2032\n",
      "7/8, train_loss: 0.0122 step time: 0.1813\n",
      "8/8, train_loss: 0.0124 step time: 0.1828\n",
      "epoch 464 average loss: 0.0118\n",
      "time consuming of epoch 464 is: 1.6102\n",
      "----------\n",
      "epoch 465/600\n",
      "1/8, train_loss: 0.0123 step time: 0.2412\n",
      "2/8, train_loss: 0.0131 step time: 0.1984\n",
      "3/8, train_loss: 0.0120 step time: 0.2006\n",
      "4/8, train_loss: 0.0115 step time: 0.2014\n",
      "5/8, train_loss: 0.0118 step time: 0.2018\n",
      "6/8, train_loss: 0.0107 step time: 0.2018\n",
      "7/8, train_loss: 0.0130 step time: 0.1823\n",
      "8/8, train_loss: 0.0118 step time: 0.1826\n",
      "epoch 465 average loss: 0.0120\n",
      "current epoch: 465 current mean dice: 0.9589 best mean dice: 0.9590 at epoch: 455\n",
      "time consuming of epoch 465 is: 2.3682\n",
      "----------\n",
      "epoch 466/600\n",
      "1/8, train_loss: 0.0122 step time: 0.2375\n",
      "2/8, train_loss: 0.0114 step time: 0.2006\n",
      "3/8, train_loss: 0.0123 step time: 0.1988\n",
      "4/8, train_loss: 0.0116 step time: 0.1992\n",
      "5/8, train_loss: 0.0137 step time: 0.1986\n",
      "6/8, train_loss: 0.0114 step time: 0.2031\n",
      "7/8, train_loss: 0.0122 step time: 0.1850\n",
      "8/8, train_loss: 0.0119 step time: 0.1807\n",
      "epoch 466 average loss: 0.0121\n",
      "time consuming of epoch 466 is: 1.6046\n",
      "----------\n",
      "epoch 467/600\n",
      "1/8, train_loss: 0.0121 step time: 0.2375\n",
      "2/8, train_loss: 0.0135 step time: 0.2025\n",
      "3/8, train_loss: 0.0109 step time: 0.2028\n",
      "4/8, train_loss: 0.0123 step time: 0.2016\n",
      "5/8, train_loss: 0.0126 step time: 0.2003\n",
      "6/8, train_loss: 0.0131 step time: 0.2038\n",
      "7/8, train_loss: 0.0109 step time: 0.1814\n",
      "8/8, train_loss: 0.0092 step time: 0.1845\n",
      "epoch 467 average loss: 0.0118\n",
      "time consuming of epoch 467 is: 1.6156\n",
      "----------\n",
      "epoch 468/600\n",
      "1/8, train_loss: 0.0120 step time: 0.2413\n",
      "2/8, train_loss: 0.0120 step time: 0.2022\n",
      "3/8, train_loss: 0.0117 step time: 0.2035\n",
      "4/8, train_loss: 0.0105 step time: 0.1977\n",
      "5/8, train_loss: 0.0143 step time: 0.2019\n",
      "6/8, train_loss: 0.0120 step time: 0.1999\n",
      "7/8, train_loss: 0.0129 step time: 0.1829\n",
      "8/8, train_loss: 0.0113 step time: 0.1815\n",
      "epoch 468 average loss: 0.0121\n",
      "time consuming of epoch 468 is: 1.6123\n",
      "----------\n",
      "epoch 469/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0139 step time: 0.2405\n",
      "2/8, train_loss: 0.0099 step time: 0.2003\n",
      "3/8, train_loss: 0.0128 step time: 0.2024\n",
      "4/8, train_loss: 0.0113 step time: 0.2015\n",
      "5/8, train_loss: 0.0114 step time: 0.2020\n",
      "6/8, train_loss: 0.0109 step time: 0.2009\n",
      "7/8, train_loss: 0.0146 step time: 0.1831\n",
      "8/8, train_loss: 0.0140 step time: 0.1827\n",
      "epoch 469 average loss: 0.0124\n",
      "time consuming of epoch 469 is: 1.6148\n",
      "----------\n",
      "epoch 470/600\n",
      "1/8, train_loss: 0.0127 step time: 0.2411\n",
      "2/8, train_loss: 0.0117 step time: 0.2061\n",
      "3/8, train_loss: 0.0111 step time: 0.2012\n",
      "4/8, train_loss: 0.0143 step time: 0.1985\n",
      "5/8, train_loss: 0.0113 step time: 0.2040\n",
      "6/8, train_loss: 0.0116 step time: 0.2006\n",
      "7/8, train_loss: 0.0098 step time: 0.1831\n",
      "8/8, train_loss: 0.0121 step time: 0.1825\n",
      "epoch 470 average loss: 0.0118\n",
      "current epoch: 470 current mean dice: 0.9579 best mean dice: 0.9590 at epoch: 455\n",
      "time consuming of epoch 470 is: 2.3899\n",
      "----------\n",
      "epoch 471/600\n",
      "1/8, train_loss: 0.0132 step time: 0.2362\n",
      "2/8, train_loss: 0.0132 step time: 0.1964\n",
      "3/8, train_loss: 0.0120 step time: 0.1936\n",
      "4/8, train_loss: 0.0130 step time: 0.1964\n",
      "5/8, train_loss: 0.0104 step time: 0.1963\n",
      "6/8, train_loss: 0.0123 step time: 0.2015\n",
      "7/8, train_loss: 0.0115 step time: 0.1826\n",
      "8/8, train_loss: 0.0118 step time: 0.1813\n",
      "epoch 471 average loss: 0.0122\n",
      "time consuming of epoch 471 is: 1.5856\n",
      "----------\n",
      "epoch 472/600\n",
      "1/8, train_loss: 0.0136 step time: 0.2316\n",
      "2/8, train_loss: 0.0148 step time: 0.1976\n",
      "3/8, train_loss: 0.0120 step time: 0.1977\n",
      "4/8, train_loss: 0.0146 step time: 0.1970\n",
      "5/8, train_loss: 0.0135 step time: 0.1970\n",
      "6/8, train_loss: 0.0111 step time: 0.2059\n",
      "7/8, train_loss: 0.0110 step time: 0.1852\n",
      "8/8, train_loss: 0.0113 step time: 0.1846\n",
      "epoch 472 average loss: 0.0127\n",
      "time consuming of epoch 472 is: 1.5975\n",
      "----------\n",
      "epoch 473/600\n",
      "1/8, train_loss: 0.0164 step time: 0.2377\n",
      "2/8, train_loss: 0.0100 step time: 0.2076\n",
      "3/8, train_loss: 0.0108 step time: 0.2002\n",
      "4/8, train_loss: 0.0144 step time: 0.2026\n",
      "5/8, train_loss: 0.0109 step time: 0.1996\n",
      "6/8, train_loss: 0.0120 step time: 0.2028\n",
      "7/8, train_loss: 0.0118 step time: 0.1838\n",
      "8/8, train_loss: 0.0117 step time: 0.1832\n",
      "epoch 473 average loss: 0.0123\n",
      "time consuming of epoch 473 is: 1.6187\n",
      "----------\n",
      "epoch 474/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2425\n",
      "2/8, train_loss: 0.0117 step time: 0.2037\n",
      "3/8, train_loss: 0.0117 step time: 0.2050\n",
      "4/8, train_loss: 0.0121 step time: 0.1988\n",
      "5/8, train_loss: 0.0117 step time: 0.2005\n",
      "6/8, train_loss: 0.0114 step time: 0.2006\n",
      "7/8, train_loss: 0.0131 step time: 0.1830\n",
      "8/8, train_loss: 0.0135 step time: 0.1823\n",
      "epoch 474 average loss: 0.0119\n",
      "time consuming of epoch 474 is: 1.6178\n",
      "----------\n",
      "epoch 475/600\n",
      "1/8, train_loss: 0.0153 step time: 0.2449\n",
      "2/8, train_loss: 0.0114 step time: 0.1997\n",
      "3/8, train_loss: 0.0107 step time: 0.2006\n",
      "4/8, train_loss: 0.0129 step time: 0.1988\n",
      "5/8, train_loss: 0.0127 step time: 0.2121\n",
      "6/8, train_loss: 0.0118 step time: 0.2113\n",
      "7/8, train_loss: 0.0118 step time: 0.1825\n",
      "8/8, train_loss: 0.0099 step time: 0.1820\n",
      "epoch 475 average loss: 0.0121\n",
      "current epoch: 475 current mean dice: 0.9583 best mean dice: 0.9590 at epoch: 455\n",
      "time consuming of epoch 475 is: 2.3880\n",
      "----------\n",
      "epoch 476/600\n",
      "1/8, train_loss: 0.0152 step time: 0.2372\n",
      "2/8, train_loss: 0.0117 step time: 0.1980\n",
      "3/8, train_loss: 0.0111 step time: 0.2002\n",
      "4/8, train_loss: 0.0126 step time: 0.1996\n",
      "5/8, train_loss: 0.0103 step time: 0.2017\n",
      "6/8, train_loss: 0.0117 step time: 0.2086\n",
      "7/8, train_loss: 0.0103 step time: 0.1818\n",
      "8/8, train_loss: 0.0167 step time: 0.1821\n",
      "epoch 476 average loss: 0.0125\n",
      "time consuming of epoch 476 is: 1.6103\n",
      "----------\n",
      "epoch 477/600\n",
      "1/8, train_loss: 0.0121 step time: 0.2354\n",
      "2/8, train_loss: 0.0141 step time: 0.2024\n",
      "3/8, train_loss: 0.0104 step time: 0.1986\n",
      "4/8, train_loss: 0.0135 step time: 0.1998\n",
      "5/8, train_loss: 0.0127 step time: 0.2018\n",
      "6/8, train_loss: 0.0111 step time: 0.1986\n",
      "7/8, train_loss: 0.0111 step time: 0.1819\n",
      "8/8, train_loss: 0.0096 step time: 0.1830\n",
      "epoch 477 average loss: 0.0118\n",
      "time consuming of epoch 477 is: 1.6027\n",
      "----------\n",
      "epoch 478/600\n",
      "1/8, train_loss: 0.0119 step time: 0.2385\n",
      "2/8, train_loss: 0.0113 step time: 0.2014\n",
      "3/8, train_loss: 0.0113 step time: 0.2010\n",
      "4/8, train_loss: 0.0139 step time: 0.1992\n",
      "5/8, train_loss: 0.0115 step time: 0.2057\n",
      "6/8, train_loss: 0.0154 step time: 0.2033\n",
      "7/8, train_loss: 0.0117 step time: 0.1837\n",
      "8/8, train_loss: 0.0097 step time: 0.1825\n",
      "epoch 478 average loss: 0.0121\n",
      "time consuming of epoch 478 is: 1.6171\n",
      "----------\n",
      "epoch 479/600\n",
      "1/8, train_loss: 0.0116 step time: 0.2376\n",
      "2/8, train_loss: 0.0115 step time: 0.2030\n",
      "3/8, train_loss: 0.0112 step time: 0.2029\n",
      "4/8, train_loss: 0.0093 step time: 0.2030\n",
      "5/8, train_loss: 0.0146 step time: 0.1998\n",
      "6/8, train_loss: 0.0124 step time: 0.2017\n",
      "7/8, train_loss: 0.0142 step time: 0.1833\n",
      "8/8, train_loss: 0.0137 step time: 0.1811\n",
      "epoch 479 average loss: 0.0123\n",
      "time consuming of epoch 479 is: 1.6139\n",
      "----------\n",
      "epoch 480/600\n",
      "1/8, train_loss: 0.0112 step time: 0.2385\n",
      "2/8, train_loss: 0.0085 step time: 0.1961\n",
      "3/8, train_loss: 0.0099 step time: 0.2048\n",
      "4/8, train_loss: 0.0131 step time: 0.1996\n",
      "5/8, train_loss: 0.0133 step time: 0.2007\n",
      "6/8, train_loss: 0.0123 step time: 0.2022\n",
      "7/8, train_loss: 0.0141 step time: 0.1825\n",
      "8/8, train_loss: 0.0120 step time: 0.1824\n",
      "epoch 480 average loss: 0.0118\n",
      "saved new best metric model\n",
      "current epoch: 480 current mean dice: 0.9597 best mean dice: 0.9597 at epoch: 480\n",
      "time consuming of epoch 480 is: 2.5079\n",
      "----------\n",
      "epoch 481/600\n",
      "1/8, train_loss: 0.0123 step time: 0.2360\n",
      "2/8, train_loss: 0.0120 step time: 0.2023\n",
      "3/8, train_loss: 0.0119 step time: 0.2010\n",
      "4/8, train_loss: 0.0122 step time: 0.2005\n",
      "5/8, train_loss: 0.0152 step time: 0.2035\n",
      "6/8, train_loss: 0.0135 step time: 0.2091\n",
      "7/8, train_loss: 0.0101 step time: 0.1828\n",
      "8/8, train_loss: 0.0106 step time: 0.1824\n",
      "epoch 481 average loss: 0.0122\n",
      "time consuming of epoch 481 is: 1.6187\n",
      "----------\n",
      "epoch 482/600\n",
      "1/8, train_loss: 0.0112 step time: 0.2386\n",
      "2/8, train_loss: 0.0114 step time: 0.2040\n",
      "3/8, train_loss: 0.0127 step time: 0.1992\n",
      "4/8, train_loss: 0.0127 step time: 0.2004\n",
      "5/8, train_loss: 0.0137 step time: 0.2001\n",
      "6/8, train_loss: 0.0115 step time: 0.2015\n",
      "7/8, train_loss: 0.0105 step time: 0.1812\n",
      "8/8, train_loss: 0.0122 step time: 0.1838\n",
      "epoch 482 average loss: 0.0120\n",
      "time consuming of epoch 482 is: 1.6101\n",
      "----------\n",
      "epoch 483/600\n",
      "1/8, train_loss: 0.0112 step time: 0.2367\n",
      "2/8, train_loss: 0.0107 step time: 0.2045\n",
      "3/8, train_loss: 0.0151 step time: 0.2003\n",
      "4/8, train_loss: 0.0115 step time: 0.2021\n",
      "5/8, train_loss: 0.0106 step time: 0.1983\n",
      "6/8, train_loss: 0.0123 step time: 0.2043\n",
      "7/8, train_loss: 0.0103 step time: 0.1836\n",
      "8/8, train_loss: 0.0118 step time: 0.1836\n",
      "epoch 483 average loss: 0.0117\n",
      "time consuming of epoch 483 is: 1.6146\n",
      "----------\n",
      "epoch 484/600\n",
      "1/8, train_loss: 0.0113 step time: 0.2436\n",
      "2/8, train_loss: 0.0102 step time: 0.2018\n",
      "3/8, train_loss: 0.0103 step time: 0.2018\n",
      "4/8, train_loss: 0.0157 step time: 0.2021\n",
      "5/8, train_loss: 0.0131 step time: 0.2056\n",
      "6/8, train_loss: 0.0111 step time: 0.2024\n",
      "7/8, train_loss: 0.0141 step time: 0.1870\n",
      "8/8, train_loss: 0.0111 step time: 0.1815\n",
      "epoch 484 average loss: 0.0121\n",
      "time consuming of epoch 484 is: 1.6273\n",
      "----------\n",
      "epoch 485/600\n",
      "1/8, train_loss: 0.0134 step time: 0.2426\n",
      "2/8, train_loss: 0.0133 step time: 0.1997\n",
      "3/8, train_loss: 0.0124 step time: 0.2025\n",
      "4/8, train_loss: 0.0128 step time: 0.1992\n",
      "5/8, train_loss: 0.0137 step time: 0.2025\n",
      "6/8, train_loss: 0.0119 step time: 0.2028\n",
      "7/8, train_loss: 0.0116 step time: 0.1825\n",
      "8/8, train_loss: 0.0105 step time: 0.1823\n",
      "epoch 485 average loss: 0.0125\n",
      "current epoch: 485 current mean dice: 0.9594 best mean dice: 0.9597 at epoch: 480\n",
      "time consuming of epoch 485 is: 2.3704\n",
      "----------\n",
      "epoch 486/600\n",
      "1/8, train_loss: 0.0121 step time: 0.2390\n",
      "2/8, train_loss: 0.0113 step time: 0.1908\n",
      "3/8, train_loss: 0.0133 step time: 0.2003\n",
      "4/8, train_loss: 0.0099 step time: 0.1998\n",
      "5/8, train_loss: 0.0108 step time: 0.1973\n",
      "6/8, train_loss: 0.0112 step time: 0.2003\n",
      "7/8, train_loss: 0.0126 step time: 0.1819\n",
      "8/8, train_loss: 0.0128 step time: 0.1830\n",
      "epoch 486 average loss: 0.0117\n",
      "time consuming of epoch 486 is: 1.5937\n",
      "----------\n",
      "epoch 487/600\n",
      "1/8, train_loss: 0.0122 step time: 0.2441\n",
      "2/8, train_loss: 0.0121 step time: 0.1962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8, train_loss: 0.0120 step time: 0.2025\n",
      "4/8, train_loss: 0.0124 step time: 0.1997\n",
      "5/8, train_loss: 0.0118 step time: 0.2001\n",
      "6/8, train_loss: 0.0096 step time: 0.1978\n",
      "7/8, train_loss: 0.0163 step time: 0.1814\n",
      "8/8, train_loss: 0.0115 step time: 0.1814\n",
      "epoch 487 average loss: 0.0122\n",
      "time consuming of epoch 487 is: 1.6044\n",
      "----------\n",
      "epoch 488/600\n",
      "1/8, train_loss: 0.0112 step time: 0.2353\n",
      "2/8, train_loss: 0.0104 step time: 0.2002\n",
      "3/8, train_loss: 0.0122 step time: 0.1955\n",
      "4/8, train_loss: 0.0103 step time: 0.1952\n",
      "5/8, train_loss: 0.0101 step time: 0.1963\n",
      "6/8, train_loss: 0.0124 step time: 0.1950\n",
      "7/8, train_loss: 0.0122 step time: 0.1829\n",
      "8/8, train_loss: 0.0143 step time: 0.1837\n",
      "epoch 488 average loss: 0.0116\n",
      "time consuming of epoch 488 is: 1.5853\n",
      "----------\n",
      "epoch 489/600\n",
      "1/8, train_loss: 0.0128 step time: 0.2424\n",
      "2/8, train_loss: 0.0122 step time: 0.2028\n",
      "3/8, train_loss: 0.0099 step time: 0.1984\n",
      "4/8, train_loss: 0.0108 step time: 0.1995\n",
      "5/8, train_loss: 0.0109 step time: 0.1997\n",
      "6/8, train_loss: 0.0114 step time: 0.1986\n",
      "7/8, train_loss: 0.0140 step time: 0.1824\n",
      "8/8, train_loss: 0.0135 step time: 0.1825\n",
      "epoch 489 average loss: 0.0120\n",
      "time consuming of epoch 489 is: 1.6083\n",
      "----------\n",
      "epoch 490/600\n",
      "1/8, train_loss: 0.0133 step time: 0.2373\n",
      "2/8, train_loss: 0.0107 step time: 0.2037\n",
      "3/8, train_loss: 0.0108 step time: 0.1945\n",
      "4/8, train_loss: 0.0124 step time: 0.2023\n",
      "5/8, train_loss: 0.0145 step time: 0.1996\n",
      "6/8, train_loss: 0.0107 step time: 0.2010\n",
      "7/8, train_loss: 0.0092 step time: 0.1816\n",
      "8/8, train_loss: 0.0119 step time: 0.1805\n",
      "epoch 490 average loss: 0.0117\n",
      "current epoch: 490 current mean dice: 0.9592 best mean dice: 0.9597 at epoch: 480\n",
      "time consuming of epoch 490 is: 2.3556\n",
      "----------\n",
      "epoch 491/600\n",
      "1/8, train_loss: 0.0159 step time: 0.2334\n",
      "2/8, train_loss: 0.0109 step time: 0.1914\n",
      "3/8, train_loss: 0.0109 step time: 0.1917\n",
      "4/8, train_loss: 0.0131 step time: 0.1947\n",
      "5/8, train_loss: 0.0125 step time: 0.1907\n",
      "6/8, train_loss: 0.0096 step time: 0.1940\n",
      "7/8, train_loss: 0.0121 step time: 0.1817\n",
      "8/8, train_loss: 0.0118 step time: 0.1820\n",
      "epoch 491 average loss: 0.0121\n",
      "time consuming of epoch 491 is: 1.5607\n",
      "----------\n",
      "epoch 492/600\n",
      "1/8, train_loss: 0.0109 step time: 0.2485\n",
      "2/8, train_loss: 0.0142 step time: 0.2058\n",
      "3/8, train_loss: 0.0102 step time: 0.2004\n",
      "4/8, train_loss: 0.0113 step time: 0.1996\n",
      "5/8, train_loss: 0.0136 step time: 0.2001\n",
      "6/8, train_loss: 0.0117 step time: 0.1998\n",
      "7/8, train_loss: 0.0150 step time: 0.1839\n",
      "8/8, train_loss: 0.0112 step time: 0.1826\n",
      "epoch 492 average loss: 0.0123\n",
      "time consuming of epoch 492 is: 1.6222\n",
      "----------\n",
      "epoch 493/600\n",
      "1/8, train_loss: 0.0097 step time: 0.2407\n",
      "2/8, train_loss: 0.0130 step time: 0.2050\n",
      "3/8, train_loss: 0.0143 step time: 0.2026\n",
      "4/8, train_loss: 0.0128 step time: 0.2003\n",
      "5/8, train_loss: 0.0116 step time: 0.2031\n",
      "6/8, train_loss: 0.0114 step time: 0.2024\n",
      "7/8, train_loss: 0.0087 step time: 0.1830\n",
      "8/8, train_loss: 0.0115 step time: 0.1819\n",
      "epoch 493 average loss: 0.0116\n",
      "time consuming of epoch 493 is: 1.6207\n",
      "----------\n",
      "epoch 494/600\n",
      "1/8, train_loss: 0.0141 step time: 0.2405\n",
      "2/8, train_loss: 0.0125 step time: 0.2028\n",
      "3/8, train_loss: 0.0106 step time: 0.2020\n",
      "4/8, train_loss: 0.0115 step time: 0.2526\n",
      "5/8, train_loss: 0.0119 step time: 0.1970\n",
      "6/8, train_loss: 0.0136 step time: 0.1988\n",
      "7/8, train_loss: 0.0107 step time: 0.1818\n",
      "8/8, train_loss: 0.0101 step time: 0.1817\n",
      "epoch 494 average loss: 0.0119\n",
      "time consuming of epoch 494 is: 1.6587\n",
      "----------\n",
      "epoch 495/600\n",
      "1/8, train_loss: 0.0119 step time: 0.2409\n",
      "2/8, train_loss: 0.0117 step time: 0.2000\n",
      "3/8, train_loss: 0.0128 step time: 0.1981\n",
      "4/8, train_loss: 0.0105 step time: 0.1990\n",
      "5/8, train_loss: 0.0126 step time: 0.2003\n",
      "6/8, train_loss: 0.0100 step time: 0.1997\n",
      "7/8, train_loss: 0.0120 step time: 0.1834\n",
      "8/8, train_loss: 0.0111 step time: 0.1815\n",
      "epoch 495 average loss: 0.0116\n",
      "current epoch: 495 current mean dice: 0.9596 best mean dice: 0.9597 at epoch: 480\n",
      "time consuming of epoch 495 is: 2.3592\n",
      "----------\n",
      "epoch 496/600\n",
      "1/8, train_loss: 0.0129 step time: 0.2389\n",
      "2/8, train_loss: 0.0094 step time: 0.2000\n",
      "3/8, train_loss: 0.0109 step time: 0.2026\n",
      "4/8, train_loss: 0.0112 step time: 0.1985\n",
      "5/8, train_loss: 0.0122 step time: 0.1973\n",
      "6/8, train_loss: 0.0134 step time: 0.1956\n",
      "7/8, train_loss: 0.0115 step time: 0.1815\n",
      "8/8, train_loss: 0.0124 step time: 0.1812\n",
      "epoch 496 average loss: 0.0117\n",
      "time consuming of epoch 496 is: 1.5968\n",
      "----------\n",
      "epoch 497/600\n",
      "1/8, train_loss: 0.0148 step time: 0.2385\n",
      "2/8, train_loss: 0.0116 step time: 0.2018\n",
      "3/8, train_loss: 0.0135 step time: 0.2003\n",
      "4/8, train_loss: 0.0107 step time: 0.2019\n",
      "5/8, train_loss: 0.0113 step time: 0.2014\n",
      "6/8, train_loss: 0.0114 step time: 0.2021\n",
      "7/8, train_loss: 0.0109 step time: 0.1827\n",
      "8/8, train_loss: 0.0120 step time: 0.1829\n",
      "epoch 497 average loss: 0.0120\n",
      "time consuming of epoch 497 is: 1.6129\n",
      "----------\n",
      "epoch 498/600\n",
      "1/8, train_loss: 0.0133 step time: 0.2399\n",
      "2/8, train_loss: 0.0129 step time: 0.2042\n",
      "3/8, train_loss: 0.0112 step time: 0.1950\n",
      "4/8, train_loss: 0.0116 step time: 0.2031\n",
      "5/8, train_loss: 0.0114 step time: 0.2033\n",
      "6/8, train_loss: 0.0093 step time: 0.1993\n",
      "7/8, train_loss: 0.0128 step time: 0.1830\n",
      "8/8, train_loss: 0.0105 step time: 0.1840\n",
      "epoch 498 average loss: 0.0116\n",
      "time consuming of epoch 498 is: 1.6135\n",
      "----------\n",
      "epoch 499/600\n",
      "1/8, train_loss: 0.0135 step time: 0.2406\n",
      "2/8, train_loss: 0.0124 step time: 0.1958\n",
      "3/8, train_loss: 0.0118 step time: 0.1964\n",
      "4/8, train_loss: 0.0103 step time: 0.1974\n",
      "5/8, train_loss: 0.0094 step time: 0.1986\n",
      "6/8, train_loss: 0.0127 step time: 0.1968\n",
      "7/8, train_loss: 0.0138 step time: 0.1831\n",
      "8/8, train_loss: 0.0132 step time: 0.1827\n",
      "epoch 499 average loss: 0.0121\n",
      "time consuming of epoch 499 is: 1.5931\n",
      "----------\n",
      "epoch 500/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2428\n",
      "2/8, train_loss: 0.0112 step time: 0.2017\n",
      "3/8, train_loss: 0.0141 step time: 0.2015\n",
      "4/8, train_loss: 0.0106 step time: 0.2018\n",
      "5/8, train_loss: 0.0106 step time: 0.2072\n",
      "6/8, train_loss: 0.0134 step time: 0.2045\n",
      "7/8, train_loss: 0.0111 step time: 0.1809\n",
      "8/8, train_loss: 0.0158 step time: 0.1855\n",
      "epoch 500 average loss: 0.0122\n",
      "current epoch: 500 current mean dice: 0.9591 best mean dice: 0.9597 at epoch: 480\n",
      "time consuming of epoch 500 is: 2.3833\n",
      "----------\n",
      "epoch 501/600\n",
      "1/8, train_loss: 0.0132 step time: 0.2296\n",
      "2/8, train_loss: 0.0091 step time: 0.1996\n",
      "3/8, train_loss: 0.0126 step time: 0.1997\n",
      "4/8, train_loss: 0.0105 step time: 0.1976\n",
      "5/8, train_loss: 0.0106 step time: 0.1975\n",
      "6/8, train_loss: 0.0133 step time: 0.1968\n",
      "7/8, train_loss: 0.0121 step time: 0.1813\n",
      "8/8, train_loss: 0.0119 step time: 0.1811\n",
      "epoch 501 average loss: 0.0117\n",
      "time consuming of epoch 501 is: 1.5843\n",
      "----------\n",
      "epoch 502/600\n",
      "1/8, train_loss: 0.0114 step time: 0.2362\n",
      "2/8, train_loss: 0.0135 step time: 0.2022\n",
      "3/8, train_loss: 0.0096 step time: 0.1996\n",
      "4/8, train_loss: 0.0101 step time: 0.2000\n",
      "5/8, train_loss: 0.0097 step time: 0.1958\n",
      "6/8, train_loss: 0.0098 step time: 0.2001\n",
      "7/8, train_loss: 0.0139 step time: 0.1829\n",
      "8/8, train_loss: 0.0133 step time: 0.1827\n",
      "epoch 502 average loss: 0.0114\n",
      "time consuming of epoch 502 is: 1.6009\n",
      "----------\n",
      "epoch 503/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2397\n",
      "2/8, train_loss: 0.0115 step time: 0.2005\n",
      "3/8, train_loss: 0.0113 step time: 0.2008\n",
      "4/8, train_loss: 0.0134 step time: 0.2020\n",
      "5/8, train_loss: 0.0106 step time: 0.1981\n",
      "6/8, train_loss: 0.0148 step time: 0.2028\n",
      "7/8, train_loss: 0.0110 step time: 0.1825\n",
      "8/8, train_loss: 0.0116 step time: 0.1826\n",
      "epoch 503 average loss: 0.0122\n",
      "time consuming of epoch 503 is: 1.6106\n",
      "----------\n",
      "epoch 504/600\n",
      "1/8, train_loss: 0.0130 step time: 0.2401\n",
      "2/8, train_loss: 0.0095 step time: 0.2035\n",
      "3/8, train_loss: 0.0104 step time: 0.2041\n",
      "4/8, train_loss: 0.0111 step time: 0.1991\n",
      "5/8, train_loss: 0.0136 step time: 0.2017\n",
      "6/8, train_loss: 0.0117 step time: 0.1990\n",
      "7/8, train_loss: 0.0117 step time: 0.1837\n",
      "8/8, train_loss: 0.0100 step time: 0.1827\n",
      "epoch 504 average loss: 0.0114\n",
      "time consuming of epoch 504 is: 1.6152\n",
      "----------\n",
      "epoch 505/600\n",
      "1/8, train_loss: 0.0123 step time: 0.2457\n",
      "2/8, train_loss: 0.0100 step time: 0.1954\n",
      "3/8, train_loss: 0.0120 step time: 0.1992\n",
      "4/8, train_loss: 0.0119 step time: 0.1975\n",
      "5/8, train_loss: 0.0107 step time: 0.1970\n",
      "6/8, train_loss: 0.0121 step time: 0.1956\n",
      "7/8, train_loss: 0.0130 step time: 0.1852\n",
      "8/8, train_loss: 0.0104 step time: 0.1951\n",
      "epoch 505 average loss: 0.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new best metric model\n",
      "current epoch: 505 current mean dice: 0.9601 best mean dice: 0.9601 at epoch: 505\n",
      "time consuming of epoch 505 is: 2.5339\n",
      "----------\n",
      "epoch 506/600\n",
      "1/8, train_loss: 0.0122 step time: 0.2301\n",
      "2/8, train_loss: 0.0118 step time: 0.1953\n",
      "3/8, train_loss: 0.0135 step time: 0.1988\n",
      "4/8, train_loss: 0.0116 step time: 0.2029\n",
      "5/8, train_loss: 0.0111 step time: 0.1980\n",
      "6/8, train_loss: 0.0141 step time: 0.2013\n",
      "7/8, train_loss: 0.0103 step time: 0.1822\n",
      "8/8, train_loss: 0.0106 step time: 0.1820\n",
      "epoch 506 average loss: 0.0119\n",
      "time consuming of epoch 506 is: 1.5921\n",
      "----------\n",
      "epoch 507/600\n",
      "1/8, train_loss: 0.0143 step time: 0.2373\n",
      "2/8, train_loss: 0.0100 step time: 0.2017\n",
      "3/8, train_loss: 0.0115 step time: 0.1992\n",
      "4/8, train_loss: 0.0099 step time: 0.2005\n",
      "5/8, train_loss: 0.0112 step time: 0.2019\n",
      "6/8, train_loss: 0.0117 step time: 0.2054\n",
      "7/8, train_loss: 0.0119 step time: 0.1838\n",
      "8/8, train_loss: 0.0104 step time: 0.1830\n",
      "epoch 507 average loss: 0.0114\n",
      "time consuming of epoch 507 is: 1.6144\n",
      "----------\n",
      "epoch 508/600\n",
      "1/8, train_loss: 0.0115 step time: 0.2391\n",
      "2/8, train_loss: 0.0105 step time: 0.2020\n",
      "3/8, train_loss: 0.0142 step time: 0.2023\n",
      "4/8, train_loss: 0.0140 step time: 0.2019\n",
      "5/8, train_loss: 0.0116 step time: 0.2010\n",
      "6/8, train_loss: 0.0112 step time: 0.2003\n",
      "7/8, train_loss: 0.0102 step time: 0.1847\n",
      "8/8, train_loss: 0.0119 step time: 0.1819\n",
      "epoch 508 average loss: 0.0119\n",
      "time consuming of epoch 508 is: 1.6150\n",
      "----------\n",
      "epoch 509/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2419\n",
      "2/8, train_loss: 0.0112 step time: 0.2072\n",
      "3/8, train_loss: 0.0117 step time: 0.2016\n",
      "4/8, train_loss: 0.0107 step time: 0.1993\n",
      "5/8, train_loss: 0.0100 step time: 0.2022\n",
      "6/8, train_loss: 0.0125 step time: 0.2058\n",
      "7/8, train_loss: 0.0110 step time: 0.1842\n",
      "8/8, train_loss: 0.0138 step time: 0.1831\n",
      "epoch 509 average loss: 0.0114\n",
      "time consuming of epoch 509 is: 1.6267\n",
      "----------\n",
      "epoch 510/600\n",
      "1/8, train_loss: 0.0120 step time: 0.2392\n",
      "2/8, train_loss: 0.0112 step time: 0.2070\n",
      "3/8, train_loss: 0.0110 step time: 0.1971\n",
      "4/8, train_loss: 0.0099 step time: 0.1979\n",
      "5/8, train_loss: 0.0132 step time: 0.1968\n",
      "6/8, train_loss: 0.0102 step time: 0.1967\n",
      "7/8, train_loss: 0.0138 step time: 0.1796\n",
      "8/8, train_loss: 0.0126 step time: 0.1790\n",
      "epoch 510 average loss: 0.0117\n",
      "current epoch: 510 current mean dice: 0.9601 best mean dice: 0.9601 at epoch: 505\n",
      "time consuming of epoch 510 is: 2.3472\n",
      "----------\n",
      "epoch 511/600\n",
      "1/8, train_loss: 0.0139 step time: 0.2397\n",
      "2/8, train_loss: 0.0134 step time: 0.2016\n",
      "3/8, train_loss: 0.0115 step time: 0.1980\n",
      "4/8, train_loss: 0.0112 step time: 0.1973\n",
      "5/8, train_loss: 0.0093 step time: 0.2001\n",
      "6/8, train_loss: 0.0130 step time: 0.1990\n",
      "7/8, train_loss: 0.0114 step time: 0.1846\n",
      "8/8, train_loss: 0.0111 step time: 0.1809\n",
      "epoch 511 average loss: 0.0118\n",
      "time consuming of epoch 511 is: 1.6023\n",
      "----------\n",
      "epoch 512/600\n",
      "1/8, train_loss: 0.0120 step time: 0.2401\n",
      "2/8, train_loss: 0.0127 step time: 0.2033\n",
      "3/8, train_loss: 0.0095 step time: 0.1990\n",
      "4/8, train_loss: 0.0126 step time: 0.2093\n",
      "5/8, train_loss: 0.0103 step time: 0.2020\n",
      "6/8, train_loss: 0.0106 step time: 0.2000\n",
      "7/8, train_loss: 0.0121 step time: 0.1836\n",
      "8/8, train_loss: 0.0139 step time: 0.1819\n",
      "epoch 512 average loss: 0.0117\n",
      "time consuming of epoch 512 is: 1.6206\n",
      "----------\n",
      "epoch 513/600\n",
      "1/8, train_loss: 0.0144 step time: 0.2377\n",
      "2/8, train_loss: 0.0096 step time: 0.2030\n",
      "3/8, train_loss: 0.0115 step time: 0.2042\n",
      "4/8, train_loss: 0.0121 step time: 0.2050\n",
      "5/8, train_loss: 0.0109 step time: 0.2027\n",
      "6/8, train_loss: 0.0104 step time: 0.2020\n",
      "7/8, train_loss: 0.0111 step time: 0.1793\n",
      "8/8, train_loss: 0.0130 step time: 0.1786\n",
      "epoch 513 average loss: 0.0116\n",
      "time consuming of epoch 513 is: 1.6140\n",
      "----------\n",
      "epoch 514/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2336\n",
      "2/8, train_loss: 0.0129 step time: 0.1946\n",
      "3/8, train_loss: 0.0115 step time: 0.1970\n",
      "4/8, train_loss: 0.0120 step time: 0.1975\n",
      "5/8, train_loss: 0.0149 step time: 0.2039\n",
      "6/8, train_loss: 0.0118 step time: 0.1983\n",
      "7/8, train_loss: 0.0109 step time: 0.1819\n",
      "8/8, train_loss: 0.0106 step time: 0.1824\n",
      "epoch 514 average loss: 0.0119\n",
      "time consuming of epoch 514 is: 1.5903\n",
      "----------\n",
      "epoch 515/600\n",
      "1/8, train_loss: 0.0114 step time: 0.2409\n",
      "2/8, train_loss: 0.0106 step time: 0.2017\n",
      "3/8, train_loss: 0.0136 step time: 0.2006\n",
      "4/8, train_loss: 0.0114 step time: 0.2071\n",
      "5/8, train_loss: 0.0095 step time: 0.2001\n",
      "6/8, train_loss: 0.0102 step time: 0.2020\n",
      "7/8, train_loss: 0.0130 step time: 0.1822\n",
      "8/8, train_loss: 0.0129 step time: 0.1820\n",
      "epoch 515 average loss: 0.0116\n",
      "current epoch: 515 current mean dice: 0.9600 best mean dice: 0.9601 at epoch: 505\n",
      "time consuming of epoch 515 is: 2.3734\n",
      "----------\n",
      "epoch 516/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2375\n",
      "2/8, train_loss: 0.0106 step time: 0.2001\n",
      "3/8, train_loss: 0.0115 step time: 0.1998\n",
      "4/8, train_loss: 0.0114 step time: 0.2032\n",
      "5/8, train_loss: 0.0121 step time: 0.1993\n",
      "6/8, train_loss: 0.0118 step time: 0.1983\n",
      "7/8, train_loss: 0.0121 step time: 0.1818\n",
      "8/8, train_loss: 0.0130 step time: 0.1814\n",
      "epoch 516 average loss: 0.0119\n",
      "time consuming of epoch 516 is: 1.6025\n",
      "----------\n",
      "epoch 517/600\n",
      "1/8, train_loss: 0.0160 step time: 0.2407\n",
      "2/8, train_loss: 0.0105 step time: 0.2038\n",
      "3/8, train_loss: 0.0122 step time: 0.1999\n",
      "4/8, train_loss: 0.0085 step time: 0.2005\n",
      "5/8, train_loss: 0.0102 step time: 0.2006\n",
      "6/8, train_loss: 0.0110 step time: 0.2007\n",
      "7/8, train_loss: 0.0109 step time: 0.1829\n",
      "8/8, train_loss: 0.0123 step time: 0.1823\n",
      "epoch 517 average loss: 0.0114\n",
      "time consuming of epoch 517 is: 1.6129\n",
      "----------\n",
      "epoch 518/600\n",
      "1/8, train_loss: 0.0121 step time: 0.2398\n",
      "2/8, train_loss: 0.0118 step time: 0.2030\n",
      "3/8, train_loss: 0.0128 step time: 0.1998\n",
      "4/8, train_loss: 0.0113 step time: 0.2006\n",
      "5/8, train_loss: 0.0113 step time: 0.1976\n",
      "6/8, train_loss: 0.0126 step time: 0.1998\n",
      "7/8, train_loss: 0.0109 step time: 0.1830\n",
      "8/8, train_loss: 0.0106 step time: 0.1829\n",
      "epoch 518 average loss: 0.0117\n",
      "time consuming of epoch 518 is: 1.6081\n",
      "----------\n",
      "epoch 519/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2384\n",
      "2/8, train_loss: 0.0126 step time: 0.2005\n",
      "3/8, train_loss: 0.0129 step time: 0.2008\n",
      "4/8, train_loss: 0.0102 step time: 0.1985\n",
      "5/8, train_loss: 0.0121 step time: 0.2060\n",
      "6/8, train_loss: 0.0105 step time: 0.2029\n",
      "7/8, train_loss: 0.0114 step time: 0.1825\n",
      "8/8, train_loss: 0.0146 step time: 0.1826\n",
      "epoch 519 average loss: 0.0118\n",
      "time consuming of epoch 519 is: 1.6135\n",
      "----------\n",
      "epoch 520/600\n",
      "1/8, train_loss: 0.0083 step time: 0.2410\n",
      "2/8, train_loss: 0.0095 step time: 0.1999\n",
      "3/8, train_loss: 0.0108 step time: 0.1989\n",
      "4/8, train_loss: 0.0120 step time: 0.1993\n",
      "5/8, train_loss: 0.0125 step time: 0.1996\n",
      "6/8, train_loss: 0.0113 step time: 0.1993\n",
      "7/8, train_loss: 0.0110 step time: 0.1837\n",
      "8/8, train_loss: 0.0147 step time: 0.1847\n",
      "epoch 520 average loss: 0.0113\n",
      "saved new best metric model\n",
      "current epoch: 520 current mean dice: 0.9603 best mean dice: 0.9603 at epoch: 520\n",
      "time consuming of epoch 520 is: 2.5019\n",
      "----------\n",
      "epoch 521/600\n",
      "1/8, train_loss: 0.0116 step time: 0.2390\n",
      "2/8, train_loss: 0.0123 step time: 0.1993\n",
      "3/8, train_loss: 0.0122 step time: 0.1989\n",
      "4/8, train_loss: 0.0108 step time: 0.1995\n",
      "5/8, train_loss: 0.0135 step time: 0.2002\n",
      "6/8, train_loss: 0.0119 step time: 0.1982\n",
      "7/8, train_loss: 0.0113 step time: 0.1798\n",
      "8/8, train_loss: 0.0112 step time: 0.1827\n",
      "epoch 521 average loss: 0.0118\n",
      "time consuming of epoch 521 is: 1.5987\n",
      "----------\n",
      "epoch 522/600\n",
      "1/8, train_loss: 0.0136 step time: 0.2379\n",
      "2/8, train_loss: 0.0103 step time: 0.2014\n",
      "3/8, train_loss: 0.0109 step time: 0.1998\n",
      "4/8, train_loss: 0.0126 step time: 0.2009\n",
      "5/8, train_loss: 0.0141 step time: 0.2001\n",
      "6/8, train_loss: 0.0101 step time: 0.2011\n",
      "7/8, train_loss: 0.0107 step time: 0.1829\n",
      "8/8, train_loss: 0.0112 step time: 0.1825\n",
      "epoch 522 average loss: 0.0117\n",
      "time consuming of epoch 522 is: 1.6083\n",
      "----------\n",
      "epoch 523/600\n",
      "1/8, train_loss: 0.0103 step time: 0.2404\n",
      "2/8, train_loss: 0.0117 step time: 0.2025\n",
      "3/8, train_loss: 0.0112 step time: 0.2026\n",
      "4/8, train_loss: 0.0124 step time: 0.2030\n",
      "5/8, train_loss: 0.0097 step time: 0.2036\n",
      "6/8, train_loss: 0.0123 step time: 0.1993\n",
      "7/8, train_loss: 0.0139 step time: 0.1830\n",
      "8/8, train_loss: 0.0139 step time: 0.1841\n",
      "epoch 523 average loss: 0.0119\n",
      "time consuming of epoch 523 is: 1.6202\n",
      "----------\n",
      "epoch 524/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0108 step time: 0.2403\n",
      "2/8, train_loss: 0.0126 step time: 0.2027\n",
      "3/8, train_loss: 0.0137 step time: 0.2030\n",
      "4/8, train_loss: 0.0110 step time: 0.2018\n",
      "5/8, train_loss: 0.0105 step time: 0.1989\n",
      "6/8, train_loss: 0.0106 step time: 0.2052\n",
      "7/8, train_loss: 0.0116 step time: 0.1852\n",
      "8/8, train_loss: 0.0101 step time: 0.1829\n",
      "epoch 524 average loss: 0.0114\n",
      "time consuming of epoch 524 is: 1.6219\n",
      "----------\n",
      "epoch 525/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2405\n",
      "2/8, train_loss: 0.0116 step time: 0.2040\n",
      "3/8, train_loss: 0.0109 step time: 0.2064\n",
      "4/8, train_loss: 0.0107 step time: 0.1998\n",
      "5/8, train_loss: 0.0131 step time: 0.2001\n",
      "6/8, train_loss: 0.0109 step time: 0.2002\n",
      "7/8, train_loss: 0.0101 step time: 0.1850\n",
      "8/8, train_loss: 0.0130 step time: 0.1838\n",
      "epoch 525 average loss: 0.0117\n",
      "current epoch: 525 current mean dice: 0.9594 best mean dice: 0.9603 at epoch: 520\n",
      "time consuming of epoch 525 is: 2.3770\n",
      "----------\n",
      "epoch 526/600\n",
      "1/8, train_loss: 0.0119 step time: 0.2398\n",
      "2/8, train_loss: 0.0135 step time: 0.1975\n",
      "3/8, train_loss: 0.0135 step time: 0.2040\n",
      "4/8, train_loss: 0.0098 step time: 0.1990\n",
      "5/8, train_loss: 0.0110 step time: 0.2032\n",
      "6/8, train_loss: 0.0119 step time: 0.1995\n",
      "7/8, train_loss: 0.0110 step time: 0.1852\n",
      "8/8, train_loss: 0.0099 step time: 0.1820\n",
      "epoch 526 average loss: 0.0116\n",
      "time consuming of epoch 526 is: 1.6114\n",
      "----------\n",
      "epoch 527/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2384\n",
      "2/8, train_loss: 0.0098 step time: 0.2043\n",
      "3/8, train_loss: 0.0121 step time: 0.2005\n",
      "4/8, train_loss: 0.0113 step time: 0.2069\n",
      "5/8, train_loss: 0.0115 step time: 0.2002\n",
      "6/8, train_loss: 0.0128 step time: 0.2009\n",
      "7/8, train_loss: 0.0122 step time: 0.1826\n",
      "8/8, train_loss: 0.0097 step time: 0.1827\n",
      "epoch 527 average loss: 0.0113\n",
      "time consuming of epoch 527 is: 1.6177\n",
      "----------\n",
      "epoch 528/600\n",
      "1/8, train_loss: 0.0117 step time: 0.2435\n",
      "2/8, train_loss: 0.0108 step time: 0.2018\n",
      "3/8, train_loss: 0.0097 step time: 0.2005\n",
      "4/8, train_loss: 0.0116 step time: 0.2039\n",
      "5/8, train_loss: 0.0115 step time: 0.1986\n",
      "6/8, train_loss: 0.0123 step time: 0.2008\n",
      "7/8, train_loss: 0.0136 step time: 0.1835\n",
      "8/8, train_loss: 0.0132 step time: 0.1818\n",
      "epoch 528 average loss: 0.0118\n",
      "time consuming of epoch 528 is: 1.6157\n",
      "----------\n",
      "epoch 529/600\n",
      "1/8, train_loss: 0.0100 step time: 0.2410\n",
      "2/8, train_loss: 0.0152 step time: 0.2004\n",
      "3/8, train_loss: 0.0114 step time: 0.1988\n",
      "4/8, train_loss: 0.0101 step time: 0.2002\n",
      "5/8, train_loss: 0.0128 step time: 0.1987\n",
      "6/8, train_loss: 0.0128 step time: 0.1982\n",
      "7/8, train_loss: 0.0114 step time: 0.1820\n",
      "8/8, train_loss: 0.0111 step time: 0.1821\n",
      "epoch 529 average loss: 0.0119\n",
      "time consuming of epoch 529 is: 1.6030\n",
      "----------\n",
      "epoch 530/600\n",
      "1/8, train_loss: 0.0124 step time: 0.2400\n",
      "2/8, train_loss: 0.0118 step time: 0.2020\n",
      "3/8, train_loss: 0.0117 step time: 0.2025\n",
      "4/8, train_loss: 0.0101 step time: 0.1999\n",
      "5/8, train_loss: 0.0122 step time: 0.1992\n",
      "6/8, train_loss: 0.0118 step time: 0.2031\n",
      "7/8, train_loss: 0.0108 step time: 0.1828\n",
      "8/8, train_loss: 0.0103 step time: 0.1811\n",
      "epoch 530 average loss: 0.0114\n",
      "current epoch: 530 current mean dice: 0.9600 best mean dice: 0.9603 at epoch: 520\n",
      "time consuming of epoch 530 is: 2.3656\n",
      "----------\n",
      "epoch 531/600\n",
      "1/8, train_loss: 0.0155 step time: 0.2373\n",
      "2/8, train_loss: 0.0123 step time: 0.1998\n",
      "3/8, train_loss: 0.0105 step time: 0.2012\n",
      "4/8, train_loss: 0.0122 step time: 0.1999\n",
      "5/8, train_loss: 0.0115 step time: 0.1986\n",
      "6/8, train_loss: 0.0102 step time: 0.1990\n",
      "7/8, train_loss: 0.0125 step time: 0.1831\n",
      "8/8, train_loss: 0.0109 step time: 0.1812\n",
      "epoch 531 average loss: 0.0119\n",
      "time consuming of epoch 531 is: 1.6012\n",
      "----------\n",
      "epoch 532/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2428\n",
      "2/8, train_loss: 0.0120 step time: 0.2028\n",
      "3/8, train_loss: 0.0117 step time: 0.1996\n",
      "4/8, train_loss: 0.0124 step time: 0.2061\n",
      "5/8, train_loss: 0.0097 step time: 0.2023\n",
      "6/8, train_loss: 0.0128 step time: 0.1979\n",
      "7/8, train_loss: 0.0098 step time: 0.1842\n",
      "8/8, train_loss: 0.0133 step time: 0.1827\n",
      "epoch 532 average loss: 0.0114\n",
      "time consuming of epoch 532 is: 1.6197\n",
      "----------\n",
      "epoch 533/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2419\n",
      "2/8, train_loss: 0.0087 step time: 0.2054\n",
      "3/8, train_loss: 0.0126 step time: 0.1998\n",
      "4/8, train_loss: 0.0114 step time: 0.2005\n",
      "5/8, train_loss: 0.0123 step time: 0.1997\n",
      "6/8, train_loss: 0.0093 step time: 0.2021\n",
      "7/8, train_loss: 0.0161 step time: 0.1841\n",
      "8/8, train_loss: 0.0106 step time: 0.1826\n",
      "epoch 533 average loss: 0.0115\n",
      "time consuming of epoch 533 is: 1.6175\n",
      "----------\n",
      "epoch 534/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2394\n",
      "2/8, train_loss: 0.0133 step time: 0.2051\n",
      "3/8, train_loss: 0.0115 step time: 0.2019\n",
      "4/8, train_loss: 0.0101 step time: 0.2015\n",
      "5/8, train_loss: 0.0101 step time: 0.1988\n",
      "6/8, train_loss: 0.0134 step time: 0.2003\n",
      "7/8, train_loss: 0.0111 step time: 0.1835\n",
      "8/8, train_loss: 0.0109 step time: 0.1822\n",
      "epoch 534 average loss: 0.0115\n",
      "time consuming of epoch 534 is: 1.6144\n",
      "----------\n",
      "epoch 535/600\n",
      "1/8, train_loss: 0.0111 step time: 0.2428\n",
      "2/8, train_loss: 0.0129 step time: 0.2039\n",
      "3/8, train_loss: 0.0128 step time: 0.2000\n",
      "4/8, train_loss: 0.0115 step time: 0.2002\n",
      "5/8, train_loss: 0.0101 step time: 0.2005\n",
      "6/8, train_loss: 0.0100 step time: 0.1985\n",
      "7/8, train_loss: 0.0097 step time: 0.1813\n",
      "8/8, train_loss: 0.0112 step time: 0.1814\n",
      "epoch 535 average loss: 0.0112\n",
      "current epoch: 535 current mean dice: 0.9598 best mean dice: 0.9603 at epoch: 520\n",
      "time consuming of epoch 535 is: 2.3634\n",
      "----------\n",
      "epoch 536/600\n",
      "1/8, train_loss: 0.0124 step time: 0.2276\n",
      "2/8, train_loss: 0.0088 step time: 0.1939\n",
      "3/8, train_loss: 0.0108 step time: 0.1988\n",
      "4/8, train_loss: 0.0136 step time: 0.2002\n",
      "5/8, train_loss: 0.0131 step time: 0.2014\n",
      "6/8, train_loss: 0.0109 step time: 0.2000\n",
      "7/8, train_loss: 0.0119 step time: 0.1843\n",
      "8/8, train_loss: 0.0117 step time: 0.1830\n",
      "epoch 536 average loss: 0.0116\n",
      "time consuming of epoch 536 is: 1.5904\n",
      "----------\n",
      "epoch 537/600\n",
      "1/8, train_loss: 0.0109 step time: 0.2295\n",
      "2/8, train_loss: 0.0105 step time: 0.1988\n",
      "3/8, train_loss: 0.0122 step time: 0.2017\n",
      "4/8, train_loss: 0.0127 step time: 0.1988\n",
      "5/8, train_loss: 0.0103 step time: 0.2017\n",
      "6/8, train_loss: 0.0101 step time: 0.2028\n",
      "7/8, train_loss: 0.0106 step time: 0.1827\n",
      "8/8, train_loss: 0.0127 step time: 0.1821\n",
      "epoch 537 average loss: 0.0113\n",
      "time consuming of epoch 537 is: 1.5998\n",
      "----------\n",
      "epoch 538/600\n",
      "1/8, train_loss: 0.0111 step time: 0.2377\n",
      "2/8, train_loss: 0.0121 step time: 0.1979\n",
      "3/8, train_loss: 0.0126 step time: 0.2011\n",
      "4/8, train_loss: 0.0102 step time: 0.2021\n",
      "5/8, train_loss: 0.0136 step time: 0.2022\n",
      "6/8, train_loss: 0.0099 step time: 0.1985\n",
      "7/8, train_loss: 0.0103 step time: 0.1887\n",
      "8/8, train_loss: 0.0118 step time: 0.1828\n",
      "epoch 538 average loss: 0.0115\n",
      "time consuming of epoch 538 is: 1.6125\n",
      "----------\n",
      "epoch 539/600\n",
      "1/8, train_loss: 0.0174 step time: 0.2432\n",
      "2/8, train_loss: 0.0105 step time: 0.2012\n",
      "3/8, train_loss: 0.0110 step time: 0.2046\n",
      "4/8, train_loss: 0.0139 step time: 0.2015\n",
      "5/8, train_loss: 0.0107 step time: 0.2001\n",
      "6/8, train_loss: 0.0110 step time: 0.1998\n",
      "7/8, train_loss: 0.0115 step time: 0.1824\n",
      "8/8, train_loss: 0.0117 step time: 0.1826\n",
      "epoch 539 average loss: 0.0122\n",
      "time consuming of epoch 539 is: 1.6169\n",
      "----------\n",
      "epoch 540/600\n",
      "1/8, train_loss: 0.0097 step time: 0.2419\n",
      "2/8, train_loss: 0.0126 step time: 0.2041\n",
      "3/8, train_loss: 0.0133 step time: 0.2074\n",
      "4/8, train_loss: 0.0102 step time: 0.1995\n",
      "5/8, train_loss: 0.0113 step time: 0.2004\n",
      "6/8, train_loss: 0.0114 step time: 0.2029\n",
      "7/8, train_loss: 0.0119 step time: 0.1823\n",
      "8/8, train_loss: 0.0120 step time: 0.1812\n",
      "epoch 540 average loss: 0.0115\n",
      "current epoch: 540 current mean dice: 0.9590 best mean dice: 0.9603 at epoch: 520\n",
      "time consuming of epoch 540 is: 2.3762\n",
      "----------\n",
      "epoch 541/600\n",
      "1/8, train_loss: 0.0106 step time: 0.2380\n",
      "2/8, train_loss: 0.0106 step time: 0.1988\n",
      "3/8, train_loss: 0.0085 step time: 0.1996\n",
      "4/8, train_loss: 0.0133 step time: 0.2021\n",
      "5/8, train_loss: 0.0115 step time: 0.1982\n",
      "6/8, train_loss: 0.0124 step time: 0.2023\n",
      "7/8, train_loss: 0.0131 step time: 0.1815\n",
      "8/8, train_loss: 0.0101 step time: 0.1815\n",
      "epoch 541 average loss: 0.0113\n",
      "time consuming of epoch 541 is: 1.6031\n",
      "----------\n",
      "epoch 542/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2400\n",
      "2/8, train_loss: 0.0101 step time: 0.1978\n",
      "3/8, train_loss: 0.0120 step time: 0.2014\n",
      "4/8, train_loss: 0.0143 step time: 0.1985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8, train_loss: 0.0108 step time: 0.1997\n",
      "6/8, train_loss: 0.0121 step time: 0.2006\n",
      "7/8, train_loss: 0.0127 step time: 0.1844\n",
      "8/8, train_loss: 0.0109 step time: 0.1826\n",
      "epoch 542 average loss: 0.0118\n",
      "time consuming of epoch 542 is: 1.6064\n",
      "----------\n",
      "epoch 543/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2391\n",
      "2/8, train_loss: 0.0112 step time: 0.1949\n",
      "3/8, train_loss: 0.0102 step time: 0.1969\n",
      "4/8, train_loss: 0.0130 step time: 0.1970\n",
      "5/8, train_loss: 0.0124 step time: 0.1959\n",
      "6/8, train_loss: 0.0133 step time: 0.1948\n",
      "7/8, train_loss: 0.0118 step time: 0.1822\n",
      "8/8, train_loss: 0.0111 step time: 0.1824\n",
      "epoch 543 average loss: 0.0116\n",
      "time consuming of epoch 543 is: 1.5847\n",
      "----------\n",
      "epoch 544/600\n",
      "1/8, train_loss: 0.0103 step time: 0.2443\n",
      "2/8, train_loss: 0.0112 step time: 0.2049\n",
      "3/8, train_loss: 0.0108 step time: 0.2022\n",
      "4/8, train_loss: 0.0105 step time: 0.1990\n",
      "5/8, train_loss: 0.0102 step time: 0.2016\n",
      "6/8, train_loss: 0.0127 step time: 0.1988\n",
      "7/8, train_loss: 0.0134 step time: 0.1820\n",
      "8/8, train_loss: 0.0109 step time: 0.1818\n",
      "epoch 544 average loss: 0.0113\n",
      "time consuming of epoch 544 is: 1.6162\n",
      "----------\n",
      "epoch 545/600\n",
      "1/8, train_loss: 0.0117 step time: 0.2412\n",
      "2/8, train_loss: 0.0106 step time: 0.2048\n",
      "3/8, train_loss: 0.0112 step time: 0.2046\n",
      "4/8, train_loss: 0.0099 step time: 0.2018\n",
      "5/8, train_loss: 0.0104 step time: 0.1993\n",
      "6/8, train_loss: 0.0097 step time: 0.2015\n",
      "7/8, train_loss: 0.0114 step time: 0.1827\n",
      "8/8, train_loss: 0.0131 step time: 0.1824\n",
      "epoch 545 average loss: 0.0110\n",
      "saved new best metric model\n",
      "current epoch: 545 current mean dice: 0.9604 best mean dice: 0.9604 at epoch: 545\n",
      "time consuming of epoch 545 is: 2.5149\n",
      "----------\n",
      "epoch 546/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2372\n",
      "2/8, train_loss: 0.0109 step time: 0.1991\n",
      "3/8, train_loss: 0.0109 step time: 0.1987\n",
      "4/8, train_loss: 0.0114 step time: 0.2038\n",
      "5/8, train_loss: 0.0133 step time: 0.1994\n",
      "6/8, train_loss: 0.0119 step time: 0.2011\n",
      "7/8, train_loss: 0.0129 step time: 0.1832\n",
      "8/8, train_loss: 0.0117 step time: 0.1822\n",
      "epoch 546 average loss: 0.0115\n",
      "time consuming of epoch 546 is: 1.6060\n",
      "----------\n",
      "epoch 547/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2424\n",
      "2/8, train_loss: 0.0102 step time: 0.2025\n",
      "3/8, train_loss: 0.0103 step time: 0.2020\n",
      "4/8, train_loss: 0.0119 step time: 0.1997\n",
      "5/8, train_loss: 0.0116 step time: 0.2018\n",
      "6/8, train_loss: 0.0105 step time: 0.2019\n",
      "7/8, train_loss: 0.0127 step time: 0.1829\n",
      "8/8, train_loss: 0.0122 step time: 0.1839\n",
      "epoch 547 average loss: 0.0112\n",
      "time consuming of epoch 547 is: 1.6189\n",
      "----------\n",
      "epoch 548/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2390\n",
      "2/8, train_loss: 0.0110 step time: 0.2016\n",
      "3/8, train_loss: 0.0103 step time: 0.1997\n",
      "4/8, train_loss: 0.0121 step time: 0.2016\n",
      "5/8, train_loss: 0.0090 step time: 0.2027\n",
      "6/8, train_loss: 0.0104 step time: 0.2037\n",
      "7/8, train_loss: 0.0142 step time: 0.1830\n",
      "8/8, train_loss: 0.0110 step time: 0.1820\n",
      "epoch 548 average loss: 0.0116\n",
      "time consuming of epoch 548 is: 1.6151\n",
      "----------\n",
      "epoch 549/600\n",
      "1/8, train_loss: 0.0109 step time: 0.2426\n",
      "2/8, train_loss: 0.0114 step time: 0.2025\n",
      "3/8, train_loss: 0.0122 step time: 0.2012\n",
      "4/8, train_loss: 0.0133 step time: 0.2012\n",
      "5/8, train_loss: 0.0098 step time: 0.2003\n",
      "6/8, train_loss: 0.0117 step time: 0.2050\n",
      "7/8, train_loss: 0.0130 step time: 0.1835\n",
      "8/8, train_loss: 0.0104 step time: 0.1826\n",
      "epoch 549 average loss: 0.0116\n",
      "time consuming of epoch 549 is: 1.6207\n",
      "----------\n",
      "epoch 550/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2386\n",
      "2/8, train_loss: 0.0134 step time: 0.2020\n",
      "3/8, train_loss: 0.0113 step time: 0.2028\n",
      "4/8, train_loss: 0.0102 step time: 0.1990\n",
      "5/8, train_loss: 0.0094 step time: 0.2024\n",
      "6/8, train_loss: 0.0099 step time: 0.2005\n",
      "7/8, train_loss: 0.0120 step time: 0.1829\n",
      "8/8, train_loss: 0.0112 step time: 0.1838\n",
      "epoch 550 average loss: 0.0110\n",
      "current epoch: 550 current mean dice: 0.9603 best mean dice: 0.9604 at epoch: 545\n",
      "time consuming of epoch 550 is: 2.3689\n",
      "----------\n",
      "epoch 551/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2356\n",
      "2/8, train_loss: 0.0107 step time: 0.1997\n",
      "3/8, train_loss: 0.0104 step time: 0.2069\n",
      "4/8, train_loss: 0.0118 step time: 0.1972\n",
      "5/8, train_loss: 0.0093 step time: 0.1980\n",
      "6/8, train_loss: 0.0109 step time: 0.1979\n",
      "7/8, train_loss: 0.0164 step time: 0.1812\n",
      "8/8, train_loss: 0.0114 step time: 0.1819\n",
      "epoch 551 average loss: 0.0114\n",
      "time consuming of epoch 551 is: 1.5995\n",
      "----------\n",
      "epoch 552/600\n",
      "1/8, train_loss: 0.0133 step time: 0.2418\n",
      "2/8, train_loss: 0.0116 step time: 0.2005\n",
      "3/8, train_loss: 0.0104 step time: 0.2014\n",
      "4/8, train_loss: 0.0117 step time: 0.1987\n",
      "5/8, train_loss: 0.0111 step time: 0.2020\n",
      "6/8, train_loss: 0.0101 step time: 0.2018\n",
      "7/8, train_loss: 0.0095 step time: 0.1822\n",
      "8/8, train_loss: 0.0133 step time: 0.1821\n",
      "epoch 552 average loss: 0.0114\n",
      "time consuming of epoch 552 is: 1.6119\n",
      "----------\n",
      "epoch 553/600\n",
      "1/8, train_loss: 0.0119 step time: 0.2441\n",
      "2/8, train_loss: 0.0113 step time: 0.2000\n",
      "3/8, train_loss: 0.0106 step time: 0.1998\n",
      "4/8, train_loss: 0.0096 step time: 0.1997\n",
      "5/8, train_loss: 0.0129 step time: 0.2051\n",
      "6/8, train_loss: 0.0099 step time: 0.2003\n",
      "7/8, train_loss: 0.0129 step time: 0.1851\n",
      "8/8, train_loss: 0.0107 step time: 0.1844\n",
      "epoch 553 average loss: 0.0112\n",
      "time consuming of epoch 553 is: 1.6199\n",
      "----------\n",
      "epoch 554/600\n",
      "1/8, train_loss: 0.0082 step time: 0.2421\n",
      "2/8, train_loss: 0.0117 step time: 0.2059\n",
      "3/8, train_loss: 0.0111 step time: 0.2029\n",
      "4/8, train_loss: 0.0118 step time: 0.2002\n",
      "5/8, train_loss: 0.0107 step time: 0.2053\n",
      "6/8, train_loss: 0.0098 step time: 0.2068\n",
      "7/8, train_loss: 0.0141 step time: 0.1829\n",
      "8/8, train_loss: 0.0098 step time: 0.1827\n",
      "epoch 554 average loss: 0.0109\n",
      "time consuming of epoch 554 is: 1.6300\n",
      "----------\n",
      "epoch 555/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2391\n",
      "2/8, train_loss: 0.0118 step time: 0.1992\n",
      "3/8, train_loss: 0.0127 step time: 0.2032\n",
      "4/8, train_loss: 0.0116 step time: 0.2028\n",
      "5/8, train_loss: 0.0131 step time: 0.2026\n",
      "6/8, train_loss: 0.0125 step time: 0.1991\n",
      "7/8, train_loss: 0.0089 step time: 0.1832\n",
      "8/8, train_loss: 0.0104 step time: 0.1823\n",
      "epoch 555 average loss: 0.0113\n",
      "current epoch: 555 current mean dice: 0.9598 best mean dice: 0.9604 at epoch: 545\n",
      "time consuming of epoch 555 is: 2.3685\n",
      "----------\n",
      "epoch 556/600\n",
      "1/8, train_loss: 0.0106 step time: 0.2396\n",
      "2/8, train_loss: 0.0110 step time: 0.1983\n",
      "3/8, train_loss: 0.0095 step time: 0.2051\n",
      "4/8, train_loss: 0.0129 step time: 0.1995\n",
      "5/8, train_loss: 0.0102 step time: 0.2017\n",
      "6/8, train_loss: 0.0111 step time: 0.1972\n",
      "7/8, train_loss: 0.0144 step time: 0.1812\n",
      "8/8, train_loss: 0.0109 step time: 0.1810\n",
      "epoch 556 average loss: 0.0113\n",
      "time consuming of epoch 556 is: 1.6047\n",
      "----------\n",
      "epoch 557/600\n",
      "1/8, train_loss: 0.0108 step time: 0.2496\n",
      "2/8, train_loss: 0.0157 step time: 0.2052\n",
      "3/8, train_loss: 0.0093 step time: 0.1986\n",
      "4/8, train_loss: 0.0108 step time: 0.2011\n",
      "5/8, train_loss: 0.0113 step time: 0.2004\n",
      "6/8, train_loss: 0.0149 step time: 0.2023\n",
      "7/8, train_loss: 0.0096 step time: 0.1824\n",
      "8/8, train_loss: 0.0107 step time: 0.1822\n",
      "epoch 557 average loss: 0.0116\n",
      "time consuming of epoch 557 is: 1.6232\n",
      "----------\n",
      "epoch 558/600\n",
      "1/8, train_loss: 0.0115 step time: 0.2309\n",
      "2/8, train_loss: 0.0114 step time: 0.2019\n",
      "3/8, train_loss: 0.0105 step time: 0.2000\n",
      "4/8, train_loss: 0.0128 step time: 0.1999\n",
      "5/8, train_loss: 0.0111 step time: 0.1999\n",
      "6/8, train_loss: 0.0128 step time: 0.1996\n",
      "7/8, train_loss: 0.0117 step time: 0.1822\n",
      "8/8, train_loss: 0.0097 step time: 0.1838\n",
      "epoch 558 average loss: 0.0114\n",
      "time consuming of epoch 558 is: 1.5998\n",
      "----------\n",
      "epoch 559/600\n",
      "1/8, train_loss: 0.0116 step time: 0.2423\n",
      "2/8, train_loss: 0.0131 step time: 0.2014\n",
      "3/8, train_loss: 0.0097 step time: 0.1982\n",
      "4/8, train_loss: 0.0118 step time: 0.2003\n",
      "5/8, train_loss: 0.0108 step time: 0.1989\n",
      "6/8, train_loss: 0.0110 step time: 0.2008\n",
      "7/8, train_loss: 0.0112 step time: 0.1824\n",
      "8/8, train_loss: 0.0113 step time: 0.1827\n",
      "epoch 559 average loss: 0.0113\n",
      "time consuming of epoch 559 is: 1.6081\n",
      "----------\n",
      "epoch 560/600\n",
      "1/8, train_loss: 0.0116 step time: 0.2395\n",
      "2/8, train_loss: 0.0102 step time: 0.2016\n",
      "3/8, train_loss: 0.0108 step time: 0.1993\n",
      "4/8, train_loss: 0.0119 step time: 0.1942\n",
      "5/8, train_loss: 0.0106 step time: 0.1929\n",
      "6/8, train_loss: 0.0112 step time: 0.1939\n",
      "7/8, train_loss: 0.0099 step time: 0.1837\n",
      "8/8, train_loss: 0.0118 step time: 0.1822\n",
      "epoch 560 average loss: 0.0110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 560 current mean dice: 0.9592 best mean dice: 0.9604 at epoch: 545\n",
      "time consuming of epoch 560 is: 2.3433\n",
      "----------\n",
      "epoch 561/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2367\n",
      "2/8, train_loss: 0.0122 step time: 0.1987\n",
      "3/8, train_loss: 0.0103 step time: 0.1995\n",
      "4/8, train_loss: 0.0123 step time: 0.2014\n",
      "5/8, train_loss: 0.0134 step time: 0.1971\n",
      "6/8, train_loss: 0.0131 step time: 0.2004\n",
      "7/8, train_loss: 0.0091 step time: 0.1815\n",
      "8/8, train_loss: 0.0105 step time: 0.1813\n",
      "epoch 561 average loss: 0.0114\n",
      "time consuming of epoch 561 is: 1.5979\n",
      "----------\n",
      "epoch 562/600\n",
      "1/8, train_loss: 0.0148 step time: 0.2457\n",
      "2/8, train_loss: 0.0111 step time: 0.1994\n",
      "3/8, train_loss: 0.0157 step time: 0.1998\n",
      "4/8, train_loss: 0.0107 step time: 0.1989\n",
      "5/8, train_loss: 0.0099 step time: 0.2007\n",
      "6/8, train_loss: 0.0140 step time: 0.2041\n",
      "7/8, train_loss: 0.0106 step time: 0.1846\n",
      "8/8, train_loss: 0.0119 step time: 0.1820\n",
      "epoch 562 average loss: 0.0124\n",
      "time consuming of epoch 562 is: 1.6166\n",
      "----------\n",
      "epoch 563/600\n",
      "1/8, train_loss: 0.0119 step time: 0.2399\n",
      "2/8, train_loss: 0.0173 step time: 0.2032\n",
      "3/8, train_loss: 0.0160 step time: 0.2013\n",
      "4/8, train_loss: 0.0122 step time: 0.2019\n",
      "5/8, train_loss: 0.0116 step time: 0.1992\n",
      "6/8, train_loss: 0.0095 step time: 0.1938\n",
      "7/8, train_loss: 0.0129 step time: 0.1826\n",
      "8/8, train_loss: 0.0106 step time: 0.1826\n",
      "epoch 563 average loss: 0.0127\n",
      "time consuming of epoch 563 is: 1.6063\n",
      "----------\n",
      "epoch 564/600\n",
      "1/8, train_loss: 0.0150 step time: 0.2378\n",
      "2/8, train_loss: 0.0128 step time: 0.1972\n",
      "3/8, train_loss: 0.0096 step time: 0.2012\n",
      "4/8, train_loss: 0.0118 step time: 0.1979\n",
      "5/8, train_loss: 0.0122 step time: 0.2003\n",
      "6/8, train_loss: 0.0124 step time: 0.1995\n",
      "7/8, train_loss: 0.0124 step time: 0.1832\n",
      "8/8, train_loss: 0.0101 step time: 0.1823\n",
      "epoch 564 average loss: 0.0120\n",
      "time consuming of epoch 564 is: 1.6009\n",
      "----------\n",
      "epoch 565/600\n",
      "1/8, train_loss: 0.0128 step time: 0.2393\n",
      "2/8, train_loss: 0.0114 step time: 0.2023\n",
      "3/8, train_loss: 0.0113 step time: 0.1988\n",
      "4/8, train_loss: 0.0114 step time: 0.1999\n",
      "5/8, train_loss: 0.0104 step time: 0.1986\n",
      "6/8, train_loss: 0.0105 step time: 0.2005\n",
      "7/8, train_loss: 0.0128 step time: 0.1828\n",
      "8/8, train_loss: 0.0120 step time: 0.1826\n",
      "epoch 565 average loss: 0.0116\n",
      "current epoch: 565 current mean dice: 0.9598 best mean dice: 0.9604 at epoch: 545\n",
      "time consuming of epoch 565 is: 2.3621\n",
      "----------\n",
      "epoch 566/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2296\n",
      "2/8, train_loss: 0.0144 step time: 0.1962\n",
      "3/8, train_loss: 0.0101 step time: 0.1962\n",
      "4/8, train_loss: 0.0118 step time: 0.1944\n",
      "5/8, train_loss: 0.0118 step time: 0.1976\n",
      "6/8, train_loss: 0.0114 step time: 0.1948\n",
      "7/8, train_loss: 0.0130 step time: 0.1816\n",
      "8/8, train_loss: 0.0104 step time: 0.1811\n",
      "epoch 566 average loss: 0.0117\n",
      "time consuming of epoch 566 is: 1.5727\n",
      "----------\n",
      "epoch 567/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2318\n",
      "2/8, train_loss: 0.0152 step time: 0.2019\n",
      "3/8, train_loss: 0.0099 step time: 0.1970\n",
      "4/8, train_loss: 0.0164 step time: 0.1959\n",
      "5/8, train_loss: 0.0107 step time: 0.1955\n",
      "6/8, train_loss: 0.0111 step time: 0.1982\n",
      "7/8, train_loss: 0.0113 step time: 0.1831\n",
      "8/8, train_loss: 0.0110 step time: 0.1821\n",
      "epoch 567 average loss: 0.0121\n",
      "time consuming of epoch 567 is: 1.5869\n",
      "----------\n",
      "epoch 568/600\n",
      "1/8, train_loss: 0.0099 step time: 0.2329\n",
      "2/8, train_loss: 0.0118 step time: 0.1982\n",
      "3/8, train_loss: 0.0117 step time: 0.1968\n",
      "4/8, train_loss: 0.0154 step time: 0.1960\n",
      "5/8, train_loss: 0.0113 step time: 0.1956\n",
      "6/8, train_loss: 0.0112 step time: 0.1996\n",
      "7/8, train_loss: 0.0109 step time: 0.1832\n",
      "8/8, train_loss: 0.0130 step time: 0.1826\n",
      "epoch 568 average loss: 0.0119\n",
      "time consuming of epoch 568 is: 1.5863\n",
      "----------\n",
      "epoch 569/600\n",
      "1/8, train_loss: 0.0120 step time: 0.2404\n",
      "2/8, train_loss: 0.0113 step time: 0.2035\n",
      "3/8, train_loss: 0.0113 step time: 0.1994\n",
      "4/8, train_loss: 0.0106 step time: 0.2040\n",
      "5/8, train_loss: 0.0139 step time: 0.2005\n",
      "6/8, train_loss: 0.0130 step time: 0.2009\n",
      "7/8, train_loss: 0.0116 step time: 0.1833\n",
      "8/8, train_loss: 0.0092 step time: 0.1824\n",
      "epoch 569 average loss: 0.0116\n",
      "time consuming of epoch 569 is: 1.6160\n",
      "----------\n",
      "epoch 570/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2386\n",
      "2/8, train_loss: 0.0117 step time: 0.2025\n",
      "3/8, train_loss: 0.0109 step time: 0.1975\n",
      "4/8, train_loss: 0.0117 step time: 0.2021\n",
      "5/8, train_loss: 0.0118 step time: 0.1992\n",
      "6/8, train_loss: 0.0118 step time: 0.1985\n",
      "7/8, train_loss: 0.0166 step time: 0.1823\n",
      "8/8, train_loss: 0.0095 step time: 0.1820\n",
      "epoch 570 average loss: 0.0121\n",
      "current epoch: 570 current mean dice: 0.9585 best mean dice: 0.9604 at epoch: 545\n",
      "time consuming of epoch 570 is: 2.3593\n",
      "----------\n",
      "epoch 571/600\n",
      "1/8, train_loss: 0.0088 step time: 0.2353\n",
      "2/8, train_loss: 0.0130 step time: 0.1971\n",
      "3/8, train_loss: 0.0139 step time: 0.2022\n",
      "4/8, train_loss: 0.0121 step time: 0.1979\n",
      "5/8, train_loss: 0.0099 step time: 0.1992\n",
      "6/8, train_loss: 0.0109 step time: 0.1987\n",
      "7/8, train_loss: 0.0142 step time: 0.1822\n",
      "8/8, train_loss: 0.0101 step time: 0.1835\n",
      "epoch 571 average loss: 0.0116\n",
      "time consuming of epoch 571 is: 1.5974\n",
      "----------\n",
      "epoch 572/600\n",
      "1/8, train_loss: 0.0120 step time: 0.2402\n",
      "2/8, train_loss: 0.0107 step time: 0.2033\n",
      "3/8, train_loss: 0.0117 step time: 0.2002\n",
      "4/8, train_loss: 0.0139 step time: 0.2004\n",
      "5/8, train_loss: 0.0120 step time: 0.1999\n",
      "6/8, train_loss: 0.0110 step time: 0.2043\n",
      "7/8, train_loss: 0.0108 step time: 0.1850\n",
      "8/8, train_loss: 0.0122 step time: 0.1824\n",
      "epoch 572 average loss: 0.0118\n",
      "time consuming of epoch 572 is: 1.6175\n",
      "----------\n",
      "epoch 573/600\n",
      "1/8, train_loss: 0.0114 step time: 0.2368\n",
      "2/8, train_loss: 0.0108 step time: 0.2035\n",
      "3/8, train_loss: 0.0102 step time: 0.1988\n",
      "4/8, train_loss: 0.0116 step time: 0.1998\n",
      "5/8, train_loss: 0.0116 step time: 0.1999\n",
      "6/8, train_loss: 0.0117 step time: 0.2006\n",
      "7/8, train_loss: 0.0118 step time: 0.1827\n",
      "8/8, train_loss: 0.0104 step time: 0.1825\n",
      "epoch 573 average loss: 0.0112\n",
      "time consuming of epoch 573 is: 1.6060\n",
      "----------\n",
      "epoch 574/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2412\n",
      "2/8, train_loss: 0.0127 step time: 0.2039\n",
      "3/8, train_loss: 0.0103 step time: 0.1997\n",
      "4/8, train_loss: 0.0120 step time: 0.2011\n",
      "5/8, train_loss: 0.0106 step time: 0.2005\n",
      "6/8, train_loss: 0.0120 step time: 0.2022\n",
      "7/8, train_loss: 0.0103 step time: 0.1832\n",
      "8/8, train_loss: 0.0110 step time: 0.1831\n",
      "epoch 574 average loss: 0.0114\n",
      "time consuming of epoch 574 is: 1.6165\n",
      "----------\n",
      "epoch 575/600\n",
      "1/8, train_loss: 0.0112 step time: 0.2424\n",
      "2/8, train_loss: 0.0100 step time: 0.2015\n",
      "3/8, train_loss: 0.0109 step time: 0.2016\n",
      "4/8, train_loss: 0.0109 step time: 0.2019\n",
      "5/8, train_loss: 0.0117 step time: 0.2023\n",
      "6/8, train_loss: 0.0107 step time: 0.1996\n",
      "7/8, train_loss: 0.0120 step time: 0.1835\n",
      "8/8, train_loss: 0.0110 step time: 0.1826\n",
      "epoch 575 average loss: 0.0111\n",
      "saved new best metric model\n",
      "current epoch: 575 current mean dice: 0.9607 best mean dice: 0.9607 at epoch: 575\n",
      "time consuming of epoch 575 is: 2.5125\n",
      "----------\n",
      "epoch 576/600\n",
      "1/8, train_loss: 0.0096 step time: 0.2341\n",
      "2/8, train_loss: 0.0111 step time: 0.1981\n",
      "3/8, train_loss: 0.0128 step time: 0.1968\n",
      "4/8, train_loss: 0.0091 step time: 0.1940\n",
      "5/8, train_loss: 0.0119 step time: 0.1954\n",
      "6/8, train_loss: 0.0122 step time: 0.1953\n",
      "7/8, train_loss: 0.0119 step time: 0.1810\n",
      "8/8, train_loss: 0.0140 step time: 0.1843\n",
      "epoch 576 average loss: 0.0116\n",
      "time consuming of epoch 576 is: 1.5801\n",
      "----------\n",
      "epoch 577/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2341\n",
      "2/8, train_loss: 0.0119 step time: 0.1987\n",
      "3/8, train_loss: 0.0119 step time: 0.1966\n",
      "4/8, train_loss: 0.0106 step time: 0.1939\n",
      "5/8, train_loss: 0.0100 step time: 0.1983\n",
      "6/8, train_loss: 0.0119 step time: 0.1961\n",
      "7/8, train_loss: 0.0127 step time: 0.1840\n",
      "8/8, train_loss: 0.0134 step time: 0.1827\n",
      "epoch 577 average loss: 0.0116\n",
      "time consuming of epoch 577 is: 1.5863\n",
      "----------\n",
      "epoch 578/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2383\n",
      "2/8, train_loss: 0.0117 step time: 0.1980\n",
      "3/8, train_loss: 0.0148 step time: 0.1972\n",
      "4/8, train_loss: 0.0101 step time: 0.1956\n",
      "5/8, train_loss: 0.0095 step time: 0.1964\n",
      "6/8, train_loss: 0.0095 step time: 0.1973\n",
      "7/8, train_loss: 0.0122 step time: 0.1830\n",
      "8/8, train_loss: 0.0138 step time: 0.1814\n",
      "epoch 578 average loss: 0.0116\n",
      "time consuming of epoch 578 is: 1.5887\n",
      "----------\n",
      "epoch 579/600\n",
      "1/8, train_loss: 0.0113 step time: 0.2327\n",
      "2/8, train_loss: 0.0109 step time: 0.1984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8, train_loss: 0.0097 step time: 0.1981\n",
      "4/8, train_loss: 0.0101 step time: 0.1986\n",
      "5/8, train_loss: 0.0129 step time: 0.1977\n",
      "6/8, train_loss: 0.0132 step time: 0.1988\n",
      "7/8, train_loss: 0.0096 step time: 0.1827\n",
      "8/8, train_loss: 0.0105 step time: 0.1819\n",
      "epoch 579 average loss: 0.0110\n",
      "time consuming of epoch 579 is: 1.5901\n",
      "----------\n",
      "epoch 580/600\n",
      "1/8, train_loss: 0.0140 step time: 0.2394\n",
      "2/8, train_loss: 0.0105 step time: 0.2020\n",
      "3/8, train_loss: 0.0101 step time: 0.2021\n",
      "4/8, train_loss: 0.0117 step time: 0.1999\n",
      "5/8, train_loss: 0.0120 step time: 0.1998\n",
      "6/8, train_loss: 0.0155 step time: 0.1988\n",
      "7/8, train_loss: 0.0093 step time: 0.1809\n",
      "8/8, train_loss: 0.0091 step time: 0.1828\n",
      "epoch 580 average loss: 0.0115\n",
      "saved new best metric model\n",
      "current epoch: 580 current mean dice: 0.9609 best mean dice: 0.9609 at epoch: 580\n",
      "time consuming of epoch 580 is: 2.5023\n",
      "----------\n",
      "epoch 581/600\n",
      "1/8, train_loss: 0.0123 step time: 0.2371\n",
      "2/8, train_loss: 0.0143 step time: 0.1998\n",
      "3/8, train_loss: 0.0115 step time: 0.1992\n",
      "4/8, train_loss: 0.0114 step time: 0.2014\n",
      "5/8, train_loss: 0.0119 step time: 0.2036\n",
      "6/8, train_loss: 0.0112 step time: 0.2003\n",
      "7/8, train_loss: 0.0128 step time: 0.1822\n",
      "8/8, train_loss: 0.0089 step time: 0.1810\n",
      "epoch 581 average loss: 0.0118\n",
      "time consuming of epoch 581 is: 1.6061\n",
      "----------\n",
      "epoch 582/600\n",
      "1/8, train_loss: 0.0120 step time: 0.2366\n",
      "2/8, train_loss: 0.0113 step time: 0.1970\n",
      "3/8, train_loss: 0.0139 step time: 0.2032\n",
      "4/8, train_loss: 0.0126 step time: 0.2077\n",
      "5/8, train_loss: 0.0102 step time: 0.2023\n",
      "6/8, train_loss: 0.0096 step time: 0.1991\n",
      "7/8, train_loss: 0.0102 step time: 0.1829\n",
      "8/8, train_loss: 0.0115 step time: 0.1823\n",
      "epoch 582 average loss: 0.0114\n",
      "time consuming of epoch 582 is: 1.6126\n",
      "----------\n",
      "epoch 583/600\n",
      "1/8, train_loss: 0.0113 step time: 0.2391\n",
      "2/8, train_loss: 0.0122 step time: 0.2020\n",
      "3/8, train_loss: 0.0107 step time: 0.1990\n",
      "4/8, train_loss: 0.0121 step time: 0.2021\n",
      "5/8, train_loss: 0.0150 step time: 0.1986\n",
      "6/8, train_loss: 0.0109 step time: 0.2022\n",
      "7/8, train_loss: 0.0117 step time: 0.1818\n",
      "8/8, train_loss: 0.0120 step time: 0.1817\n",
      "epoch 583 average loss: 0.0120\n",
      "time consuming of epoch 583 is: 1.6078\n",
      "----------\n",
      "epoch 584/600\n",
      "1/8, train_loss: 0.0151 step time: 0.2406\n",
      "2/8, train_loss: 0.0140 step time: 0.2024\n",
      "3/8, train_loss: 0.0112 step time: 0.1994\n",
      "4/8, train_loss: 0.0111 step time: 0.2017\n",
      "5/8, train_loss: 0.0129 step time: 0.2001\n",
      "6/8, train_loss: 0.0095 step time: 0.1989\n",
      "7/8, train_loss: 0.0131 step time: 0.1829\n",
      "8/8, train_loss: 0.0120 step time: 0.1819\n",
      "epoch 584 average loss: 0.0124\n",
      "time consuming of epoch 584 is: 1.6093\n",
      "----------\n",
      "epoch 585/600\n",
      "1/8, train_loss: 0.0117 step time: 0.2411\n",
      "2/8, train_loss: 0.0156 step time: 0.2030\n",
      "3/8, train_loss: 0.0114 step time: 0.2009\n",
      "4/8, train_loss: 0.0099 step time: 0.2009\n",
      "5/8, train_loss: 0.0110 step time: 0.2001\n",
      "6/8, train_loss: 0.0149 step time: 0.2021\n",
      "7/8, train_loss: 0.0157 step time: 0.1830\n",
      "8/8, train_loss: 0.0098 step time: 0.1844\n",
      "epoch 585 average loss: 0.0125\n",
      "current epoch: 585 current mean dice: 0.9583 best mean dice: 0.9609 at epoch: 580\n",
      "time consuming of epoch 585 is: 2.3747\n",
      "----------\n",
      "epoch 586/600\n",
      "1/8, train_loss: 0.0103 step time: 0.2389\n",
      "2/8, train_loss: 0.0128 step time: 0.1983\n",
      "3/8, train_loss: 0.0145 step time: 0.2003\n",
      "4/8, train_loss: 0.0125 step time: 0.2032\n",
      "5/8, train_loss: 0.0116 step time: 0.1989\n",
      "6/8, train_loss: 0.0094 step time: 0.2017\n",
      "7/8, train_loss: 0.0132 step time: 0.1824\n",
      "8/8, train_loss: 0.0162 step time: 0.1822\n",
      "epoch 586 average loss: 0.0126\n",
      "time consuming of epoch 586 is: 1.6070\n",
      "----------\n",
      "epoch 587/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2388\n",
      "2/8, train_loss: 0.0136 step time: 0.1992\n",
      "3/8, train_loss: 0.0123 step time: 0.1995\n",
      "4/8, train_loss: 0.0111 step time: 0.1986\n",
      "5/8, train_loss: 0.0116 step time: 0.1971\n",
      "6/8, train_loss: 0.0096 step time: 0.1977\n",
      "7/8, train_loss: 0.0116 step time: 0.1824\n",
      "8/8, train_loss: 0.0151 step time: 0.1818\n",
      "epoch 587 average loss: 0.0120\n",
      "time consuming of epoch 587 is: 1.5965\n",
      "----------\n",
      "epoch 588/600\n",
      "1/8, train_loss: 0.0124 step time: 0.2388\n",
      "2/8, train_loss: 0.0117 step time: 0.1973\n",
      "3/8, train_loss: 0.0129 step time: 0.1994\n",
      "4/8, train_loss: 0.0105 step time: 0.1970\n",
      "5/8, train_loss: 0.0116 step time: 0.1984\n",
      "6/8, train_loss: 0.0111 step time: 0.1986\n",
      "7/8, train_loss: 0.0115 step time: 0.1828\n",
      "8/8, train_loss: 0.0131 step time: 0.1836\n",
      "epoch 588 average loss: 0.0119\n",
      "time consuming of epoch 588 is: 1.5972\n",
      "----------\n",
      "epoch 589/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2406\n",
      "2/8, train_loss: 0.0119 step time: 0.2046\n",
      "3/8, train_loss: 0.0103 step time: 0.1991\n",
      "4/8, train_loss: 0.0106 step time: 0.2009\n",
      "5/8, train_loss: 0.0145 step time: 0.2042\n",
      "6/8, train_loss: 0.0109 step time: 0.2038\n",
      "7/8, train_loss: 0.0106 step time: 0.1822\n",
      "8/8, train_loss: 0.0128 step time: 0.1835\n",
      "epoch 589 average loss: 0.0116\n",
      "time consuming of epoch 589 is: 1.6207\n",
      "----------\n",
      "epoch 590/600\n",
      "1/8, train_loss: 0.0109 step time: 0.2412\n",
      "2/8, train_loss: 0.0147 step time: 0.2031\n",
      "3/8, train_loss: 0.0105 step time: 0.2044\n",
      "4/8, train_loss: 0.0114 step time: 0.2003\n",
      "5/8, train_loss: 0.0114 step time: 0.2018\n",
      "6/8, train_loss: 0.0133 step time: 0.2034\n",
      "7/8, train_loss: 0.0096 step time: 0.1839\n",
      "8/8, train_loss: 0.0127 step time: 0.1833\n",
      "epoch 590 average loss: 0.0118\n",
      "current epoch: 590 current mean dice: 0.9602 best mean dice: 0.9609 at epoch: 580\n",
      "time consuming of epoch 590 is: 2.3797\n",
      "----------\n",
      "epoch 591/600\n",
      "1/8, train_loss: 0.0120 step time: 0.2425\n",
      "2/8, train_loss: 0.0120 step time: 0.1977\n",
      "3/8, train_loss: 0.0102 step time: 0.2025\n",
      "4/8, train_loss: 0.0107 step time: 0.2019\n",
      "5/8, train_loss: 0.0125 step time: 0.1973\n",
      "6/8, train_loss: 0.0124 step time: 0.2022\n",
      "7/8, train_loss: 0.0110 step time: 0.1830\n",
      "8/8, train_loss: 0.0122 step time: 0.1821\n",
      "epoch 591 average loss: 0.0116\n",
      "time consuming of epoch 591 is: 1.6103\n",
      "----------\n",
      "epoch 592/600\n",
      "1/8, train_loss: 0.0109 step time: 0.2403\n",
      "2/8, train_loss: 0.0116 step time: 0.2026\n",
      "3/8, train_loss: 0.0103 step time: 0.1990\n",
      "4/8, train_loss: 0.0113 step time: 0.2024\n",
      "5/8, train_loss: 0.0109 step time: 0.2013\n",
      "6/8, train_loss: 0.0092 step time: 0.2006\n",
      "7/8, train_loss: 0.0104 step time: 0.1833\n",
      "8/8, train_loss: 0.0101 step time: 0.1825\n",
      "epoch 592 average loss: 0.0106\n",
      "time consuming of epoch 592 is: 1.6133\n",
      "----------\n",
      "epoch 593/600\n",
      "1/8, train_loss: 0.0127 step time: 0.2395\n",
      "2/8, train_loss: 0.0138 step time: 0.2037\n",
      "3/8, train_loss: 0.0106 step time: 0.2006\n",
      "4/8, train_loss: 0.0116 step time: 0.1995\n",
      "5/8, train_loss: 0.0111 step time: 0.2027\n",
      "6/8, train_loss: 0.0096 step time: 0.2037\n",
      "7/8, train_loss: 0.0131 step time: 0.1812\n",
      "8/8, train_loss: 0.0144 step time: 0.1817\n",
      "epoch 593 average loss: 0.0121\n",
      "time consuming of epoch 593 is: 1.6143\n",
      "----------\n",
      "epoch 594/600\n",
      "1/8, train_loss: 0.0095 step time: 0.2401\n",
      "2/8, train_loss: 0.0157 step time: 0.2027\n",
      "3/8, train_loss: 0.0137 step time: 0.1993\n",
      "4/8, train_loss: 0.0121 step time: 0.2005\n",
      "5/8, train_loss: 0.0121 step time: 0.1994\n",
      "6/8, train_loss: 0.0110 step time: 0.2003\n",
      "7/8, train_loss: 0.0096 step time: 0.1821\n",
      "8/8, train_loss: 0.0116 step time: 0.1824\n",
      "epoch 594 average loss: 0.0119\n",
      "time consuming of epoch 594 is: 1.6081\n",
      "----------\n",
      "epoch 595/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2381\n",
      "2/8, train_loss: 0.0104 step time: 0.2044\n",
      "3/8, train_loss: 0.0139 step time: 0.1995\n",
      "4/8, train_loss: 0.0104 step time: 0.2019\n",
      "5/8, train_loss: 0.0115 step time: 0.1990\n",
      "6/8, train_loss: 0.0100 step time: 0.2011\n",
      "7/8, train_loss: 0.0142 step time: 0.1809\n",
      "8/8, train_loss: 0.0127 step time: 0.1833\n",
      "epoch 595 average loss: 0.0117\n",
      "current epoch: 595 current mean dice: 0.9595 best mean dice: 0.9609 at epoch: 580\n",
      "time consuming of epoch 595 is: 2.3647\n",
      "----------\n",
      "epoch 596/600\n",
      "1/8, train_loss: 0.0145 step time: 0.2362\n",
      "2/8, train_loss: 0.0112 step time: 0.1984\n",
      "3/8, train_loss: 0.0130 step time: 0.2000\n",
      "4/8, train_loss: 0.0105 step time: 0.1975\n",
      "5/8, train_loss: 0.0114 step time: 0.2010\n",
      "6/8, train_loss: 0.0099 step time: 0.1983\n",
      "7/8, train_loss: 0.0104 step time: 0.1812\n",
      "8/8, train_loss: 0.0111 step time: 0.1811\n",
      "epoch 596 average loss: 0.0115\n",
      "time consuming of epoch 596 is: 1.5946\n",
      "----------\n",
      "epoch 597/600\n",
      "1/8, train_loss: 0.0120 step time: 0.2397\n",
      "2/8, train_loss: 0.0102 step time: 0.2024\n",
      "3/8, train_loss: 0.0104 step time: 0.2006\n",
      "4/8, train_loss: 0.0119 step time: 0.2010\n",
      "5/8, train_loss: 0.0106 step time: 0.1992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/8, train_loss: 0.0119 step time: 0.2000\n",
      "7/8, train_loss: 0.0098 step time: 0.1849\n",
      "8/8, train_loss: 0.0105 step time: 0.1816\n",
      "epoch 597 average loss: 0.0109\n",
      "time consuming of epoch 597 is: 1.6109\n",
      "----------\n",
      "epoch 598/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2424\n",
      "2/8, train_loss: 0.0103 step time: 0.2051\n",
      "3/8, train_loss: 0.0104 step time: 0.1989\n",
      "4/8, train_loss: 0.0115 step time: 0.1993\n",
      "5/8, train_loss: 0.0092 step time: 0.1990\n",
      "6/8, train_loss: 0.0125 step time: 0.2018\n",
      "7/8, train_loss: 0.0133 step time: 0.1823\n",
      "8/8, train_loss: 0.0099 step time: 0.1836\n",
      "epoch 598 average loss: 0.0108\n",
      "time consuming of epoch 598 is: 1.6138\n",
      "----------\n",
      "epoch 599/600\n",
      "1/8, train_loss: 0.0113 step time: 0.2416\n",
      "2/8, train_loss: 0.0116 step time: 0.2066\n",
      "3/8, train_loss: 0.0110 step time: 0.2002\n",
      "4/8, train_loss: 0.0116 step time: 0.2008\n",
      "5/8, train_loss: 0.0114 step time: 0.1988\n",
      "6/8, train_loss: 0.0102 step time: 0.1928\n",
      "7/8, train_loss: 0.0118 step time: 0.1821\n",
      "8/8, train_loss: 0.0109 step time: 0.1810\n",
      "epoch 599 average loss: 0.0112\n",
      "time consuming of epoch 599 is: 1.6055\n",
      "----------\n",
      "epoch 600/600\n",
      "1/8, train_loss: 0.0128 step time: 0.2422\n",
      "2/8, train_loss: 0.0105 step time: 0.2032\n",
      "3/8, train_loss: 0.0106 step time: 0.2012\n",
      "4/8, train_loss: 0.0111 step time: 0.2043\n",
      "5/8, train_loss: 0.0134 step time: 0.2016\n",
      "6/8, train_loss: 0.0109 step time: 0.2004\n",
      "7/8, train_loss: 0.0085 step time: 0.1837\n",
      "8/8, train_loss: 0.0100 step time: 0.1810\n",
      "epoch 600 average loss: 0.0110\n",
      "current epoch: 600 current mean dice: 0.9599 best mean dice: 0.9609 at epoch: 580\n",
      "time consuming of epoch 600 is: 2.3716\n",
      "train completed, best_metric: 0.9609 at epoch: 580 total time: 1057.9996\n",
      "----------\n",
      "epoch 1/600\n",
      "1/8, train_loss: 0.0106 step time: 0.2264\n",
      "2/8, train_loss: 0.0101 step time: 0.1957\n",
      "3/8, train_loss: 0.0139 step time: 0.1953\n",
      "4/8, train_loss: 0.0140 step time: 0.1953\n",
      "5/8, train_loss: 0.0093 step time: 0.1951\n",
      "6/8, train_loss: 0.0092 step time: 0.1963\n",
      "7/8, train_loss: 0.0107 step time: 0.1847\n",
      "8/8, train_loss: 0.0114 step time: 0.1828\n",
      "epoch 1 average loss: 0.0111\n",
      "time consuming of epoch 1 is: 1.5728\n",
      "----------\n",
      "epoch 2/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2403\n",
      "2/8, train_loss: 0.0100 step time: 0.2050\n",
      "3/8, train_loss: 0.0100 step time: 0.2009\n",
      "4/8, train_loss: 0.0110 step time: 0.1996\n",
      "5/8, train_loss: 0.0139 step time: 0.2037\n",
      "6/8, train_loss: 0.0105 step time: 0.1999\n",
      "7/8, train_loss: 0.0102 step time: 0.1835\n",
      "8/8, train_loss: 0.0133 step time: 0.1827\n",
      "epoch 2 average loss: 0.0112\n",
      "time consuming of epoch 2 is: 1.6170\n",
      "----------\n",
      "epoch 3/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2404\n",
      "2/8, train_loss: 0.0128 step time: 0.2021\n",
      "3/8, train_loss: 0.0120 step time: 0.2018\n",
      "4/8, train_loss: 0.0093 step time: 0.2032\n",
      "5/8, train_loss: 0.0105 step time: 0.1988\n",
      "6/8, train_loss: 0.0126 step time: 0.2005\n",
      "7/8, train_loss: 0.0113 step time: 0.1826\n",
      "8/8, train_loss: 0.0103 step time: 0.1816\n",
      "epoch 3 average loss: 0.0113\n",
      "time consuming of epoch 3 is: 1.6124\n",
      "----------\n",
      "epoch 4/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2415\n",
      "2/8, train_loss: 0.0127 step time: 0.2002\n",
      "3/8, train_loss: 0.0108 step time: 0.2005\n",
      "4/8, train_loss: 0.0120 step time: 0.2004\n",
      "5/8, train_loss: 0.0086 step time: 0.2000\n",
      "6/8, train_loss: 0.0103 step time: 0.2022\n",
      "7/8, train_loss: 0.0087 step time: 0.1825\n",
      "8/8, train_loss: 0.0115 step time: 0.1827\n",
      "epoch 4 average loss: 0.0107\n",
      "time consuming of epoch 4 is: 1.6114\n",
      "----------\n",
      "epoch 5/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2423\n",
      "2/8, train_loss: 0.0107 step time: 0.2020\n",
      "3/8, train_loss: 0.0099 step time: 0.1995\n",
      "4/8, train_loss: 0.0107 step time: 0.1998\n",
      "5/8, train_loss: 0.0144 step time: 0.2023\n",
      "6/8, train_loss: 0.0132 step time: 0.1975\n",
      "7/8, train_loss: 0.0104 step time: 0.1821\n",
      "8/8, train_loss: 0.0098 step time: 0.1808\n",
      "epoch 5 average loss: 0.0111\n",
      "saved new best metric model\n",
      "current epoch: 5 current mean dice: 0.9597 best mean dice: 0.9597 at epoch: 5\n",
      "time consuming of epoch 5 is: 2.4998\n",
      "----------\n",
      "epoch 6/600\n",
      "1/8, train_loss: 0.0113 step time: 0.2302\n",
      "2/8, train_loss: 0.0117 step time: 0.1991\n",
      "3/8, train_loss: 0.0101 step time: 0.1940\n",
      "4/8, train_loss: 0.0092 step time: 0.1947\n",
      "5/8, train_loss: 0.0104 step time: 0.1963\n",
      "6/8, train_loss: 0.0096 step time: 0.1957\n",
      "7/8, train_loss: 0.0098 step time: 0.1820\n",
      "8/8, train_loss: 0.0120 step time: 0.1814\n",
      "epoch 6 average loss: 0.0105\n",
      "time consuming of epoch 6 is: 1.5745\n",
      "----------\n",
      "epoch 7/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2401\n",
      "2/8, train_loss: 0.0100 step time: 0.2026\n",
      "3/8, train_loss: 0.0100 step time: 0.1999\n",
      "4/8, train_loss: 0.0119 step time: 0.2025\n",
      "5/8, train_loss: 0.0115 step time: 0.2000\n",
      "6/8, train_loss: 0.0096 step time: 0.2009\n",
      "7/8, train_loss: 0.0116 step time: 0.1831\n",
      "8/8, train_loss: 0.0112 step time: 0.1829\n",
      "epoch 7 average loss: 0.0109\n",
      "time consuming of epoch 7 is: 1.6136\n",
      "----------\n",
      "epoch 8/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2406\n",
      "2/8, train_loss: 0.0090 step time: 0.2025\n",
      "3/8, train_loss: 0.0099 step time: 0.2012\n",
      "4/8, train_loss: 0.0124 step time: 0.2023\n",
      "5/8, train_loss: 0.0112 step time: 0.1999\n",
      "6/8, train_loss: 0.0113 step time: 0.2006\n",
      "7/8, train_loss: 0.0105 step time: 0.1830\n",
      "8/8, train_loss: 0.0111 step time: 0.1830\n",
      "epoch 8 average loss: 0.0110\n",
      "time consuming of epoch 8 is: 1.6149\n",
      "----------\n",
      "epoch 9/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2413\n",
      "2/8, train_loss: 0.0110 step time: 0.2043\n",
      "3/8, train_loss: 0.0108 step time: 0.2040\n",
      "4/8, train_loss: 0.0116 step time: 0.2004\n",
      "5/8, train_loss: 0.0135 step time: 0.2002\n",
      "6/8, train_loss: 0.0109 step time: 0.1999\n",
      "7/8, train_loss: 0.0109 step time: 0.1839\n",
      "8/8, train_loss: 0.0092 step time: 0.1825\n",
      "epoch 9 average loss: 0.0109\n",
      "time consuming of epoch 9 is: 1.6183\n",
      "----------\n",
      "epoch 10/600\n",
      "1/8, train_loss: 0.0094 step time: 0.2395\n",
      "2/8, train_loss: 0.0102 step time: 0.2014\n",
      "3/8, train_loss: 0.0100 step time: 0.1997\n",
      "4/8, train_loss: 0.0128 step time: 0.2002\n",
      "5/8, train_loss: 0.0108 step time: 0.1989\n",
      "6/8, train_loss: 0.0112 step time: 0.2024\n",
      "7/8, train_loss: 0.0092 step time: 0.1842\n",
      "8/8, train_loss: 0.0109 step time: 0.1842\n",
      "epoch 10 average loss: 0.0106\n",
      "saved new best metric model\n",
      "current epoch: 10 current mean dice: 0.9611 best mean dice: 0.9611 at epoch: 10\n",
      "time consuming of epoch 10 is: 2.5071\n",
      "----------\n",
      "epoch 11/600\n",
      "1/8, train_loss: 0.0116 step time: 0.2391\n",
      "2/8, train_loss: 0.0097 step time: 0.1983\n",
      "3/8, train_loss: 0.0088 step time: 0.2006\n",
      "4/8, train_loss: 0.0150 step time: 0.1983\n",
      "5/8, train_loss: 0.0091 step time: 0.1981\n",
      "6/8, train_loss: 0.0113 step time: 0.1989\n",
      "7/8, train_loss: 0.0097 step time: 0.1821\n",
      "8/8, train_loss: 0.0115 step time: 0.1829\n",
      "epoch 11 average loss: 0.0108\n",
      "time consuming of epoch 11 is: 1.5994\n",
      "----------\n",
      "epoch 12/600\n",
      "1/8, train_loss: 0.0082 step time: 0.2377\n",
      "2/8, train_loss: 0.0103 step time: 0.2033\n",
      "3/8, train_loss: 0.0125 step time: 0.2026\n",
      "4/8, train_loss: 0.0121 step time: 0.2018\n",
      "5/8, train_loss: 0.0095 step time: 0.2001\n",
      "6/8, train_loss: 0.0129 step time: 0.2012\n",
      "7/8, train_loss: 0.0088 step time: 0.1830\n",
      "8/8, train_loss: 0.0117 step time: 0.1836\n",
      "epoch 12 average loss: 0.0108\n",
      "time consuming of epoch 12 is: 1.6149\n",
      "----------\n",
      "epoch 13/600\n",
      "1/8, train_loss: 0.0111 step time: 0.2376\n",
      "2/8, train_loss: 0.0103 step time: 0.1981\n",
      "3/8, train_loss: 0.0113 step time: 0.1943\n",
      "4/8, train_loss: 0.0108 step time: 0.1926\n",
      "5/8, train_loss: 0.0104 step time: 0.1963\n",
      "6/8, train_loss: 0.0162 step time: 0.1969\n",
      "7/8, train_loss: 0.0106 step time: 0.1831\n",
      "8/8, train_loss: 0.0109 step time: 0.1847\n",
      "epoch 13 average loss: 0.0115\n",
      "time consuming of epoch 13 is: 1.5847\n",
      "----------\n",
      "epoch 14/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2415\n",
      "2/8, train_loss: 0.0105 step time: 0.2051\n",
      "3/8, train_loss: 0.0139 step time: 0.2019\n",
      "4/8, train_loss: 0.0121 step time: 0.2059\n",
      "5/8, train_loss: 0.0118 step time: 0.2043\n",
      "6/8, train_loss: 0.0102 step time: 0.1993\n",
      "7/8, train_loss: 0.0119 step time: 0.1848\n",
      "8/8, train_loss: 0.0105 step time: 0.1819\n",
      "epoch 14 average loss: 0.0115\n",
      "time consuming of epoch 14 is: 1.6262\n",
      "----------\n",
      "epoch 15/600\n",
      "1/8, train_loss: 0.0112 step time: 0.2452\n",
      "2/8, train_loss: 0.0094 step time: 0.2017\n",
      "3/8, train_loss: 0.0116 step time: 0.1983\n",
      "4/8, train_loss: 0.0112 step time: 0.2020\n",
      "5/8, train_loss: 0.0106 step time: 0.2027\n",
      "6/8, train_loss: 0.0116 step time: 0.2024\n",
      "7/8, train_loss: 0.0091 step time: 0.1837\n",
      "8/8, train_loss: 0.0145 step time: 0.1816\n",
      "epoch 15 average loss: 0.0111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 15 current mean dice: 0.9608 best mean dice: 0.9611 at epoch: 10\n",
      "time consuming of epoch 15 is: 2.3747\n",
      "----------\n",
      "epoch 16/600\n",
      "1/8, train_loss: 0.0109 step time: 0.2361\n",
      "2/8, train_loss: 0.0111 step time: 0.1985\n",
      "3/8, train_loss: 0.0091 step time: 0.2010\n",
      "4/8, train_loss: 0.0124 step time: 0.1999\n",
      "5/8, train_loss: 0.0130 step time: 0.1982\n",
      "6/8, train_loss: 0.0099 step time: 0.2058\n",
      "7/8, train_loss: 0.0099 step time: 0.1829\n",
      "8/8, train_loss: 0.0116 step time: 0.1832\n",
      "epoch 16 average loss: 0.0110\n",
      "time consuming of epoch 16 is: 1.6068\n",
      "----------\n",
      "epoch 17/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2397\n",
      "2/8, train_loss: 0.0097 step time: 0.2002\n",
      "3/8, train_loss: 0.0117 step time: 0.2018\n",
      "4/8, train_loss: 0.0106 step time: 0.2015\n",
      "5/8, train_loss: 0.0102 step time: 0.2021\n",
      "6/8, train_loss: 0.0144 step time: 0.2002\n",
      "7/8, train_loss: 0.0112 step time: 0.1828\n",
      "8/8, train_loss: 0.0098 step time: 0.1821\n",
      "epoch 17 average loss: 0.0110\n",
      "time consuming of epoch 17 is: 1.6119\n",
      "----------\n",
      "epoch 18/600\n",
      "1/8, train_loss: 0.0114 step time: 0.2420\n",
      "2/8, train_loss: 0.0106 step time: 0.2031\n",
      "3/8, train_loss: 0.0134 step time: 0.2016\n",
      "4/8, train_loss: 0.0093 step time: 0.2020\n",
      "5/8, train_loss: 0.0107 step time: 0.2028\n",
      "6/8, train_loss: 0.0126 step time: 0.2021\n",
      "7/8, train_loss: 0.0110 step time: 0.1851\n",
      "8/8, train_loss: 0.0126 step time: 0.1837\n",
      "epoch 18 average loss: 0.0114\n",
      "time consuming of epoch 18 is: 1.6239\n",
      "----------\n",
      "epoch 19/600\n",
      "1/8, train_loss: 0.0142 step time: 0.2396\n",
      "2/8, train_loss: 0.0124 step time: 0.1984\n",
      "3/8, train_loss: 0.0103 step time: 0.1988\n",
      "4/8, train_loss: 0.0098 step time: 0.2018\n",
      "5/8, train_loss: 0.0108 step time: 0.1974\n",
      "6/8, train_loss: 0.0105 step time: 0.1971\n",
      "7/8, train_loss: 0.0093 step time: 0.1822\n",
      "8/8, train_loss: 0.0102 step time: 0.1835\n",
      "epoch 19 average loss: 0.0109\n",
      "time consuming of epoch 19 is: 1.6001\n",
      "----------\n",
      "epoch 20/600\n",
      "1/8, train_loss: 0.0116 step time: 0.2330\n",
      "2/8, train_loss: 0.0111 step time: 0.1970\n",
      "3/8, train_loss: 0.0092 step time: 0.1968\n",
      "4/8, train_loss: 0.0105 step time: 0.1972\n",
      "5/8, train_loss: 0.0117 step time: 0.1967\n",
      "6/8, train_loss: 0.0119 step time: 0.1978\n",
      "7/8, train_loss: 0.0090 step time: 0.1834\n",
      "8/8, train_loss: 0.0118 step time: 0.1827\n",
      "epoch 20 average loss: 0.0109\n",
      "current epoch: 20 current mean dice: 0.9605 best mean dice: 0.9611 at epoch: 10\n",
      "time consuming of epoch 20 is: 2.3428\n",
      "----------\n",
      "epoch 21/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2388\n",
      "2/8, train_loss: 0.0108 step time: 0.1998\n",
      "3/8, train_loss: 0.0096 step time: 0.2007\n",
      "4/8, train_loss: 0.0101 step time: 0.1994\n",
      "5/8, train_loss: 0.0127 step time: 0.2004\n",
      "6/8, train_loss: 0.0139 step time: 0.1965\n",
      "7/8, train_loss: 0.0104 step time: 0.1790\n",
      "8/8, train_loss: 0.0096 step time: 0.1791\n",
      "epoch 21 average loss: 0.0109\n",
      "time consuming of epoch 21 is: 1.5949\n",
      "----------\n",
      "epoch 22/600\n",
      "1/8, train_loss: 0.0109 step time: 0.2333\n",
      "2/8, train_loss: 0.0149 step time: 0.2025\n",
      "3/8, train_loss: 0.0102 step time: 0.2014\n",
      "4/8, train_loss: 0.0118 step time: 0.1995\n",
      "5/8, train_loss: 0.0118 step time: 0.2003\n",
      "6/8, train_loss: 0.0096 step time: 0.2041\n",
      "7/8, train_loss: 0.0110 step time: 0.1840\n",
      "8/8, train_loss: 0.0123 step time: 0.1836\n",
      "epoch 22 average loss: 0.0116\n",
      "time consuming of epoch 22 is: 1.6100\n",
      "----------\n",
      "epoch 23/600\n",
      "1/8, train_loss: 0.0116 step time: 0.2408\n",
      "2/8, train_loss: 0.0109 step time: 0.2021\n",
      "3/8, train_loss: 0.0109 step time: 0.2026\n",
      "4/8, train_loss: 0.0107 step time: 0.2013\n",
      "5/8, train_loss: 0.0110 step time: 0.2039\n",
      "6/8, train_loss: 0.0093 step time: 0.2000\n",
      "7/8, train_loss: 0.0099 step time: 0.1833\n",
      "8/8, train_loss: 0.0132 step time: 0.1823\n",
      "epoch 23 average loss: 0.0109\n",
      "time consuming of epoch 23 is: 1.6176\n",
      "----------\n",
      "epoch 24/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2422\n",
      "2/8, train_loss: 0.0110 step time: 0.2005\n",
      "3/8, train_loss: 0.0132 step time: 0.2007\n",
      "4/8, train_loss: 0.0099 step time: 0.2029\n",
      "5/8, train_loss: 0.0126 step time: 0.2026\n",
      "6/8, train_loss: 0.0084 step time: 0.2023\n",
      "7/8, train_loss: 0.0117 step time: 0.1836\n",
      "8/8, train_loss: 0.0115 step time: 0.1842\n",
      "epoch 24 average loss: 0.0112\n",
      "time consuming of epoch 24 is: 1.6208\n",
      "----------\n",
      "epoch 25/600\n",
      "1/8, train_loss: 0.0143 step time: 0.2406\n",
      "2/8, train_loss: 0.0107 step time: 0.2016\n",
      "3/8, train_loss: 0.0100 step time: 0.2000\n",
      "4/8, train_loss: 0.0092 step time: 0.2063\n",
      "5/8, train_loss: 0.0114 step time: 0.1989\n",
      "6/8, train_loss: 0.0117 step time: 0.2006\n",
      "7/8, train_loss: 0.0144 step time: 0.1829\n",
      "8/8, train_loss: 0.0101 step time: 0.1826\n",
      "epoch 25 average loss: 0.0115\n",
      "current epoch: 25 current mean dice: 0.9599 best mean dice: 0.9611 at epoch: 10\n",
      "time consuming of epoch 25 is: 2.3715\n",
      "----------\n",
      "epoch 26/600\n",
      "1/8, train_loss: 0.0123 step time: 0.2403\n",
      "2/8, train_loss: 0.0132 step time: 0.1999\n",
      "3/8, train_loss: 0.0090 step time: 0.1980\n",
      "4/8, train_loss: 0.0097 step time: 0.2001\n",
      "5/8, train_loss: 0.0111 step time: 0.1994\n",
      "6/8, train_loss: 0.0106 step time: 0.1987\n",
      "7/8, train_loss: 0.0108 step time: 0.1814\n",
      "8/8, train_loss: 0.0097 step time: 0.1817\n",
      "epoch 26 average loss: 0.0108\n",
      "time consuming of epoch 26 is: 1.6008\n",
      "----------\n",
      "epoch 27/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2415\n",
      "2/8, train_loss: 0.0117 step time: 0.2029\n",
      "3/8, train_loss: 0.0156 step time: 0.2020\n",
      "4/8, train_loss: 0.0117 step time: 0.2027\n",
      "5/8, train_loss: 0.0093 step time: 0.2003\n",
      "6/8, train_loss: 0.0084 step time: 0.2002\n",
      "7/8, train_loss: 0.0115 step time: 0.1829\n",
      "8/8, train_loss: 0.0102 step time: 0.1837\n",
      "epoch 27 average loss: 0.0111\n",
      "time consuming of epoch 27 is: 1.6178\n",
      "----------\n",
      "epoch 28/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2405\n",
      "2/8, train_loss: 0.0150 step time: 0.2021\n",
      "3/8, train_loss: 0.0107 step time: 0.1976\n",
      "4/8, train_loss: 0.0113 step time: 0.2020\n",
      "5/8, train_loss: 0.0117 step time: 0.1999\n",
      "6/8, train_loss: 0.0118 step time: 0.2024\n",
      "7/8, train_loss: 0.0109 step time: 0.1821\n",
      "8/8, train_loss: 0.0100 step time: 0.1825\n",
      "epoch 28 average loss: 0.0115\n",
      "time consuming of epoch 28 is: 1.6102\n",
      "----------\n",
      "epoch 29/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2408\n",
      "2/8, train_loss: 0.0144 step time: 0.2032\n",
      "3/8, train_loss: 0.0094 step time: 0.2062\n",
      "4/8, train_loss: 0.0131 step time: 0.2030\n",
      "5/8, train_loss: 0.0101 step time: 0.2003\n",
      "6/8, train_loss: 0.0096 step time: 0.2014\n",
      "7/8, train_loss: 0.0094 step time: 0.1844\n",
      "8/8, train_loss: 0.0106 step time: 0.1830\n",
      "epoch 29 average loss: 0.0109\n",
      "time consuming of epoch 29 is: 1.6239\n",
      "----------\n",
      "epoch 30/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2409\n",
      "2/8, train_loss: 0.0115 step time: 0.2012\n",
      "3/8, train_loss: 0.0120 step time: 0.1994\n",
      "4/8, train_loss: 0.0125 step time: 0.1996\n",
      "5/8, train_loss: 0.0105 step time: 0.1993\n",
      "6/8, train_loss: 0.0116 step time: 0.1992\n",
      "7/8, train_loss: 0.0127 step time: 0.1833\n",
      "8/8, train_loss: 0.0109 step time: 0.1818\n",
      "epoch 30 average loss: 0.0115\n",
      "current epoch: 30 current mean dice: 0.9586 best mean dice: 0.9611 at epoch: 10\n",
      "time consuming of epoch 30 is: 2.3631\n",
      "----------\n",
      "epoch 31/600\n",
      "1/8, train_loss: 0.0121 step time: 0.2352\n",
      "2/8, train_loss: 0.0143 step time: 0.1932\n",
      "3/8, train_loss: 0.0101 step time: 0.1946\n",
      "4/8, train_loss: 0.0108 step time: 0.1928\n",
      "5/8, train_loss: 0.0127 step time: 0.1947\n",
      "6/8, train_loss: 0.0129 step time: 0.1964\n",
      "7/8, train_loss: 0.0116 step time: 0.1809\n",
      "8/8, train_loss: 0.0134 step time: 0.1828\n",
      "epoch 31 average loss: 0.0122\n",
      "time consuming of epoch 31 is: 1.5716\n",
      "----------\n",
      "epoch 32/600\n",
      "1/8, train_loss: 0.0121 step time: 0.2356\n",
      "2/8, train_loss: 0.0102 step time: 0.1963\n",
      "3/8, train_loss: 0.0113 step time: 0.1959\n",
      "4/8, train_loss: 0.0149 step time: 0.2001\n",
      "5/8, train_loss: 0.0112 step time: 0.2056\n",
      "6/8, train_loss: 0.0097 step time: 0.1982\n",
      "7/8, train_loss: 0.0119 step time: 0.1824\n",
      "8/8, train_loss: 0.0135 step time: 0.1828\n",
      "epoch 32 average loss: 0.0118\n",
      "time consuming of epoch 32 is: 1.5986\n",
      "----------\n",
      "epoch 33/600\n",
      "1/8, train_loss: 0.0100 step time: 0.2415\n",
      "2/8, train_loss: 0.0139 step time: 0.2028\n",
      "3/8, train_loss: 0.0114 step time: 0.1991\n",
      "4/8, train_loss: 0.0124 step time: 0.2006\n",
      "5/8, train_loss: 0.0155 step time: 0.2014\n",
      "6/8, train_loss: 0.0112 step time: 0.1999\n",
      "7/8, train_loss: 0.0166 step time: 0.1841\n",
      "8/8, train_loss: 0.0117 step time: 0.1823\n",
      "epoch 33 average loss: 0.0128\n",
      "time consuming of epoch 33 is: 1.6132\n",
      "----------\n",
      "epoch 34/600\n",
      "1/8, train_loss: 0.0106 step time: 0.2394\n",
      "2/8, train_loss: 0.0123 step time: 0.2060\n",
      "3/8, train_loss: 0.0114 step time: 0.1983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/8, train_loss: 0.0102 step time: 0.1977\n",
      "5/8, train_loss: 0.0108 step time: 0.2004\n",
      "6/8, train_loss: 0.0105 step time: 0.2000\n",
      "7/8, train_loss: 0.0141 step time: 0.1825\n",
      "8/8, train_loss: 0.0110 step time: 0.1820\n",
      "epoch 34 average loss: 0.0114\n",
      "time consuming of epoch 34 is: 1.6079\n",
      "----------\n",
      "epoch 35/600\n",
      "1/8, train_loss: 0.0124 step time: 0.2378\n",
      "2/8, train_loss: 0.0116 step time: 0.2004\n",
      "3/8, train_loss: 0.0117 step time: 0.2013\n",
      "4/8, train_loss: 0.0136 step time: 0.2000\n",
      "5/8, train_loss: 0.0107 step time: 0.2011\n",
      "6/8, train_loss: 0.0121 step time: 0.2018\n",
      "7/8, train_loss: 0.0105 step time: 0.1821\n",
      "8/8, train_loss: 0.0103 step time: 0.1833\n",
      "epoch 35 average loss: 0.0116\n",
      "current epoch: 35 current mean dice: 0.9577 best mean dice: 0.9611 at epoch: 10\n",
      "time consuming of epoch 35 is: 2.3662\n",
      "----------\n",
      "epoch 36/600\n",
      "1/8, train_loss: 0.0112 step time: 0.2446\n",
      "2/8, train_loss: 0.0105 step time: 0.2023\n",
      "3/8, train_loss: 0.0108 step time: 0.1952\n",
      "4/8, train_loss: 0.0110 step time: 0.1996\n",
      "5/8, train_loss: 0.0137 step time: 0.1990\n",
      "6/8, train_loss: 0.0108 step time: 0.1993\n",
      "7/8, train_loss: 0.0098 step time: 0.1820\n",
      "8/8, train_loss: 0.0106 step time: 0.1849\n",
      "epoch 36 average loss: 0.0110\n",
      "time consuming of epoch 36 is: 1.6080\n",
      "----------\n",
      "epoch 37/600\n",
      "1/8, train_loss: 0.0121 step time: 0.2397\n",
      "2/8, train_loss: 0.0110 step time: 0.2035\n",
      "3/8, train_loss: 0.0129 step time: 0.1993\n",
      "4/8, train_loss: 0.0110 step time: 0.1985\n",
      "5/8, train_loss: 0.0105 step time: 0.2020\n",
      "6/8, train_loss: 0.0102 step time: 0.2004\n",
      "7/8, train_loss: 0.0110 step time: 0.1845\n",
      "8/8, train_loss: 0.0102 step time: 0.1836\n",
      "epoch 37 average loss: 0.0111\n",
      "time consuming of epoch 37 is: 1.6133\n",
      "----------\n",
      "epoch 38/600\n",
      "1/8, train_loss: 0.0115 step time: 0.2393\n",
      "2/8, train_loss: 0.0098 step time: 0.2027\n",
      "3/8, train_loss: 0.0103 step time: 0.1999\n",
      "4/8, train_loss: 0.0106 step time: 0.1998\n",
      "5/8, train_loss: 0.0105 step time: 0.2035\n",
      "6/8, train_loss: 0.0118 step time: 0.1994\n",
      "7/8, train_loss: 0.0126 step time: 0.1842\n",
      "8/8, train_loss: 0.0143 step time: 0.1816\n",
      "epoch 38 average loss: 0.0114\n",
      "time consuming of epoch 38 is: 1.6118\n",
      "----------\n",
      "epoch 39/600\n",
      "1/8, train_loss: 0.0142 step time: 0.2411\n",
      "2/8, train_loss: 0.0105 step time: 0.2023\n",
      "3/8, train_loss: 0.0106 step time: 0.2034\n",
      "4/8, train_loss: 0.0111 step time: 0.2021\n",
      "5/8, train_loss: 0.0109 step time: 0.2013\n",
      "6/8, train_loss: 0.0103 step time: 0.2001\n",
      "7/8, train_loss: 0.0113 step time: 0.1843\n",
      "8/8, train_loss: 0.0116 step time: 0.1824\n",
      "epoch 39 average loss: 0.0113\n",
      "time consuming of epoch 39 is: 1.6184\n",
      "----------\n",
      "epoch 40/600\n",
      "1/8, train_loss: 0.0099 step time: 0.2400\n",
      "2/8, train_loss: 0.0096 step time: 0.1994\n",
      "3/8, train_loss: 0.0096 step time: 0.1984\n",
      "4/8, train_loss: 0.0104 step time: 0.2020\n",
      "5/8, train_loss: 0.0141 step time: 0.1991\n",
      "6/8, train_loss: 0.0116 step time: 0.2008\n",
      "7/8, train_loss: 0.0111 step time: 0.1826\n",
      "8/8, train_loss: 0.0110 step time: 0.1851\n",
      "epoch 40 average loss: 0.0109\n",
      "current epoch: 40 current mean dice: 0.9609 best mean dice: 0.9611 at epoch: 10\n",
      "time consuming of epoch 40 is: 2.3660\n",
      "----------\n",
      "epoch 41/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2385\n",
      "2/8, train_loss: 0.0087 step time: 0.1982\n",
      "3/8, train_loss: 0.0174 step time: 0.2043\n",
      "4/8, train_loss: 0.0103 step time: 0.1988\n",
      "5/8, train_loss: 0.0107 step time: 0.1979\n",
      "6/8, train_loss: 0.0123 step time: 0.1973\n",
      "7/8, train_loss: 0.0113 step time: 0.1813\n",
      "8/8, train_loss: 0.0104 step time: 0.1817\n",
      "epoch 41 average loss: 0.0116\n",
      "time consuming of epoch 41 is: 1.5991\n",
      "----------\n",
      "epoch 42/600\n",
      "1/8, train_loss: 0.0152 step time: 0.2358\n",
      "2/8, train_loss: 0.0109 step time: 0.2036\n",
      "3/8, train_loss: 0.0098 step time: 0.1990\n",
      "4/8, train_loss: 0.0142 step time: 0.1999\n",
      "5/8, train_loss: 0.0119 step time: 0.1999\n",
      "6/8, train_loss: 0.0130 step time: 0.2535\n",
      "7/8, train_loss: 0.0118 step time: 0.1829\n",
      "8/8, train_loss: 0.0114 step time: 0.1825\n",
      "epoch 42 average loss: 0.0123\n",
      "time consuming of epoch 42 is: 1.6583\n",
      "----------\n",
      "epoch 43/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2385\n",
      "2/8, train_loss: 0.0144 step time: 0.2017\n",
      "3/8, train_loss: 0.0127 step time: 0.1979\n",
      "4/8, train_loss: 0.0122 step time: 0.2013\n",
      "5/8, train_loss: 0.0127 step time: 0.2026\n",
      "6/8, train_loss: 0.0120 step time: 0.1985\n",
      "7/8, train_loss: 0.0117 step time: 0.1824\n",
      "8/8, train_loss: 0.0149 step time: 0.1827\n",
      "epoch 43 average loss: 0.0128\n",
      "time consuming of epoch 43 is: 1.6072\n",
      "----------\n",
      "epoch 44/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2401\n",
      "2/8, train_loss: 0.0118 step time: 0.2050\n",
      "3/8, train_loss: 0.0125 step time: 0.2004\n",
      "4/8, train_loss: 0.0141 step time: 0.2014\n",
      "5/8, train_loss: 0.0139 step time: 0.2023\n",
      "6/8, train_loss: 0.0098 step time: 0.2044\n",
      "7/8, train_loss: 0.0119 step time: 0.1824\n",
      "8/8, train_loss: 0.0133 step time: 0.1817\n",
      "epoch 44 average loss: 0.0123\n",
      "time consuming of epoch 44 is: 1.6195\n",
      "----------\n",
      "epoch 45/600\n",
      "1/8, train_loss: 0.0114 step time: 0.2410\n",
      "2/8, train_loss: 0.0116 step time: 0.2048\n",
      "3/8, train_loss: 0.0108 step time: 0.2004\n",
      "4/8, train_loss: 0.0108 step time: 0.2022\n",
      "5/8, train_loss: 0.0139 step time: 0.2045\n",
      "6/8, train_loss: 0.0122 step time: 0.2000\n",
      "7/8, train_loss: 0.0118 step time: 0.1832\n",
      "8/8, train_loss: 0.0099 step time: 0.1818\n",
      "epoch 45 average loss: 0.0116\n",
      "current epoch: 45 current mean dice: 0.9591 best mean dice: 0.9611 at epoch: 10\n",
      "time consuming of epoch 45 is: 2.3755\n",
      "----------\n",
      "epoch 46/600\n",
      "1/8, train_loss: 0.0123 step time: 0.2358\n",
      "2/8, train_loss: 0.0128 step time: 0.1990\n",
      "3/8, train_loss: 0.0111 step time: 0.1977\n",
      "4/8, train_loss: 0.0107 step time: 0.1973\n",
      "5/8, train_loss: 0.0113 step time: 0.1936\n",
      "6/8, train_loss: 0.0131 step time: 0.1919\n",
      "7/8, train_loss: 0.0094 step time: 0.1816\n",
      "8/8, train_loss: 0.0113 step time: 0.1814\n",
      "epoch 46 average loss: 0.0115\n",
      "time consuming of epoch 46 is: 1.5794\n",
      "----------\n",
      "epoch 47/600\n",
      "1/8, train_loss: 0.0116 step time: 0.2383\n",
      "2/8, train_loss: 0.0131 step time: 0.2035\n",
      "3/8, train_loss: 0.0112 step time: 0.2001\n",
      "4/8, train_loss: 0.0121 step time: 0.1983\n",
      "5/8, train_loss: 0.0090 step time: 0.1998\n",
      "6/8, train_loss: 0.0093 step time: 0.2011\n",
      "7/8, train_loss: 0.0142 step time: 0.1828\n",
      "8/8, train_loss: 0.0105 step time: 0.1827\n",
      "epoch 47 average loss: 0.0114\n",
      "time consuming of epoch 47 is: 1.6080\n",
      "----------\n",
      "epoch 48/600\n",
      "1/8, train_loss: 0.0121 step time: 0.2420\n",
      "2/8, train_loss: 0.0101 step time: 0.2034\n",
      "3/8, train_loss: 0.0116 step time: 0.1994\n",
      "4/8, train_loss: 0.0111 step time: 0.1981\n",
      "5/8, train_loss: 0.0091 step time: 0.1999\n",
      "6/8, train_loss: 0.0110 step time: 0.1995\n",
      "7/8, train_loss: 0.0120 step time: 0.1814\n",
      "8/8, train_loss: 0.0094 step time: 0.1814\n",
      "epoch 48 average loss: 0.0108\n",
      "time consuming of epoch 48 is: 1.6064\n",
      "----------\n",
      "epoch 49/600\n",
      "1/8, train_loss: 0.0117 step time: 0.2416\n",
      "2/8, train_loss: 0.0128 step time: 0.2020\n",
      "3/8, train_loss: 0.0109 step time: 0.1990\n",
      "4/8, train_loss: 0.0144 step time: 0.2012\n",
      "5/8, train_loss: 0.0097 step time: 0.1996\n",
      "6/8, train_loss: 0.0099 step time: 0.2001\n",
      "7/8, train_loss: 0.0101 step time: 0.1827\n",
      "8/8, train_loss: 0.0100 step time: 0.1826\n",
      "epoch 49 average loss: 0.0112\n",
      "time consuming of epoch 49 is: 1.6104\n",
      "----------\n",
      "epoch 50/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2376\n",
      "2/8, train_loss: 0.0105 step time: 0.1990\n",
      "3/8, train_loss: 0.0113 step time: 0.2008\n",
      "4/8, train_loss: 0.0148 step time: 0.2001\n",
      "5/8, train_loss: 0.0116 step time: 0.2002\n",
      "6/8, train_loss: 0.0114 step time: 0.1989\n",
      "7/8, train_loss: 0.0101 step time: 0.1819\n",
      "8/8, train_loss: 0.0093 step time: 0.1826\n",
      "epoch 50 average loss: 0.0110\n",
      "current epoch: 50 current mean dice: 0.9582 best mean dice: 0.9611 at epoch: 10\n",
      "time consuming of epoch 50 is: 2.3578\n",
      "----------\n",
      "epoch 51/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2284\n",
      "2/8, train_loss: 0.0101 step time: 0.1919\n",
      "3/8, train_loss: 0.0107 step time: 0.2039\n",
      "4/8, train_loss: 0.0103 step time: 0.1997\n",
      "5/8, train_loss: 0.0094 step time: 0.2021\n",
      "6/8, train_loss: 0.0142 step time: 0.1969\n",
      "7/8, train_loss: 0.0116 step time: 0.1812\n",
      "8/8, train_loss: 0.0096 step time: 0.1817\n",
      "epoch 51 average loss: 0.0108\n",
      "time consuming of epoch 51 is: 1.5867\n",
      "----------\n",
      "epoch 52/600\n",
      "1/8, train_loss: 0.0111 step time: 0.2399\n",
      "2/8, train_loss: 0.0112 step time: 0.2019\n",
      "3/8, train_loss: 0.0104 step time: 0.2002\n",
      "4/8, train_loss: 0.0102 step time: 0.2027\n",
      "5/8, train_loss: 0.0126 step time: 0.2001\n",
      "6/8, train_loss: 0.0105 step time: 0.2016\n",
      "7/8, train_loss: 0.0084 step time: 0.1827\n",
      "8/8, train_loss: 0.0110 step time: 0.1835\n",
      "epoch 52 average loss: 0.0107\n",
      "time consuming of epoch 52 is: 1.6138\n",
      "----------\n",
      "epoch 53/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0112 step time: 0.2404\n",
      "2/8, train_loss: 0.0140 step time: 0.2003\n",
      "3/8, train_loss: 0.0094 step time: 0.1997\n",
      "4/8, train_loss: 0.0096 step time: 0.2001\n",
      "5/8, train_loss: 0.0122 step time: 0.2005\n",
      "6/8, train_loss: 0.0105 step time: 0.2000\n",
      "7/8, train_loss: 0.0107 step time: 0.1830\n",
      "8/8, train_loss: 0.0138 step time: 0.1823\n",
      "epoch 53 average loss: 0.0114\n",
      "time consuming of epoch 53 is: 1.6077\n",
      "----------\n",
      "epoch 54/600\n",
      "1/8, train_loss: 0.0096 step time: 0.2387\n",
      "2/8, train_loss: 0.0096 step time: 0.2027\n",
      "3/8, train_loss: 0.0111 step time: 0.2069\n",
      "4/8, train_loss: 0.0128 step time: 0.2068\n",
      "5/8, train_loss: 0.0095 step time: 0.2017\n",
      "6/8, train_loss: 0.0105 step time: 0.2030\n",
      "7/8, train_loss: 0.0120 step time: 0.1828\n",
      "8/8, train_loss: 0.0118 step time: 0.1828\n",
      "epoch 54 average loss: 0.0109\n",
      "time consuming of epoch 54 is: 1.6270\n",
      "----------\n",
      "epoch 55/600\n",
      "1/8, train_loss: 0.0108 step time: 0.2389\n",
      "2/8, train_loss: 0.0105 step time: 0.2015\n",
      "3/8, train_loss: 0.0091 step time: 0.2027\n",
      "4/8, train_loss: 0.0117 step time: 0.2014\n",
      "5/8, train_loss: 0.0097 step time: 0.2033\n",
      "6/8, train_loss: 0.0121 step time: 0.2006\n",
      "7/8, train_loss: 0.0118 step time: 0.1819\n",
      "8/8, train_loss: 0.0104 step time: 0.1820\n",
      "epoch 55 average loss: 0.0108\n",
      "current epoch: 55 current mean dice: 0.9609 best mean dice: 0.9611 at epoch: 10\n",
      "time consuming of epoch 55 is: 2.3688\n",
      "----------\n",
      "epoch 56/600\n",
      "1/8, train_loss: 0.0113 step time: 0.2369\n",
      "2/8, train_loss: 0.0097 step time: 0.1931\n",
      "3/8, train_loss: 0.0121 step time: 0.1972\n",
      "4/8, train_loss: 0.0087 step time: 0.1947\n",
      "5/8, train_loss: 0.0099 step time: 0.1950\n",
      "6/8, train_loss: 0.0110 step time: 0.1942\n",
      "7/8, train_loss: 0.0106 step time: 0.1812\n",
      "8/8, train_loss: 0.0141 step time: 0.1834\n",
      "epoch 56 average loss: 0.0109\n",
      "time consuming of epoch 56 is: 1.5769\n",
      "----------\n",
      "epoch 57/600\n",
      "1/8, train_loss: 0.0094 step time: 0.2308\n",
      "2/8, train_loss: 0.0125 step time: 0.1991\n",
      "3/8, train_loss: 0.0099 step time: 0.1960\n",
      "4/8, train_loss: 0.0126 step time: 0.1974\n",
      "5/8, train_loss: 0.0100 step time: 0.2006\n",
      "6/8, train_loss: 0.0096 step time: 0.1969\n",
      "7/8, train_loss: 0.0122 step time: 0.1818\n",
      "8/8, train_loss: 0.0126 step time: 0.1825\n",
      "epoch 57 average loss: 0.0111\n",
      "time consuming of epoch 57 is: 1.5862\n",
      "----------\n",
      "epoch 58/600\n",
      "1/8, train_loss: 0.0124 step time: 0.2404\n",
      "2/8, train_loss: 0.0112 step time: 0.2012\n",
      "3/8, train_loss: 0.0106 step time: 0.2023\n",
      "4/8, train_loss: 0.0101 step time: 0.1993\n",
      "5/8, train_loss: 0.0127 step time: 0.2002\n",
      "6/8, train_loss: 0.0100 step time: 0.1997\n",
      "7/8, train_loss: 0.0121 step time: 0.1841\n",
      "8/8, train_loss: 0.0107 step time: 0.1822\n",
      "epoch 58 average loss: 0.0112\n",
      "time consuming of epoch 58 is: 1.6112\n",
      "----------\n",
      "epoch 59/600\n",
      "1/8, train_loss: 0.0106 step time: 0.2385\n",
      "2/8, train_loss: 0.0100 step time: 0.1997\n",
      "3/8, train_loss: 0.0111 step time: 0.2015\n",
      "4/8, train_loss: 0.0102 step time: 0.2004\n",
      "5/8, train_loss: 0.0115 step time: 0.2012\n",
      "6/8, train_loss: 0.0110 step time: 0.2015\n",
      "7/8, train_loss: 0.0096 step time: 0.1825\n",
      "8/8, train_loss: 0.0110 step time: 0.1822\n",
      "epoch 59 average loss: 0.0106\n",
      "time consuming of epoch 59 is: 1.6090\n",
      "----------\n",
      "epoch 60/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2402\n",
      "2/8, train_loss: 0.0116 step time: 0.2034\n",
      "3/8, train_loss: 0.0109 step time: 0.1985\n",
      "4/8, train_loss: 0.0103 step time: 0.2036\n",
      "5/8, train_loss: 0.0094 step time: 0.1983\n",
      "6/8, train_loss: 0.0110 step time: 0.2003\n",
      "7/8, train_loss: 0.0120 step time: 0.1833\n",
      "8/8, train_loss: 0.0107 step time: 0.1814\n",
      "epoch 60 average loss: 0.0110\n",
      "current epoch: 60 current mean dice: 0.9608 best mean dice: 0.9611 at epoch: 10\n",
      "time consuming of epoch 60 is: 2.3652\n",
      "----------\n",
      "epoch 61/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2256\n",
      "2/8, train_loss: 0.0095 step time: 0.1937\n",
      "3/8, train_loss: 0.0102 step time: 0.1916\n",
      "4/8, train_loss: 0.0103 step time: 0.1905\n",
      "5/8, train_loss: 0.0103 step time: 0.1931\n",
      "6/8, train_loss: 0.0119 step time: 0.1909\n",
      "7/8, train_loss: 0.0108 step time: 0.1829\n",
      "8/8, train_loss: 0.0129 step time: 0.1809\n",
      "epoch 61 average loss: 0.0108\n",
      "time consuming of epoch 61 is: 1.5503\n",
      "----------\n",
      "epoch 62/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2414\n",
      "2/8, train_loss: 0.0126 step time: 0.2042\n",
      "3/8, train_loss: 0.0107 step time: 0.1997\n",
      "4/8, train_loss: 0.0095 step time: 0.2017\n",
      "5/8, train_loss: 0.0113 step time: 0.2002\n",
      "6/8, train_loss: 0.0096 step time: 0.2014\n",
      "7/8, train_loss: 0.0105 step time: 0.1830\n",
      "8/8, train_loss: 0.0099 step time: 0.1838\n",
      "epoch 62 average loss: 0.0106\n",
      "time consuming of epoch 62 is: 1.6168\n",
      "----------\n",
      "epoch 63/600\n",
      "1/8, train_loss: 0.0103 step time: 0.2408\n",
      "2/8, train_loss: 0.0114 step time: 0.2023\n",
      "3/8, train_loss: 0.0102 step time: 0.2005\n",
      "4/8, train_loss: 0.0104 step time: 0.2007\n",
      "5/8, train_loss: 0.0108 step time: 0.1997\n",
      "6/8, train_loss: 0.0104 step time: 0.2002\n",
      "7/8, train_loss: 0.0111 step time: 0.1830\n",
      "8/8, train_loss: 0.0116 step time: 0.1826\n",
      "epoch 63 average loss: 0.0108\n",
      "time consuming of epoch 63 is: 1.6115\n",
      "----------\n",
      "epoch 64/600\n",
      "1/8, train_loss: 0.0129 step time: 0.2402\n",
      "2/8, train_loss: 0.0102 step time: 0.2033\n",
      "3/8, train_loss: 0.0109 step time: 0.1993\n",
      "4/8, train_loss: 0.0107 step time: 0.2010\n",
      "5/8, train_loss: 0.0102 step time: 0.1991\n",
      "6/8, train_loss: 0.0115 step time: 0.2009\n",
      "7/8, train_loss: 0.0110 step time: 0.1831\n",
      "8/8, train_loss: 0.0108 step time: 0.1822\n",
      "epoch 64 average loss: 0.0110\n",
      "time consuming of epoch 64 is: 1.6106\n",
      "----------\n",
      "epoch 65/600\n",
      "1/8, train_loss: 0.0089 step time: 0.2404\n",
      "2/8, train_loss: 0.0104 step time: 0.2021\n",
      "3/8, train_loss: 0.0104 step time: 0.2003\n",
      "4/8, train_loss: 0.0105 step time: 0.2009\n",
      "5/8, train_loss: 0.0107 step time: 0.2002\n",
      "6/8, train_loss: 0.0112 step time: 0.2017\n",
      "7/8, train_loss: 0.0098 step time: 0.1825\n",
      "8/8, train_loss: 0.0115 step time: 0.1832\n",
      "epoch 65 average loss: 0.0104\n",
      "current epoch: 65 current mean dice: 0.9609 best mean dice: 0.9611 at epoch: 10\n",
      "time consuming of epoch 65 is: 2.3688\n",
      "----------\n",
      "epoch 66/600\n",
      "1/8, train_loss: 0.0132 step time: 0.2325\n",
      "2/8, train_loss: 0.0105 step time: 0.1998\n",
      "3/8, train_loss: 0.0139 step time: 0.1928\n",
      "4/8, train_loss: 0.0108 step time: 0.1955\n",
      "5/8, train_loss: 0.0090 step time: 0.1954\n",
      "6/8, train_loss: 0.0105 step time: 0.1953\n",
      "7/8, train_loss: 0.0086 step time: 0.1814\n",
      "8/8, train_loss: 0.0124 step time: 0.1796\n",
      "epoch 66 average loss: 0.0111\n",
      "time consuming of epoch 66 is: 1.5733\n",
      "----------\n",
      "epoch 67/600\n",
      "1/8, train_loss: 0.0130 step time: 0.2338\n",
      "2/8, train_loss: 0.0109 step time: 0.1981\n",
      "3/8, train_loss: 0.0093 step time: 0.1972\n",
      "4/8, train_loss: 0.0094 step time: 0.1960\n",
      "5/8, train_loss: 0.0108 step time: 0.1968\n",
      "6/8, train_loss: 0.0107 step time: 0.1948\n",
      "7/8, train_loss: 0.0089 step time: 0.1818\n",
      "8/8, train_loss: 0.0124 step time: 0.1813\n",
      "epoch 67 average loss: 0.0107\n",
      "time consuming of epoch 67 is: 1.5810\n",
      "----------\n",
      "epoch 68/600\n",
      "1/8, train_loss: 0.0109 step time: 0.2385\n",
      "2/8, train_loss: 0.0127 step time: 0.1994\n",
      "3/8, train_loss: 0.0122 step time: 0.2042\n",
      "4/8, train_loss: 0.0108 step time: 0.2035\n",
      "5/8, train_loss: 0.0119 step time: 0.2022\n",
      "6/8, train_loss: 0.0089 step time: 0.2001\n",
      "7/8, train_loss: 0.0100 step time: 0.1828\n",
      "8/8, train_loss: 0.0115 step time: 0.1828\n",
      "epoch 68 average loss: 0.0111\n",
      "time consuming of epoch 68 is: 1.6148\n",
      "----------\n",
      "epoch 69/600\n",
      "1/8, train_loss: 0.0099 step time: 0.2396\n",
      "2/8, train_loss: 0.0106 step time: 0.2034\n",
      "3/8, train_loss: 0.0108 step time: 0.2017\n",
      "4/8, train_loss: 0.0094 step time: 0.2001\n",
      "5/8, train_loss: 0.0086 step time: 0.2013\n",
      "6/8, train_loss: 0.0104 step time: 0.2012\n",
      "7/8, train_loss: 0.0129 step time: 0.1842\n",
      "8/8, train_loss: 0.0135 step time: 0.1825\n",
      "epoch 69 average loss: 0.0108\n",
      "time consuming of epoch 69 is: 1.6158\n",
      "----------\n",
      "epoch 70/600\n",
      "1/8, train_loss: 0.0101 step time: 0.2376\n",
      "2/8, train_loss: 0.0155 step time: 0.2012\n",
      "3/8, train_loss: 0.0104 step time: 0.2018\n",
      "4/8, train_loss: 0.0094 step time: 0.1996\n",
      "5/8, train_loss: 0.0093 step time: 0.2034\n",
      "6/8, train_loss: 0.0114 step time: 0.2003\n",
      "7/8, train_loss: 0.0124 step time: 0.1852\n",
      "8/8, train_loss: 0.0100 step time: 0.1823\n",
      "epoch 70 average loss: 0.0111\n",
      "current epoch: 70 current mean dice: 0.9606 best mean dice: 0.9611 at epoch: 10\n",
      "time consuming of epoch 70 is: 2.3691\n",
      "----------\n",
      "epoch 71/600\n",
      "1/8, train_loss: 0.0128 step time: 0.2267\n",
      "2/8, train_loss: 0.0084 step time: 0.2010\n",
      "3/8, train_loss: 0.0094 step time: 0.1996\n",
      "4/8, train_loss: 0.0089 step time: 0.1996\n",
      "5/8, train_loss: 0.0098 step time: 0.1990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/8, train_loss: 0.0099 step time: 0.2000\n",
      "7/8, train_loss: 0.0138 step time: 0.1817\n",
      "8/8, train_loss: 0.0128 step time: 0.1821\n",
      "epoch 71 average loss: 0.0107\n",
      "time consuming of epoch 71 is: 1.5910\n",
      "----------\n",
      "epoch 72/600\n",
      "1/8, train_loss: 0.0122 step time: 0.2429\n",
      "2/8, train_loss: 0.0088 step time: 0.1989\n",
      "3/8, train_loss: 0.0088 step time: 0.2010\n",
      "4/8, train_loss: 0.0103 step time: 0.2017\n",
      "5/8, train_loss: 0.0123 step time: 0.2021\n",
      "6/8, train_loss: 0.0100 step time: 0.2003\n",
      "7/8, train_loss: 0.0094 step time: 0.1824\n",
      "8/8, train_loss: 0.0146 step time: 0.1827\n",
      "epoch 72 average loss: 0.0108\n",
      "time consuming of epoch 72 is: 1.6133\n",
      "----------\n",
      "epoch 73/600\n",
      "1/8, train_loss: 0.0099 step time: 0.2379\n",
      "2/8, train_loss: 0.0089 step time: 0.2049\n",
      "3/8, train_loss: 0.0109 step time: 0.1990\n",
      "4/8, train_loss: 0.0104 step time: 0.2000\n",
      "5/8, train_loss: 0.0123 step time: 0.2017\n",
      "6/8, train_loss: 0.0093 step time: 0.1973\n",
      "7/8, train_loss: 0.0093 step time: 0.1825\n",
      "8/8, train_loss: 0.0124 step time: 0.1824\n",
      "epoch 73 average loss: 0.0104\n",
      "time consuming of epoch 73 is: 1.6070\n",
      "----------\n",
      "epoch 74/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2417\n",
      "2/8, train_loss: 0.0100 step time: 0.2013\n",
      "3/8, train_loss: 0.0117 step time: 0.2025\n",
      "4/8, train_loss: 0.0103 step time: 0.2028\n",
      "5/8, train_loss: 0.0112 step time: 0.2024\n",
      "6/8, train_loss: 0.0098 step time: 0.2007\n",
      "7/8, train_loss: 0.0087 step time: 0.1846\n",
      "8/8, train_loss: 0.0164 step time: 0.1815\n",
      "epoch 74 average loss: 0.0110\n",
      "time consuming of epoch 74 is: 1.6191\n",
      "----------\n",
      "epoch 75/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2412\n",
      "2/8, train_loss: 0.0105 step time: 0.2020\n",
      "3/8, train_loss: 0.0120 step time: 0.1999\n",
      "4/8, train_loss: 0.0096 step time: 0.2001\n",
      "5/8, train_loss: 0.0098 step time: 0.2011\n",
      "6/8, train_loss: 0.0104 step time: 0.2010\n",
      "7/8, train_loss: 0.0111 step time: 0.1830\n",
      "8/8, train_loss: 0.0113 step time: 0.1818\n",
      "epoch 75 average loss: 0.0105\n",
      "current epoch: 75 current mean dice: 0.9606 best mean dice: 0.9611 at epoch: 10\n",
      "time consuming of epoch 75 is: 2.3669\n",
      "----------\n",
      "epoch 76/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2368\n",
      "2/8, train_loss: 0.0131 step time: 0.1995\n",
      "3/8, train_loss: 0.0087 step time: 0.2000\n",
      "4/8, train_loss: 0.0124 step time: 0.2005\n",
      "5/8, train_loss: 0.0099 step time: 0.1997\n",
      "6/8, train_loss: 0.0107 step time: 0.1989\n",
      "7/8, train_loss: 0.0102 step time: 0.1820\n",
      "8/8, train_loss: 0.0102 step time: 0.1833\n",
      "epoch 76 average loss: 0.0106\n",
      "time consuming of epoch 76 is: 1.6018\n",
      "----------\n",
      "epoch 77/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2399\n",
      "2/8, train_loss: 0.0098 step time: 0.2044\n",
      "3/8, train_loss: 0.0110 step time: 0.1986\n",
      "4/8, train_loss: 0.0093 step time: 0.2009\n",
      "5/8, train_loss: 0.0115 step time: 0.1992\n",
      "6/8, train_loss: 0.0108 step time: 0.2070\n",
      "7/8, train_loss: 0.0120 step time: 0.1855\n",
      "8/8, train_loss: 0.0142 step time: 0.1840\n",
      "epoch 77 average loss: 0.0110\n",
      "time consuming of epoch 77 is: 1.6214\n",
      "----------\n",
      "epoch 78/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2417\n",
      "2/8, train_loss: 0.0107 step time: 0.2006\n",
      "3/8, train_loss: 0.0093 step time: 0.1985\n",
      "4/8, train_loss: 0.0114 step time: 0.2019\n",
      "5/8, train_loss: 0.0105 step time: 0.2003\n",
      "6/8, train_loss: 0.0100 step time: 0.2011\n",
      "7/8, train_loss: 0.0104 step time: 0.1831\n",
      "8/8, train_loss: 0.0092 step time: 0.1837\n",
      "epoch 78 average loss: 0.0104\n",
      "time consuming of epoch 78 is: 1.6122\n",
      "----------\n",
      "epoch 79/600\n",
      "1/8, train_loss: 0.0095 step time: 0.2362\n",
      "2/8, train_loss: 0.0099 step time: 0.1971\n",
      "3/8, train_loss: 0.0102 step time: 0.1964\n",
      "4/8, train_loss: 0.0110 step time: 0.1976\n",
      "5/8, train_loss: 0.0107 step time: 0.1979\n",
      "6/8, train_loss: 0.0098 step time: 0.1981\n",
      "7/8, train_loss: 0.0102 step time: 0.1826\n",
      "8/8, train_loss: 0.0090 step time: 0.1806\n",
      "epoch 79 average loss: 0.0100\n",
      "time consuming of epoch 79 is: 1.5879\n",
      "----------\n",
      "epoch 80/600\n",
      "1/8, train_loss: 0.0087 step time: 0.2408\n",
      "2/8, train_loss: 0.0107 step time: 0.2030\n",
      "3/8, train_loss: 0.0116 step time: 0.1995\n",
      "4/8, train_loss: 0.0116 step time: 0.1993\n",
      "5/8, train_loss: 0.0110 step time: 0.1997\n",
      "6/8, train_loss: 0.0089 step time: 0.2045\n",
      "7/8, train_loss: 0.0114 step time: 0.1833\n",
      "8/8, train_loss: 0.0095 step time: 0.1850\n",
      "epoch 80 average loss: 0.0104\n",
      "current epoch: 80 current mean dice: 0.9607 best mean dice: 0.9611 at epoch: 10\n",
      "time consuming of epoch 80 is: 2.3738\n",
      "----------\n",
      "epoch 81/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2393\n",
      "2/8, train_loss: 0.0087 step time: 0.2028\n",
      "3/8, train_loss: 0.0113 step time: 0.2031\n",
      "4/8, train_loss: 0.0109 step time: 0.1983\n",
      "5/8, train_loss: 0.0104 step time: 0.2006\n",
      "6/8, train_loss: 0.0105 step time: 0.1991\n",
      "7/8, train_loss: 0.0106 step time: 0.1806\n",
      "8/8, train_loss: 0.0137 step time: 0.1815\n",
      "epoch 81 average loss: 0.0111\n",
      "time consuming of epoch 81 is: 1.6063\n",
      "----------\n",
      "epoch 82/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2436\n",
      "2/8, train_loss: 0.0105 step time: 0.2039\n",
      "3/8, train_loss: 0.0101 step time: 0.1999\n",
      "4/8, train_loss: 0.0111 step time: 0.1996\n",
      "5/8, train_loss: 0.0083 step time: 0.2035\n",
      "6/8, train_loss: 0.0105 step time: 0.2004\n",
      "7/8, train_loss: 0.0098 step time: 0.1828\n",
      "8/8, train_loss: 0.0138 step time: 0.1824\n",
      "epoch 82 average loss: 0.0106\n",
      "time consuming of epoch 82 is: 1.6174\n",
      "----------\n",
      "epoch 83/600\n",
      "1/8, train_loss: 0.0094 step time: 0.2353\n",
      "2/8, train_loss: 0.0100 step time: 0.1971\n",
      "3/8, train_loss: 0.0119 step time: 0.1981\n",
      "4/8, train_loss: 0.0122 step time: 0.1976\n",
      "5/8, train_loss: 0.0083 step time: 0.2062\n",
      "6/8, train_loss: 0.0110 step time: 0.2006\n",
      "7/8, train_loss: 0.0092 step time: 0.1825\n",
      "8/8, train_loss: 0.0110 step time: 0.1819\n",
      "epoch 83 average loss: 0.0104\n",
      "time consuming of epoch 83 is: 1.6010\n",
      "----------\n",
      "epoch 84/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2403\n",
      "2/8, train_loss: 0.0085 step time: 0.2039\n",
      "3/8, train_loss: 0.0104 step time: 0.1998\n",
      "4/8, train_loss: 0.0087 step time: 0.2003\n",
      "5/8, train_loss: 0.0147 step time: 0.1998\n",
      "6/8, train_loss: 0.0106 step time: 0.2029\n",
      "7/8, train_loss: 0.0113 step time: 0.1823\n",
      "8/8, train_loss: 0.0134 step time: 0.1817\n",
      "epoch 84 average loss: 0.0111\n",
      "time consuming of epoch 84 is: 1.6123\n",
      "----------\n",
      "epoch 85/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2399\n",
      "2/8, train_loss: 0.0092 step time: 0.2056\n",
      "3/8, train_loss: 0.0090 step time: 0.1993\n",
      "4/8, train_loss: 0.0094 step time: 0.1988\n",
      "5/8, train_loss: 0.0102 step time: 0.1991\n",
      "6/8, train_loss: 0.0132 step time: 0.2059\n",
      "7/8, train_loss: 0.0100 step time: 0.1835\n",
      "8/8, train_loss: 0.0090 step time: 0.1819\n",
      "epoch 85 average loss: 0.0101\n",
      "saved new best metric model\n",
      "current epoch: 85 current mean dice: 0.9614 best mean dice: 0.9614 at epoch: 85\n",
      "time consuming of epoch 85 is: 2.5141\n",
      "----------\n",
      "epoch 86/600\n",
      "1/8, train_loss: 0.0097 step time: 0.2423\n",
      "2/8, train_loss: 0.0102 step time: 0.2016\n",
      "3/8, train_loss: 0.0117 step time: 0.2002\n",
      "4/8, train_loss: 0.0100 step time: 0.1986\n",
      "5/8, train_loss: 0.0123 step time: 0.2042\n",
      "6/8, train_loss: 0.0114 step time: 0.1970\n",
      "7/8, train_loss: 0.0096 step time: 0.1814\n",
      "8/8, train_loss: 0.0121 step time: 0.1827\n",
      "epoch 86 average loss: 0.0109\n",
      "time consuming of epoch 86 is: 1.6092\n",
      "----------\n",
      "epoch 87/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2448\n",
      "2/8, train_loss: 0.0103 step time: 0.2025\n",
      "3/8, train_loss: 0.0086 step time: 0.2029\n",
      "4/8, train_loss: 0.0101 step time: 0.2002\n",
      "5/8, train_loss: 0.0119 step time: 0.2027\n",
      "6/8, train_loss: 0.0133 step time: 0.2041\n",
      "7/8, train_loss: 0.0091 step time: 0.1820\n",
      "8/8, train_loss: 0.0106 step time: 0.1836\n",
      "epoch 87 average loss: 0.0107\n",
      "time consuming of epoch 87 is: 1.6244\n",
      "----------\n",
      "epoch 88/600\n",
      "1/8, train_loss: 0.0106 step time: 0.2405\n",
      "2/8, train_loss: 0.0102 step time: 0.2019\n",
      "3/8, train_loss: 0.0101 step time: 0.2016\n",
      "4/8, train_loss: 0.0116 step time: 0.2004\n",
      "5/8, train_loss: 0.0122 step time: 0.1994\n",
      "6/8, train_loss: 0.0109 step time: 0.2013\n",
      "7/8, train_loss: 0.0121 step time: 0.1827\n",
      "8/8, train_loss: 0.0086 step time: 0.1826\n",
      "epoch 88 average loss: 0.0108\n",
      "time consuming of epoch 88 is: 1.6123\n",
      "----------\n",
      "epoch 89/600\n",
      "1/8, train_loss: 0.0115 step time: 0.2393\n",
      "2/8, train_loss: 0.0119 step time: 0.2035\n",
      "3/8, train_loss: 0.0120 step time: 0.2023\n",
      "4/8, train_loss: 0.0089 step time: 0.2018\n",
      "5/8, train_loss: 0.0114 step time: 0.2029\n",
      "6/8, train_loss: 0.0108 step time: 0.2017\n",
      "7/8, train_loss: 0.0097 step time: 0.1813\n",
      "8/8, train_loss: 0.0094 step time: 0.1824\n",
      "epoch 89 average loss: 0.0107\n",
      "time consuming of epoch 89 is: 1.6166\n",
      "----------\n",
      "epoch 90/600\n",
      "1/8, train_loss: 0.0109 step time: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/8, train_loss: 0.0110 step time: 0.2016\n",
      "3/8, train_loss: 0.0106 step time: 0.1994\n",
      "4/8, train_loss: 0.0109 step time: 0.2010\n",
      "5/8, train_loss: 0.0124 step time: 0.2019\n",
      "6/8, train_loss: 0.0106 step time: 0.2011\n",
      "7/8, train_loss: 0.0098 step time: 0.1835\n",
      "8/8, train_loss: 0.0100 step time: 0.1821\n",
      "epoch 90 average loss: 0.0107\n",
      "current epoch: 90 current mean dice: 0.9612 best mean dice: 0.9614 at epoch: 85\n",
      "time consuming of epoch 90 is: 2.3687\n",
      "----------\n",
      "epoch 91/600\n",
      "1/8, train_loss: 0.0089 step time: 0.2377\n",
      "2/8, train_loss: 0.0128 step time: 0.1980\n",
      "3/8, train_loss: 0.0117 step time: 0.2011\n",
      "4/8, train_loss: 0.0114 step time: 0.1981\n",
      "5/8, train_loss: 0.0097 step time: 0.1978\n",
      "6/8, train_loss: 0.0100 step time: 0.1989\n",
      "7/8, train_loss: 0.0116 step time: 0.1823\n",
      "8/8, train_loss: 0.0100 step time: 0.1816\n",
      "epoch 91 average loss: 0.0108\n",
      "time consuming of epoch 91 is: 1.5966\n",
      "----------\n",
      "epoch 92/600\n",
      "1/8, train_loss: 0.0101 step time: 0.2387\n",
      "2/8, train_loss: 0.0115 step time: 0.2022\n",
      "3/8, train_loss: 0.0101 step time: 0.1992\n",
      "4/8, train_loss: 0.0097 step time: 0.2004\n",
      "5/8, train_loss: 0.0104 step time: 0.2017\n",
      "6/8, train_loss: 0.0142 step time: 0.2005\n",
      "7/8, train_loss: 0.0097 step time: 0.1829\n",
      "8/8, train_loss: 0.0110 step time: 0.1824\n",
      "epoch 92 average loss: 0.0108\n",
      "time consuming of epoch 92 is: 1.6095\n",
      "----------\n",
      "epoch 93/600\n",
      "1/8, train_loss: 0.0100 step time: 0.2397\n",
      "2/8, train_loss: 0.0116 step time: 0.2033\n",
      "3/8, train_loss: 0.0133 step time: 0.1993\n",
      "4/8, train_loss: 0.0094 step time: 0.2019\n",
      "5/8, train_loss: 0.0130 step time: 0.2035\n",
      "6/8, train_loss: 0.0099 step time: 0.2029\n",
      "7/8, train_loss: 0.0101 step time: 0.1826\n",
      "8/8, train_loss: 0.0091 step time: 0.1837\n",
      "epoch 93 average loss: 0.0108\n",
      "time consuming of epoch 93 is: 1.6183\n",
      "----------\n",
      "epoch 94/600\n",
      "1/8, train_loss: 0.0095 step time: 0.2397\n",
      "2/8, train_loss: 0.0125 step time: 0.2014\n",
      "3/8, train_loss: 0.0094 step time: 0.1980\n",
      "4/8, train_loss: 0.0116 step time: 0.2004\n",
      "5/8, train_loss: 0.0102 step time: 0.2023\n",
      "6/8, train_loss: 0.0118 step time: 0.2001\n",
      "7/8, train_loss: 0.0098 step time: 0.1829\n",
      "8/8, train_loss: 0.0133 step time: 0.1822\n",
      "epoch 94 average loss: 0.0110\n",
      "time consuming of epoch 94 is: 1.6083\n",
      "----------\n",
      "epoch 95/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2391\n",
      "2/8, train_loss: 0.0093 step time: 0.2037\n",
      "3/8, train_loss: 0.0132 step time: 0.2002\n",
      "4/8, train_loss: 0.0105 step time: 0.2015\n",
      "5/8, train_loss: 0.0119 step time: 0.1997\n",
      "6/8, train_loss: 0.0096 step time: 0.2016\n",
      "7/8, train_loss: 0.0121 step time: 0.1837\n",
      "8/8, train_loss: 0.0108 step time: 0.1818\n",
      "epoch 95 average loss: 0.0110\n",
      "current epoch: 95 current mean dice: 0.9599 best mean dice: 0.9614 at epoch: 85\n",
      "time consuming of epoch 95 is: 2.3695\n",
      "----------\n",
      "epoch 96/600\n",
      "1/8, train_loss: 0.0100 step time: 0.2391\n",
      "2/8, train_loss: 0.0138 step time: 0.2010\n",
      "3/8, train_loss: 0.0123 step time: 0.2047\n",
      "4/8, train_loss: 0.0103 step time: 0.1987\n",
      "5/8, train_loss: 0.0085 step time: 0.1991\n",
      "6/8, train_loss: 0.0091 step time: 0.1991\n",
      "7/8, train_loss: 0.0089 step time: 0.1823\n",
      "8/8, train_loss: 0.0095 step time: 0.1813\n",
      "epoch 96 average loss: 0.0103\n",
      "time consuming of epoch 96 is: 1.6063\n",
      "----------\n",
      "epoch 97/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2374\n",
      "2/8, train_loss: 0.0139 step time: 0.2003\n",
      "3/8, train_loss: 0.0111 step time: 0.2020\n",
      "4/8, train_loss: 0.0097 step time: 0.2014\n",
      "5/8, train_loss: 0.0099 step time: 0.2011\n",
      "6/8, train_loss: 0.0100 step time: 0.1996\n",
      "7/8, train_loss: 0.0097 step time: 0.1835\n",
      "8/8, train_loss: 0.0088 step time: 0.1822\n",
      "epoch 97 average loss: 0.0104\n",
      "time consuming of epoch 97 is: 1.6092\n",
      "----------\n",
      "epoch 98/600\n",
      "1/8, train_loss: 0.0136 step time: 0.2395\n",
      "2/8, train_loss: 0.0085 step time: 0.2000\n",
      "3/8, train_loss: 0.0099 step time: 0.2000\n",
      "4/8, train_loss: 0.0100 step time: 0.1997\n",
      "5/8, train_loss: 0.0101 step time: 0.2014\n",
      "6/8, train_loss: 0.0106 step time: 0.1997\n",
      "7/8, train_loss: 0.0140 step time: 0.1829\n",
      "8/8, train_loss: 0.0098 step time: 0.1827\n",
      "epoch 98 average loss: 0.0108\n",
      "time consuming of epoch 98 is: 1.6073\n",
      "----------\n",
      "epoch 99/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2404\n",
      "2/8, train_loss: 0.0107 step time: 0.2030\n",
      "3/8, train_loss: 0.0118 step time: 0.1996\n",
      "4/8, train_loss: 0.0087 step time: 0.2001\n",
      "5/8, train_loss: 0.0099 step time: 0.1995\n",
      "6/8, train_loss: 0.0136 step time: 0.2000\n",
      "7/8, train_loss: 0.0102 step time: 0.1822\n",
      "8/8, train_loss: 0.0097 step time: 0.1821\n",
      "epoch 99 average loss: 0.0105\n",
      "time consuming of epoch 99 is: 1.6086\n",
      "----------\n",
      "epoch 100/600\n",
      "1/8, train_loss: 0.0138 step time: 0.2408\n",
      "2/8, train_loss: 0.0094 step time: 0.1994\n",
      "3/8, train_loss: 0.0094 step time: 0.2007\n",
      "4/8, train_loss: 0.0105 step time: 0.2019\n",
      "5/8, train_loss: 0.0119 step time: 0.1980\n",
      "6/8, train_loss: 0.0107 step time: 0.1997\n",
      "7/8, train_loss: 0.0100 step time: 0.1826\n",
      "8/8, train_loss: 0.0092 step time: 0.1836\n",
      "epoch 100 average loss: 0.0106\n",
      "current epoch: 100 current mean dice: 0.9600 best mean dice: 0.9614 at epoch: 85\n",
      "time consuming of epoch 100 is: 2.3628\n",
      "----------\n",
      "epoch 101/600\n",
      "1/8, train_loss: 0.0101 step time: 0.2390\n",
      "2/8, train_loss: 0.0113 step time: 0.1983\n",
      "3/8, train_loss: 0.0135 step time: 0.2042\n",
      "4/8, train_loss: 0.0088 step time: 0.1979\n",
      "5/8, train_loss: 0.0110 step time: 0.2016\n",
      "6/8, train_loss: 0.0124 step time: 0.2025\n",
      "7/8, train_loss: 0.0089 step time: 0.1824\n",
      "8/8, train_loss: 0.0089 step time: 0.1822\n",
      "epoch 101 average loss: 0.0106\n",
      "time consuming of epoch 101 is: 1.6092\n",
      "----------\n",
      "epoch 102/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2404\n",
      "2/8, train_loss: 0.0112 step time: 0.2027\n",
      "3/8, train_loss: 0.0096 step time: 0.1996\n",
      "4/8, train_loss: 0.0115 step time: 0.1999\n",
      "5/8, train_loss: 0.0101 step time: 0.2006\n",
      "6/8, train_loss: 0.0086 step time: 0.2013\n",
      "7/8, train_loss: 0.0098 step time: 0.1825\n",
      "8/8, train_loss: 0.0099 step time: 0.1829\n",
      "epoch 102 average loss: 0.0101\n",
      "time consuming of epoch 102 is: 1.6112\n",
      "----------\n",
      "epoch 103/600\n",
      "1/8, train_loss: 0.0095 step time: 0.2399\n",
      "2/8, train_loss: 0.0098 step time: 0.1983\n",
      "3/8, train_loss: 0.0089 step time: 0.2006\n",
      "4/8, train_loss: 0.0108 step time: 0.2018\n",
      "5/8, train_loss: 0.0108 step time: 0.2001\n",
      "6/8, train_loss: 0.0101 step time: 0.2002\n",
      "7/8, train_loss: 0.0095 step time: 0.1823\n",
      "8/8, train_loss: 0.0111 step time: 0.1825\n",
      "epoch 103 average loss: 0.0100\n",
      "time consuming of epoch 103 is: 1.6074\n",
      "----------\n",
      "epoch 104/600\n",
      "1/8, train_loss: 0.0114 step time: 0.2404\n",
      "2/8, train_loss: 0.0107 step time: 0.2001\n",
      "3/8, train_loss: 0.0109 step time: 0.1994\n",
      "4/8, train_loss: 0.0077 step time: 0.1992\n",
      "5/8, train_loss: 0.0103 step time: 0.2013\n",
      "6/8, train_loss: 0.0095 step time: 0.2003\n",
      "7/8, train_loss: 0.0102 step time: 0.1830\n",
      "8/8, train_loss: 0.0115 step time: 0.1816\n",
      "epoch 104 average loss: 0.0103\n",
      "time consuming of epoch 104 is: 1.6068\n",
      "----------\n",
      "epoch 105/600\n",
      "1/8, train_loss: 0.0132 step time: 0.2392\n",
      "2/8, train_loss: 0.0095 step time: 0.2019\n",
      "3/8, train_loss: 0.0096 step time: 0.2020\n",
      "4/8, train_loss: 0.0105 step time: 0.2032\n",
      "5/8, train_loss: 0.0106 step time: 0.2017\n",
      "6/8, train_loss: 0.0112 step time: 0.2000\n",
      "7/8, train_loss: 0.0117 step time: 0.1833\n",
      "8/8, train_loss: 0.0081 step time: 0.1824\n",
      "epoch 105 average loss: 0.0105\n",
      "saved new best metric model\n",
      "current epoch: 105 current mean dice: 0.9614 best mean dice: 0.9614 at epoch: 105\n",
      "time consuming of epoch 105 is: 2.5107\n",
      "----------\n",
      "epoch 106/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2403\n",
      "2/8, train_loss: 0.0090 step time: 0.2025\n",
      "3/8, train_loss: 0.0115 step time: 0.1980\n",
      "4/8, train_loss: 0.0105 step time: 0.1981\n",
      "5/8, train_loss: 0.0084 step time: 0.1999\n",
      "6/8, train_loss: 0.0089 step time: 0.1989\n",
      "7/8, train_loss: 0.0108 step time: 0.1818\n",
      "8/8, train_loss: 0.0129 step time: 0.1811\n",
      "epoch 106 average loss: 0.0103\n",
      "time consuming of epoch 106 is: 1.6018\n",
      "----------\n",
      "epoch 107/600\n",
      "1/8, train_loss: 0.0086 step time: 0.2385\n",
      "2/8, train_loss: 0.0138 step time: 0.1989\n",
      "3/8, train_loss: 0.0097 step time: 0.2013\n",
      "4/8, train_loss: 0.0091 step time: 0.1994\n",
      "5/8, train_loss: 0.0104 step time: 0.2014\n",
      "6/8, train_loss: 0.0098 step time: 0.2014\n",
      "7/8, train_loss: 0.0141 step time: 0.1832\n",
      "8/8, train_loss: 0.0096 step time: 0.1832\n",
      "epoch 107 average loss: 0.0106\n",
      "time consuming of epoch 107 is: 1.6088\n",
      "----------\n",
      "epoch 108/600\n",
      "1/8, train_loss: 0.0144 step time: 0.2412\n",
      "2/8, train_loss: 0.0099 step time: 0.2029\n",
      "3/8, train_loss: 0.0107 step time: 0.2012\n",
      "4/8, train_loss: 0.0118 step time: 0.2005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8, train_loss: 0.0100 step time: 0.1999\n",
      "6/8, train_loss: 0.0094 step time: 0.1997\n",
      "7/8, train_loss: 0.0092 step time: 0.1825\n",
      "8/8, train_loss: 0.0136 step time: 0.1848\n",
      "epoch 108 average loss: 0.0111\n",
      "time consuming of epoch 108 is: 1.6141\n",
      "----------\n",
      "epoch 109/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2387\n",
      "2/8, train_loss: 0.0116 step time: 0.1981\n",
      "3/8, train_loss: 0.0092 step time: 0.1991\n",
      "4/8, train_loss: 0.0102 step time: 0.1986\n",
      "5/8, train_loss: 0.0092 step time: 0.2006\n",
      "6/8, train_loss: 0.0117 step time: 0.1997\n",
      "7/8, train_loss: 0.0094 step time: 0.1836\n",
      "8/8, train_loss: 0.0125 step time: 0.1821\n",
      "epoch 109 average loss: 0.0105\n",
      "time consuming of epoch 109 is: 1.6021\n",
      "----------\n",
      "epoch 110/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2400\n",
      "2/8, train_loss: 0.0143 step time: 0.2020\n",
      "3/8, train_loss: 0.0097 step time: 0.2020\n",
      "4/8, train_loss: 0.0111 step time: 0.1997\n",
      "5/8, train_loss: 0.0122 step time: 0.2035\n",
      "6/8, train_loss: 0.0098 step time: 0.1985\n",
      "7/8, train_loss: 0.0111 step time: 0.1818\n",
      "8/8, train_loss: 0.0082 step time: 0.1808\n",
      "epoch 110 average loss: 0.0109\n",
      "current epoch: 110 current mean dice: 0.9605 best mean dice: 0.9614 at epoch: 105\n",
      "time consuming of epoch 110 is: 2.3648\n",
      "----------\n",
      "epoch 111/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2373\n",
      "2/8, train_loss: 0.0098 step time: 0.2000\n",
      "3/8, train_loss: 0.0095 step time: 0.1960\n",
      "4/8, train_loss: 0.0109 step time: 0.1961\n",
      "5/8, train_loss: 0.0103 step time: 0.1949\n",
      "6/8, train_loss: 0.0095 step time: 0.1935\n",
      "7/8, train_loss: 0.0120 step time: 0.1845\n",
      "8/8, train_loss: 0.0089 step time: 0.1805\n",
      "epoch 111 average loss: 0.0102\n",
      "time consuming of epoch 111 is: 1.5839\n",
      "----------\n",
      "epoch 112/600\n",
      "1/8, train_loss: 0.0094 step time: 0.2390\n",
      "2/8, train_loss: 0.0089 step time: 0.2000\n",
      "3/8, train_loss: 0.0106 step time: 0.2002\n",
      "4/8, train_loss: 0.0100 step time: 0.1999\n",
      "5/8, train_loss: 0.0141 step time: 0.2008\n",
      "6/8, train_loss: 0.0111 step time: 0.2023\n",
      "7/8, train_loss: 0.0102 step time: 0.1824\n",
      "8/8, train_loss: 0.0109 step time: 0.1822\n",
      "epoch 112 average loss: 0.0107\n",
      "time consuming of epoch 112 is: 1.6079\n",
      "----------\n",
      "epoch 113/600\n",
      "1/8, train_loss: 0.0112 step time: 0.2394\n",
      "2/8, train_loss: 0.0112 step time: 0.2020\n",
      "3/8, train_loss: 0.0107 step time: 0.1986\n",
      "4/8, train_loss: 0.0120 step time: 0.1980\n",
      "5/8, train_loss: 0.0104 step time: 0.1983\n",
      "6/8, train_loss: 0.0099 step time: 0.2029\n",
      "7/8, train_loss: 0.0102 step time: 0.1819\n",
      "8/8, train_loss: 0.0095 step time: 0.1817\n",
      "epoch 113 average loss: 0.0106\n",
      "time consuming of epoch 113 is: 1.6044\n",
      "----------\n",
      "epoch 114/600\n",
      "1/8, train_loss: 0.0101 step time: 0.2371\n",
      "2/8, train_loss: 0.0106 step time: 0.2021\n",
      "3/8, train_loss: 0.0102 step time: 0.2044\n",
      "4/8, train_loss: 0.0098 step time: 0.1969\n",
      "5/8, train_loss: 0.0104 step time: 0.2033\n",
      "6/8, train_loss: 0.0126 step time: 0.1978\n",
      "7/8, train_loss: 0.0128 step time: 0.1831\n",
      "8/8, train_loss: 0.0095 step time: 0.1834\n",
      "epoch 114 average loss: 0.0108\n",
      "time consuming of epoch 114 is: 1.6096\n",
      "----------\n",
      "epoch 115/600\n",
      "1/8, train_loss: 0.0108 step time: 0.2404\n",
      "2/8, train_loss: 0.0100 step time: 0.2013\n",
      "3/8, train_loss: 0.0092 step time: 0.1984\n",
      "4/8, train_loss: 0.0097 step time: 0.2015\n",
      "5/8, train_loss: 0.0099 step time: 0.1987\n",
      "6/8, train_loss: 0.0116 step time: 0.2011\n",
      "7/8, train_loss: 0.0098 step time: 0.1820\n",
      "8/8, train_loss: 0.0112 step time: 0.1820\n",
      "epoch 115 average loss: 0.0103\n",
      "current epoch: 115 current mean dice: 0.9596 best mean dice: 0.9614 at epoch: 105\n",
      "time consuming of epoch 115 is: 2.3625\n",
      "----------\n",
      "epoch 116/600\n",
      "1/8, train_loss: 0.0106 step time: 0.2386\n",
      "2/8, train_loss: 0.0118 step time: 0.1980\n",
      "3/8, train_loss: 0.0139 step time: 0.2027\n",
      "4/8, train_loss: 0.0113 step time: 0.1992\n",
      "5/8, train_loss: 0.0137 step time: 0.2008\n",
      "6/8, train_loss: 0.0097 step time: 0.1985\n",
      "7/8, train_loss: 0.0093 step time: 0.1821\n",
      "8/8, train_loss: 0.0101 step time: 0.1819\n",
      "epoch 116 average loss: 0.0113\n",
      "time consuming of epoch 116 is: 1.6029\n",
      "----------\n",
      "epoch 117/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2397\n",
      "2/8, train_loss: 0.0110 step time: 0.2033\n",
      "3/8, train_loss: 0.0091 step time: 0.1990\n",
      "4/8, train_loss: 0.0109 step time: 0.1995\n",
      "5/8, train_loss: 0.0122 step time: 0.1993\n",
      "6/8, train_loss: 0.0119 step time: 0.2009\n",
      "7/8, train_loss: 0.0134 step time: 0.1823\n",
      "8/8, train_loss: 0.0118 step time: 0.1822\n",
      "epoch 117 average loss: 0.0112\n",
      "time consuming of epoch 117 is: 1.6078\n",
      "----------\n",
      "epoch 118/600\n",
      "1/8, train_loss: 0.0086 step time: 0.2365\n",
      "2/8, train_loss: 0.0089 step time: 0.1992\n",
      "3/8, train_loss: 0.0102 step time: 0.1989\n",
      "4/8, train_loss: 0.0098 step time: 0.2049\n",
      "5/8, train_loss: 0.0101 step time: 0.1990\n",
      "6/8, train_loss: 0.0104 step time: 0.1996\n",
      "7/8, train_loss: 0.0128 step time: 0.1825\n",
      "8/8, train_loss: 0.0124 step time: 0.1825\n",
      "epoch 118 average loss: 0.0104\n",
      "time consuming of epoch 118 is: 1.6047\n",
      "----------\n",
      "epoch 119/600\n",
      "1/8, train_loss: 0.0134 step time: 0.2419\n",
      "2/8, train_loss: 0.0093 step time: 0.1982\n",
      "3/8, train_loss: 0.0098 step time: 0.2000\n",
      "4/8, train_loss: 0.0109 step time: 0.2013\n",
      "5/8, train_loss: 0.0113 step time: 0.1987\n",
      "6/8, train_loss: 0.0098 step time: 0.2005\n",
      "7/8, train_loss: 0.0093 step time: 0.1846\n",
      "8/8, train_loss: 0.0123 step time: 0.1821\n",
      "epoch 119 average loss: 0.0108\n",
      "time consuming of epoch 119 is: 1.6089\n",
      "----------\n",
      "epoch 120/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2327\n",
      "2/8, train_loss: 0.0088 step time: 0.2002\n",
      "3/8, train_loss: 0.0087 step time: 0.1992\n",
      "4/8, train_loss: 0.0088 step time: 0.1951\n",
      "5/8, train_loss: 0.0107 step time: 0.2022\n",
      "6/8, train_loss: 0.0107 step time: 0.2013\n",
      "7/8, train_loss: 0.0105 step time: 0.1820\n",
      "8/8, train_loss: 0.0102 step time: 0.1815\n",
      "epoch 120 average loss: 0.0099\n",
      "current epoch: 120 current mean dice: 0.9608 best mean dice: 0.9614 at epoch: 105\n",
      "time consuming of epoch 120 is: 2.3504\n",
      "----------\n",
      "epoch 121/600\n",
      "1/8, train_loss: 0.0119 step time: 0.2386\n",
      "2/8, train_loss: 0.0116 step time: 0.1973\n",
      "3/8, train_loss: 0.0086 step time: 0.1974\n",
      "4/8, train_loss: 0.0133 step time: 0.2000\n",
      "5/8, train_loss: 0.0093 step time: 0.1988\n",
      "6/8, train_loss: 0.0099 step time: 0.1975\n",
      "7/8, train_loss: 0.0095 step time: 0.1798\n",
      "8/8, train_loss: 0.0097 step time: 0.1800\n",
      "epoch 121 average loss: 0.0105\n",
      "time consuming of epoch 121 is: 1.5904\n",
      "----------\n",
      "epoch 122/600\n",
      "1/8, train_loss: 0.0086 step time: 0.2381\n",
      "2/8, train_loss: 0.0099 step time: 0.2010\n",
      "3/8, train_loss: 0.0101 step time: 0.2000\n",
      "4/8, train_loss: 0.0134 step time: 0.1993\n",
      "5/8, train_loss: 0.0090 step time: 0.2002\n",
      "6/8, train_loss: 0.0120 step time: 0.1995\n",
      "7/8, train_loss: 0.0098 step time: 0.1826\n",
      "8/8, train_loss: 0.0105 step time: 0.1830\n",
      "epoch 122 average loss: 0.0104\n",
      "time consuming of epoch 122 is: 1.6048\n",
      "----------\n",
      "epoch 123/600\n",
      "1/8, train_loss: 0.0124 step time: 0.2406\n",
      "2/8, train_loss: 0.0095 step time: 0.2008\n",
      "3/8, train_loss: 0.0097 step time: 0.2001\n",
      "4/8, train_loss: 0.0091 step time: 0.1997\n",
      "5/8, train_loss: 0.0098 step time: 0.1996\n",
      "6/8, train_loss: 0.0116 step time: 0.1999\n",
      "7/8, train_loss: 0.0117 step time: 0.1820\n",
      "8/8, train_loss: 0.0110 step time: 0.1822\n",
      "epoch 123 average loss: 0.0106\n",
      "time consuming of epoch 123 is: 1.6066\n",
      "----------\n",
      "epoch 124/600\n",
      "1/8, train_loss: 0.0106 step time: 0.2399\n",
      "2/8, train_loss: 0.0098 step time: 0.2044\n",
      "3/8, train_loss: 0.0098 step time: 0.1983\n",
      "4/8, train_loss: 0.0106 step time: 0.2002\n",
      "5/8, train_loss: 0.0102 step time: 0.1986\n",
      "6/8, train_loss: 0.0105 step time: 0.1979\n",
      "7/8, train_loss: 0.0117 step time: 0.1826\n",
      "8/8, train_loss: 0.0099 step time: 0.1821\n",
      "epoch 124 average loss: 0.0104\n",
      "time consuming of epoch 124 is: 1.6057\n",
      "----------\n",
      "epoch 125/600\n",
      "1/8, train_loss: 0.0096 step time: 0.2393\n",
      "2/8, train_loss: 0.0117 step time: 0.2016\n",
      "3/8, train_loss: 0.0113 step time: 0.1990\n",
      "4/8, train_loss: 0.0087 step time: 0.2020\n",
      "5/8, train_loss: 0.0095 step time: 0.2003\n",
      "6/8, train_loss: 0.0116 step time: 0.1986\n",
      "7/8, train_loss: 0.0096 step time: 0.1829\n",
      "8/8, train_loss: 0.0096 step time: 0.1821\n",
      "epoch 125 average loss: 0.0102\n",
      "current epoch: 125 current mean dice: 0.9594 best mean dice: 0.9614 at epoch: 105\n",
      "time consuming of epoch 125 is: 2.3612\n",
      "----------\n",
      "epoch 126/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2339\n",
      "2/8, train_loss: 0.0103 step time: 0.1969\n",
      "3/8, train_loss: 0.0103 step time: 0.2005\n",
      "4/8, train_loss: 0.0105 step time: 0.1980\n",
      "5/8, train_loss: 0.0103 step time: 0.2015\n",
      "6/8, train_loss: 0.0089 step time: 0.1983\n",
      "7/8, train_loss: 0.0091 step time: 0.1817\n",
      "8/8, train_loss: 0.0109 step time: 0.1827\n",
      "epoch 126 average loss: 0.0100\n",
      "time consuming of epoch 126 is: 1.5946\n",
      "----------\n",
      "epoch 127/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0127 step time: 0.2395\n",
      "2/8, train_loss: 0.0083 step time: 0.2005\n",
      "3/8, train_loss: 0.0087 step time: 0.2073\n",
      "4/8, train_loss: 0.0099 step time: 0.2045\n",
      "5/8, train_loss: 0.0086 step time: 0.2002\n",
      "6/8, train_loss: 0.0099 step time: 0.1987\n",
      "7/8, train_loss: 0.0131 step time: 0.1813\n",
      "8/8, train_loss: 0.0099 step time: 0.1808\n",
      "epoch 127 average loss: 0.0101\n",
      "time consuming of epoch 127 is: 1.6141\n",
      "----------\n",
      "epoch 128/600\n",
      "1/8, train_loss: 0.0101 step time: 0.2389\n",
      "2/8, train_loss: 0.0093 step time: 0.1958\n",
      "3/8, train_loss: 0.0097 step time: 0.2015\n",
      "4/8, train_loss: 0.0101 step time: 0.1981\n",
      "5/8, train_loss: 0.0104 step time: 0.2012\n",
      "6/8, train_loss: 0.0110 step time: 0.2014\n",
      "7/8, train_loss: 0.0096 step time: 0.1827\n",
      "8/8, train_loss: 0.0138 step time: 0.1820\n",
      "epoch 128 average loss: 0.0105\n",
      "time consuming of epoch 128 is: 1.6031\n",
      "----------\n",
      "epoch 129/600\n",
      "1/8, train_loss: 0.0113 step time: 0.2406\n",
      "2/8, train_loss: 0.0118 step time: 0.2031\n",
      "3/8, train_loss: 0.0090 step time: 0.1992\n",
      "4/8, train_loss: 0.0127 step time: 0.2011\n",
      "5/8, train_loss: 0.0099 step time: 0.2019\n",
      "6/8, train_loss: 0.0112 step time: 0.1988\n",
      "7/8, train_loss: 0.0088 step time: 0.1826\n",
      "8/8, train_loss: 0.0091 step time: 0.1806\n",
      "epoch 129 average loss: 0.0105\n",
      "time consuming of epoch 129 is: 1.6095\n",
      "----------\n",
      "epoch 130/600\n",
      "1/8, train_loss: 0.0137 step time: 0.2405\n",
      "2/8, train_loss: 0.0117 step time: 0.2078\n",
      "3/8, train_loss: 0.0089 step time: 0.1984\n",
      "4/8, train_loss: 0.0095 step time: 0.1986\n",
      "5/8, train_loss: 0.0102 step time: 0.1976\n",
      "6/8, train_loss: 0.0100 step time: 0.2009\n",
      "7/8, train_loss: 0.0119 step time: 0.1825\n",
      "8/8, train_loss: 0.0100 step time: 0.1817\n",
      "epoch 130 average loss: 0.0107\n",
      "current epoch: 130 current mean dice: 0.9604 best mean dice: 0.9614 at epoch: 105\n",
      "time consuming of epoch 130 is: 2.3649\n",
      "----------\n",
      "epoch 131/600\n",
      "1/8, train_loss: 0.0099 step time: 0.2371\n",
      "2/8, train_loss: 0.0131 step time: 0.1974\n",
      "3/8, train_loss: 0.0091 step time: 0.1964\n",
      "4/8, train_loss: 0.0103 step time: 0.1993\n",
      "5/8, train_loss: 0.0116 step time: 0.2007\n",
      "6/8, train_loss: 0.0089 step time: 0.2002\n",
      "7/8, train_loss: 0.0113 step time: 0.1836\n",
      "8/8, train_loss: 0.0105 step time: 0.1807\n",
      "epoch 131 average loss: 0.0106\n",
      "time consuming of epoch 131 is: 1.5964\n",
      "----------\n",
      "epoch 132/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2374\n",
      "2/8, train_loss: 0.0091 step time: 0.2015\n",
      "3/8, train_loss: 0.0107 step time: 0.1984\n",
      "4/8, train_loss: 0.0108 step time: 0.2018\n",
      "5/8, train_loss: 0.0096 step time: 0.2022\n",
      "6/8, train_loss: 0.0124 step time: 0.2017\n",
      "7/8, train_loss: 0.0114 step time: 0.1820\n",
      "8/8, train_loss: 0.0089 step time: 0.1810\n",
      "epoch 132 average loss: 0.0103\n",
      "time consuming of epoch 132 is: 1.6074\n",
      "----------\n",
      "epoch 133/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2402\n",
      "2/8, train_loss: 0.0111 step time: 0.2017\n",
      "3/8, train_loss: 0.0107 step time: 0.2013\n",
      "4/8, train_loss: 0.0096 step time: 0.1999\n",
      "5/8, train_loss: 0.0108 step time: 0.2004\n",
      "6/8, train_loss: 0.0107 step time: 0.1989\n",
      "7/8, train_loss: 0.0093 step time: 0.1834\n",
      "8/8, train_loss: 0.0110 step time: 0.1820\n",
      "epoch 133 average loss: 0.0104\n",
      "time consuming of epoch 133 is: 1.6092\n",
      "----------\n",
      "epoch 134/600\n",
      "1/8, train_loss: 0.0106 step time: 0.2383\n",
      "2/8, train_loss: 0.0081 step time: 0.2005\n",
      "3/8, train_loss: 0.0080 step time: 0.2026\n",
      "4/8, train_loss: 0.0088 step time: 0.1978\n",
      "5/8, train_loss: 0.0113 step time: 0.2025\n",
      "6/8, train_loss: 0.0126 step time: 0.2023\n",
      "7/8, train_loss: 0.0119 step time: 0.1830\n",
      "8/8, train_loss: 0.0104 step time: 0.1825\n",
      "epoch 134 average loss: 0.0102\n",
      "time consuming of epoch 134 is: 1.6111\n",
      "----------\n",
      "epoch 135/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2393\n",
      "2/8, train_loss: 0.0104 step time: 0.2021\n",
      "3/8, train_loss: 0.0085 step time: 0.1996\n",
      "4/8, train_loss: 0.0100 step time: 0.2012\n",
      "5/8, train_loss: 0.0095 step time: 0.2000\n",
      "6/8, train_loss: 0.0105 step time: 0.1992\n",
      "7/8, train_loss: 0.0111 step time: 0.1843\n",
      "8/8, train_loss: 0.0101 step time: 0.1824\n",
      "epoch 135 average loss: 0.0101\n",
      "current epoch: 135 current mean dice: 0.9609 best mean dice: 0.9614 at epoch: 105\n",
      "time consuming of epoch 135 is: 2.3658\n",
      "----------\n",
      "epoch 136/600\n",
      "1/8, train_loss: 0.0085 step time: 0.2503\n",
      "2/8, train_loss: 0.0135 step time: 0.2041\n",
      "3/8, train_loss: 0.0134 step time: 0.1969\n",
      "4/8, train_loss: 0.0104 step time: 0.1996\n",
      "5/8, train_loss: 0.0092 step time: 0.1988\n",
      "6/8, train_loss: 0.0097 step time: 0.1976\n",
      "7/8, train_loss: 0.0099 step time: 0.1827\n",
      "8/8, train_loss: 0.0092 step time: 0.1826\n",
      "epoch 136 average loss: 0.0105\n",
      "time consuming of epoch 136 is: 1.6136\n",
      "----------\n",
      "epoch 137/600\n",
      "1/8, train_loss: 0.0103 step time: 0.2404\n",
      "2/8, train_loss: 0.0099 step time: 0.1993\n",
      "3/8, train_loss: 0.0118 step time: 0.1987\n",
      "4/8, train_loss: 0.0102 step time: 0.2029\n",
      "5/8, train_loss: 0.0100 step time: 0.2052\n",
      "6/8, train_loss: 0.0090 step time: 0.2018\n",
      "7/8, train_loss: 0.0146 step time: 0.1825\n",
      "8/8, train_loss: 0.0088 step time: 0.1832\n",
      "epoch 137 average loss: 0.0106\n",
      "time consuming of epoch 137 is: 1.6153\n",
      "----------\n",
      "epoch 138/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2396\n",
      "2/8, train_loss: 0.0093 step time: 0.2029\n",
      "3/8, train_loss: 0.0106 step time: 0.1988\n",
      "4/8, train_loss: 0.0139 step time: 0.2028\n",
      "5/8, train_loss: 0.0092 step time: 0.2028\n",
      "6/8, train_loss: 0.0093 step time: 0.1976\n",
      "7/8, train_loss: 0.0089 step time: 0.1807\n",
      "8/8, train_loss: 0.0118 step time: 0.1820\n",
      "epoch 138 average loss: 0.0103\n",
      "time consuming of epoch 138 is: 1.6089\n",
      "----------\n",
      "epoch 139/600\n",
      "1/8, train_loss: 0.0108 step time: 0.2418\n",
      "2/8, train_loss: 0.0100 step time: 0.2048\n",
      "3/8, train_loss: 0.0105 step time: 0.1987\n",
      "4/8, train_loss: 0.0086 step time: 0.2016\n",
      "5/8, train_loss: 0.0097 step time: 0.2027\n",
      "6/8, train_loss: 0.0093 step time: 0.2019\n",
      "7/8, train_loss: 0.0105 step time: 0.1832\n",
      "8/8, train_loss: 0.0103 step time: 0.1817\n",
      "epoch 139 average loss: 0.0100\n",
      "time consuming of epoch 139 is: 1.6177\n",
      "----------\n",
      "epoch 140/600\n",
      "1/8, train_loss: 0.0111 step time: 0.2423\n",
      "2/8, train_loss: 0.0129 step time: 0.2035\n",
      "3/8, train_loss: 0.0105 step time: 0.1999\n",
      "4/8, train_loss: 0.0086 step time: 0.2008\n",
      "5/8, train_loss: 0.0098 step time: 0.2019\n",
      "6/8, train_loss: 0.0090 step time: 0.1984\n",
      "7/8, train_loss: 0.0093 step time: 0.1827\n",
      "8/8, train_loss: 0.0110 step time: 0.1823\n",
      "epoch 140 average loss: 0.0103\n",
      "current epoch: 140 current mean dice: 0.9604 best mean dice: 0.9614 at epoch: 105\n",
      "time consuming of epoch 140 is: 2.3694\n",
      "----------\n",
      "epoch 141/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2350\n",
      "2/8, train_loss: 0.0089 step time: 0.2025\n",
      "3/8, train_loss: 0.0089 step time: 0.1985\n",
      "4/8, train_loss: 0.0110 step time: 0.1997\n",
      "5/8, train_loss: 0.0099 step time: 0.1992\n",
      "6/8, train_loss: 0.0093 step time: 0.2010\n",
      "7/8, train_loss: 0.0085 step time: 0.1825\n",
      "8/8, train_loss: 0.0111 step time: 0.1825\n",
      "epoch 141 average loss: 0.0099\n",
      "time consuming of epoch 141 is: 1.6020\n",
      "----------\n",
      "epoch 142/600\n",
      "1/8, train_loss: 0.0128 step time: 0.2381\n",
      "2/8, train_loss: 0.0077 step time: 0.2034\n",
      "3/8, train_loss: 0.0089 step time: 0.1997\n",
      "4/8, train_loss: 0.0111 step time: 0.2053\n",
      "5/8, train_loss: 0.0103 step time: 0.2006\n",
      "6/8, train_loss: 0.0093 step time: 0.2024\n",
      "7/8, train_loss: 0.0106 step time: 0.1839\n",
      "8/8, train_loss: 0.0104 step time: 0.1841\n",
      "epoch 142 average loss: 0.0101\n",
      "time consuming of epoch 142 is: 1.6189\n",
      "----------\n",
      "epoch 143/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2380\n",
      "2/8, train_loss: 0.0102 step time: 0.1992\n",
      "3/8, train_loss: 0.0104 step time: 0.1955\n",
      "4/8, train_loss: 0.0095 step time: 0.1945\n",
      "5/8, train_loss: 0.0084 step time: 0.1958\n",
      "6/8, train_loss: 0.0098 step time: 0.1985\n",
      "7/8, train_loss: 0.0117 step time: 0.1821\n",
      "8/8, train_loss: 0.0110 step time: 0.1824\n",
      "epoch 143 average loss: 0.0102\n",
      "time consuming of epoch 143 is: 1.5875\n",
      "----------\n",
      "epoch 144/600\n",
      "1/8, train_loss: 0.0108 step time: 0.2420\n",
      "2/8, train_loss: 0.0082 step time: 0.2015\n",
      "3/8, train_loss: 0.0092 step time: 0.2013\n",
      "4/8, train_loss: 0.0097 step time: 0.2011\n",
      "5/8, train_loss: 0.0116 step time: 0.1989\n",
      "6/8, train_loss: 0.0095 step time: 0.2008\n",
      "7/8, train_loss: 0.0117 step time: 0.1828\n",
      "8/8, train_loss: 0.0107 step time: 0.1829\n",
      "epoch 144 average loss: 0.0102\n",
      "time consuming of epoch 144 is: 1.6128\n",
      "----------\n",
      "epoch 145/600\n",
      "1/8, train_loss: 0.0090 step time: 0.2393\n",
      "2/8, train_loss: 0.0121 step time: 0.2032\n",
      "3/8, train_loss: 0.0087 step time: 0.2011\n",
      "4/8, train_loss: 0.0097 step time: 0.1991\n",
      "5/8, train_loss: 0.0103 step time: 0.2036\n",
      "6/8, train_loss: 0.0111 step time: 0.1996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/8, train_loss: 0.0100 step time: 0.1831\n",
      "8/8, train_loss: 0.0102 step time: 0.1825\n",
      "epoch 145 average loss: 0.0101\n",
      "current epoch: 145 current mean dice: 0.9602 best mean dice: 0.9614 at epoch: 105\n",
      "time consuming of epoch 145 is: 2.3686\n",
      "----------\n",
      "epoch 146/600\n",
      "1/8, train_loss: 0.0115 step time: 0.2376\n",
      "2/8, train_loss: 0.0126 step time: 0.1997\n",
      "3/8, train_loss: 0.0087 step time: 0.1985\n",
      "4/8, train_loss: 0.0095 step time: 0.2005\n",
      "5/8, train_loss: 0.0107 step time: 0.1979\n",
      "6/8, train_loss: 0.0109 step time: 0.1958\n",
      "7/8, train_loss: 0.0115 step time: 0.1808\n",
      "8/8, train_loss: 0.0113 step time: 0.1814\n",
      "epoch 146 average loss: 0.0108\n",
      "time consuming of epoch 146 is: 1.5933\n",
      "----------\n",
      "epoch 147/600\n",
      "1/8, train_loss: 0.0115 step time: 0.2398\n",
      "2/8, train_loss: 0.0125 step time: 0.2025\n",
      "3/8, train_loss: 0.0101 step time: 0.2018\n",
      "4/8, train_loss: 0.0096 step time: 0.1984\n",
      "5/8, train_loss: 0.0094 step time: 0.2015\n",
      "6/8, train_loss: 0.0091 step time: 0.2013\n",
      "7/8, train_loss: 0.0103 step time: 0.1829\n",
      "8/8, train_loss: 0.0086 step time: 0.1836\n",
      "epoch 147 average loss: 0.0102\n",
      "time consuming of epoch 147 is: 1.6134\n",
      "----------\n",
      "epoch 148/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2407\n",
      "2/8, train_loss: 0.0088 step time: 0.2024\n",
      "3/8, train_loss: 0.0090 step time: 0.2014\n",
      "4/8, train_loss: 0.0104 step time: 0.1999\n",
      "5/8, train_loss: 0.0144 step time: 0.2016\n",
      "6/8, train_loss: 0.0105 step time: 0.2002\n",
      "7/8, train_loss: 0.0106 step time: 0.1832\n",
      "8/8, train_loss: 0.0098 step time: 0.1839\n",
      "epoch 148 average loss: 0.0105\n",
      "time consuming of epoch 148 is: 1.6149\n",
      "----------\n",
      "epoch 149/600\n",
      "1/8, train_loss: 0.0087 step time: 0.2405\n",
      "2/8, train_loss: 0.0098 step time: 0.1987\n",
      "3/8, train_loss: 0.0116 step time: 0.2009\n",
      "4/8, train_loss: 0.0095 step time: 0.2020\n",
      "5/8, train_loss: 0.0089 step time: 0.2034\n",
      "6/8, train_loss: 0.0108 step time: 0.2003\n",
      "7/8, train_loss: 0.0113 step time: 0.1834\n",
      "8/8, train_loss: 0.0117 step time: 0.1826\n",
      "epoch 149 average loss: 0.0103\n",
      "time consuming of epoch 149 is: 1.6137\n",
      "----------\n",
      "epoch 150/600\n",
      "1/8, train_loss: 0.0116 step time: 0.2356\n",
      "2/8, train_loss: 0.0103 step time: 0.1998\n",
      "3/8, train_loss: 0.0091 step time: 0.2008\n",
      "4/8, train_loss: 0.0106 step time: 0.2026\n",
      "5/8, train_loss: 0.0109 step time: 0.1996\n",
      "6/8, train_loss: 0.0096 step time: 0.2027\n",
      "7/8, train_loss: 0.0106 step time: 0.1827\n",
      "8/8, train_loss: 0.0111 step time: 0.1822\n",
      "epoch 150 average loss: 0.0105\n",
      "current epoch: 150 current mean dice: 0.9594 best mean dice: 0.9614 at epoch: 105\n",
      "time consuming of epoch 150 is: 2.3636\n",
      "----------\n",
      "epoch 151/600\n",
      "1/8, train_loss: 0.0101 step time: 0.2376\n",
      "2/8, train_loss: 0.0089 step time: 0.2020\n",
      "3/8, train_loss: 0.0104 step time: 0.1998\n",
      "4/8, train_loss: 0.0113 step time: 0.2007\n",
      "5/8, train_loss: 0.0110 step time: 0.2016\n",
      "6/8, train_loss: 0.0102 step time: 0.1989\n",
      "7/8, train_loss: 0.0102 step time: 0.1842\n",
      "8/8, train_loss: 0.0131 step time: 0.1835\n",
      "epoch 151 average loss: 0.0107\n",
      "time consuming of epoch 151 is: 1.6095\n",
      "----------\n",
      "epoch 152/600\n",
      "1/8, train_loss: 0.0097 step time: 0.2409\n",
      "2/8, train_loss: 0.0114 step time: 0.2037\n",
      "3/8, train_loss: 0.0100 step time: 0.2018\n",
      "4/8, train_loss: 0.0118 step time: 0.1995\n",
      "5/8, train_loss: 0.0103 step time: 0.2024\n",
      "6/8, train_loss: 0.0076 step time: 0.1995\n",
      "7/8, train_loss: 0.0113 step time: 0.1836\n",
      "8/8, train_loss: 0.0097 step time: 0.1829\n",
      "epoch 152 average loss: 0.0102\n",
      "time consuming of epoch 152 is: 1.6159\n",
      "----------\n",
      "epoch 153/600\n",
      "1/8, train_loss: 0.0087 step time: 0.2437\n",
      "2/8, train_loss: 0.0094 step time: 0.2046\n",
      "3/8, train_loss: 0.0095 step time: 0.2022\n",
      "4/8, train_loss: 0.0101 step time: 0.2015\n",
      "5/8, train_loss: 0.0111 step time: 0.1982\n",
      "6/8, train_loss: 0.0093 step time: 0.1998\n",
      "7/8, train_loss: 0.0097 step time: 0.1827\n",
      "8/8, train_loss: 0.0112 step time: 0.1814\n",
      "epoch 153 average loss: 0.0099\n",
      "time consuming of epoch 153 is: 1.6154\n",
      "----------\n",
      "epoch 154/600\n",
      "1/8, train_loss: 0.0108 step time: 0.2376\n",
      "2/8, train_loss: 0.0085 step time: 0.2031\n",
      "3/8, train_loss: 0.0111 step time: 0.1998\n",
      "4/8, train_loss: 0.0122 step time: 0.2015\n",
      "5/8, train_loss: 0.0085 step time: 0.2014\n",
      "6/8, train_loss: 0.0108 step time: 0.2017\n",
      "7/8, train_loss: 0.0100 step time: 0.1823\n",
      "8/8, train_loss: 0.0114 step time: 0.1826\n",
      "epoch 154 average loss: 0.0104\n",
      "time consuming of epoch 154 is: 1.6114\n",
      "----------\n",
      "epoch 155/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2423\n",
      "2/8, train_loss: 0.0097 step time: 0.2042\n",
      "3/8, train_loss: 0.0107 step time: 0.2031\n",
      "4/8, train_loss: 0.0088 step time: 0.2030\n",
      "5/8, train_loss: 0.0125 step time: 0.2001\n",
      "6/8, train_loss: 0.0103 step time: 0.2016\n",
      "7/8, train_loss: 0.0092 step time: 0.1821\n",
      "8/8, train_loss: 0.0088 step time: 0.1823\n",
      "epoch 155 average loss: 0.0100\n",
      "current epoch: 155 current mean dice: 0.9610 best mean dice: 0.9614 at epoch: 105\n",
      "time consuming of epoch 155 is: 2.3774\n",
      "----------\n",
      "epoch 156/600\n",
      "1/8, train_loss: 0.0094 step time: 0.2376\n",
      "2/8, train_loss: 0.0160 step time: 0.1985\n",
      "3/8, train_loss: 0.0100 step time: 0.2004\n",
      "4/8, train_loss: 0.0116 step time: 0.2001\n",
      "5/8, train_loss: 0.0091 step time: 0.1997\n",
      "6/8, train_loss: 0.0104 step time: 0.2014\n",
      "7/8, train_loss: 0.0097 step time: 0.1818\n",
      "8/8, train_loss: 0.0117 step time: 0.1825\n",
      "epoch 156 average loss: 0.0110\n",
      "time consuming of epoch 156 is: 1.6031\n",
      "----------\n",
      "epoch 157/600\n",
      "1/8, train_loss: 0.0109 step time: 0.2394\n",
      "2/8, train_loss: 0.0112 step time: 0.2032\n",
      "3/8, train_loss: 0.0102 step time: 0.2004\n",
      "4/8, train_loss: 0.0104 step time: 0.2003\n",
      "5/8, train_loss: 0.0103 step time: 0.1983\n",
      "6/8, train_loss: 0.0105 step time: 0.2019\n",
      "7/8, train_loss: 0.0102 step time: 0.1836\n",
      "8/8, train_loss: 0.0140 step time: 0.1828\n",
      "epoch 157 average loss: 0.0109\n",
      "time consuming of epoch 157 is: 1.6111\n",
      "----------\n",
      "epoch 158/600\n",
      "1/8, train_loss: 0.0124 step time: 0.2426\n",
      "2/8, train_loss: 0.0116 step time: 0.2004\n",
      "3/8, train_loss: 0.0094 step time: 0.2011\n",
      "4/8, train_loss: 0.0101 step time: 0.2034\n",
      "5/8, train_loss: 0.0093 step time: 0.2005\n",
      "6/8, train_loss: 0.0098 step time: 0.2025\n",
      "7/8, train_loss: 0.0107 step time: 0.1822\n",
      "8/8, train_loss: 0.0093 step time: 0.1828\n",
      "epoch 158 average loss: 0.0103\n",
      "time consuming of epoch 158 is: 1.6170\n",
      "----------\n",
      "epoch 159/600\n",
      "1/8, train_loss: 0.0086 step time: 0.2441\n",
      "2/8, train_loss: 0.0121 step time: 0.2068\n",
      "3/8, train_loss: 0.0085 step time: 0.1994\n",
      "4/8, train_loss: 0.0102 step time: 0.2010\n",
      "5/8, train_loss: 0.0086 step time: 0.2029\n",
      "6/8, train_loss: 0.0107 step time: 0.2011\n",
      "7/8, train_loss: 0.0104 step time: 0.1838\n",
      "8/8, train_loss: 0.0099 step time: 0.1845\n",
      "epoch 159 average loss: 0.0099\n",
      "time consuming of epoch 159 is: 1.6250\n",
      "----------\n",
      "epoch 160/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2410\n",
      "2/8, train_loss: 0.0110 step time: 0.2039\n",
      "3/8, train_loss: 0.0086 step time: 0.2026\n",
      "4/8, train_loss: 0.0112 step time: 0.2046\n",
      "5/8, train_loss: 0.0088 step time: 0.1995\n",
      "6/8, train_loss: 0.0098 step time: 0.2002\n",
      "7/8, train_loss: 0.0121 step time: 0.1831\n",
      "8/8, train_loss: 0.0097 step time: 0.1842\n",
      "epoch 160 average loss: 0.0101\n",
      "saved new best metric model\n",
      "current epoch: 160 current mean dice: 0.9615 best mean dice: 0.9615 at epoch: 160\n",
      "time consuming of epoch 160 is: 2.5222\n",
      "----------\n",
      "epoch 161/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2393\n",
      "2/8, train_loss: 0.0089 step time: 0.1993\n",
      "3/8, train_loss: 0.0089 step time: 0.2017\n",
      "4/8, train_loss: 0.0105 step time: 0.2022\n",
      "5/8, train_loss: 0.0101 step time: 0.2026\n",
      "6/8, train_loss: 0.0083 step time: 0.2022\n",
      "7/8, train_loss: 0.0126 step time: 0.1816\n",
      "8/8, train_loss: 0.0106 step time: 0.1815\n",
      "epoch 161 average loss: 0.0100\n",
      "time consuming of epoch 161 is: 1.6117\n",
      "----------\n",
      "epoch 162/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2411\n",
      "2/8, train_loss: 0.0119 step time: 0.2024\n",
      "3/8, train_loss: 0.0116 step time: 0.2033\n",
      "4/8, train_loss: 0.0099 step time: 0.2044\n",
      "5/8, train_loss: 0.0091 step time: 0.2010\n",
      "6/8, train_loss: 0.0125 step time: 0.2040\n",
      "7/8, train_loss: 0.0103 step time: 0.1827\n",
      "8/8, train_loss: 0.0099 step time: 0.1827\n",
      "epoch 162 average loss: 0.0106\n",
      "time consuming of epoch 162 is: 1.6230\n",
      "----------\n",
      "epoch 163/600\n",
      "1/8, train_loss: 0.0106 step time: 0.2412\n",
      "2/8, train_loss: 0.0108 step time: 0.2076\n",
      "3/8, train_loss: 0.0086 step time: 0.2002\n",
      "4/8, train_loss: 0.0117 step time: 0.2044\n",
      "5/8, train_loss: 0.0083 step time: 0.2030\n",
      "6/8, train_loss: 0.0102 step time: 0.2000\n",
      "7/8, train_loss: 0.0104 step time: 0.1815\n",
      "8/8, train_loss: 0.0103 step time: 0.1831\n",
      "epoch 163 average loss: 0.0101\n",
      "time consuming of epoch 163 is: 1.6226\n",
      "----------\n",
      "epoch 164/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0141 step time: 0.2377\n",
      "2/8, train_loss: 0.0090 step time: 0.2046\n",
      "3/8, train_loss: 0.0095 step time: 0.2032\n",
      "4/8, train_loss: 0.0093 step time: 0.1997\n",
      "5/8, train_loss: 0.0092 step time: 0.2026\n",
      "6/8, train_loss: 0.0109 step time: 0.2022\n",
      "7/8, train_loss: 0.0086 step time: 0.1813\n",
      "8/8, train_loss: 0.0089 step time: 0.1832\n",
      "epoch 164 average loss: 0.0099\n",
      "time consuming of epoch 164 is: 1.6157\n",
      "----------\n",
      "epoch 165/600\n",
      "1/8, train_loss: 0.0090 step time: 0.2385\n",
      "2/8, train_loss: 0.0100 step time: 0.2027\n",
      "3/8, train_loss: 0.0104 step time: 0.1979\n",
      "4/8, train_loss: 0.0104 step time: 0.2041\n",
      "5/8, train_loss: 0.0105 step time: 0.1987\n",
      "6/8, train_loss: 0.0099 step time: 0.1998\n",
      "7/8, train_loss: 0.0107 step time: 0.1818\n",
      "8/8, train_loss: 0.0102 step time: 0.1820\n",
      "epoch 165 average loss: 0.0101\n",
      "saved new best metric model\n",
      "current epoch: 165 current mean dice: 0.9615 best mean dice: 0.9615 at epoch: 165\n",
      "time consuming of epoch 165 is: 2.5029\n",
      "----------\n",
      "epoch 166/600\n",
      "1/8, train_loss: 0.0089 step time: 0.2289\n",
      "2/8, train_loss: 0.0100 step time: 0.1958\n",
      "3/8, train_loss: 0.0104 step time: 0.1943\n",
      "4/8, train_loss: 0.0116 step time: 0.1939\n",
      "5/8, train_loss: 0.0148 step time: 0.1970\n",
      "6/8, train_loss: 0.0085 step time: 0.1943\n",
      "7/8, train_loss: 0.0083 step time: 0.1813\n",
      "8/8, train_loss: 0.0092 step time: 0.1812\n",
      "epoch 166 average loss: 0.0102\n",
      "time consuming of epoch 166 is: 1.5680\n",
      "----------\n",
      "epoch 167/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2391\n",
      "2/8, train_loss: 0.0100 step time: 0.1985\n",
      "3/8, train_loss: 0.0111 step time: 0.1997\n",
      "4/8, train_loss: 0.0099 step time: 0.1993\n",
      "5/8, train_loss: 0.0113 step time: 0.2030\n",
      "6/8, train_loss: 0.0094 step time: 0.1998\n",
      "7/8, train_loss: 0.0094 step time: 0.1846\n",
      "8/8, train_loss: 0.0112 step time: 0.1839\n",
      "epoch 167 average loss: 0.0102\n",
      "time consuming of epoch 167 is: 1.6092\n",
      "----------\n",
      "epoch 168/600\n",
      "1/8, train_loss: 0.0121 step time: 0.2394\n",
      "2/8, train_loss: 0.0096 step time: 0.2034\n",
      "3/8, train_loss: 0.0093 step time: 0.2007\n",
      "4/8, train_loss: 0.0089 step time: 0.1986\n",
      "5/8, train_loss: 0.0083 step time: 0.2047\n",
      "6/8, train_loss: 0.0100 step time: 0.2034\n",
      "7/8, train_loss: 0.0089 step time: 0.1821\n",
      "8/8, train_loss: 0.0108 step time: 0.1824\n",
      "epoch 168 average loss: 0.0097\n",
      "time consuming of epoch 168 is: 1.6162\n",
      "----------\n",
      "epoch 169/600\n",
      "1/8, train_loss: 0.0085 step time: 0.2394\n",
      "2/8, train_loss: 0.0082 step time: 0.1997\n",
      "3/8, train_loss: 0.0088 step time: 0.1999\n",
      "4/8, train_loss: 0.0094 step time: 0.2010\n",
      "5/8, train_loss: 0.0106 step time: 0.1968\n",
      "6/8, train_loss: 0.0088 step time: 0.2002\n",
      "7/8, train_loss: 0.0116 step time: 0.1825\n",
      "8/8, train_loss: 0.0123 step time: 0.1835\n",
      "epoch 169 average loss: 0.0098\n",
      "time consuming of epoch 169 is: 1.6046\n",
      "----------\n",
      "epoch 170/600\n",
      "1/8, train_loss: 0.0112 step time: 0.2390\n",
      "2/8, train_loss: 0.0088 step time: 0.1978\n",
      "3/8, train_loss: 0.0099 step time: 0.1967\n",
      "4/8, train_loss: 0.0091 step time: 0.1969\n",
      "5/8, train_loss: 0.0099 step time: 0.1974\n",
      "6/8, train_loss: 0.0088 step time: 0.1964\n",
      "7/8, train_loss: 0.0135 step time: 0.1791\n",
      "8/8, train_loss: 0.0111 step time: 0.1792\n",
      "epoch 170 average loss: 0.0103\n",
      "current epoch: 170 current mean dice: 0.9610 best mean dice: 0.9615 at epoch: 165\n",
      "time consuming of epoch 170 is: 2.3348\n",
      "----------\n",
      "epoch 171/600\n",
      "1/8, train_loss: 0.0097 step time: 0.2321\n",
      "2/8, train_loss: 0.0096 step time: 0.1920\n",
      "3/8, train_loss: 0.0094 step time: 0.1942\n",
      "4/8, train_loss: 0.0120 step time: 0.2045\n",
      "5/8, train_loss: 0.0089 step time: 0.1995\n",
      "6/8, train_loss: 0.0101 step time: 0.1992\n",
      "7/8, train_loss: 0.0112 step time: 0.1839\n",
      "8/8, train_loss: 0.0093 step time: 0.1831\n",
      "epoch 171 average loss: 0.0100\n",
      "time consuming of epoch 171 is: 1.5895\n",
      "----------\n",
      "epoch 172/600\n",
      "1/8, train_loss: 0.0134 step time: 0.2413\n",
      "2/8, train_loss: 0.0091 step time: 0.2023\n",
      "3/8, train_loss: 0.0116 step time: 0.2011\n",
      "4/8, train_loss: 0.0103 step time: 0.2061\n",
      "5/8, train_loss: 0.0096 step time: 0.2019\n",
      "6/8, train_loss: 0.0090 step time: 0.1999\n",
      "7/8, train_loss: 0.0086 step time: 0.1841\n",
      "8/8, train_loss: 0.0090 step time: 0.1819\n",
      "epoch 172 average loss: 0.0101\n",
      "time consuming of epoch 172 is: 1.6204\n",
      "----------\n",
      "epoch 173/600\n",
      "1/8, train_loss: 0.0103 step time: 0.2425\n",
      "2/8, train_loss: 0.0095 step time: 0.2063\n",
      "3/8, train_loss: 0.0131 step time: 0.2104\n",
      "4/8, train_loss: 0.0123 step time: 0.2092\n",
      "5/8, train_loss: 0.0094 step time: 0.2105\n",
      "6/8, train_loss: 0.0104 step time: 0.2107\n",
      "7/8, train_loss: 0.0076 step time: 0.1831\n",
      "8/8, train_loss: 0.0087 step time: 0.1818\n",
      "epoch 173 average loss: 0.0102\n",
      "time consuming of epoch 173 is: 1.6562\n",
      "----------\n",
      "epoch 174/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2398\n",
      "2/8, train_loss: 0.0108 step time: 0.2036\n",
      "3/8, train_loss: 0.0088 step time: 0.2012\n",
      "4/8, train_loss: 0.0091 step time: 0.2019\n",
      "5/8, train_loss: 0.0108 step time: 0.2021\n",
      "6/8, train_loss: 0.0105 step time: 0.2003\n",
      "7/8, train_loss: 0.0088 step time: 0.1834\n",
      "8/8, train_loss: 0.0112 step time: 0.1825\n",
      "epoch 174 average loss: 0.0100\n",
      "time consuming of epoch 174 is: 1.6164\n",
      "----------\n",
      "epoch 175/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2431\n",
      "2/8, train_loss: 0.0116 step time: 0.2038\n",
      "3/8, train_loss: 0.0094 step time: 0.2012\n",
      "4/8, train_loss: 0.0089 step time: 0.2012\n",
      "5/8, train_loss: 0.0096 step time: 0.2015\n",
      "6/8, train_loss: 0.0105 step time: 0.2022\n",
      "7/8, train_loss: 0.0091 step time: 0.1827\n",
      "8/8, train_loss: 0.0133 step time: 0.1820\n",
      "epoch 175 average loss: 0.0104\n",
      "current epoch: 175 current mean dice: 0.9612 best mean dice: 0.9615 at epoch: 165\n",
      "time consuming of epoch 175 is: 2.3771\n",
      "----------\n",
      "epoch 176/600\n",
      "1/8, train_loss: 0.0088 step time: 0.2391\n",
      "2/8, train_loss: 0.0101 step time: 0.2025\n",
      "3/8, train_loss: 0.0097 step time: 0.1982\n",
      "4/8, train_loss: 0.0120 step time: 0.2015\n",
      "5/8, train_loss: 0.0091 step time: 0.2055\n",
      "6/8, train_loss: 0.0097 step time: 0.2018\n",
      "7/8, train_loss: 0.0102 step time: 0.1824\n",
      "8/8, train_loss: 0.0089 step time: 0.1818\n",
      "epoch 176 average loss: 0.0098\n",
      "time consuming of epoch 176 is: 1.6141\n",
      "----------\n",
      "epoch 177/600\n",
      "1/8, train_loss: 0.0088 step time: 0.2418\n",
      "2/8, train_loss: 0.0094 step time: 0.2024\n",
      "3/8, train_loss: 0.0124 step time: 0.2000\n",
      "4/8, train_loss: 0.0117 step time: 0.1989\n",
      "5/8, train_loss: 0.0085 step time: 0.2001\n",
      "6/8, train_loss: 0.0098 step time: 0.1993\n",
      "7/8, train_loss: 0.0097 step time: 0.1822\n",
      "8/8, train_loss: 0.0119 step time: 0.1821\n",
      "epoch 177 average loss: 0.0103\n",
      "time consuming of epoch 177 is: 1.6083\n",
      "----------\n",
      "epoch 178/600\n",
      "1/8, train_loss: 0.0090 step time: 0.2351\n",
      "2/8, train_loss: 0.0096 step time: 0.1999\n",
      "3/8, train_loss: 0.0121 step time: 0.1994\n",
      "4/8, train_loss: 0.0098 step time: 0.1978\n",
      "5/8, train_loss: 0.0098 step time: 0.1996\n",
      "6/8, train_loss: 0.0103 step time: 0.2027\n",
      "7/8, train_loss: 0.0111 step time: 0.1821\n",
      "8/8, train_loss: 0.0103 step time: 0.1813\n",
      "epoch 178 average loss: 0.0103\n",
      "time consuming of epoch 178 is: 1.5995\n",
      "----------\n",
      "epoch 179/600\n",
      "1/8, train_loss: 0.0089 step time: 0.2415\n",
      "2/8, train_loss: 0.0093 step time: 0.2014\n",
      "3/8, train_loss: 0.0102 step time: 0.1998\n",
      "4/8, train_loss: 0.0105 step time: 0.2017\n",
      "5/8, train_loss: 0.0088 step time: 0.2004\n",
      "6/8, train_loss: 0.0114 step time: 0.2003\n",
      "7/8, train_loss: 0.0095 step time: 0.1836\n",
      "8/8, train_loss: 0.0117 step time: 0.1837\n",
      "epoch 179 average loss: 0.0100\n",
      "time consuming of epoch 179 is: 1.6138\n",
      "----------\n",
      "epoch 180/600\n",
      "1/8, train_loss: 0.0097 step time: 0.2383\n",
      "2/8, train_loss: 0.0105 step time: 0.2010\n",
      "3/8, train_loss: 0.0093 step time: 0.1999\n",
      "4/8, train_loss: 0.0103 step time: 0.2011\n",
      "5/8, train_loss: 0.0096 step time: 0.1980\n",
      "6/8, train_loss: 0.0121 step time: 0.2014\n",
      "7/8, train_loss: 0.0111 step time: 0.1827\n",
      "8/8, train_loss: 0.0107 step time: 0.1824\n",
      "epoch 180 average loss: 0.0104\n",
      "current epoch: 180 current mean dice: 0.9608 best mean dice: 0.9615 at epoch: 165\n",
      "time consuming of epoch 180 is: 2.3615\n",
      "----------\n",
      "epoch 181/600\n",
      "1/8, train_loss: 0.0109 step time: 0.2328\n",
      "2/8, train_loss: 0.0093 step time: 0.1967\n",
      "3/8, train_loss: 0.0094 step time: 0.1927\n",
      "4/8, train_loss: 0.0121 step time: 0.1928\n",
      "5/8, train_loss: 0.0082 step time: 0.1938\n",
      "6/8, train_loss: 0.0089 step time: 0.1962\n",
      "7/8, train_loss: 0.0101 step time: 0.1819\n",
      "8/8, train_loss: 0.0112 step time: 0.1810\n",
      "epoch 181 average loss: 0.0100\n",
      "time consuming of epoch 181 is: 1.5690\n",
      "----------\n",
      "epoch 182/600\n",
      "1/8, train_loss: 0.0125 step time: 0.2298\n",
      "2/8, train_loss: 0.0092 step time: 0.1963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8, train_loss: 0.0101 step time: 0.2009\n",
      "4/8, train_loss: 0.0094 step time: 0.1969\n",
      "5/8, train_loss: 0.0097 step time: 0.1969\n",
      "6/8, train_loss: 0.0103 step time: 0.1990\n",
      "7/8, train_loss: 0.0103 step time: 0.1843\n",
      "8/8, train_loss: 0.0090 step time: 0.1825\n",
      "epoch 182 average loss: 0.0101\n",
      "time consuming of epoch 182 is: 1.5881\n",
      "----------\n",
      "epoch 183/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2394\n",
      "2/8, train_loss: 0.0097 step time: 0.2025\n",
      "3/8, train_loss: 0.0083 step time: 0.1995\n",
      "4/8, train_loss: 0.0112 step time: 0.2011\n",
      "5/8, train_loss: 0.0123 step time: 0.2002\n",
      "6/8, train_loss: 0.0095 step time: 0.2013\n",
      "7/8, train_loss: 0.0096 step time: 0.1846\n",
      "8/8, train_loss: 0.0105 step time: 0.1815\n",
      "epoch 183 average loss: 0.0102\n",
      "time consuming of epoch 183 is: 1.6116\n",
      "----------\n",
      "epoch 184/600\n",
      "1/8, train_loss: 0.0122 step time: 0.2401\n",
      "2/8, train_loss: 0.0092 step time: 0.1998\n",
      "3/8, train_loss: 0.0087 step time: 0.1967\n",
      "4/8, train_loss: 0.0093 step time: 0.2036\n",
      "5/8, train_loss: 0.0083 step time: 0.1992\n",
      "6/8, train_loss: 0.0098 step time: 0.1967\n",
      "7/8, train_loss: 0.0101 step time: 0.1842\n",
      "8/8, train_loss: 0.0101 step time: 0.1830\n",
      "epoch 184 average loss: 0.0097\n",
      "time consuming of epoch 184 is: 1.6053\n",
      "----------\n",
      "epoch 185/600\n",
      "1/8, train_loss: 0.0100 step time: 0.2401\n",
      "2/8, train_loss: 0.0097 step time: 0.2000\n",
      "3/8, train_loss: 0.0122 step time: 0.1996\n",
      "4/8, train_loss: 0.0108 step time: 0.2044\n",
      "5/8, train_loss: 0.0099 step time: 0.2014\n",
      "6/8, train_loss: 0.0085 step time: 0.1979\n",
      "7/8, train_loss: 0.0095 step time: 0.1825\n",
      "8/8, train_loss: 0.0102 step time: 0.1822\n",
      "epoch 185 average loss: 0.0101\n",
      "saved new best metric model\n",
      "current epoch: 185 current mean dice: 0.9618 best mean dice: 0.9618 at epoch: 185\n",
      "time consuming of epoch 185 is: 2.5084\n",
      "----------\n",
      "epoch 186/600\n",
      "1/8, train_loss: 0.0089 step time: 0.2389\n",
      "2/8, train_loss: 0.0079 step time: 0.1975\n",
      "3/8, train_loss: 0.0095 step time: 0.1991\n",
      "4/8, train_loss: 0.0112 step time: 0.2013\n",
      "5/8, train_loss: 0.0096 step time: 0.2020\n",
      "6/8, train_loss: 0.0082 step time: 0.1985\n",
      "7/8, train_loss: 0.0095 step time: 0.1813\n",
      "8/8, train_loss: 0.0109 step time: 0.1815\n",
      "epoch 186 average loss: 0.0095\n",
      "time consuming of epoch 186 is: 1.6013\n",
      "----------\n",
      "epoch 187/600\n",
      "1/8, train_loss: 0.0095 step time: 0.2386\n",
      "2/8, train_loss: 0.0076 step time: 0.2005\n",
      "3/8, train_loss: 0.0109 step time: 0.2004\n",
      "4/8, train_loss: 0.0093 step time: 0.2026\n",
      "5/8, train_loss: 0.0093 step time: 0.2004\n",
      "6/8, train_loss: 0.0086 step time: 0.2027\n",
      "7/8, train_loss: 0.0113 step time: 0.1823\n",
      "8/8, train_loss: 0.0128 step time: 0.1826\n",
      "epoch 187 average loss: 0.0099\n",
      "time consuming of epoch 187 is: 1.6115\n",
      "----------\n",
      "epoch 188/600\n",
      "1/8, train_loss: 0.0103 step time: 0.2435\n",
      "2/8, train_loss: 0.0083 step time: 0.2010\n",
      "3/8, train_loss: 0.0095 step time: 0.2021\n",
      "4/8, train_loss: 0.0097 step time: 0.1986\n",
      "5/8, train_loss: 0.0084 step time: 0.2000\n",
      "6/8, train_loss: 0.0106 step time: 0.1997\n",
      "7/8, train_loss: 0.0125 step time: 0.1832\n",
      "8/8, train_loss: 0.0100 step time: 0.1827\n",
      "epoch 188 average loss: 0.0099\n",
      "time consuming of epoch 188 is: 1.6122\n",
      "----------\n",
      "epoch 189/600\n",
      "1/8, train_loss: 0.0090 step time: 0.2402\n",
      "2/8, train_loss: 0.0103 step time: 0.2012\n",
      "3/8, train_loss: 0.0125 step time: 0.1989\n",
      "4/8, train_loss: 0.0092 step time: 0.2485\n",
      "5/8, train_loss: 0.0083 step time: 0.2037\n",
      "6/8, train_loss: 0.0128 step time: 0.2006\n",
      "7/8, train_loss: 0.0108 step time: 0.1827\n",
      "8/8, train_loss: 0.0108 step time: 0.1828\n",
      "epoch 189 average loss: 0.0105\n",
      "time consuming of epoch 189 is: 1.6602\n",
      "----------\n",
      "epoch 190/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2366\n",
      "2/8, train_loss: 0.0112 step time: 0.2016\n",
      "3/8, train_loss: 0.0112 step time: 0.1989\n",
      "4/8, train_loss: 0.0086 step time: 0.2025\n",
      "5/8, train_loss: 0.0092 step time: 0.2000\n",
      "6/8, train_loss: 0.0100 step time: 0.2001\n",
      "7/8, train_loss: 0.0094 step time: 0.1822\n",
      "8/8, train_loss: 0.0104 step time: 0.1822\n",
      "epoch 190 average loss: 0.0099\n",
      "current epoch: 190 current mean dice: 0.9612 best mean dice: 0.9618 at epoch: 185\n",
      "time consuming of epoch 190 is: 2.3613\n",
      "----------\n",
      "epoch 191/600\n",
      "1/8, train_loss: 0.0090 step time: 0.2405\n",
      "2/8, train_loss: 0.0106 step time: 0.2032\n",
      "3/8, train_loss: 0.0077 step time: 0.2057\n",
      "4/8, train_loss: 0.0076 step time: 0.1994\n",
      "5/8, train_loss: 0.0091 step time: 0.2034\n",
      "6/8, train_loss: 0.0110 step time: 0.2020\n",
      "7/8, train_loss: 0.0128 step time: 0.1826\n",
      "8/8, train_loss: 0.0117 step time: 0.1811\n",
      "epoch 191 average loss: 0.0099\n",
      "time consuming of epoch 191 is: 1.6191\n",
      "----------\n",
      "epoch 192/600\n",
      "1/8, train_loss: 0.0101 step time: 0.2410\n",
      "2/8, train_loss: 0.0080 step time: 0.2038\n",
      "3/8, train_loss: 0.0109 step time: 0.1991\n",
      "4/8, train_loss: 0.0093 step time: 0.2010\n",
      "5/8, train_loss: 0.0140 step time: 0.2026\n",
      "6/8, train_loss: 0.0095 step time: 0.2017\n",
      "7/8, train_loss: 0.0093 step time: 0.1844\n",
      "8/8, train_loss: 0.0099 step time: 0.1831\n",
      "epoch 192 average loss: 0.0101\n",
      "time consuming of epoch 192 is: 1.6180\n",
      "----------\n",
      "epoch 193/600\n",
      "1/8, train_loss: 0.0103 step time: 0.2401\n",
      "2/8, train_loss: 0.0113 step time: 0.2002\n",
      "3/8, train_loss: 0.0113 step time: 0.1961\n",
      "4/8, train_loss: 0.0112 step time: 0.1953\n",
      "5/8, train_loss: 0.0095 step time: 0.2000\n",
      "6/8, train_loss: 0.0081 step time: 0.1987\n",
      "7/8, train_loss: 0.0090 step time: 0.1823\n",
      "8/8, train_loss: 0.0105 step time: 0.1820\n",
      "epoch 193 average loss: 0.0102\n",
      "time consuming of epoch 193 is: 1.5961\n",
      "----------\n",
      "epoch 194/600\n",
      "1/8, train_loss: 0.0094 step time: 0.2429\n",
      "2/8, train_loss: 0.0093 step time: 0.2041\n",
      "3/8, train_loss: 0.0099 step time: 0.2021\n",
      "4/8, train_loss: 0.0116 step time: 0.2022\n",
      "5/8, train_loss: 0.0087 step time: 0.2017\n",
      "6/8, train_loss: 0.0087 step time: 0.2002\n",
      "7/8, train_loss: 0.0138 step time: 0.1850\n",
      "8/8, train_loss: 0.0112 step time: 0.1821\n",
      "epoch 194 average loss: 0.0103\n",
      "time consuming of epoch 194 is: 1.6216\n",
      "----------\n",
      "epoch 195/600\n",
      "1/8, train_loss: 0.0111 step time: 0.2411\n",
      "2/8, train_loss: 0.0091 step time: 0.2000\n",
      "3/8, train_loss: 0.0096 step time: 0.2012\n",
      "4/8, train_loss: 0.0103 step time: 0.1997\n",
      "5/8, train_loss: 0.0105 step time: 0.1978\n",
      "6/8, train_loss: 0.0104 step time: 0.1997\n",
      "7/8, train_loss: 0.0099 step time: 0.1857\n",
      "8/8, train_loss: 0.0089 step time: 0.1841\n",
      "epoch 195 average loss: 0.0100\n",
      "current epoch: 195 current mean dice: 0.9607 best mean dice: 0.9618 at epoch: 185\n",
      "time consuming of epoch 195 is: 2.3659\n",
      "----------\n",
      "epoch 196/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2401\n",
      "2/8, train_loss: 0.0093 step time: 0.1966\n",
      "3/8, train_loss: 0.0097 step time: 0.1953\n",
      "4/8, train_loss: 0.0134 step time: 0.1949\n",
      "5/8, train_loss: 0.0095 step time: 0.1945\n",
      "6/8, train_loss: 0.0101 step time: 0.1931\n",
      "7/8, train_loss: 0.0105 step time: 0.1831\n",
      "8/8, train_loss: 0.0081 step time: 0.1828\n",
      "epoch 196 average loss: 0.0100\n",
      "time consuming of epoch 196 is: 1.5814\n",
      "----------\n",
      "epoch 197/600\n",
      "1/8, train_loss: 0.0109 step time: 0.2394\n",
      "2/8, train_loss: 0.0097 step time: 0.1938\n",
      "3/8, train_loss: 0.0092 step time: 0.1972\n",
      "4/8, train_loss: 0.0127 step time: 0.1943\n",
      "5/8, train_loss: 0.0121 step time: 0.1981\n",
      "6/8, train_loss: 0.0098 step time: 0.1961\n",
      "7/8, train_loss: 0.0087 step time: 0.1821\n",
      "8/8, train_loss: 0.0089 step time: 0.1826\n",
      "epoch 197 average loss: 0.0102\n",
      "time consuming of epoch 197 is: 1.5850\n",
      "----------\n",
      "epoch 198/600\n",
      "1/8, train_loss: 0.0099 step time: 0.2394\n",
      "2/8, train_loss: 0.0105 step time: 0.2037\n",
      "3/8, train_loss: 0.0103 step time: 0.1990\n",
      "4/8, train_loss: 0.0089 step time: 0.2005\n",
      "5/8, train_loss: 0.0100 step time: 0.2018\n",
      "6/8, train_loss: 0.0107 step time: 0.1983\n",
      "7/8, train_loss: 0.0089 step time: 0.1821\n",
      "8/8, train_loss: 0.0127 step time: 0.1821\n",
      "epoch 198 average loss: 0.0102\n",
      "time consuming of epoch 198 is: 1.6086\n",
      "----------\n",
      "epoch 199/600\n",
      "1/8, train_loss: 0.0120 step time: 0.2393\n",
      "2/8, train_loss: 0.0119 step time: 0.2024\n",
      "3/8, train_loss: 0.0100 step time: 0.1992\n",
      "4/8, train_loss: 0.0099 step time: 0.1993\n",
      "5/8, train_loss: 0.0099 step time: 0.1996\n",
      "6/8, train_loss: 0.0114 step time: 0.2015\n",
      "7/8, train_loss: 0.0093 step time: 0.1831\n",
      "8/8, train_loss: 0.0097 step time: 0.1823\n",
      "epoch 199 average loss: 0.0105\n",
      "time consuming of epoch 199 is: 1.6083\n",
      "----------\n",
      "epoch 200/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2403\n",
      "2/8, train_loss: 0.0088 step time: 0.2029\n",
      "3/8, train_loss: 0.0104 step time: 0.1989\n",
      "4/8, train_loss: 0.0088 step time: 0.2008\n",
      "5/8, train_loss: 0.0088 step time: 0.2006\n",
      "6/8, train_loss: 0.0100 step time: 0.2013\n",
      "7/8, train_loss: 0.0131 step time: 0.1825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8, train_loss: 0.0112 step time: 0.1820\n",
      "epoch 200 average loss: 0.0100\n",
      "current epoch: 200 current mean dice: 0.9613 best mean dice: 0.9618 at epoch: 185\n",
      "time consuming of epoch 200 is: 2.3658\n",
      "----------\n",
      "epoch 201/600\n",
      "1/8, train_loss: 0.0096 step time: 0.2362\n",
      "2/8, train_loss: 0.0089 step time: 0.1973\n",
      "3/8, train_loss: 0.0101 step time: 0.2014\n",
      "4/8, train_loss: 0.0091 step time: 0.1979\n",
      "5/8, train_loss: 0.0124 step time: 0.1987\n",
      "6/8, train_loss: 0.0085 step time: 0.1992\n",
      "7/8, train_loss: 0.0100 step time: 0.1824\n",
      "8/8, train_loss: 0.0127 step time: 0.1809\n",
      "epoch 201 average loss: 0.0102\n",
      "time consuming of epoch 201 is: 1.5951\n",
      "----------\n",
      "epoch 202/600\n",
      "1/8, train_loss: 0.0090 step time: 0.2404\n",
      "2/8, train_loss: 0.0101 step time: 0.2055\n",
      "3/8, train_loss: 0.0090 step time: 0.2022\n",
      "4/8, train_loss: 0.0097 step time: 0.1996\n",
      "5/8, train_loss: 0.0113 step time: 0.2012\n",
      "6/8, train_loss: 0.0100 step time: 0.2019\n",
      "7/8, train_loss: 0.0106 step time: 0.1829\n",
      "8/8, train_loss: 0.0089 step time: 0.1827\n",
      "epoch 202 average loss: 0.0098\n",
      "time consuming of epoch 202 is: 1.6180\n",
      "----------\n",
      "epoch 203/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2396\n",
      "2/8, train_loss: 0.0121 step time: 0.2030\n",
      "3/8, train_loss: 0.0103 step time: 0.1973\n",
      "4/8, train_loss: 0.0085 step time: 0.2033\n",
      "5/8, train_loss: 0.0076 step time: 0.2015\n",
      "6/8, train_loss: 0.0099 step time: 0.1987\n",
      "7/8, train_loss: 0.0088 step time: 0.1825\n",
      "8/8, train_loss: 0.0123 step time: 0.1828\n",
      "epoch 203 average loss: 0.0099\n",
      "time consuming of epoch 203 is: 1.6105\n",
      "----------\n",
      "epoch 204/600\n",
      "1/8, train_loss: 0.0095 step time: 0.2402\n",
      "2/8, train_loss: 0.0087 step time: 0.2038\n",
      "3/8, train_loss: 0.0080 step time: 0.2026\n",
      "4/8, train_loss: 0.0088 step time: 0.2002\n",
      "5/8, train_loss: 0.0098 step time: 0.2021\n",
      "6/8, train_loss: 0.0107 step time: 0.2003\n",
      "7/8, train_loss: 0.0093 step time: 0.1844\n",
      "8/8, train_loss: 0.0108 step time: 0.1849\n",
      "epoch 204 average loss: 0.0095\n",
      "time consuming of epoch 204 is: 1.6199\n",
      "----------\n",
      "epoch 205/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2421\n",
      "2/8, train_loss: 0.0111 step time: 0.2056\n",
      "3/8, train_loss: 0.0115 step time: 0.2033\n",
      "4/8, train_loss: 0.0091 step time: 0.2000\n",
      "5/8, train_loss: 0.0094 step time: 0.2069\n",
      "6/8, train_loss: 0.0106 step time: 0.2057\n",
      "7/8, train_loss: 0.0116 step time: 0.1835\n",
      "8/8, train_loss: 0.0091 step time: 0.1826\n",
      "epoch 205 average loss: 0.0102\n",
      "saved new best metric model\n",
      "current epoch: 205 current mean dice: 0.9622 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 205 is: 2.5289\n",
      "----------\n",
      "epoch 206/600\n",
      "1/8, train_loss: 0.0074 step time: 0.2391\n",
      "2/8, train_loss: 0.0093 step time: 0.1995\n",
      "3/8, train_loss: 0.0093 step time: 0.1997\n",
      "4/8, train_loss: 0.0103 step time: 0.1984\n",
      "5/8, train_loss: 0.0110 step time: 0.2013\n",
      "6/8, train_loss: 0.0094 step time: 0.2013\n",
      "7/8, train_loss: 0.0097 step time: 0.1819\n",
      "8/8, train_loss: 0.0116 step time: 0.1812\n",
      "epoch 206 average loss: 0.0097\n",
      "time consuming of epoch 206 is: 1.6037\n",
      "----------\n",
      "epoch 207/600\n",
      "1/8, train_loss: 0.0084 step time: 0.2392\n",
      "2/8, train_loss: 0.0089 step time: 0.2001\n",
      "3/8, train_loss: 0.0102 step time: 0.2002\n",
      "4/8, train_loss: 0.0143 step time: 0.2017\n",
      "5/8, train_loss: 0.0087 step time: 0.2013\n",
      "6/8, train_loss: 0.0096 step time: 0.1992\n",
      "7/8, train_loss: 0.0101 step time: 0.1833\n",
      "8/8, train_loss: 0.0086 step time: 0.1835\n",
      "epoch 207 average loss: 0.0098\n",
      "time consuming of epoch 207 is: 1.6099\n",
      "----------\n",
      "epoch 208/600\n",
      "1/8, train_loss: 0.0077 step time: 0.2412\n",
      "2/8, train_loss: 0.0081 step time: 0.1999\n",
      "3/8, train_loss: 0.0119 step time: 0.2023\n",
      "4/8, train_loss: 0.0090 step time: 0.2041\n",
      "5/8, train_loss: 0.0094 step time: 0.1986\n",
      "6/8, train_loss: 0.0092 step time: 0.2003\n",
      "7/8, train_loss: 0.0097 step time: 0.1838\n",
      "8/8, train_loss: 0.0133 step time: 0.1827\n",
      "epoch 208 average loss: 0.0098\n",
      "time consuming of epoch 208 is: 1.6145\n",
      "----------\n",
      "epoch 209/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2408\n",
      "2/8, train_loss: 0.0100 step time: 0.1994\n",
      "3/8, train_loss: 0.0112 step time: 0.2009\n",
      "4/8, train_loss: 0.0088 step time: 0.2017\n",
      "5/8, train_loss: 0.0089 step time: 0.1988\n",
      "6/8, train_loss: 0.0121 step time: 0.2026\n",
      "7/8, train_loss: 0.0093 step time: 0.1825\n",
      "8/8, train_loss: 0.0092 step time: 0.1821\n",
      "epoch 209 average loss: 0.0100\n",
      "time consuming of epoch 209 is: 1.6103\n",
      "----------\n",
      "epoch 210/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2430\n",
      "2/8, train_loss: 0.0095 step time: 0.2034\n",
      "3/8, train_loss: 0.0095 step time: 0.1982\n",
      "4/8, train_loss: 0.0089 step time: 0.2028\n",
      "5/8, train_loss: 0.0099 step time: 0.2014\n",
      "6/8, train_loss: 0.0087 step time: 0.2017\n",
      "7/8, train_loss: 0.0107 step time: 0.1825\n",
      "8/8, train_loss: 0.0102 step time: 0.1833\n",
      "epoch 210 average loss: 0.0096\n",
      "current epoch: 210 current mean dice: 0.9606 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 210 is: 2.3756\n",
      "----------\n",
      "epoch 211/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2398\n",
      "2/8, train_loss: 0.0098 step time: 0.1993\n",
      "3/8, train_loss: 0.0116 step time: 0.1997\n",
      "4/8, train_loss: 0.0095 step time: 0.2027\n",
      "5/8, train_loss: 0.0093 step time: 0.1981\n",
      "6/8, train_loss: 0.0087 step time: 0.2006\n",
      "7/8, train_loss: 0.0105 step time: 0.1813\n",
      "8/8, train_loss: 0.0089 step time: 0.1811\n",
      "epoch 211 average loss: 0.0102\n",
      "time consuming of epoch 211 is: 1.6036\n",
      "----------\n",
      "epoch 212/600\n",
      "1/8, train_loss: 0.0087 step time: 0.2390\n",
      "2/8, train_loss: 0.0095 step time: 0.1998\n",
      "3/8, train_loss: 0.0106 step time: 0.2025\n",
      "4/8, train_loss: 0.0099 step time: 0.2024\n",
      "5/8, train_loss: 0.0091 step time: 0.1995\n",
      "6/8, train_loss: 0.0126 step time: 0.1994\n",
      "7/8, train_loss: 0.0081 step time: 0.1838\n",
      "8/8, train_loss: 0.0097 step time: 0.1828\n",
      "epoch 212 average loss: 0.0098\n",
      "time consuming of epoch 212 is: 1.6102\n",
      "----------\n",
      "epoch 213/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2391\n",
      "2/8, train_loss: 0.0085 step time: 0.1965\n",
      "3/8, train_loss: 0.0102 step time: 0.1983\n",
      "4/8, train_loss: 0.0099 step time: 0.1964\n",
      "5/8, train_loss: 0.0089 step time: 0.1969\n",
      "6/8, train_loss: 0.0158 step time: 0.1963\n",
      "7/8, train_loss: 0.0092 step time: 0.1824\n",
      "8/8, train_loss: 0.0110 step time: 0.1823\n",
      "epoch 213 average loss: 0.0104\n",
      "time consuming of epoch 213 is: 1.5897\n",
      "----------\n",
      "epoch 214/600\n",
      "1/8, train_loss: 0.0084 step time: 0.2331\n",
      "2/8, train_loss: 0.0104 step time: 0.1982\n",
      "3/8, train_loss: 0.0092 step time: 0.1966\n",
      "4/8, train_loss: 0.0100 step time: 0.2001\n",
      "5/8, train_loss: 0.0091 step time: 0.1980\n",
      "6/8, train_loss: 0.0136 step time: 0.2013\n",
      "7/8, train_loss: 0.0110 step time: 0.1842\n",
      "8/8, train_loss: 0.0080 step time: 0.1844\n",
      "epoch 214 average loss: 0.0100\n",
      "time consuming of epoch 214 is: 1.5976\n",
      "----------\n",
      "epoch 215/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2382\n",
      "2/8, train_loss: 0.0106 step time: 0.2013\n",
      "3/8, train_loss: 0.0098 step time: 0.1983\n",
      "4/8, train_loss: 0.0099 step time: 0.2018\n",
      "5/8, train_loss: 0.0099 step time: 0.1967\n",
      "6/8, train_loss: 0.0097 step time: 0.2002\n",
      "7/8, train_loss: 0.0094 step time: 0.1823\n",
      "8/8, train_loss: 0.0099 step time: 0.1812\n",
      "epoch 215 average loss: 0.0100\n",
      "current epoch: 215 current mean dice: 0.9608 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 215 is: 2.3543\n",
      "----------\n",
      "epoch 216/600\n",
      "1/8, train_loss: 0.0083 step time: 0.2277\n",
      "2/8, train_loss: 0.0110 step time: 0.1964\n",
      "3/8, train_loss: 0.0094 step time: 0.1969\n",
      "4/8, train_loss: 0.0109 step time: 0.1990\n",
      "5/8, train_loss: 0.0117 step time: 0.1999\n",
      "6/8, train_loss: 0.0156 step time: 0.1980\n",
      "7/8, train_loss: 0.0098 step time: 0.1815\n",
      "8/8, train_loss: 0.0103 step time: 0.1813\n",
      "epoch 216 average loss: 0.0109\n",
      "time consuming of epoch 216 is: 1.5819\n",
      "----------\n",
      "epoch 217/600\n",
      "1/8, train_loss: 0.0089 step time: 0.2398\n",
      "2/8, train_loss: 0.0085 step time: 0.2020\n",
      "3/8, train_loss: 0.0123 step time: 0.1995\n",
      "4/8, train_loss: 0.0099 step time: 0.2004\n",
      "5/8, train_loss: 0.0105 step time: 0.2001\n",
      "6/8, train_loss: 0.0118 step time: 0.1997\n",
      "7/8, train_loss: 0.0086 step time: 0.1824\n",
      "8/8, train_loss: 0.0117 step time: 0.1822\n",
      "epoch 217 average loss: 0.0103\n",
      "time consuming of epoch 217 is: 1.6077\n",
      "----------\n",
      "epoch 218/600\n",
      "1/8, train_loss: 0.0106 step time: 0.2351\n",
      "2/8, train_loss: 0.0106 step time: 0.1995\n",
      "3/8, train_loss: 0.0099 step time: 0.1970\n",
      "4/8, train_loss: 0.0100 step time: 0.1964\n",
      "5/8, train_loss: 0.0105 step time: 0.2001\n",
      "6/8, train_loss: 0.0096 step time: 0.1955\n",
      "7/8, train_loss: 0.0109 step time: 0.1826\n",
      "8/8, train_loss: 0.0131 step time: 0.1824\n",
      "epoch 218 average loss: 0.0107\n",
      "time consuming of epoch 218 is: 1.5901\n",
      "----------\n",
      "epoch 219/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0099 step time: 0.2266\n",
      "2/8, train_loss: 0.0104 step time: 0.2004\n",
      "3/8, train_loss: 0.0082 step time: 0.1988\n",
      "4/8, train_loss: 0.0116 step time: 0.2031\n",
      "5/8, train_loss: 0.0124 step time: 0.2024\n",
      "6/8, train_loss: 0.0093 step time: 0.1992\n",
      "7/8, train_loss: 0.0090 step time: 0.1824\n",
      "8/8, train_loss: 0.0123 step time: 0.1823\n",
      "epoch 219 average loss: 0.0104\n",
      "time consuming of epoch 219 is: 1.5968\n",
      "----------\n",
      "epoch 220/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2405\n",
      "2/8, train_loss: 0.0114 step time: 0.2040\n",
      "3/8, train_loss: 0.0105 step time: 0.1993\n",
      "4/8, train_loss: 0.0093 step time: 0.2009\n",
      "5/8, train_loss: 0.0095 step time: 0.2003\n",
      "6/8, train_loss: 0.0094 step time: 0.2001\n",
      "7/8, train_loss: 0.0108 step time: 0.1832\n",
      "8/8, train_loss: 0.0092 step time: 0.1837\n",
      "epoch 220 average loss: 0.0100\n",
      "current epoch: 220 current mean dice: 0.9602 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 220 is: 2.3698\n",
      "----------\n",
      "epoch 221/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2400\n",
      "2/8, train_loss: 0.0105 step time: 0.1995\n",
      "3/8, train_loss: 0.0112 step time: 0.1984\n",
      "4/8, train_loss: 0.0091 step time: 0.1990\n",
      "5/8, train_loss: 0.0076 step time: 0.2004\n",
      "6/8, train_loss: 0.0097 step time: 0.1993\n",
      "7/8, train_loss: 0.0103 step time: 0.1832\n",
      "8/8, train_loss: 0.0103 step time: 0.1834\n",
      "epoch 221 average loss: 0.0099\n",
      "time consuming of epoch 221 is: 1.6044\n",
      "----------\n",
      "epoch 222/600\n",
      "1/8, train_loss: 0.0087 step time: 0.2399\n",
      "2/8, train_loss: 0.0118 step time: 0.2036\n",
      "3/8, train_loss: 0.0088 step time: 0.2016\n",
      "4/8, train_loss: 0.0081 step time: 0.2000\n",
      "5/8, train_loss: 0.0104 step time: 0.1995\n",
      "6/8, train_loss: 0.0138 step time: 0.2018\n",
      "7/8, train_loss: 0.0090 step time: 0.1835\n",
      "8/8, train_loss: 0.0102 step time: 0.1837\n",
      "epoch 222 average loss: 0.0101\n",
      "time consuming of epoch 222 is: 1.6149\n",
      "----------\n",
      "epoch 223/600\n",
      "1/8, train_loss: 0.0114 step time: 0.2392\n",
      "2/8, train_loss: 0.0085 step time: 0.2026\n",
      "3/8, train_loss: 0.0116 step time: 0.2023\n",
      "4/8, train_loss: 0.0097 step time: 0.2010\n",
      "5/8, train_loss: 0.0105 step time: 0.1994\n",
      "6/8, train_loss: 0.0102 step time: 0.2013\n",
      "7/8, train_loss: 0.0100 step time: 0.1828\n",
      "8/8, train_loss: 0.0093 step time: 0.1826\n",
      "epoch 223 average loss: 0.0101\n",
      "time consuming of epoch 223 is: 1.6126\n",
      "----------\n",
      "epoch 224/600\n",
      "1/8, train_loss: 0.0100 step time: 0.2413\n",
      "2/8, train_loss: 0.0120 step time: 0.2043\n",
      "3/8, train_loss: 0.0105 step time: 0.2003\n",
      "4/8, train_loss: 0.0102 step time: 0.2005\n",
      "5/8, train_loss: 0.0093 step time: 0.2028\n",
      "6/8, train_loss: 0.0094 step time: 0.2009\n",
      "7/8, train_loss: 0.0094 step time: 0.1833\n",
      "8/8, train_loss: 0.0111 step time: 0.1826\n",
      "epoch 224 average loss: 0.0102\n",
      "time consuming of epoch 224 is: 1.6179\n",
      "----------\n",
      "epoch 225/600\n",
      "1/8, train_loss: 0.0103 step time: 0.2405\n",
      "2/8, train_loss: 0.0084 step time: 0.2039\n",
      "3/8, train_loss: 0.0101 step time: 0.1994\n",
      "4/8, train_loss: 0.0093 step time: 0.2009\n",
      "5/8, train_loss: 0.0106 step time: 0.2017\n",
      "6/8, train_loss: 0.0087 step time: 0.2001\n",
      "7/8, train_loss: 0.0144 step time: 0.1828\n",
      "8/8, train_loss: 0.0109 step time: 0.1880\n",
      "epoch 225 average loss: 0.0103\n",
      "current epoch: 225 current mean dice: 0.9596 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 225 is: 2.3754\n",
      "----------\n",
      "epoch 226/600\n",
      "1/8, train_loss: 0.0099 step time: 0.2331\n",
      "2/8, train_loss: 0.0135 step time: 0.1999\n",
      "3/8, train_loss: 0.0099 step time: 0.1994\n",
      "4/8, train_loss: 0.0094 step time: 0.2005\n",
      "5/8, train_loss: 0.0116 step time: 0.1991\n",
      "6/8, train_loss: 0.0097 step time: 0.1966\n",
      "7/8, train_loss: 0.0103 step time: 0.1819\n",
      "8/8, train_loss: 0.0089 step time: 0.1820\n",
      "epoch 226 average loss: 0.0104\n",
      "time consuming of epoch 226 is: 1.5935\n",
      "----------\n",
      "epoch 227/600\n",
      "1/8, train_loss: 0.0096 step time: 0.2424\n",
      "2/8, train_loss: 0.0076 step time: 0.2024\n",
      "3/8, train_loss: 0.0115 step time: 0.1987\n",
      "4/8, train_loss: 0.0085 step time: 0.2016\n",
      "5/8, train_loss: 0.0104 step time: 0.1991\n",
      "6/8, train_loss: 0.0124 step time: 0.2016\n",
      "7/8, train_loss: 0.0097 step time: 0.1824\n",
      "8/8, train_loss: 0.0099 step time: 0.1823\n",
      "epoch 227 average loss: 0.0099\n",
      "time consuming of epoch 227 is: 1.6119\n",
      "----------\n",
      "epoch 228/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2377\n",
      "2/8, train_loss: 0.0112 step time: 0.2021\n",
      "3/8, train_loss: 0.0102 step time: 0.2015\n",
      "4/8, train_loss: 0.0099 step time: 0.1995\n",
      "5/8, train_loss: 0.0095 step time: 0.2030\n",
      "6/8, train_loss: 0.0093 step time: 0.2003\n",
      "7/8, train_loss: 0.0083 step time: 0.1836\n",
      "8/8, train_loss: 0.0095 step time: 0.1823\n",
      "epoch 228 average loss: 0.0097\n",
      "time consuming of epoch 228 is: 1.6116\n",
      "----------\n",
      "epoch 229/600\n",
      "1/8, train_loss: 0.0108 step time: 0.2392\n",
      "2/8, train_loss: 0.0117 step time: 0.2021\n",
      "3/8, train_loss: 0.0078 step time: 0.1996\n",
      "4/8, train_loss: 0.0085 step time: 0.1983\n",
      "5/8, train_loss: 0.0095 step time: 0.1989\n",
      "6/8, train_loss: 0.0106 step time: 0.1988\n",
      "7/8, train_loss: 0.0114 step time: 0.1812\n",
      "8/8, train_loss: 0.0125 step time: 0.1821\n",
      "epoch 229 average loss: 0.0103\n",
      "time consuming of epoch 229 is: 1.6017\n",
      "----------\n",
      "epoch 230/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2412\n",
      "2/8, train_loss: 0.0127 step time: 0.1990\n",
      "3/8, train_loss: 0.0084 step time: 0.2007\n",
      "4/8, train_loss: 0.0106 step time: 0.1978\n",
      "5/8, train_loss: 0.0127 step time: 0.2006\n",
      "6/8, train_loss: 0.0090 step time: 0.1995\n",
      "7/8, train_loss: 0.0118 step time: 0.1825\n",
      "8/8, train_loss: 0.0093 step time: 0.1824\n",
      "epoch 230 average loss: 0.0105\n",
      "current epoch: 230 current mean dice: 0.9616 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 230 is: 2.3609\n",
      "----------\n",
      "epoch 231/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2277\n",
      "2/8, train_loss: 0.0136 step time: 0.1919\n",
      "3/8, train_loss: 0.0109 step time: 0.1910\n",
      "4/8, train_loss: 0.0091 step time: 0.1921\n",
      "5/8, train_loss: 0.0092 step time: 0.1915\n",
      "6/8, train_loss: 0.0102 step time: 0.1901\n",
      "7/8, train_loss: 0.0101 step time: 0.1811\n",
      "8/8, train_loss: 0.0083 step time: 0.1810\n",
      "epoch 231 average loss: 0.0101\n",
      "time consuming of epoch 231 is: 1.5474\n",
      "----------\n",
      "epoch 232/600\n",
      "1/8, train_loss: 0.0123 step time: 0.2394\n",
      "2/8, train_loss: 0.0117 step time: 0.2000\n",
      "3/8, train_loss: 0.0091 step time: 0.1986\n",
      "4/8, train_loss: 0.0086 step time: 0.2013\n",
      "5/8, train_loss: 0.0127 step time: 0.1995\n",
      "6/8, train_loss: 0.0108 step time: 0.2013\n",
      "7/8, train_loss: 0.0105 step time: 0.1820\n",
      "8/8, train_loss: 0.0126 step time: 0.1833\n",
      "epoch 232 average loss: 0.0110\n",
      "time consuming of epoch 232 is: 1.6070\n",
      "----------\n",
      "epoch 233/600\n",
      "1/8, train_loss: 0.0099 step time: 0.2420\n",
      "2/8, train_loss: 0.0107 step time: 0.2063\n",
      "3/8, train_loss: 0.0118 step time: 0.2023\n",
      "4/8, train_loss: 0.0114 step time: 0.2001\n",
      "5/8, train_loss: 0.0125 step time: 0.1993\n",
      "6/8, train_loss: 0.0116 step time: 0.2001\n",
      "7/8, train_loss: 0.0088 step time: 0.1820\n",
      "8/8, train_loss: 0.0113 step time: 0.1828\n",
      "epoch 233 average loss: 0.0110\n",
      "time consuming of epoch 233 is: 1.6163\n",
      "----------\n",
      "epoch 234/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2383\n",
      "2/8, train_loss: 0.0101 step time: 0.2020\n",
      "3/8, train_loss: 0.0101 step time: 0.1991\n",
      "4/8, train_loss: 0.0079 step time: 0.2017\n",
      "5/8, train_loss: 0.0129 step time: 0.2002\n",
      "6/8, train_loss: 0.0102 step time: 0.2008\n",
      "7/8, train_loss: 0.0131 step time: 0.1827\n",
      "8/8, train_loss: 0.0093 step time: 0.1835\n",
      "epoch 234 average loss: 0.0107\n",
      "time consuming of epoch 234 is: 1.6101\n",
      "----------\n",
      "epoch 235/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2412\n",
      "2/8, train_loss: 0.0106 step time: 0.2038\n",
      "3/8, train_loss: 0.0095 step time: 0.2023\n",
      "4/8, train_loss: 0.0089 step time: 0.1989\n",
      "5/8, train_loss: 0.0098 step time: 0.1999\n",
      "6/8, train_loss: 0.0094 step time: 0.2003\n",
      "7/8, train_loss: 0.0130 step time: 0.1836\n",
      "8/8, train_loss: 0.0133 step time: 0.1820\n",
      "epoch 235 average loss: 0.0105\n",
      "current epoch: 235 current mean dice: 0.9599 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 235 is: 2.3689\n",
      "----------\n",
      "epoch 236/600\n",
      "1/8, train_loss: 0.0113 step time: 0.2269\n",
      "2/8, train_loss: 0.0085 step time: 0.1978\n",
      "3/8, train_loss: 0.0131 step time: 0.1938\n",
      "4/8, train_loss: 0.0087 step time: 0.1942\n",
      "5/8, train_loss: 0.0099 step time: 0.1955\n",
      "6/8, train_loss: 0.0095 step time: 0.1944\n",
      "7/8, train_loss: 0.0107 step time: 0.1810\n",
      "8/8, train_loss: 0.0097 step time: 0.1824\n",
      "epoch 236 average loss: 0.0102\n",
      "time consuming of epoch 236 is: 1.5670\n",
      "----------\n",
      "epoch 237/600\n",
      "1/8, train_loss: 0.0095 step time: 0.2319\n",
      "2/8, train_loss: 0.0113 step time: 0.1970\n",
      "3/8, train_loss: 0.0113 step time: 0.1983\n",
      "4/8, train_loss: 0.0085 step time: 0.1988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8, train_loss: 0.0104 step time: 0.2022\n",
      "6/8, train_loss: 0.0100 step time: 0.1993\n",
      "7/8, train_loss: 0.0088 step time: 0.1811\n",
      "8/8, train_loss: 0.0103 step time: 0.1815\n",
      "epoch 237 average loss: 0.0100\n",
      "time consuming of epoch 237 is: 1.5917\n",
      "----------\n",
      "epoch 238/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2393\n",
      "2/8, train_loss: 0.0121 step time: 0.1999\n",
      "3/8, train_loss: 0.0098 step time: 0.1992\n",
      "4/8, train_loss: 0.0113 step time: 0.2017\n",
      "5/8, train_loss: 0.0088 step time: 0.2001\n",
      "6/8, train_loss: 0.0083 step time: 0.2028\n",
      "7/8, train_loss: 0.0101 step time: 0.1828\n",
      "8/8, train_loss: 0.0088 step time: 0.1825\n",
      "epoch 238 average loss: 0.0098\n",
      "time consuming of epoch 238 is: 1.6098\n",
      "----------\n",
      "epoch 239/600\n",
      "1/8, train_loss: 0.0112 step time: 0.2414\n",
      "2/8, train_loss: 0.0087 step time: 0.2025\n",
      "3/8, train_loss: 0.0092 step time: 0.2037\n",
      "4/8, train_loss: 0.0108 step time: 0.2014\n",
      "5/8, train_loss: 0.0098 step time: 0.2019\n",
      "6/8, train_loss: 0.0096 step time: 0.1989\n",
      "7/8, train_loss: 0.0092 step time: 0.1835\n",
      "8/8, train_loss: 0.0089 step time: 0.1822\n",
      "epoch 239 average loss: 0.0097\n",
      "time consuming of epoch 239 is: 1.6169\n",
      "----------\n",
      "epoch 240/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2398\n",
      "2/8, train_loss: 0.0096 step time: 0.2042\n",
      "3/8, train_loss: 0.0087 step time: 0.2015\n",
      "4/8, train_loss: 0.0116 step time: 0.2023\n",
      "5/8, train_loss: 0.0093 step time: 0.1989\n",
      "6/8, train_loss: 0.0118 step time: 0.2019\n",
      "7/8, train_loss: 0.0119 step time: 0.1830\n",
      "8/8, train_loss: 0.0083 step time: 0.1829\n",
      "epoch 240 average loss: 0.0101\n",
      "current epoch: 240 current mean dice: 0.9606 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 240 is: 2.3736\n",
      "----------\n",
      "epoch 241/600\n",
      "1/8, train_loss: 0.0095 step time: 0.2281\n",
      "2/8, train_loss: 0.0086 step time: 0.2016\n",
      "3/8, train_loss: 0.0084 step time: 0.1948\n",
      "4/8, train_loss: 0.0104 step time: 0.1955\n",
      "5/8, train_loss: 0.0131 step time: 0.1958\n",
      "6/8, train_loss: 0.0079 step time: 0.2024\n",
      "7/8, train_loss: 0.0094 step time: 0.1820\n",
      "8/8, train_loss: 0.0109 step time: 0.1815\n",
      "epoch 241 average loss: 0.0098\n",
      "time consuming of epoch 241 is: 1.5828\n",
      "----------\n",
      "epoch 242/600\n",
      "1/8, train_loss: 0.0108 step time: 0.2329\n",
      "2/8, train_loss: 0.0118 step time: 0.1993\n",
      "3/8, train_loss: 0.0088 step time: 0.1996\n",
      "4/8, train_loss: 0.0104 step time: 0.1968\n",
      "5/8, train_loss: 0.0099 step time: 0.1962\n",
      "6/8, train_loss: 0.0096 step time: 0.1965\n",
      "7/8, train_loss: 0.0112 step time: 0.1830\n",
      "8/8, train_loss: 0.0104 step time: 0.1833\n",
      "epoch 242 average loss: 0.0104\n",
      "time consuming of epoch 242 is: 1.5890\n",
      "----------\n",
      "epoch 243/600\n",
      "1/8, train_loss: 0.0106 step time: 0.2449\n",
      "2/8, train_loss: 0.0097 step time: 0.2026\n",
      "3/8, train_loss: 0.0083 step time: 0.2019\n",
      "4/8, train_loss: 0.0096 step time: 0.2018\n",
      "5/8, train_loss: 0.0112 step time: 0.2019\n",
      "6/8, train_loss: 0.0104 step time: 0.2028\n",
      "7/8, train_loss: 0.0093 step time: 0.1831\n",
      "8/8, train_loss: 0.0087 step time: 0.1823\n",
      "epoch 243 average loss: 0.0097\n",
      "time consuming of epoch 243 is: 1.6230\n",
      "----------\n",
      "epoch 244/600\n",
      "1/8, train_loss: 0.0097 step time: 0.2421\n",
      "2/8, train_loss: 0.0107 step time: 0.2033\n",
      "3/8, train_loss: 0.0093 step time: 0.2031\n",
      "4/8, train_loss: 0.0098 step time: 0.2014\n",
      "5/8, train_loss: 0.0095 step time: 0.2014\n",
      "6/8, train_loss: 0.0097 step time: 0.2016\n",
      "7/8, train_loss: 0.0108 step time: 0.1830\n",
      "8/8, train_loss: 0.0099 step time: 0.1821\n",
      "epoch 244 average loss: 0.0099\n",
      "time consuming of epoch 244 is: 1.6199\n",
      "----------\n",
      "epoch 245/600\n",
      "1/8, train_loss: 0.0130 step time: 0.2378\n",
      "2/8, train_loss: 0.0103 step time: 0.2025\n",
      "3/8, train_loss: 0.0097 step time: 0.1974\n",
      "4/8, train_loss: 0.0096 step time: 0.1962\n",
      "5/8, train_loss: 0.0088 step time: 0.1963\n",
      "6/8, train_loss: 0.0103 step time: 0.1957\n",
      "7/8, train_loss: 0.0088 step time: 0.1823\n",
      "8/8, train_loss: 0.0090 step time: 0.1820\n",
      "epoch 245 average loss: 0.0099\n",
      "current epoch: 245 current mean dice: 0.9603 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 245 is: 2.3473\n",
      "----------\n",
      "epoch 246/600\n",
      "1/8, train_loss: 0.0106 step time: 0.2305\n",
      "2/8, train_loss: 0.0108 step time: 0.1991\n",
      "3/8, train_loss: 0.0092 step time: 0.1959\n",
      "4/8, train_loss: 0.0118 step time: 0.1938\n",
      "5/8, train_loss: 0.0107 step time: 0.1990\n",
      "6/8, train_loss: 0.0083 step time: 0.1982\n",
      "7/8, train_loss: 0.0105 step time: 0.1809\n",
      "8/8, train_loss: 0.0103 step time: 0.1835\n",
      "epoch 246 average loss: 0.0103\n",
      "time consuming of epoch 246 is: 1.5819\n",
      "----------\n",
      "epoch 247/600\n",
      "1/8, train_loss: 0.0097 step time: 0.2421\n",
      "2/8, train_loss: 0.0099 step time: 0.2029\n",
      "3/8, train_loss: 0.0090 step time: 0.2003\n",
      "4/8, train_loss: 0.0130 step time: 0.2018\n",
      "5/8, train_loss: 0.0108 step time: 0.2005\n",
      "6/8, train_loss: 0.0082 step time: 0.2018\n",
      "7/8, train_loss: 0.0095 step time: 0.1823\n",
      "8/8, train_loss: 0.0081 step time: 0.1819\n",
      "epoch 247 average loss: 0.0098\n",
      "time consuming of epoch 247 is: 1.6156\n",
      "----------\n",
      "epoch 248/600\n",
      "1/8, train_loss: 0.0096 step time: 0.2395\n",
      "2/8, train_loss: 0.0116 step time: 0.2031\n",
      "3/8, train_loss: 0.0104 step time: 0.2023\n",
      "4/8, train_loss: 0.0087 step time: 0.1990\n",
      "5/8, train_loss: 0.0090 step time: 0.2021\n",
      "6/8, train_loss: 0.0090 step time: 0.2005\n",
      "7/8, train_loss: 0.0099 step time: 0.1854\n",
      "8/8, train_loss: 0.0102 step time: 0.1824\n",
      "epoch 248 average loss: 0.0098\n",
      "time consuming of epoch 248 is: 1.6159\n",
      "----------\n",
      "epoch 249/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2395\n",
      "2/8, train_loss: 0.0100 step time: 0.1969\n",
      "3/8, train_loss: 0.0091 step time: 0.2000\n",
      "4/8, train_loss: 0.0088 step time: 0.2035\n",
      "5/8, train_loss: 0.0110 step time: 0.1990\n",
      "6/8, train_loss: 0.0087 step time: 0.2016\n",
      "7/8, train_loss: 0.0084 step time: 0.1823\n",
      "8/8, train_loss: 0.0084 step time: 0.1819\n",
      "epoch 249 average loss: 0.0094\n",
      "time consuming of epoch 249 is: 1.6063\n",
      "----------\n",
      "epoch 250/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2396\n",
      "2/8, train_loss: 0.0105 step time: 0.2030\n",
      "3/8, train_loss: 0.0112 step time: 0.2017\n",
      "4/8, train_loss: 0.0096 step time: 0.2004\n",
      "5/8, train_loss: 0.0090 step time: 0.2001\n",
      "6/8, train_loss: 0.0131 step time: 0.2003\n",
      "7/8, train_loss: 0.0081 step time: 0.1838\n",
      "8/8, train_loss: 0.0090 step time: 0.1838\n",
      "epoch 250 average loss: 0.0101\n",
      "current epoch: 250 current mean dice: 0.9607 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 250 is: 2.3716\n",
      "----------\n",
      "epoch 251/600\n",
      "1/8, train_loss: 0.0080 step time: 0.2379\n",
      "2/8, train_loss: 0.0090 step time: 0.2002\n",
      "3/8, train_loss: 0.0121 step time: 0.2000\n",
      "4/8, train_loss: 0.0094 step time: 0.1978\n",
      "5/8, train_loss: 0.0079 step time: 0.2012\n",
      "6/8, train_loss: 0.0092 step time: 0.2001\n",
      "7/8, train_loss: 0.0084 step time: 0.1822\n",
      "8/8, train_loss: 0.0111 step time: 0.1817\n",
      "epoch 251 average loss: 0.0094\n",
      "time consuming of epoch 251 is: 1.6021\n",
      "----------\n",
      "epoch 252/600\n",
      "1/8, train_loss: 0.0084 step time: 0.2423\n",
      "2/8, train_loss: 0.0088 step time: 0.2006\n",
      "3/8, train_loss: 0.0081 step time: 0.2019\n",
      "4/8, train_loss: 0.0129 step time: 0.2004\n",
      "5/8, train_loss: 0.0110 step time: 0.1994\n",
      "6/8, train_loss: 0.0086 step time: 0.2004\n",
      "7/8, train_loss: 0.0098 step time: 0.1838\n",
      "8/8, train_loss: 0.0131 step time: 0.1823\n",
      "epoch 252 average loss: 0.0101\n",
      "time consuming of epoch 252 is: 1.6125\n",
      "----------\n",
      "epoch 253/600\n",
      "1/8, train_loss: 0.0087 step time: 0.2421\n",
      "2/8, train_loss: 0.0090 step time: 0.2085\n",
      "3/8, train_loss: 0.0096 step time: 0.2056\n",
      "4/8, train_loss: 0.0127 step time: 0.1994\n",
      "5/8, train_loss: 0.0110 step time: 0.2000\n",
      "6/8, train_loss: 0.0087 step time: 0.1977\n",
      "7/8, train_loss: 0.0098 step time: 0.1815\n",
      "8/8, train_loss: 0.0097 step time: 0.1822\n",
      "epoch 253 average loss: 0.0099\n",
      "time consuming of epoch 253 is: 1.6185\n",
      "----------\n",
      "epoch 254/600\n",
      "1/8, train_loss: 0.0106 step time: 0.2408\n",
      "2/8, train_loss: 0.0102 step time: 0.1974\n",
      "3/8, train_loss: 0.0081 step time: 0.2020\n",
      "4/8, train_loss: 0.0117 step time: 0.2000\n",
      "5/8, train_loss: 0.0097 step time: 0.2009\n",
      "6/8, train_loss: 0.0110 step time: 0.1996\n",
      "7/8, train_loss: 0.0100 step time: 0.1828\n",
      "8/8, train_loss: 0.0087 step time: 0.1820\n",
      "epoch 254 average loss: 0.0100\n",
      "time consuming of epoch 254 is: 1.6071\n",
      "----------\n",
      "epoch 255/600\n",
      "1/8, train_loss: 0.0123 step time: 0.2408\n",
      "2/8, train_loss: 0.0086 step time: 0.2005\n",
      "3/8, train_loss: 0.0081 step time: 0.2048\n",
      "4/8, train_loss: 0.0105 step time: 0.2093\n",
      "5/8, train_loss: 0.0110 step time: 0.2091\n",
      "6/8, train_loss: 0.0090 step time: 0.2113\n",
      "7/8, train_loss: 0.0091 step time: 0.1825\n",
      "8/8, train_loss: 0.0092 step time: 0.1818\n",
      "epoch 255 average loss: 0.0097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 255 current mean dice: 0.9601 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 255 is: 2.3972\n",
      "----------\n",
      "epoch 256/600\n",
      "1/8, train_loss: 0.0083 step time: 0.2387\n",
      "2/8, train_loss: 0.0107 step time: 0.2055\n",
      "3/8, train_loss: 0.0118 step time: 0.2012\n",
      "4/8, train_loss: 0.0090 step time: 0.1990\n",
      "5/8, train_loss: 0.0099 step time: 0.1973\n",
      "6/8, train_loss: 0.0099 step time: 0.2001\n",
      "7/8, train_loss: 0.0105 step time: 0.1822\n",
      "8/8, train_loss: 0.0093 step time: 0.1811\n",
      "epoch 256 average loss: 0.0099\n",
      "time consuming of epoch 256 is: 1.6065\n",
      "----------\n",
      "epoch 257/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2395\n",
      "2/8, train_loss: 0.0107 step time: 0.2042\n",
      "3/8, train_loss: 0.0089 step time: 0.2015\n",
      "4/8, train_loss: 0.0086 step time: 0.2002\n",
      "5/8, train_loss: 0.0106 step time: 0.2019\n",
      "6/8, train_loss: 0.0098 step time: 0.1995\n",
      "7/8, train_loss: 0.0098 step time: 0.1827\n",
      "8/8, train_loss: 0.0074 step time: 0.1824\n",
      "epoch 257 average loss: 0.0095\n",
      "time consuming of epoch 257 is: 1.6131\n",
      "----------\n",
      "epoch 258/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2395\n",
      "2/8, train_loss: 0.0091 step time: 0.1998\n",
      "3/8, train_loss: 0.0107 step time: 0.2015\n",
      "4/8, train_loss: 0.0101 step time: 0.2005\n",
      "5/8, train_loss: 0.0093 step time: 0.2001\n",
      "6/8, train_loss: 0.0089 step time: 0.2000\n",
      "7/8, train_loss: 0.0115 step time: 0.1827\n",
      "8/8, train_loss: 0.0082 step time: 0.1823\n",
      "epoch 258 average loss: 0.0098\n",
      "time consuming of epoch 258 is: 1.6080\n",
      "----------\n",
      "epoch 259/600\n",
      "1/8, train_loss: 0.0108 step time: 0.2386\n",
      "2/8, train_loss: 0.0081 step time: 0.2031\n",
      "3/8, train_loss: 0.0101 step time: 0.2005\n",
      "4/8, train_loss: 0.0100 step time: 0.1996\n",
      "5/8, train_loss: 0.0080 step time: 0.2013\n",
      "6/8, train_loss: 0.0105 step time: 0.1975\n",
      "7/8, train_loss: 0.0087 step time: 0.1810\n",
      "8/8, train_loss: 0.0102 step time: 0.1815\n",
      "epoch 259 average loss: 0.0096\n",
      "time consuming of epoch 259 is: 1.6048\n",
      "----------\n",
      "epoch 260/600\n",
      "1/8, train_loss: 0.0083 step time: 0.2383\n",
      "2/8, train_loss: 0.0109 step time: 0.2016\n",
      "3/8, train_loss: 0.0111 step time: 0.1971\n",
      "4/8, train_loss: 0.0106 step time: 0.2037\n",
      "5/8, train_loss: 0.0097 step time: 0.1985\n",
      "6/8, train_loss: 0.0100 step time: 0.2017\n",
      "7/8, train_loss: 0.0089 step time: 0.1818\n",
      "8/8, train_loss: 0.0107 step time: 0.1821\n",
      "epoch 260 average loss: 0.0100\n",
      "current epoch: 260 current mean dice: 0.9592 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 260 is: 2.3618\n",
      "----------\n",
      "epoch 261/600\n",
      "1/8, train_loss: 0.0088 step time: 0.2340\n",
      "2/8, train_loss: 0.0106 step time: 0.1986\n",
      "3/8, train_loss: 0.0106 step time: 0.1957\n",
      "4/8, train_loss: 0.0086 step time: 0.1948\n",
      "5/8, train_loss: 0.0099 step time: 0.1964\n",
      "6/8, train_loss: 0.0094 step time: 0.1936\n",
      "7/8, train_loss: 0.0086 step time: 0.1819\n",
      "8/8, train_loss: 0.0101 step time: 0.1814\n",
      "epoch 261 average loss: 0.0096\n",
      "time consuming of epoch 261 is: 1.5778\n",
      "----------\n",
      "epoch 262/600\n",
      "1/8, train_loss: 0.0084 step time: 0.2386\n",
      "2/8, train_loss: 0.0117 step time: 0.1986\n",
      "3/8, train_loss: 0.0117 step time: 0.1988\n",
      "4/8, train_loss: 0.0085 step time: 0.1959\n",
      "5/8, train_loss: 0.0101 step time: 0.1971\n",
      "6/8, train_loss: 0.0118 step time: 0.1964\n",
      "7/8, train_loss: 0.0088 step time: 0.1824\n",
      "8/8, train_loss: 0.0104 step time: 0.1828\n",
      "epoch 262 average loss: 0.0102\n",
      "time consuming of epoch 262 is: 1.5921\n",
      "----------\n",
      "epoch 263/600\n",
      "1/8, train_loss: 0.0086 step time: 0.2415\n",
      "2/8, train_loss: 0.0078 step time: 0.2035\n",
      "3/8, train_loss: 0.0091 step time: 0.2005\n",
      "4/8, train_loss: 0.0097 step time: 0.1995\n",
      "5/8, train_loss: 0.0096 step time: 0.1989\n",
      "6/8, train_loss: 0.0107 step time: 0.2018\n",
      "7/8, train_loss: 0.0135 step time: 0.1834\n",
      "8/8, train_loss: 0.0140 step time: 0.1822\n",
      "epoch 263 average loss: 0.0104\n",
      "time consuming of epoch 263 is: 1.6130\n",
      "----------\n",
      "epoch 264/600\n",
      "1/8, train_loss: 0.0119 step time: 0.2448\n",
      "2/8, train_loss: 0.0093 step time: 0.2048\n",
      "3/8, train_loss: 0.0092 step time: 0.2027\n",
      "4/8, train_loss: 0.0098 step time: 0.2020\n",
      "5/8, train_loss: 0.0093 step time: 0.1997\n",
      "6/8, train_loss: 0.0088 step time: 0.2017\n",
      "7/8, train_loss: 0.0099 step time: 0.1830\n",
      "8/8, train_loss: 0.0096 step time: 0.1830\n",
      "epoch 264 average loss: 0.0097\n",
      "time consuming of epoch 264 is: 1.6233\n",
      "----------\n",
      "epoch 265/600\n",
      "1/8, train_loss: 0.0094 step time: 0.2444\n",
      "2/8, train_loss: 0.0085 step time: 0.1996\n",
      "3/8, train_loss: 0.0120 step time: 0.2027\n",
      "4/8, train_loss: 0.0094 step time: 0.2010\n",
      "5/8, train_loss: 0.0107 step time: 0.2027\n",
      "6/8, train_loss: 0.0083 step time: 0.2001\n",
      "7/8, train_loss: 0.0089 step time: 0.1818\n",
      "8/8, train_loss: 0.0109 step time: 0.1809\n",
      "epoch 265 average loss: 0.0098\n",
      "current epoch: 265 current mean dice: 0.9557 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 265 is: 2.3695\n",
      "----------\n",
      "epoch 266/600\n",
      "1/8, train_loss: 0.0117 step time: 0.2320\n",
      "2/8, train_loss: 0.0088 step time: 0.1971\n",
      "3/8, train_loss: 0.0095 step time: 0.1953\n",
      "4/8, train_loss: 0.0101 step time: 0.1934\n",
      "5/8, train_loss: 0.0096 step time: 0.1943\n",
      "6/8, train_loss: 0.0113 step time: 0.1941\n",
      "7/8, train_loss: 0.0089 step time: 0.1808\n",
      "8/8, train_loss: 0.0087 step time: 0.1807\n",
      "epoch 266 average loss: 0.0098\n",
      "time consuming of epoch 266 is: 1.5689\n",
      "----------\n",
      "epoch 267/600\n",
      "1/8, train_loss: 0.0095 step time: 0.2397\n",
      "2/8, train_loss: 0.0093 step time: 0.2009\n",
      "3/8, train_loss: 0.0081 step time: 0.2000\n",
      "4/8, train_loss: 0.0085 step time: 0.2001\n",
      "5/8, train_loss: 0.0111 step time: 0.1987\n",
      "6/8, train_loss: 0.0098 step time: 0.1990\n",
      "7/8, train_loss: 0.0111 step time: 0.1824\n",
      "8/8, train_loss: 0.0123 step time: 0.1819\n",
      "epoch 267 average loss: 0.0100\n",
      "time consuming of epoch 267 is: 1.6040\n",
      "----------\n",
      "epoch 268/600\n",
      "1/8, train_loss: 0.0099 step time: 0.2394\n",
      "2/8, train_loss: 0.0100 step time: 0.2018\n",
      "3/8, train_loss: 0.0138 step time: 0.1991\n",
      "4/8, train_loss: 0.0102 step time: 0.1990\n",
      "5/8, train_loss: 0.0079 step time: 0.1991\n",
      "6/8, train_loss: 0.0101 step time: 0.1997\n",
      "7/8, train_loss: 0.0088 step time: 0.1820\n",
      "8/8, train_loss: 0.0102 step time: 0.1821\n",
      "epoch 268 average loss: 0.0101\n",
      "time consuming of epoch 268 is: 1.6038\n",
      "----------\n",
      "epoch 269/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2349\n",
      "2/8, train_loss: 0.0095 step time: 0.1988\n",
      "3/8, train_loss: 0.0086 step time: 0.1956\n",
      "4/8, train_loss: 0.0097 step time: 0.1953\n",
      "5/8, train_loss: 0.0091 step time: 0.1966\n",
      "6/8, train_loss: 0.0082 step time: 0.1950\n",
      "7/8, train_loss: 0.0121 step time: 0.1825\n",
      "8/8, train_loss: 0.0138 step time: 0.1828\n",
      "epoch 269 average loss: 0.0102\n",
      "time consuming of epoch 269 is: 1.5828\n",
      "----------\n",
      "epoch 270/600\n",
      "1/8, train_loss: 0.0100 step time: 0.2292\n",
      "2/8, train_loss: 0.0106 step time: 0.1992\n",
      "3/8, train_loss: 0.0097 step time: 0.1946\n",
      "4/8, train_loss: 0.0096 step time: 0.1974\n",
      "5/8, train_loss: 0.0091 step time: 0.1963\n",
      "6/8, train_loss: 0.0112 step time: 0.1917\n",
      "7/8, train_loss: 0.0091 step time: 0.1794\n",
      "8/8, train_loss: 0.0097 step time: 0.1805\n",
      "epoch 270 average loss: 0.0099\n",
      "current epoch: 270 current mean dice: 0.9606 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 270 is: 2.3221\n",
      "----------\n",
      "epoch 271/600\n",
      "1/8, train_loss: 0.0120 step time: 0.2307\n",
      "2/8, train_loss: 0.0084 step time: 0.1982\n",
      "3/8, train_loss: 0.0088 step time: 0.1953\n",
      "4/8, train_loss: 0.0095 step time: 0.1944\n",
      "5/8, train_loss: 0.0119 step time: 0.1950\n",
      "6/8, train_loss: 0.0105 step time: 0.1940\n",
      "7/8, train_loss: 0.0089 step time: 0.1813\n",
      "8/8, train_loss: 0.0132 step time: 0.1811\n",
      "epoch 271 average loss: 0.0104\n",
      "time consuming of epoch 271 is: 1.5710\n",
      "----------\n",
      "epoch 272/600\n",
      "1/8, train_loss: 0.0112 step time: 0.2276\n",
      "2/8, train_loss: 0.0084 step time: 0.1969\n",
      "3/8, train_loss: 0.0085 step time: 0.1960\n",
      "4/8, train_loss: 0.0093 step time: 0.1962\n",
      "5/8, train_loss: 0.0127 step time: 0.1955\n",
      "6/8, train_loss: 0.0093 step time: 0.1942\n",
      "7/8, train_loss: 0.0097 step time: 0.1825\n",
      "8/8, train_loss: 0.0085 step time: 0.1817\n",
      "epoch 272 average loss: 0.0097\n",
      "time consuming of epoch 272 is: 1.5720\n",
      "----------\n",
      "epoch 273/600\n",
      "1/8, train_loss: 0.0094 step time: 0.2285\n",
      "2/8, train_loss: 0.0091 step time: 0.1994\n",
      "3/8, train_loss: 0.0093 step time: 0.1957\n",
      "4/8, train_loss: 0.0108 step time: 0.1953\n",
      "5/8, train_loss: 0.0099 step time: 0.1981\n",
      "6/8, train_loss: 0.0096 step time: 0.2000\n",
      "7/8, train_loss: 0.0090 step time: 0.1828\n",
      "8/8, train_loss: 0.0091 step time: 0.1825\n",
      "epoch 273 average loss: 0.0095\n",
      "time consuming of epoch 273 is: 1.5836\n",
      "----------\n",
      "epoch 274/600\n",
      "1/8, train_loss: 0.0121 step time: 0.2406\n",
      "2/8, train_loss: 0.0081 step time: 0.2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8, train_loss: 0.0087 step time: 0.2021\n",
      "4/8, train_loss: 0.0124 step time: 0.1989\n",
      "5/8, train_loss: 0.0087 step time: 0.2001\n",
      "6/8, train_loss: 0.0092 step time: 0.2021\n",
      "7/8, train_loss: 0.0080 step time: 0.1812\n",
      "8/8, train_loss: 0.0079 step time: 0.1822\n",
      "epoch 274 average loss: 0.0094\n",
      "time consuming of epoch 274 is: 1.6087\n",
      "----------\n",
      "epoch 275/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2421\n",
      "2/8, train_loss: 0.0099 step time: 0.2029\n",
      "3/8, train_loss: 0.0096 step time: 0.2019\n",
      "4/8, train_loss: 0.0096 step time: 0.2017\n",
      "5/8, train_loss: 0.0108 step time: 0.1990\n",
      "6/8, train_loss: 0.0129 step time: 0.2026\n",
      "7/8, train_loss: 0.0097 step time: 0.1829\n",
      "8/8, train_loss: 0.0097 step time: 0.1824\n",
      "epoch 275 average loss: 0.0102\n",
      "current epoch: 275 current mean dice: 0.9614 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 275 is: 2.3720\n",
      "----------\n",
      "epoch 276/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2386\n",
      "2/8, train_loss: 0.0086 step time: 0.2002\n",
      "3/8, train_loss: 0.0093 step time: 0.1989\n",
      "4/8, train_loss: 0.0097 step time: 0.2036\n",
      "5/8, train_loss: 0.0118 step time: 0.1986\n",
      "6/8, train_loss: 0.0103 step time: 0.2001\n",
      "7/8, train_loss: 0.0102 step time: 0.1821\n",
      "8/8, train_loss: 0.0095 step time: 0.1816\n",
      "epoch 276 average loss: 0.0099\n",
      "time consuming of epoch 276 is: 1.6050\n",
      "----------\n",
      "epoch 277/600\n",
      "1/8, train_loss: 0.0094 step time: 0.2375\n",
      "2/8, train_loss: 0.0128 step time: 0.2025\n",
      "3/8, train_loss: 0.0097 step time: 0.2011\n",
      "4/8, train_loss: 0.0090 step time: 0.2025\n",
      "5/8, train_loss: 0.0096 step time: 0.1986\n",
      "6/8, train_loss: 0.0080 step time: 0.2014\n",
      "7/8, train_loss: 0.0093 step time: 0.1830\n",
      "8/8, train_loss: 0.0082 step time: 0.1835\n",
      "epoch 277 average loss: 0.0095\n",
      "time consuming of epoch 277 is: 1.6118\n",
      "----------\n",
      "epoch 278/600\n",
      "1/8, train_loss: 0.0079 step time: 0.2419\n",
      "2/8, train_loss: 0.0106 step time: 0.1978\n",
      "3/8, train_loss: 0.0087 step time: 0.2009\n",
      "4/8, train_loss: 0.0105 step time: 0.2006\n",
      "5/8, train_loss: 0.0114 step time: 0.2003\n",
      "6/8, train_loss: 0.0102 step time: 0.2018\n",
      "7/8, train_loss: 0.0086 step time: 0.1830\n",
      "8/8, train_loss: 0.0089 step time: 0.1823\n",
      "epoch 278 average loss: 0.0096\n",
      "time consuming of epoch 278 is: 1.6101\n",
      "----------\n",
      "epoch 279/600\n",
      "1/8, train_loss: 0.0111 step time: 0.2397\n",
      "2/8, train_loss: 0.0090 step time: 0.1993\n",
      "3/8, train_loss: 0.0094 step time: 0.2037\n",
      "4/8, train_loss: 0.0109 step time: 0.1976\n",
      "5/8, train_loss: 0.0095 step time: 0.2009\n",
      "6/8, train_loss: 0.0085 step time: 0.1970\n",
      "7/8, train_loss: 0.0086 step time: 0.1827\n",
      "8/8, train_loss: 0.0089 step time: 0.1845\n",
      "epoch 279 average loss: 0.0095\n",
      "time consuming of epoch 279 is: 1.6069\n",
      "----------\n",
      "epoch 280/600\n",
      "1/8, train_loss: 0.0114 step time: 0.2397\n",
      "2/8, train_loss: 0.0101 step time: 0.2027\n",
      "3/8, train_loss: 0.0081 step time: 0.1987\n",
      "4/8, train_loss: 0.0111 step time: 0.1999\n",
      "5/8, train_loss: 0.0087 step time: 0.2019\n",
      "6/8, train_loss: 0.0087 step time: 0.1992\n",
      "7/8, train_loss: 0.0079 step time: 0.1830\n",
      "8/8, train_loss: 0.0081 step time: 0.1826\n",
      "epoch 280 average loss: 0.0093\n",
      "current epoch: 280 current mean dice: 0.9610 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 280 is: 2.3666\n",
      "----------\n",
      "epoch 281/600\n",
      "1/8, train_loss: 0.0088 step time: 0.2398\n",
      "2/8, train_loss: 0.0092 step time: 0.2004\n",
      "3/8, train_loss: 0.0101 step time: 0.1988\n",
      "4/8, train_loss: 0.0092 step time: 0.1962\n",
      "5/8, train_loss: 0.0084 step time: 0.1986\n",
      "6/8, train_loss: 0.0108 step time: 0.1968\n",
      "7/8, train_loss: 0.0122 step time: 0.1818\n",
      "8/8, train_loss: 0.0078 step time: 0.1824\n",
      "epoch 281 average loss: 0.0096\n",
      "time consuming of epoch 281 is: 1.5960\n",
      "----------\n",
      "epoch 282/600\n",
      "1/8, train_loss: 0.0089 step time: 0.2398\n",
      "2/8, train_loss: 0.0077 step time: 0.2028\n",
      "3/8, train_loss: 0.0109 step time: 0.1998\n",
      "4/8, train_loss: 0.0104 step time: 0.1963\n",
      "5/8, train_loss: 0.0107 step time: 0.2014\n",
      "6/8, train_loss: 0.0086 step time: 0.1994\n",
      "7/8, train_loss: 0.0119 step time: 0.1828\n",
      "8/8, train_loss: 0.0110 step time: 0.1824\n",
      "epoch 282 average loss: 0.0100\n",
      "time consuming of epoch 282 is: 1.6057\n",
      "----------\n",
      "epoch 283/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2384\n",
      "2/8, train_loss: 0.0120 step time: 0.2040\n",
      "3/8, train_loss: 0.0089 step time: 0.1995\n",
      "4/8, train_loss: 0.0105 step time: 0.2017\n",
      "5/8, train_loss: 0.0095 step time: 0.2013\n",
      "6/8, train_loss: 0.0088 step time: 0.1997\n",
      "7/8, train_loss: 0.0095 step time: 0.1833\n",
      "8/8, train_loss: 0.0120 step time: 0.1825\n",
      "epoch 283 average loss: 0.0100\n",
      "time consuming of epoch 283 is: 1.6121\n",
      "----------\n",
      "epoch 284/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2404\n",
      "2/8, train_loss: 0.0096 step time: 0.1984\n",
      "3/8, train_loss: 0.0105 step time: 0.2002\n",
      "4/8, train_loss: 0.0095 step time: 0.2016\n",
      "5/8, train_loss: 0.0108 step time: 0.2018\n",
      "6/8, train_loss: 0.0098 step time: 0.2024\n",
      "7/8, train_loss: 0.0095 step time: 0.1829\n",
      "8/8, train_loss: 0.0099 step time: 0.1824\n",
      "epoch 284 average loss: 0.0098\n",
      "time consuming of epoch 284 is: 1.6116\n",
      "----------\n",
      "epoch 285/600\n",
      "1/8, train_loss: 0.0080 step time: 0.2402\n",
      "2/8, train_loss: 0.0080 step time: 0.2017\n",
      "3/8, train_loss: 0.0110 step time: 0.2019\n",
      "4/8, train_loss: 0.0099 step time: 0.2016\n",
      "5/8, train_loss: 0.0079 step time: 0.2031\n",
      "6/8, train_loss: 0.0105 step time: 0.2018\n",
      "7/8, train_loss: 0.0091 step time: 0.1841\n",
      "8/8, train_loss: 0.0110 step time: 0.1826\n",
      "epoch 285 average loss: 0.0094\n",
      "current epoch: 285 current mean dice: 0.9616 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 285 is: 2.3746\n",
      "----------\n",
      "epoch 286/600\n",
      "1/8, train_loss: 0.0114 step time: 0.2370\n",
      "2/8, train_loss: 0.0076 step time: 0.2000\n",
      "3/8, train_loss: 0.0083 step time: 0.2014\n",
      "4/8, train_loss: 0.0080 step time: 0.1993\n",
      "5/8, train_loss: 0.0105 step time: 0.1985\n",
      "6/8, train_loss: 0.0107 step time: 0.2019\n",
      "7/8, train_loss: 0.0090 step time: 0.1816\n",
      "8/8, train_loss: 0.0106 step time: 0.1832\n",
      "epoch 286 average loss: 0.0095\n",
      "time consuming of epoch 286 is: 1.6041\n",
      "----------\n",
      "epoch 287/600\n",
      "1/8, train_loss: 0.0099 step time: 0.2397\n",
      "2/8, train_loss: 0.0119 step time: 0.2036\n",
      "3/8, train_loss: 0.0116 step time: 0.2072\n",
      "4/8, train_loss: 0.0109 step time: 0.2025\n",
      "5/8, train_loss: 0.0096 step time: 0.2001\n",
      "6/8, train_loss: 0.0080 step time: 0.2013\n",
      "7/8, train_loss: 0.0099 step time: 0.1841\n",
      "8/8, train_loss: 0.0094 step time: 0.1821\n",
      "epoch 287 average loss: 0.0101\n",
      "time consuming of epoch 287 is: 1.6220\n",
      "----------\n",
      "epoch 288/600\n",
      "1/8, train_loss: 0.0090 step time: 0.2394\n",
      "2/8, train_loss: 0.0118 step time: 0.2018\n",
      "3/8, train_loss: 0.0101 step time: 0.1994\n",
      "4/8, train_loss: 0.0077 step time: 0.2010\n",
      "5/8, train_loss: 0.0118 step time: 0.1988\n",
      "6/8, train_loss: 0.0098 step time: 0.2008\n",
      "7/8, train_loss: 0.0096 step time: 0.1827\n",
      "8/8, train_loss: 0.0111 step time: 0.1825\n",
      "epoch 288 average loss: 0.0101\n",
      "time consuming of epoch 288 is: 1.6081\n",
      "----------\n",
      "epoch 289/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2369\n",
      "2/8, train_loss: 0.0099 step time: 0.2042\n",
      "3/8, train_loss: 0.0097 step time: 0.1994\n",
      "4/8, train_loss: 0.0087 step time: 0.2008\n",
      "5/8, train_loss: 0.0107 step time: 0.1993\n",
      "6/8, train_loss: 0.0106 step time: 0.1999\n",
      "7/8, train_loss: 0.0089 step time: 0.1822\n",
      "8/8, train_loss: 0.0088 step time: 0.1819\n",
      "epoch 289 average loss: 0.0096\n",
      "time consuming of epoch 289 is: 1.6061\n",
      "----------\n",
      "epoch 290/600\n",
      "1/8, train_loss: 0.0094 step time: 0.2394\n",
      "2/8, train_loss: 0.0112 step time: 0.2015\n",
      "3/8, train_loss: 0.0092 step time: 0.1994\n",
      "4/8, train_loss: 0.0091 step time: 0.2005\n",
      "5/8, train_loss: 0.0116 step time: 0.1987\n",
      "6/8, train_loss: 0.0089 step time: 0.1985\n",
      "7/8, train_loss: 0.0086 step time: 0.1831\n",
      "8/8, train_loss: 0.0120 step time: 0.1820\n",
      "epoch 290 average loss: 0.0100\n",
      "current epoch: 290 current mean dice: 0.9611 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 290 is: 2.3609\n",
      "----------\n",
      "epoch 291/600\n",
      "1/8, train_loss: 0.0097 step time: 0.2376\n",
      "2/8, train_loss: 0.0098 step time: 0.1992\n",
      "3/8, train_loss: 0.0079 step time: 0.1986\n",
      "4/8, train_loss: 0.0103 step time: 0.2060\n",
      "5/8, train_loss: 0.0089 step time: 0.1953\n",
      "6/8, train_loss: 0.0103 step time: 0.1962\n",
      "7/8, train_loss: 0.0116 step time: 0.1828\n",
      "8/8, train_loss: 0.0117 step time: 0.1810\n",
      "epoch 291 average loss: 0.0100\n",
      "time consuming of epoch 291 is: 1.5977\n",
      "----------\n",
      "epoch 292/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2352\n",
      "2/8, train_loss: 0.0086 step time: 0.1981\n",
      "3/8, train_loss: 0.0102 step time: 0.1963\n",
      "4/8, train_loss: 0.0097 step time: 0.1949\n",
      "5/8, train_loss: 0.0120 step time: 0.1969\n",
      "6/8, train_loss: 0.0087 step time: 0.1962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/8, train_loss: 0.0090 step time: 0.1837\n",
      "8/8, train_loss: 0.0115 step time: 0.1817\n",
      "epoch 292 average loss: 0.0099\n",
      "time consuming of epoch 292 is: 1.5844\n",
      "----------\n",
      "epoch 293/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2372\n",
      "2/8, train_loss: 0.0101 step time: 0.2020\n",
      "3/8, train_loss: 0.0097 step time: 0.2000\n",
      "4/8, train_loss: 0.0117 step time: 0.1996\n",
      "5/8, train_loss: 0.0087 step time: 0.2055\n",
      "6/8, train_loss: 0.0095 step time: 0.1972\n",
      "7/8, train_loss: 0.0113 step time: 0.1823\n",
      "8/8, train_loss: 0.0086 step time: 0.1825\n",
      "epoch 293 average loss: 0.0100\n",
      "time consuming of epoch 293 is: 1.6079\n",
      "----------\n",
      "epoch 294/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2387\n",
      "2/8, train_loss: 0.0098 step time: 0.1991\n",
      "3/8, train_loss: 0.0117 step time: 0.2003\n",
      "4/8, train_loss: 0.0071 step time: 0.2002\n",
      "5/8, train_loss: 0.0105 step time: 0.2010\n",
      "6/8, train_loss: 0.0112 step time: 0.2014\n",
      "7/8, train_loss: 0.0098 step time: 0.1828\n",
      "8/8, train_loss: 0.0103 step time: 0.1828\n",
      "epoch 294 average loss: 0.0101\n",
      "time consuming of epoch 294 is: 1.6079\n",
      "----------\n",
      "epoch 295/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2381\n",
      "2/8, train_loss: 0.0080 step time: 0.1997\n",
      "3/8, train_loss: 0.0099 step time: 0.1988\n",
      "4/8, train_loss: 0.0097 step time: 0.2001\n",
      "5/8, train_loss: 0.0092 step time: 0.2014\n",
      "6/8, train_loss: 0.0097 step time: 0.2049\n",
      "7/8, train_loss: 0.0086 step time: 0.1821\n",
      "8/8, train_loss: 0.0100 step time: 0.1820\n",
      "epoch 295 average loss: 0.0094\n",
      "current epoch: 295 current mean dice: 0.9617 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 295 is: 2.3630\n",
      "----------\n",
      "epoch 296/600\n",
      "1/8, train_loss: 0.0103 step time: 0.2358\n",
      "2/8, train_loss: 0.0110 step time: 0.1995\n",
      "3/8, train_loss: 0.0088 step time: 0.2002\n",
      "4/8, train_loss: 0.0096 step time: 0.1976\n",
      "5/8, train_loss: 0.0099 step time: 0.1992\n",
      "6/8, train_loss: 0.0090 step time: 0.1984\n",
      "7/8, train_loss: 0.0087 step time: 0.1809\n",
      "8/8, train_loss: 0.0105 step time: 0.1818\n",
      "epoch 296 average loss: 0.0097\n",
      "time consuming of epoch 296 is: 1.5946\n",
      "----------\n",
      "epoch 297/600\n",
      "1/8, train_loss: 0.0094 step time: 0.2385\n",
      "2/8, train_loss: 0.0114 step time: 0.2017\n",
      "3/8, train_loss: 0.0092 step time: 0.1993\n",
      "4/8, train_loss: 0.0103 step time: 0.1991\n",
      "5/8, train_loss: 0.0101 step time: 0.1993\n",
      "6/8, train_loss: 0.0094 step time: 0.2024\n",
      "7/8, train_loss: 0.0090 step time: 0.1824\n",
      "8/8, train_loss: 0.0086 step time: 0.1826\n",
      "epoch 297 average loss: 0.0097\n",
      "time consuming of epoch 297 is: 1.6069\n",
      "----------\n",
      "epoch 298/600\n",
      "1/8, train_loss: 0.0088 step time: 0.2392\n",
      "2/8, train_loss: 0.0098 step time: 0.2036\n",
      "3/8, train_loss: 0.0099 step time: 0.1987\n",
      "4/8, train_loss: 0.0076 step time: 0.1992\n",
      "5/8, train_loss: 0.0093 step time: 0.2070\n",
      "6/8, train_loss: 0.0076 step time: 0.2071\n",
      "7/8, train_loss: 0.0129 step time: 0.1824\n",
      "8/8, train_loss: 0.0112 step time: 0.1825\n",
      "epoch 298 average loss: 0.0097\n",
      "time consuming of epoch 298 is: 1.6211\n",
      "----------\n",
      "epoch 299/600\n",
      "1/8, train_loss: 0.0086 step time: 0.2376\n",
      "2/8, train_loss: 0.0099 step time: 0.1991\n",
      "3/8, train_loss: 0.0102 step time: 0.1979\n",
      "4/8, train_loss: 0.0090 step time: 0.1991\n",
      "5/8, train_loss: 0.0084 step time: 0.1998\n",
      "6/8, train_loss: 0.0095 step time: 0.2028\n",
      "7/8, train_loss: 0.0095 step time: 0.1823\n",
      "8/8, train_loss: 0.0125 step time: 0.1827\n",
      "epoch 299 average loss: 0.0097\n",
      "time consuming of epoch 299 is: 1.6030\n",
      "----------\n",
      "epoch 300/600\n",
      "1/8, train_loss: 0.0111 step time: 0.2372\n",
      "2/8, train_loss: 0.0095 step time: 0.1988\n",
      "3/8, train_loss: 0.0094 step time: 0.2002\n",
      "4/8, train_loss: 0.0084 step time: 0.2005\n",
      "5/8, train_loss: 0.0098 step time: 0.1986\n",
      "6/8, train_loss: 0.0092 step time: 0.2004\n",
      "7/8, train_loss: 0.0093 step time: 0.1828\n",
      "8/8, train_loss: 0.0088 step time: 0.1828\n",
      "epoch 300 average loss: 0.0094\n",
      "current epoch: 300 current mean dice: 0.9618 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 300 is: 2.3579\n",
      "----------\n",
      "epoch 301/600\n",
      "1/8, train_loss: 0.0089 step time: 0.2374\n",
      "2/8, train_loss: 0.0085 step time: 0.2004\n",
      "3/8, train_loss: 0.0101 step time: 0.1974\n",
      "4/8, train_loss: 0.0117 step time: 0.1990\n",
      "5/8, train_loss: 0.0118 step time: 0.1993\n",
      "6/8, train_loss: 0.0124 step time: 0.2002\n",
      "7/8, train_loss: 0.0093 step time: 0.1822\n",
      "8/8, train_loss: 0.0084 step time: 0.1816\n",
      "epoch 301 average loss: 0.0101\n",
      "time consuming of epoch 301 is: 1.5986\n",
      "----------\n",
      "epoch 302/600\n",
      "1/8, train_loss: 0.0101 step time: 0.2400\n",
      "2/8, train_loss: 0.0092 step time: 0.2030\n",
      "3/8, train_loss: 0.0089 step time: 0.1983\n",
      "4/8, train_loss: 0.0096 step time: 0.2006\n",
      "5/8, train_loss: 0.0088 step time: 0.2022\n",
      "6/8, train_loss: 0.0111 step time: 0.1998\n",
      "7/8, train_loss: 0.0093 step time: 0.1831\n",
      "8/8, train_loss: 0.0077 step time: 0.1811\n",
      "epoch 302 average loss: 0.0093\n",
      "time consuming of epoch 302 is: 1.6096\n",
      "----------\n",
      "epoch 303/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2393\n",
      "2/8, train_loss: 0.0090 step time: 0.2020\n",
      "3/8, train_loss: 0.0083 step time: 0.1995\n",
      "4/8, train_loss: 0.0078 step time: 0.2016\n",
      "5/8, train_loss: 0.0111 step time: 0.1984\n",
      "6/8, train_loss: 0.0110 step time: 0.2015\n",
      "7/8, train_loss: 0.0091 step time: 0.1822\n",
      "8/8, train_loss: 0.0099 step time: 0.1825\n",
      "epoch 303 average loss: 0.0094\n",
      "time consuming of epoch 303 is: 1.6085\n",
      "----------\n",
      "epoch 304/600\n",
      "1/8, train_loss: 0.0090 step time: 0.2426\n",
      "2/8, train_loss: 0.0110 step time: 0.1999\n",
      "3/8, train_loss: 0.0133 step time: 0.1995\n",
      "4/8, train_loss: 0.0088 step time: 0.1992\n",
      "5/8, train_loss: 0.0099 step time: 0.2013\n",
      "6/8, train_loss: 0.0100 step time: 0.1993\n",
      "7/8, train_loss: 0.0089 step time: 0.1824\n",
      "8/8, train_loss: 0.0087 step time: 0.1824\n",
      "epoch 304 average loss: 0.0100\n",
      "time consuming of epoch 304 is: 1.6081\n",
      "----------\n",
      "epoch 305/600\n",
      "1/8, train_loss: 0.0074 step time: 0.2405\n",
      "2/8, train_loss: 0.0093 step time: 0.2019\n",
      "3/8, train_loss: 0.0089 step time: 0.2014\n",
      "4/8, train_loss: 0.0087 step time: 0.1994\n",
      "5/8, train_loss: 0.0086 step time: 0.2013\n",
      "6/8, train_loss: 0.0076 step time: 0.2006\n",
      "7/8, train_loss: 0.0118 step time: 0.1835\n",
      "8/8, train_loss: 0.0114 step time: 0.1835\n",
      "epoch 305 average loss: 0.0092\n",
      "current epoch: 305 current mean dice: 0.9606 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 305 is: 2.3683\n",
      "----------\n",
      "epoch 306/600\n",
      "1/8, train_loss: 0.0128 step time: 0.2370\n",
      "2/8, train_loss: 0.0072 step time: 0.1971\n",
      "3/8, train_loss: 0.0084 step time: 0.1993\n",
      "4/8, train_loss: 0.0088 step time: 0.1990\n",
      "5/8, train_loss: 0.0100 step time: 0.1975\n",
      "6/8, train_loss: 0.0099 step time: 0.2002\n",
      "7/8, train_loss: 0.0112 step time: 0.1848\n",
      "8/8, train_loss: 0.0086 step time: 0.1822\n",
      "epoch 306 average loss: 0.0096\n",
      "time consuming of epoch 306 is: 1.5981\n",
      "----------\n",
      "epoch 307/600\n",
      "1/8, train_loss: 0.0096 step time: 0.2383\n",
      "2/8, train_loss: 0.0103 step time: 0.2010\n",
      "3/8, train_loss: 0.0080 step time: 0.2009\n",
      "4/8, train_loss: 0.0113 step time: 0.2006\n",
      "5/8, train_loss: 0.0087 step time: 0.1994\n",
      "6/8, train_loss: 0.0100 step time: 0.2014\n",
      "7/8, train_loss: 0.0097 step time: 0.1826\n",
      "8/8, train_loss: 0.0125 step time: 0.1841\n",
      "epoch 307 average loss: 0.0100\n",
      "time consuming of epoch 307 is: 1.6100\n",
      "----------\n",
      "epoch 308/600\n",
      "1/8, train_loss: 0.0108 step time: 0.2409\n",
      "2/8, train_loss: 0.0091 step time: 0.2028\n",
      "3/8, train_loss: 0.0116 step time: 0.2041\n",
      "4/8, train_loss: 0.0087 step time: 0.1992\n",
      "5/8, train_loss: 0.0109 step time: 0.2018\n",
      "6/8, train_loss: 0.0086 step time: 0.1992\n",
      "7/8, train_loss: 0.0087 step time: 0.1827\n",
      "8/8, train_loss: 0.0099 step time: 0.1833\n",
      "epoch 308 average loss: 0.0098\n",
      "time consuming of epoch 308 is: 1.6154\n",
      "----------\n",
      "epoch 309/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2387\n",
      "2/8, train_loss: 0.0088 step time: 0.2040\n",
      "3/8, train_loss: 0.0091 step time: 0.2051\n",
      "4/8, train_loss: 0.0131 step time: 0.2030\n",
      "5/8, train_loss: 0.0100 step time: 0.2001\n",
      "6/8, train_loss: 0.0100 step time: 0.2012\n",
      "7/8, train_loss: 0.0091 step time: 0.1815\n",
      "8/8, train_loss: 0.0096 step time: 0.1819\n",
      "epoch 309 average loss: 0.0099\n",
      "time consuming of epoch 309 is: 1.6171\n",
      "----------\n",
      "epoch 310/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2400\n",
      "2/8, train_loss: 0.0080 step time: 0.2015\n",
      "3/8, train_loss: 0.0102 step time: 0.2013\n",
      "4/8, train_loss: 0.0093 step time: 0.1985\n",
      "5/8, train_loss: 0.0086 step time: 0.2007\n",
      "6/8, train_loss: 0.0096 step time: 0.1998\n",
      "7/8, train_loss: 0.0112 step time: 0.1833\n",
      "8/8, train_loss: 0.0103 step time: 0.1823\n",
      "epoch 310 average loss: 0.0097\n",
      "current epoch: 310 current mean dice: 0.9598 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 310 is: 2.3644\n",
      "----------\n",
      "epoch 311/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0093 step time: 0.2347\n",
      "2/8, train_loss: 0.0100 step time: 0.1984\n",
      "3/8, train_loss: 0.0094 step time: 0.1998\n",
      "4/8, train_loss: 0.0100 step time: 0.1981\n",
      "5/8, train_loss: 0.0089 step time: 0.2008\n",
      "6/8, train_loss: 0.0103 step time: 0.1974\n",
      "7/8, train_loss: 0.0104 step time: 0.1812\n",
      "8/8, train_loss: 0.0106 step time: 0.1812\n",
      "epoch 311 average loss: 0.0099\n",
      "time consuming of epoch 311 is: 1.5927\n",
      "----------\n",
      "epoch 312/600\n",
      "1/8, train_loss: 0.0127 step time: 0.2404\n",
      "2/8, train_loss: 0.0089 step time: 0.2017\n",
      "3/8, train_loss: 0.0108 step time: 0.1990\n",
      "4/8, train_loss: 0.0082 step time: 0.1989\n",
      "5/8, train_loss: 0.0099 step time: 0.1989\n",
      "6/8, train_loss: 0.0094 step time: 0.2001\n",
      "7/8, train_loss: 0.0083 step time: 0.1840\n",
      "8/8, train_loss: 0.0092 step time: 0.1825\n",
      "epoch 312 average loss: 0.0097\n",
      "time consuming of epoch 312 is: 1.6071\n",
      "----------\n",
      "epoch 313/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2377\n",
      "2/8, train_loss: 0.0101 step time: 0.1997\n",
      "3/8, train_loss: 0.0077 step time: 0.2008\n",
      "4/8, train_loss: 0.0086 step time: 0.1989\n",
      "5/8, train_loss: 0.0105 step time: 0.1999\n",
      "6/8, train_loss: 0.0097 step time: 0.1991\n",
      "7/8, train_loss: 0.0105 step time: 0.1844\n",
      "8/8, train_loss: 0.0100 step time: 0.1823\n",
      "epoch 313 average loss: 0.0095\n",
      "time consuming of epoch 313 is: 1.6043\n",
      "----------\n",
      "epoch 314/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2403\n",
      "2/8, train_loss: 0.0078 step time: 0.2028\n",
      "3/8, train_loss: 0.0097 step time: 0.1994\n",
      "4/8, train_loss: 0.0101 step time: 0.2019\n",
      "5/8, train_loss: 0.0098 step time: 0.1986\n",
      "6/8, train_loss: 0.0106 step time: 0.1996\n",
      "7/8, train_loss: 0.0089 step time: 0.1821\n",
      "8/8, train_loss: 0.0102 step time: 0.1824\n",
      "epoch 314 average loss: 0.0096\n",
      "time consuming of epoch 314 is: 1.6087\n",
      "----------\n",
      "epoch 315/600\n",
      "1/8, train_loss: 0.0095 step time: 0.2380\n",
      "2/8, train_loss: 0.0102 step time: 0.2003\n",
      "3/8, train_loss: 0.0091 step time: 0.1983\n",
      "4/8, train_loss: 0.0089 step time: 0.1993\n",
      "5/8, train_loss: 0.0095 step time: 0.2011\n",
      "6/8, train_loss: 0.0087 step time: 0.1985\n",
      "7/8, train_loss: 0.0092 step time: 0.1821\n",
      "8/8, train_loss: 0.0084 step time: 0.1827\n",
      "epoch 315 average loss: 0.0092\n",
      "current epoch: 315 current mean dice: 0.9618 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 315 is: 2.3568\n",
      "----------\n",
      "epoch 316/600\n",
      "1/8, train_loss: 0.0106 step time: 0.2394\n",
      "2/8, train_loss: 0.0101 step time: 0.2025\n",
      "3/8, train_loss: 0.0098 step time: 0.1986\n",
      "4/8, train_loss: 0.0078 step time: 0.1994\n",
      "5/8, train_loss: 0.0125 step time: 0.1977\n",
      "6/8, train_loss: 0.0090 step time: 0.2001\n",
      "7/8, train_loss: 0.0085 step time: 0.1816\n",
      "8/8, train_loss: 0.0088 step time: 0.1809\n",
      "epoch 316 average loss: 0.0097\n",
      "time consuming of epoch 316 is: 1.6012\n",
      "----------\n",
      "epoch 317/600\n",
      "1/8, train_loss: 0.0124 step time: 0.2409\n",
      "2/8, train_loss: 0.0092 step time: 0.2024\n",
      "3/8, train_loss: 0.0086 step time: 0.2022\n",
      "4/8, train_loss: 0.0100 step time: 0.2003\n",
      "5/8, train_loss: 0.0105 step time: 0.2065\n",
      "6/8, train_loss: 0.0077 step time: 0.2104\n",
      "7/8, train_loss: 0.0101 step time: 0.1837\n",
      "8/8, train_loss: 0.0090 step time: 0.1837\n",
      "epoch 317 average loss: 0.0097\n",
      "time consuming of epoch 317 is: 1.6313\n",
      "----------\n",
      "epoch 318/600\n",
      "1/8, train_loss: 0.0090 step time: 0.2395\n",
      "2/8, train_loss: 0.0084 step time: 0.2010\n",
      "3/8, train_loss: 0.0117 step time: 0.1971\n",
      "4/8, train_loss: 0.0099 step time: 0.2011\n",
      "5/8, train_loss: 0.0087 step time: 0.2019\n",
      "6/8, train_loss: 0.0081 step time: 0.2000\n",
      "7/8, train_loss: 0.0094 step time: 0.1829\n",
      "8/8, train_loss: 0.0091 step time: 0.1829\n",
      "epoch 318 average loss: 0.0093\n",
      "time consuming of epoch 318 is: 1.6082\n",
      "----------\n",
      "epoch 319/600\n",
      "1/8, train_loss: 0.0082 step time: 0.2454\n",
      "2/8, train_loss: 0.0093 step time: 0.2026\n",
      "3/8, train_loss: 0.0091 step time: 0.2038\n",
      "4/8, train_loss: 0.0073 step time: 0.2026\n",
      "5/8, train_loss: 0.0112 step time: 0.2046\n",
      "6/8, train_loss: 0.0119 step time: 0.1994\n",
      "7/8, train_loss: 0.0099 step time: 0.1822\n",
      "8/8, train_loss: 0.0093 step time: 0.1824\n",
      "epoch 319 average loss: 0.0095\n",
      "time consuming of epoch 319 is: 1.6244\n",
      "----------\n",
      "epoch 320/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2413\n",
      "2/8, train_loss: 0.0091 step time: 0.2018\n",
      "3/8, train_loss: 0.0106 step time: 0.2068\n",
      "4/8, train_loss: 0.0090 step time: 0.2002\n",
      "5/8, train_loss: 0.0103 step time: 0.2010\n",
      "6/8, train_loss: 0.0091 step time: 0.2017\n",
      "7/8, train_loss: 0.0103 step time: 0.1829\n",
      "8/8, train_loss: 0.0085 step time: 0.1810\n",
      "epoch 320 average loss: 0.0096\n",
      "current epoch: 320 current mean dice: 0.9614 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 320 is: 2.3717\n",
      "----------\n",
      "epoch 321/600\n",
      "1/8, train_loss: 0.0070 step time: 0.2309\n",
      "2/8, train_loss: 0.0098 step time: 0.1988\n",
      "3/8, train_loss: 0.0100 step time: 0.1955\n",
      "4/8, train_loss: 0.0136 step time: 0.1945\n",
      "5/8, train_loss: 0.0102 step time: 0.1944\n",
      "6/8, train_loss: 0.0100 step time: 0.1964\n",
      "7/8, train_loss: 0.0089 step time: 0.1814\n",
      "8/8, train_loss: 0.0084 step time: 0.1818\n",
      "epoch 321 average loss: 0.0097\n",
      "time consuming of epoch 321 is: 1.5748\n",
      "----------\n",
      "epoch 322/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2314\n",
      "2/8, train_loss: 0.0086 step time: 0.1992\n",
      "3/8, train_loss: 0.0098 step time: 0.1973\n",
      "4/8, train_loss: 0.0112 step time: 0.1995\n",
      "5/8, train_loss: 0.0096 step time: 0.1998\n",
      "6/8, train_loss: 0.0085 step time: 0.1969\n",
      "7/8, train_loss: 0.0078 step time: 0.1824\n",
      "8/8, train_loss: 0.0085 step time: 0.1824\n",
      "epoch 322 average loss: 0.0093\n",
      "time consuming of epoch 322 is: 1.5903\n",
      "----------\n",
      "epoch 323/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2406\n",
      "2/8, train_loss: 0.0091 step time: 0.2022\n",
      "3/8, train_loss: 0.0105 step time: 0.2022\n",
      "4/8, train_loss: 0.0091 step time: 0.1940\n",
      "5/8, train_loss: 0.0090 step time: 0.1942\n",
      "6/8, train_loss: 0.0123 step time: 0.1961\n",
      "7/8, train_loss: 0.0106 step time: 0.1797\n",
      "8/8, train_loss: 0.0072 step time: 0.1798\n",
      "epoch 323 average loss: 0.0096\n",
      "time consuming of epoch 323 is: 1.5903\n",
      "----------\n",
      "epoch 324/600\n",
      "1/8, train_loss: 0.0097 step time: 0.2323\n",
      "2/8, train_loss: 0.0079 step time: 0.1929\n",
      "3/8, train_loss: 0.0107 step time: 0.1959\n",
      "4/8, train_loss: 0.0110 step time: 0.1961\n",
      "5/8, train_loss: 0.0093 step time: 0.1960\n",
      "6/8, train_loss: 0.0098 step time: 0.1972\n",
      "7/8, train_loss: 0.0088 step time: 0.1798\n",
      "8/8, train_loss: 0.0144 step time: 0.1795\n",
      "epoch 324 average loss: 0.0102\n",
      "time consuming of epoch 324 is: 1.5707\n",
      "----------\n",
      "epoch 325/600\n",
      "1/8, train_loss: 0.0100 step time: 0.2333\n",
      "2/8, train_loss: 0.0100 step time: 0.1978\n",
      "3/8, train_loss: 0.0084 step time: 0.1965\n",
      "4/8, train_loss: 0.0085 step time: 0.1938\n",
      "5/8, train_loss: 0.0101 step time: 0.1983\n",
      "6/8, train_loss: 0.0093 step time: 0.1979\n",
      "7/8, train_loss: 0.0090 step time: 0.1798\n",
      "8/8, train_loss: 0.0098 step time: 0.1797\n",
      "epoch 325 average loss: 0.0094\n",
      "current epoch: 325 current mean dice: 0.9612 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 325 is: 2.3312\n",
      "----------\n",
      "epoch 326/600\n",
      "1/8, train_loss: 0.0097 step time: 0.2316\n",
      "2/8, train_loss: 0.0092 step time: 0.1957\n",
      "3/8, train_loss: 0.0073 step time: 0.1959\n",
      "4/8, train_loss: 0.0088 step time: 0.1923\n",
      "5/8, train_loss: 0.0086 step time: 0.1939\n",
      "6/8, train_loss: 0.0129 step time: 0.1935\n",
      "7/8, train_loss: 0.0088 step time: 0.1800\n",
      "8/8, train_loss: 0.0083 step time: 0.1800\n",
      "epoch 326 average loss: 0.0092\n",
      "time consuming of epoch 326 is: 1.5638\n",
      "----------\n",
      "epoch 327/600\n",
      "1/8, train_loss: 0.0085 step time: 0.2365\n",
      "2/8, train_loss: 0.0119 step time: 0.1950\n",
      "3/8, train_loss: 0.0114 step time: 0.1988\n",
      "4/8, train_loss: 0.0109 step time: 0.1987\n",
      "5/8, train_loss: 0.0082 step time: 0.1985\n",
      "6/8, train_loss: 0.0090 step time: 0.1982\n",
      "7/8, train_loss: 0.0086 step time: 0.1797\n",
      "8/8, train_loss: 0.0091 step time: 0.1795\n",
      "epoch 327 average loss: 0.0097\n",
      "time consuming of epoch 327 is: 1.5860\n",
      "----------\n",
      "epoch 328/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2349\n",
      "2/8, train_loss: 0.0112 step time: 0.1965\n",
      "3/8, train_loss: 0.0121 step time: 0.1980\n",
      "4/8, train_loss: 0.0095 step time: 0.1980\n",
      "5/8, train_loss: 0.0087 step time: 0.2061\n",
      "6/8, train_loss: 0.0087 step time: 0.2003\n",
      "7/8, train_loss: 0.0081 step time: 0.1838\n",
      "8/8, train_loss: 0.0097 step time: 0.1833\n",
      "epoch 328 average loss: 0.0100\n",
      "time consuming of epoch 328 is: 1.6019\n",
      "----------\n",
      "epoch 329/600\n",
      "1/8, train_loss: 0.0097 step time: 0.2413\n",
      "2/8, train_loss: 0.0092 step time: 0.2023\n",
      "3/8, train_loss: 0.0105 step time: 0.2002\n",
      "4/8, train_loss: 0.0085 step time: 0.2001\n",
      "5/8, train_loss: 0.0087 step time: 0.1985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/8, train_loss: 0.0109 step time: 0.1983\n",
      "7/8, train_loss: 0.0084 step time: 0.1827\n",
      "8/8, train_loss: 0.0114 step time: 0.1827\n",
      "epoch 329 average loss: 0.0097\n",
      "time consuming of epoch 329 is: 1.6078\n",
      "----------\n",
      "epoch 330/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2396\n",
      "2/8, train_loss: 0.0098 step time: 0.2019\n",
      "3/8, train_loss: 0.0101 step time: 0.1999\n",
      "4/8, train_loss: 0.0097 step time: 0.1992\n",
      "5/8, train_loss: 0.0086 step time: 0.1990\n",
      "6/8, train_loss: 0.0104 step time: 0.2018\n",
      "7/8, train_loss: 0.0094 step time: 0.1826\n",
      "8/8, train_loss: 0.0118 step time: 0.1822\n",
      "epoch 330 average loss: 0.0098\n",
      "current epoch: 330 current mean dice: 0.9616 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 330 is: 2.3631\n",
      "----------\n",
      "epoch 331/600\n",
      "1/8, train_loss: 0.0113 step time: 0.2413\n",
      "2/8, train_loss: 0.0117 step time: 0.2026\n",
      "3/8, train_loss: 0.0087 step time: 0.1981\n",
      "4/8, train_loss: 0.0088 step time: 0.1983\n",
      "5/8, train_loss: 0.0118 step time: 0.2005\n",
      "6/8, train_loss: 0.0106 step time: 0.1985\n",
      "7/8, train_loss: 0.0091 step time: 0.1809\n",
      "8/8, train_loss: 0.0099 step time: 0.1843\n",
      "epoch 331 average loss: 0.0102\n",
      "time consuming of epoch 331 is: 1.6057\n",
      "----------\n",
      "epoch 332/600\n",
      "1/8, train_loss: 0.0070 step time: 0.2416\n",
      "2/8, train_loss: 0.0087 step time: 0.2029\n",
      "3/8, train_loss: 0.0088 step time: 0.1996\n",
      "4/8, train_loss: 0.0102 step time: 0.2017\n",
      "5/8, train_loss: 0.0118 step time: 0.1986\n",
      "6/8, train_loss: 0.0108 step time: 0.2036\n",
      "7/8, train_loss: 0.0102 step time: 0.1829\n",
      "8/8, train_loss: 0.0097 step time: 0.1824\n",
      "epoch 332 average loss: 0.0097\n",
      "time consuming of epoch 332 is: 1.6145\n",
      "----------\n",
      "epoch 333/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2407\n",
      "2/8, train_loss: 0.0084 step time: 0.2000\n",
      "3/8, train_loss: 0.0103 step time: 0.2004\n",
      "4/8, train_loss: 0.0081 step time: 0.1998\n",
      "5/8, train_loss: 0.0129 step time: 0.1989\n",
      "6/8, train_loss: 0.0111 step time: 0.2003\n",
      "7/8, train_loss: 0.0097 step time: 0.1836\n",
      "8/8, train_loss: 0.0103 step time: 0.1823\n",
      "epoch 333 average loss: 0.0100\n",
      "time consuming of epoch 333 is: 1.6074\n",
      "----------\n",
      "epoch 334/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2386\n",
      "2/8, train_loss: 0.0109 step time: 0.2016\n",
      "3/8, train_loss: 0.0091 step time: 0.1987\n",
      "4/8, train_loss: 0.0087 step time: 0.1969\n",
      "5/8, train_loss: 0.0083 step time: 0.1994\n",
      "6/8, train_loss: 0.0095 step time: 0.1999\n",
      "7/8, train_loss: 0.0093 step time: 0.1844\n",
      "8/8, train_loss: 0.0096 step time: 0.1827\n",
      "epoch 334 average loss: 0.0093\n",
      "time consuming of epoch 334 is: 1.6038\n",
      "----------\n",
      "epoch 335/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2399\n",
      "2/8, train_loss: 0.0113 step time: 0.2036\n",
      "3/8, train_loss: 0.0076 step time: 0.2005\n",
      "4/8, train_loss: 0.0080 step time: 0.1998\n",
      "5/8, train_loss: 0.0086 step time: 0.1996\n",
      "6/8, train_loss: 0.0106 step time: 0.2002\n",
      "7/8, train_loss: 0.0087 step time: 0.1850\n",
      "8/8, train_loss: 0.0100 step time: 0.1826\n",
      "epoch 335 average loss: 0.0092\n",
      "current epoch: 335 current mean dice: 0.9604 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 335 is: 2.3683\n",
      "----------\n",
      "epoch 336/600\n",
      "1/8, train_loss: 0.0082 step time: 0.2413\n",
      "2/8, train_loss: 0.0087 step time: 0.1995\n",
      "3/8, train_loss: 0.0132 step time: 0.2010\n",
      "4/8, train_loss: 0.0110 step time: 0.1978\n",
      "5/8, train_loss: 0.0088 step time: 0.2012\n",
      "6/8, train_loss: 0.0103 step time: 0.1989\n",
      "7/8, train_loss: 0.0096 step time: 0.1827\n",
      "8/8, train_loss: 0.0106 step time: 0.1812\n",
      "epoch 336 average loss: 0.0100\n",
      "time consuming of epoch 336 is: 1.6046\n",
      "----------\n",
      "epoch 337/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2412\n",
      "2/8, train_loss: 0.0092 step time: 0.2041\n",
      "3/8, train_loss: 0.0107 step time: 0.2021\n",
      "4/8, train_loss: 0.0089 step time: 0.2001\n",
      "5/8, train_loss: 0.0117 step time: 0.2020\n",
      "6/8, train_loss: 0.0086 step time: 0.1992\n",
      "7/8, train_loss: 0.0105 step time: 0.1833\n",
      "8/8, train_loss: 0.0090 step time: 0.1827\n",
      "epoch 337 average loss: 0.0097\n",
      "time consuming of epoch 337 is: 1.6160\n",
      "----------\n",
      "epoch 338/600\n",
      "1/8, train_loss: 0.0103 step time: 0.2370\n",
      "2/8, train_loss: 0.0093 step time: 0.2015\n",
      "3/8, train_loss: 0.0098 step time: 0.1988\n",
      "4/8, train_loss: 0.0093 step time: 0.1997\n",
      "5/8, train_loss: 0.0093 step time: 0.2000\n",
      "6/8, train_loss: 0.0098 step time: 0.2559\n",
      "7/8, train_loss: 0.0081 step time: 0.1826\n",
      "8/8, train_loss: 0.0109 step time: 0.1819\n",
      "epoch 338 average loss: 0.0096\n",
      "time consuming of epoch 338 is: 1.6590\n",
      "----------\n",
      "epoch 339/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2386\n",
      "2/8, train_loss: 0.0108 step time: 0.1974\n",
      "3/8, train_loss: 0.0093 step time: 0.1974\n",
      "4/8, train_loss: 0.0088 step time: 0.1995\n",
      "5/8, train_loss: 0.0120 step time: 0.2007\n",
      "6/8, train_loss: 0.0089 step time: 0.2041\n",
      "7/8, train_loss: 0.0087 step time: 0.1824\n",
      "8/8, train_loss: 0.0127 step time: 0.1829\n",
      "epoch 339 average loss: 0.0102\n",
      "time consuming of epoch 339 is: 1.6043\n",
      "----------\n",
      "epoch 340/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2354\n",
      "2/8, train_loss: 0.0110 step time: 0.1985\n",
      "3/8, train_loss: 0.0128 step time: 0.2013\n",
      "4/8, train_loss: 0.0079 step time: 0.1982\n",
      "5/8, train_loss: 0.0096 step time: 0.2011\n",
      "6/8, train_loss: 0.0079 step time: 0.2012\n",
      "7/8, train_loss: 0.0104 step time: 0.1828\n",
      "8/8, train_loss: 0.0076 step time: 0.1819\n",
      "epoch 340 average loss: 0.0096\n",
      "current epoch: 340 current mean dice: 0.9605 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 340 is: 2.3561\n",
      "----------\n",
      "epoch 341/600\n",
      "1/8, train_loss: 0.0094 step time: 0.2380\n",
      "2/8, train_loss: 0.0094 step time: 0.2059\n",
      "3/8, train_loss: 0.0107 step time: 0.2042\n",
      "4/8, train_loss: 0.0081 step time: 0.1993\n",
      "5/8, train_loss: 0.0089 step time: 0.1993\n",
      "6/8, train_loss: 0.0103 step time: 0.2041\n",
      "7/8, train_loss: 0.0115 step time: 0.1836\n",
      "8/8, train_loss: 0.0083 step time: 0.1819\n",
      "epoch 341 average loss: 0.0096\n",
      "time consuming of epoch 341 is: 1.6175\n",
      "----------\n",
      "epoch 342/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2390\n",
      "2/8, train_loss: 0.0089 step time: 0.2022\n",
      "3/8, train_loss: 0.0114 step time: 0.2063\n",
      "4/8, train_loss: 0.0086 step time: 0.2005\n",
      "5/8, train_loss: 0.0082 step time: 0.1990\n",
      "6/8, train_loss: 0.0089 step time: 0.2003\n",
      "7/8, train_loss: 0.0095 step time: 0.1831\n",
      "8/8, train_loss: 0.0109 step time: 0.1829\n",
      "epoch 342 average loss: 0.0095\n",
      "time consuming of epoch 342 is: 1.6146\n",
      "----------\n",
      "epoch 343/600\n",
      "1/8, train_loss: 0.0099 step time: 0.2425\n",
      "2/8, train_loss: 0.0107 step time: 0.2041\n",
      "3/8, train_loss: 0.0085 step time: 0.1993\n",
      "4/8, train_loss: 0.0084 step time: 0.2015\n",
      "5/8, train_loss: 0.0119 step time: 0.1997\n",
      "6/8, train_loss: 0.0074 step time: 0.2016\n",
      "7/8, train_loss: 0.0083 step time: 0.1832\n",
      "8/8, train_loss: 0.0111 step time: 0.1821\n",
      "epoch 343 average loss: 0.0095\n",
      "time consuming of epoch 343 is: 1.6154\n",
      "----------\n",
      "epoch 344/600\n",
      "1/8, train_loss: 0.0101 step time: 0.2415\n",
      "2/8, train_loss: 0.0079 step time: 0.2022\n",
      "3/8, train_loss: 0.0088 step time: 0.2010\n",
      "4/8, train_loss: 0.0104 step time: 0.2055\n",
      "5/8, train_loss: 0.0096 step time: 0.2029\n",
      "6/8, train_loss: 0.0110 step time: 0.1992\n",
      "7/8, train_loss: 0.0090 step time: 0.1847\n",
      "8/8, train_loss: 0.0101 step time: 0.1844\n",
      "epoch 344 average loss: 0.0096\n",
      "time consuming of epoch 344 is: 1.6232\n",
      "----------\n",
      "epoch 345/600\n",
      "1/8, train_loss: 0.0127 step time: 0.2419\n",
      "2/8, train_loss: 0.0103 step time: 0.2063\n",
      "3/8, train_loss: 0.0078 step time: 0.2015\n",
      "4/8, train_loss: 0.0104 step time: 0.2026\n",
      "5/8, train_loss: 0.0091 step time: 0.2022\n",
      "6/8, train_loss: 0.0084 step time: 0.1995\n",
      "7/8, train_loss: 0.0100 step time: 0.1853\n",
      "8/8, train_loss: 0.0083 step time: 0.1830\n",
      "epoch 345 average loss: 0.0096\n",
      "current epoch: 345 current mean dice: 0.9611 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 345 is: 2.3796\n",
      "----------\n",
      "epoch 346/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2358\n",
      "2/8, train_loss: 0.0094 step time: 0.1991\n",
      "3/8, train_loss: 0.0115 step time: 0.2004\n",
      "4/8, train_loss: 0.0094 step time: 0.1994\n",
      "5/8, train_loss: 0.0089 step time: 0.2005\n",
      "6/8, train_loss: 0.0123 step time: 0.1975\n",
      "7/8, train_loss: 0.0091 step time: 0.1818\n",
      "8/8, train_loss: 0.0081 step time: 0.1821\n",
      "epoch 346 average loss: 0.0097\n",
      "time consuming of epoch 346 is: 1.5978\n",
      "----------\n",
      "epoch 347/600\n",
      "1/8, train_loss: 0.0081 step time: 0.2393\n",
      "2/8, train_loss: 0.0082 step time: 0.2022\n",
      "3/8, train_loss: 0.0125 step time: 0.2004\n",
      "4/8, train_loss: 0.0126 step time: 0.2061\n",
      "5/8, train_loss: 0.0096 step time: 0.2030\n",
      "6/8, train_loss: 0.0118 step time: 0.2028\n",
      "7/8, train_loss: 0.0084 step time: 0.1825\n",
      "8/8, train_loss: 0.0081 step time: 0.1823\n",
      "epoch 347 average loss: 0.0099\n",
      "time consuming of epoch 347 is: 1.6200\n",
      "----------\n",
      "epoch 348/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0085 step time: 0.2408\n",
      "2/8, train_loss: 0.0095 step time: 0.2040\n",
      "3/8, train_loss: 0.0098 step time: 0.2023\n",
      "4/8, train_loss: 0.0086 step time: 0.1998\n",
      "5/8, train_loss: 0.0085 step time: 0.2006\n",
      "6/8, train_loss: 0.0092 step time: 0.2013\n",
      "7/8, train_loss: 0.0112 step time: 0.1841\n",
      "8/8, train_loss: 0.0098 step time: 0.1823\n",
      "epoch 348 average loss: 0.0094\n",
      "time consuming of epoch 348 is: 1.6168\n",
      "----------\n",
      "epoch 349/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2409\n",
      "2/8, train_loss: 0.0101 step time: 0.2038\n",
      "3/8, train_loss: 0.0096 step time: 0.1957\n",
      "4/8, train_loss: 0.0097 step time: 0.1985\n",
      "5/8, train_loss: 0.0089 step time: 0.2000\n",
      "6/8, train_loss: 0.0083 step time: 0.1980\n",
      "7/8, train_loss: 0.0114 step time: 0.1798\n",
      "8/8, train_loss: 0.0089 step time: 0.1795\n",
      "epoch 349 average loss: 0.0095\n",
      "time consuming of epoch 349 is: 1.5976\n",
      "----------\n",
      "epoch 350/600\n",
      "1/8, train_loss: 0.0095 step time: 0.2343\n",
      "2/8, train_loss: 0.0084 step time: 0.1974\n",
      "3/8, train_loss: 0.0101 step time: 0.2052\n",
      "4/8, train_loss: 0.0083 step time: 0.2030\n",
      "5/8, train_loss: 0.0106 step time: 0.1999\n",
      "6/8, train_loss: 0.0124 step time: 0.2023\n",
      "7/8, train_loss: 0.0087 step time: 0.1825\n",
      "8/8, train_loss: 0.0111 step time: 0.1817\n",
      "epoch 350 average loss: 0.0099\n",
      "current epoch: 350 current mean dice: 0.9609 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 350 is: 2.3616\n",
      "----------\n",
      "epoch 351/600\n",
      "1/8, train_loss: 0.0087 step time: 0.2390\n",
      "2/8, train_loss: 0.0100 step time: 0.2060\n",
      "3/8, train_loss: 0.0083 step time: 0.1991\n",
      "4/8, train_loss: 0.0096 step time: 0.2018\n",
      "5/8, train_loss: 0.0105 step time: 0.2024\n",
      "6/8, train_loss: 0.0090 step time: 0.2032\n",
      "7/8, train_loss: 0.0085 step time: 0.1812\n",
      "8/8, train_loss: 0.0093 step time: 0.1810\n",
      "epoch 351 average loss: 0.0092\n",
      "time consuming of epoch 351 is: 1.6148\n",
      "----------\n",
      "epoch 352/600\n",
      "1/8, train_loss: 0.0100 step time: 0.2417\n",
      "2/8, train_loss: 0.0087 step time: 0.1986\n",
      "3/8, train_loss: 0.0080 step time: 0.1979\n",
      "4/8, train_loss: 0.0095 step time: 0.1985\n",
      "5/8, train_loss: 0.0091 step time: 0.2068\n",
      "6/8, train_loss: 0.0108 step time: 0.2026\n",
      "7/8, train_loss: 0.0092 step time: 0.1824\n",
      "8/8, train_loss: 0.0089 step time: 0.1809\n",
      "epoch 352 average loss: 0.0093\n",
      "time consuming of epoch 352 is: 1.6107\n",
      "----------\n",
      "epoch 353/600\n",
      "1/8, train_loss: 0.0100 step time: 0.2355\n",
      "2/8, train_loss: 0.0090 step time: 0.1998\n",
      "3/8, train_loss: 0.0090 step time: 0.2071\n",
      "4/8, train_loss: 0.0091 step time: 0.2047\n",
      "5/8, train_loss: 0.0088 step time: 0.2037\n",
      "6/8, train_loss: 0.0102 step time: 0.2023\n",
      "7/8, train_loss: 0.0092 step time: 0.1820\n",
      "8/8, train_loss: 0.0108 step time: 0.1837\n",
      "epoch 353 average loss: 0.0095\n",
      "time consuming of epoch 353 is: 1.6203\n",
      "----------\n",
      "epoch 354/600\n",
      "1/8, train_loss: 0.0082 step time: 0.2424\n",
      "2/8, train_loss: 0.0087 step time: 0.2042\n",
      "3/8, train_loss: 0.0124 step time: 0.2021\n",
      "4/8, train_loss: 0.0085 step time: 0.1990\n",
      "5/8, train_loss: 0.0086 step time: 0.1981\n",
      "6/8, train_loss: 0.0088 step time: 0.2036\n",
      "7/8, train_loss: 0.0105 step time: 0.1816\n",
      "8/8, train_loss: 0.0109 step time: 0.1827\n",
      "epoch 354 average loss: 0.0096\n",
      "time consuming of epoch 354 is: 1.6153\n",
      "----------\n",
      "epoch 355/600\n",
      "1/8, train_loss: 0.0096 step time: 0.2395\n",
      "2/8, train_loss: 0.0079 step time: 0.2035\n",
      "3/8, train_loss: 0.0127 step time: 0.1997\n",
      "4/8, train_loss: 0.0089 step time: 0.2022\n",
      "5/8, train_loss: 0.0080 step time: 0.2018\n",
      "6/8, train_loss: 0.0095 step time: 0.2027\n",
      "7/8, train_loss: 0.0090 step time: 0.1833\n",
      "8/8, train_loss: 0.0119 step time: 0.1825\n",
      "epoch 355 average loss: 0.0097\n",
      "current epoch: 355 current mean dice: 0.9606 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 355 is: 2.3739\n",
      "----------\n",
      "epoch 356/600\n",
      "1/8, train_loss: 0.0088 step time: 0.2303\n",
      "2/8, train_loss: 0.0100 step time: 0.1976\n",
      "3/8, train_loss: 0.0084 step time: 0.2032\n",
      "4/8, train_loss: 0.0097 step time: 0.1965\n",
      "5/8, train_loss: 0.0121 step time: 0.2012\n",
      "6/8, train_loss: 0.0109 step time: 0.2022\n",
      "7/8, train_loss: 0.0093 step time: 0.1836\n",
      "8/8, train_loss: 0.0104 step time: 0.1837\n",
      "epoch 356 average loss: 0.0100\n",
      "time consuming of epoch 356 is: 1.5994\n",
      "----------\n",
      "epoch 357/600\n",
      "1/8, train_loss: 0.0079 step time: 0.2413\n",
      "2/8, train_loss: 0.0128 step time: 0.2049\n",
      "3/8, train_loss: 0.0115 step time: 0.2030\n",
      "4/8, train_loss: 0.0077 step time: 0.2025\n",
      "5/8, train_loss: 0.0096 step time: 0.1987\n",
      "6/8, train_loss: 0.0082 step time: 0.2031\n",
      "7/8, train_loss: 0.0094 step time: 0.1826\n",
      "8/8, train_loss: 0.0084 step time: 0.1836\n",
      "epoch 357 average loss: 0.0094\n",
      "time consuming of epoch 357 is: 1.6210\n",
      "----------\n",
      "epoch 358/600\n",
      "1/8, train_loss: 0.0080 step time: 0.2435\n",
      "2/8, train_loss: 0.0106 step time: 0.2051\n",
      "3/8, train_loss: 0.0075 step time: 0.2001\n",
      "4/8, train_loss: 0.0098 step time: 0.2031\n",
      "5/8, train_loss: 0.0087 step time: 0.1984\n",
      "6/8, train_loss: 0.0093 step time: 0.1988\n",
      "7/8, train_loss: 0.0096 step time: 0.1817\n",
      "8/8, train_loss: 0.0092 step time: 0.1818\n",
      "epoch 358 average loss: 0.0091\n",
      "time consuming of epoch 358 is: 1.6140\n",
      "----------\n",
      "epoch 359/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2371\n",
      "2/8, train_loss: 0.0131 step time: 0.2003\n",
      "3/8, train_loss: 0.0094 step time: 0.2000\n",
      "4/8, train_loss: 0.0082 step time: 0.2023\n",
      "5/8, train_loss: 0.0102 step time: 0.1993\n",
      "6/8, train_loss: 0.0081 step time: 0.2010\n",
      "7/8, train_loss: 0.0089 step time: 0.1823\n",
      "8/8, train_loss: 0.0110 step time: 0.1828\n",
      "epoch 359 average loss: 0.0098\n",
      "time consuming of epoch 359 is: 1.6066\n",
      "----------\n",
      "epoch 360/600\n",
      "1/8, train_loss: 0.0087 step time: 0.2364\n",
      "2/8, train_loss: 0.0073 step time: 0.2002\n",
      "3/8, train_loss: 0.0111 step time: 0.2028\n",
      "4/8, train_loss: 0.0098 step time: 0.2044\n",
      "5/8, train_loss: 0.0108 step time: 0.2003\n",
      "6/8, train_loss: 0.0090 step time: 0.2016\n",
      "7/8, train_loss: 0.0087 step time: 0.1853\n",
      "8/8, train_loss: 0.0085 step time: 0.1826\n",
      "epoch 360 average loss: 0.0092\n",
      "current epoch: 360 current mean dice: 0.9603 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 360 is: 2.3711\n",
      "----------\n",
      "epoch 361/600\n",
      "1/8, train_loss: 0.0083 step time: 0.2279\n",
      "2/8, train_loss: 0.0092 step time: 0.1985\n",
      "3/8, train_loss: 0.0086 step time: 0.1953\n",
      "4/8, train_loss: 0.0139 step time: 0.1935\n",
      "5/8, train_loss: 0.0114 step time: 0.1950\n",
      "6/8, train_loss: 0.0081 step time: 0.1957\n",
      "7/8, train_loss: 0.0110 step time: 0.1840\n",
      "8/8, train_loss: 0.0087 step time: 0.1828\n",
      "epoch 361 average loss: 0.0099\n",
      "time consuming of epoch 361 is: 1.5738\n",
      "----------\n",
      "epoch 362/600\n",
      "1/8, train_loss: 0.0099 step time: 0.2338\n",
      "2/8, train_loss: 0.0094 step time: 0.1976\n",
      "3/8, train_loss: 0.0086 step time: 0.1966\n",
      "4/8, train_loss: 0.0116 step time: 0.1953\n",
      "5/8, train_loss: 0.0111 step time: 0.1961\n",
      "6/8, train_loss: 0.0084 step time: 0.1947\n",
      "7/8, train_loss: 0.0084 step time: 0.1824\n",
      "8/8, train_loss: 0.0115 step time: 0.1825\n",
      "epoch 362 average loss: 0.0099\n",
      "time consuming of epoch 362 is: 1.5808\n",
      "----------\n",
      "epoch 363/600\n",
      "1/8, train_loss: 0.0087 step time: 0.2318\n",
      "2/8, train_loss: 0.0090 step time: 0.1952\n",
      "3/8, train_loss: 0.0100 step time: 0.1971\n",
      "4/8, train_loss: 0.0102 step time: 0.1964\n",
      "5/8, train_loss: 0.0108 step time: 0.1962\n",
      "6/8, train_loss: 0.0093 step time: 0.1951\n",
      "7/8, train_loss: 0.0083 step time: 0.1821\n",
      "8/8, train_loss: 0.0087 step time: 0.1822\n",
      "epoch 363 average loss: 0.0094\n",
      "time consuming of epoch 363 is: 1.5776\n",
      "----------\n",
      "epoch 364/600\n",
      "1/8, train_loss: 0.0081 step time: 0.2392\n",
      "2/8, train_loss: 0.0087 step time: 0.2019\n",
      "3/8, train_loss: 0.0089 step time: 0.2030\n",
      "4/8, train_loss: 0.0087 step time: 0.1994\n",
      "5/8, train_loss: 0.0116 step time: 0.2029\n",
      "6/8, train_loss: 0.0085 step time: 0.2013\n",
      "7/8, train_loss: 0.0098 step time: 0.1837\n",
      "8/8, train_loss: 0.0112 step time: 0.1828\n",
      "epoch 364 average loss: 0.0094\n",
      "time consuming of epoch 364 is: 1.6159\n",
      "----------\n",
      "epoch 365/600\n",
      "1/8, train_loss: 0.0095 step time: 0.2398\n",
      "2/8, train_loss: 0.0113 step time: 0.2019\n",
      "3/8, train_loss: 0.0081 step time: 0.1996\n",
      "4/8, train_loss: 0.0103 step time: 0.2018\n",
      "5/8, train_loss: 0.0083 step time: 0.2027\n",
      "6/8, train_loss: 0.0108 step time: 0.2017\n",
      "7/8, train_loss: 0.0074 step time: 0.1836\n",
      "8/8, train_loss: 0.0089 step time: 0.1835\n",
      "epoch 365 average loss: 0.0093\n",
      "current epoch: 365 current mean dice: 0.9618 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 365 is: 2.3721\n",
      "----------\n",
      "epoch 366/600\n",
      "1/8, train_loss: 0.0089 step time: 0.2391\n",
      "2/8, train_loss: 0.0090 step time: 0.1998\n",
      "3/8, train_loss: 0.0088 step time: 0.2008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/8, train_loss: 0.0081 step time: 0.2019\n",
      "5/8, train_loss: 0.0089 step time: 0.1971\n",
      "6/8, train_loss: 0.0095 step time: 0.1985\n",
      "7/8, train_loss: 0.0107 step time: 0.1821\n",
      "8/8, train_loss: 0.0086 step time: 0.1810\n",
      "epoch 366 average loss: 0.0091\n",
      "time consuming of epoch 366 is: 1.6015\n",
      "----------\n",
      "epoch 367/600\n",
      "1/8, train_loss: 0.0085 step time: 0.2416\n",
      "2/8, train_loss: 0.0083 step time: 0.2052\n",
      "3/8, train_loss: 0.0082 step time: 0.1992\n",
      "4/8, train_loss: 0.0096 step time: 0.2005\n",
      "5/8, train_loss: 0.0104 step time: 0.1992\n",
      "6/8, train_loss: 0.0100 step time: 0.2001\n",
      "7/8, train_loss: 0.0111 step time: 0.1844\n",
      "8/8, train_loss: 0.0095 step time: 0.1806\n",
      "epoch 367 average loss: 0.0094\n",
      "time consuming of epoch 367 is: 1.6123\n",
      "----------\n",
      "epoch 368/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2363\n",
      "2/8, train_loss: 0.0079 step time: 0.1979\n",
      "3/8, train_loss: 0.0086 step time: 0.1989\n",
      "4/8, train_loss: 0.0097 step time: 0.1981\n",
      "5/8, train_loss: 0.0091 step time: 0.1972\n",
      "6/8, train_loss: 0.0091 step time: 0.1962\n",
      "7/8, train_loss: 0.0092 step time: 0.1823\n",
      "8/8, train_loss: 0.0101 step time: 0.1835\n",
      "epoch 368 average loss: 0.0091\n",
      "time consuming of epoch 368 is: 1.5915\n",
      "----------\n",
      "epoch 369/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2431\n",
      "2/8, train_loss: 0.0110 step time: 0.2030\n",
      "3/8, train_loss: 0.0095 step time: 0.1994\n",
      "4/8, train_loss: 0.0083 step time: 0.1979\n",
      "5/8, train_loss: 0.0091 step time: 0.2006\n",
      "6/8, train_loss: 0.0115 step time: 0.2017\n",
      "7/8, train_loss: 0.0083 step time: 0.1838\n",
      "8/8, train_loss: 0.0082 step time: 0.1829\n",
      "epoch 369 average loss: 0.0094\n",
      "time consuming of epoch 369 is: 1.6137\n",
      "----------\n",
      "epoch 370/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2425\n",
      "2/8, train_loss: 0.0086 step time: 0.2025\n",
      "3/8, train_loss: 0.0092 step time: 0.1989\n",
      "4/8, train_loss: 0.0074 step time: 0.2012\n",
      "5/8, train_loss: 0.0096 step time: 0.1980\n",
      "6/8, train_loss: 0.0084 step time: 0.2007\n",
      "7/8, train_loss: 0.0114 step time: 0.1838\n",
      "8/8, train_loss: 0.0085 step time: 0.1826\n",
      "epoch 370 average loss: 0.0094\n",
      "current epoch: 370 current mean dice: 0.9601 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 370 is: 2.3677\n",
      "----------\n",
      "epoch 371/600\n",
      "1/8, train_loss: 0.0082 step time: 0.2306\n",
      "2/8, train_loss: 0.0084 step time: 0.1963\n",
      "3/8, train_loss: 0.0087 step time: 0.1946\n",
      "4/8, train_loss: 0.0094 step time: 0.1936\n",
      "5/8, train_loss: 0.0124 step time: 0.1949\n",
      "6/8, train_loss: 0.0105 step time: 0.1932\n",
      "7/8, train_loss: 0.0091 step time: 0.1810\n",
      "8/8, train_loss: 0.0085 step time: 0.1811\n",
      "epoch 371 average loss: 0.0094\n",
      "time consuming of epoch 371 is: 1.5664\n",
      "----------\n",
      "epoch 372/600\n",
      "1/8, train_loss: 0.0108 step time: 0.2397\n",
      "2/8, train_loss: 0.0106 step time: 0.1990\n",
      "3/8, train_loss: 0.0100 step time: 0.1992\n",
      "4/8, train_loss: 0.0080 step time: 0.1990\n",
      "5/8, train_loss: 0.0086 step time: 0.2002\n",
      "6/8, train_loss: 0.0096 step time: 0.1973\n",
      "7/8, train_loss: 0.0086 step time: 0.1825\n",
      "8/8, train_loss: 0.0091 step time: 0.1826\n",
      "epoch 372 average loss: 0.0094\n",
      "time consuming of epoch 372 is: 1.6008\n",
      "----------\n",
      "epoch 373/600\n",
      "1/8, train_loss: 0.0130 step time: 0.2379\n",
      "2/8, train_loss: 0.0108 step time: 0.1995\n",
      "3/8, train_loss: 0.0088 step time: 0.2035\n",
      "4/8, train_loss: 0.0100 step time: 0.1993\n",
      "5/8, train_loss: 0.0083 step time: 0.2016\n",
      "6/8, train_loss: 0.0089 step time: 0.1980\n",
      "7/8, train_loss: 0.0105 step time: 0.1825\n",
      "8/8, train_loss: 0.0097 step time: 0.1820\n",
      "epoch 373 average loss: 0.0100\n",
      "time consuming of epoch 373 is: 1.6055\n",
      "----------\n",
      "epoch 374/600\n",
      "1/8, train_loss: 0.0114 step time: 0.2376\n",
      "2/8, train_loss: 0.0104 step time: 0.2024\n",
      "3/8, train_loss: 0.0097 step time: 0.1993\n",
      "4/8, train_loss: 0.0095 step time: 0.1984\n",
      "5/8, train_loss: 0.0086 step time: 0.2003\n",
      "6/8, train_loss: 0.0112 step time: 0.2004\n",
      "7/8, train_loss: 0.0094 step time: 0.1841\n",
      "8/8, train_loss: 0.0166 step time: 0.1829\n",
      "epoch 374 average loss: 0.0108\n",
      "time consuming of epoch 374 is: 1.6072\n",
      "----------\n",
      "epoch 375/600\n",
      "1/8, train_loss: 0.0097 step time: 0.2423\n",
      "2/8, train_loss: 0.0120 step time: 0.2003\n",
      "3/8, train_loss: 0.0129 step time: 0.2017\n",
      "4/8, train_loss: 0.0104 step time: 0.2003\n",
      "5/8, train_loss: 0.0161 step time: 0.2012\n",
      "6/8, train_loss: 0.0148 step time: 0.2004\n",
      "7/8, train_loss: 0.0130 step time: 0.1819\n",
      "8/8, train_loss: 0.0173 step time: 0.1822\n",
      "epoch 375 average loss: 0.0133\n",
      "current epoch: 375 current mean dice: 0.9425 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 375 is: 2.3671\n",
      "----------\n",
      "epoch 376/600\n",
      "1/8, train_loss: 0.0194 step time: 0.2371\n",
      "2/8, train_loss: 0.0156 step time: 0.1994\n",
      "3/8, train_loss: 0.0152 step time: 0.1992\n",
      "4/8, train_loss: 0.0137 step time: 0.1982\n",
      "5/8, train_loss: 0.0148 step time: 0.1982\n",
      "6/8, train_loss: 0.0146 step time: 0.1983\n",
      "7/8, train_loss: 0.0120 step time: 0.1813\n",
      "8/8, train_loss: 0.0115 step time: 0.1818\n",
      "epoch 376 average loss: 0.0146\n",
      "time consuming of epoch 376 is: 1.5944\n",
      "----------\n",
      "epoch 377/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2396\n",
      "2/8, train_loss: 0.0122 step time: 0.2032\n",
      "3/8, train_loss: 0.0109 step time: 0.2017\n",
      "4/8, train_loss: 0.0119 step time: 0.1996\n",
      "5/8, train_loss: 0.0116 step time: 0.2067\n",
      "6/8, train_loss: 0.0147 step time: 0.1999\n",
      "7/8, train_loss: 0.0121 step time: 0.1851\n",
      "8/8, train_loss: 0.0156 step time: 0.1820\n",
      "epoch 377 average loss: 0.0128\n",
      "time consuming of epoch 377 is: 1.6193\n",
      "----------\n",
      "epoch 378/600\n",
      "1/8, train_loss: 0.0100 step time: 0.2403\n",
      "2/8, train_loss: 0.0092 step time: 0.2030\n",
      "3/8, train_loss: 0.0139 step time: 0.2021\n",
      "4/8, train_loss: 0.0129 step time: 0.2032\n",
      "5/8, train_loss: 0.0141 step time: 0.2016\n",
      "6/8, train_loss: 0.0119 step time: 0.2018\n",
      "7/8, train_loss: 0.0100 step time: 0.1841\n",
      "8/8, train_loss: 0.0136 step time: 0.1839\n",
      "epoch 378 average loss: 0.0120\n",
      "time consuming of epoch 378 is: 1.6216\n",
      "----------\n",
      "epoch 379/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2400\n",
      "2/8, train_loss: 0.0127 step time: 0.2031\n",
      "3/8, train_loss: 0.0129 step time: 0.1996\n",
      "4/8, train_loss: 0.0109 step time: 0.2002\n",
      "5/8, train_loss: 0.0097 step time: 0.2042\n",
      "6/8, train_loss: 0.0105 step time: 0.2029\n",
      "7/8, train_loss: 0.0116 step time: 0.1827\n",
      "8/8, train_loss: 0.0133 step time: 0.1817\n",
      "epoch 379 average loss: 0.0115\n",
      "time consuming of epoch 379 is: 1.6160\n",
      "----------\n",
      "epoch 380/600\n",
      "1/8, train_loss: 0.0124 step time: 0.2369\n",
      "2/8, train_loss: 0.0109 step time: 0.1979\n",
      "3/8, train_loss: 0.0106 step time: 0.1966\n",
      "4/8, train_loss: 0.0122 step time: 0.1991\n",
      "5/8, train_loss: 0.0107 step time: 0.2008\n",
      "6/8, train_loss: 0.0095 step time: 0.2018\n",
      "7/8, train_loss: 0.0142 step time: 0.1827\n",
      "8/8, train_loss: 0.0143 step time: 0.1825\n",
      "epoch 380 average loss: 0.0118\n",
      "current epoch: 380 current mean dice: 0.9586 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 380 is: 2.3579\n",
      "----------\n",
      "epoch 381/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2375\n",
      "2/8, train_loss: 0.0102 step time: 0.1985\n",
      "3/8, train_loss: 0.0103 step time: 0.1984\n",
      "4/8, train_loss: 0.0154 step time: 0.1987\n",
      "5/8, train_loss: 0.0124 step time: 0.1979\n",
      "6/8, train_loss: 0.0118 step time: 0.1979\n",
      "7/8, train_loss: 0.0120 step time: 0.1831\n",
      "8/8, train_loss: 0.0154 step time: 0.1829\n",
      "epoch 381 average loss: 0.0123\n",
      "time consuming of epoch 381 is: 1.5960\n",
      "----------\n",
      "epoch 382/600\n",
      "1/8, train_loss: 0.0116 step time: 0.2411\n",
      "2/8, train_loss: 0.0135 step time: 0.2035\n",
      "3/8, train_loss: 0.0137 step time: 0.2027\n",
      "4/8, train_loss: 0.0138 step time: 0.1990\n",
      "5/8, train_loss: 0.0118 step time: 0.2029\n",
      "6/8, train_loss: 0.0103 step time: 0.2029\n",
      "7/8, train_loss: 0.0145 step time: 0.1827\n",
      "8/8, train_loss: 0.0135 step time: 0.1828\n",
      "epoch 382 average loss: 0.0128\n",
      "time consuming of epoch 382 is: 1.6190\n",
      "----------\n",
      "epoch 383/600\n",
      "1/8, train_loss: 0.0140 step time: 0.2384\n",
      "2/8, train_loss: 0.0127 step time: 0.2031\n",
      "3/8, train_loss: 0.0115 step time: 0.2024\n",
      "4/8, train_loss: 0.0173 step time: 0.1999\n",
      "5/8, train_loss: 0.0153 step time: 0.2001\n",
      "6/8, train_loss: 0.0103 step time: 0.2020\n",
      "7/8, train_loss: 0.0133 step time: 0.1832\n",
      "8/8, train_loss: 0.0166 step time: 0.1827\n",
      "epoch 383 average loss: 0.0139\n",
      "time consuming of epoch 383 is: 1.6133\n",
      "----------\n",
      "epoch 384/600\n",
      "1/8, train_loss: 0.0136 step time: 0.2407\n",
      "2/8, train_loss: 0.0200 step time: 0.2031\n",
      "3/8, train_loss: 0.0115 step time: 0.1998\n",
      "4/8, train_loss: 0.0116 step time: 0.2019\n",
      "5/8, train_loss: 0.0113 step time: 0.2021\n",
      "6/8, train_loss: 0.0112 step time: 0.2009\n",
      "7/8, train_loss: 0.0155 step time: 0.1834\n",
      "8/8, train_loss: 0.0121 step time: 0.1825\n",
      "epoch 384 average loss: 0.0133\n",
      "time consuming of epoch 384 is: 1.6161\n",
      "----------\n",
      "epoch 385/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0111 step time: 0.2408\n",
      "2/8, train_loss: 0.0154 step time: 0.2024\n",
      "3/8, train_loss: 0.0138 step time: 0.2024\n",
      "4/8, train_loss: 0.0108 step time: 0.2000\n",
      "5/8, train_loss: 0.0115 step time: 0.1990\n",
      "6/8, train_loss: 0.0105 step time: 0.1993\n",
      "7/8, train_loss: 0.0123 step time: 0.1836\n",
      "8/8, train_loss: 0.0148 step time: 0.1825\n",
      "epoch 385 average loss: 0.0125\n",
      "current epoch: 385 current mean dice: 0.9523 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 385 is: 2.3676\n",
      "----------\n",
      "epoch 386/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2375\n",
      "2/8, train_loss: 0.0098 step time: 0.1999\n",
      "3/8, train_loss: 0.0125 step time: 0.1987\n",
      "4/8, train_loss: 0.0120 step time: 0.2019\n",
      "5/8, train_loss: 0.0105 step time: 0.1975\n",
      "6/8, train_loss: 0.0130 step time: 0.1984\n",
      "7/8, train_loss: 0.0117 step time: 0.1819\n",
      "8/8, train_loss: 0.0139 step time: 0.1818\n",
      "epoch 386 average loss: 0.0117\n",
      "time consuming of epoch 386 is: 1.5986\n",
      "----------\n",
      "epoch 387/600\n",
      "1/8, train_loss: 0.0117 step time: 0.2412\n",
      "2/8, train_loss: 0.0107 step time: 0.2042\n",
      "3/8, train_loss: 0.0113 step time: 0.2012\n",
      "4/8, train_loss: 0.0089 step time: 0.2002\n",
      "5/8, train_loss: 0.0143 step time: 0.2031\n",
      "6/8, train_loss: 0.0118 step time: 0.2033\n",
      "7/8, train_loss: 0.0100 step time: 0.1831\n",
      "8/8, train_loss: 0.0136 step time: 0.1827\n",
      "epoch 387 average loss: 0.0116\n",
      "time consuming of epoch 387 is: 1.6203\n",
      "----------\n",
      "epoch 388/600\n",
      "1/8, train_loss: 0.0139 step time: 0.2419\n",
      "2/8, train_loss: 0.0117 step time: 0.2040\n",
      "3/8, train_loss: 0.0122 step time: 0.2042\n",
      "4/8, train_loss: 0.0132 step time: 0.2020\n",
      "5/8, train_loss: 0.0112 step time: 0.2013\n",
      "6/8, train_loss: 0.0091 step time: 0.2019\n",
      "7/8, train_loss: 0.0103 step time: 0.1836\n",
      "8/8, train_loss: 0.0110 step time: 0.1825\n",
      "epoch 388 average loss: 0.0116\n",
      "time consuming of epoch 388 is: 1.6231\n",
      "----------\n",
      "epoch 389/600\n",
      "1/8, train_loss: 0.0095 step time: 0.2389\n",
      "2/8, train_loss: 0.0100 step time: 0.2102\n",
      "3/8, train_loss: 0.0110 step time: 0.2108\n",
      "4/8, train_loss: 0.0126 step time: 0.2001\n",
      "5/8, train_loss: 0.0096 step time: 0.1991\n",
      "6/8, train_loss: 0.0157 step time: 0.2053\n",
      "7/8, train_loss: 0.0124 step time: 0.1825\n",
      "8/8, train_loss: 0.0092 step time: 0.1838\n",
      "epoch 389 average loss: 0.0113\n",
      "time consuming of epoch 389 is: 1.6323\n",
      "----------\n",
      "epoch 390/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2407\n",
      "2/8, train_loss: 0.0106 step time: 0.2052\n",
      "3/8, train_loss: 0.0104 step time: 0.2017\n",
      "4/8, train_loss: 0.0136 step time: 0.2047\n",
      "5/8, train_loss: 0.0106 step time: 0.2019\n",
      "6/8, train_loss: 0.0117 step time: 0.1994\n",
      "7/8, train_loss: 0.0093 step time: 0.1836\n",
      "8/8, train_loss: 0.0100 step time: 0.1830\n",
      "epoch 390 average loss: 0.0108\n",
      "current epoch: 390 current mean dice: 0.9611 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 390 is: 2.3781\n",
      "----------\n",
      "epoch 391/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2391\n",
      "2/8, train_loss: 0.0101 step time: 0.1988\n",
      "3/8, train_loss: 0.0104 step time: 0.2026\n",
      "4/8, train_loss: 0.0099 step time: 0.1965\n",
      "5/8, train_loss: 0.0109 step time: 0.2012\n",
      "6/8, train_loss: 0.0107 step time: 0.1991\n",
      "7/8, train_loss: 0.0102 step time: 0.1825\n",
      "8/8, train_loss: 0.0112 step time: 0.1813\n",
      "epoch 391 average loss: 0.0105\n",
      "time consuming of epoch 391 is: 1.6022\n",
      "----------\n",
      "epoch 392/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2370\n",
      "2/8, train_loss: 0.0102 step time: 0.1968\n",
      "3/8, train_loss: 0.0120 step time: 0.1957\n",
      "4/8, train_loss: 0.0103 step time: 0.1959\n",
      "5/8, train_loss: 0.0112 step time: 0.2043\n",
      "6/8, train_loss: 0.0088 step time: 0.2010\n",
      "7/8, train_loss: 0.0111 step time: 0.1836\n",
      "8/8, train_loss: 0.0112 step time: 0.1824\n",
      "epoch 392 average loss: 0.0105\n",
      "time consuming of epoch 392 is: 1.5983\n",
      "----------\n",
      "epoch 393/600\n",
      "1/8, train_loss: 0.0100 step time: 0.2393\n",
      "2/8, train_loss: 0.0103 step time: 0.1990\n",
      "3/8, train_loss: 0.0090 step time: 0.1959\n",
      "4/8, train_loss: 0.0104 step time: 0.1979\n",
      "5/8, train_loss: 0.0097 step time: 0.2025\n",
      "6/8, train_loss: 0.0096 step time: 0.2017\n",
      "7/8, train_loss: 0.0106 step time: 0.1840\n",
      "8/8, train_loss: 0.0100 step time: 0.1806\n",
      "epoch 393 average loss: 0.0100\n",
      "time consuming of epoch 393 is: 1.6023\n",
      "----------\n",
      "epoch 394/600\n",
      "1/8, train_loss: 0.0109 step time: 0.2380\n",
      "2/8, train_loss: 0.0105 step time: 0.2037\n",
      "3/8, train_loss: 0.0116 step time: 0.2014\n",
      "4/8, train_loss: 0.0097 step time: 0.1994\n",
      "5/8, train_loss: 0.0088 step time: 0.2021\n",
      "6/8, train_loss: 0.0097 step time: 0.1990\n",
      "7/8, train_loss: 0.0105 step time: 0.1837\n",
      "8/8, train_loss: 0.0078 step time: 0.1832\n",
      "epoch 394 average loss: 0.0100\n",
      "time consuming of epoch 394 is: 1.6119\n",
      "----------\n",
      "epoch 395/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2381\n",
      "2/8, train_loss: 0.0105 step time: 0.2040\n",
      "3/8, train_loss: 0.0098 step time: 0.2000\n",
      "4/8, train_loss: 0.0138 step time: 0.1993\n",
      "5/8, train_loss: 0.0095 step time: 0.2011\n",
      "6/8, train_loss: 0.0109 step time: 0.1984\n",
      "7/8, train_loss: 0.0084 step time: 0.1823\n",
      "8/8, train_loss: 0.0122 step time: 0.1833\n",
      "epoch 395 average loss: 0.0106\n",
      "current epoch: 395 current mean dice: 0.9604 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 395 is: 2.3638\n",
      "----------\n",
      "epoch 396/600\n",
      "1/8, train_loss: 0.0095 step time: 0.2392\n",
      "2/8, train_loss: 0.0114 step time: 0.2001\n",
      "3/8, train_loss: 0.0105 step time: 0.1986\n",
      "4/8, train_loss: 0.0086 step time: 0.1992\n",
      "5/8, train_loss: 0.0112 step time: 0.1990\n",
      "6/8, train_loss: 0.0082 step time: 0.2023\n",
      "7/8, train_loss: 0.0120 step time: 0.1818\n",
      "8/8, train_loss: 0.0108 step time: 0.1826\n",
      "epoch 396 average loss: 0.0103\n",
      "time consuming of epoch 396 is: 1.6042\n",
      "----------\n",
      "epoch 397/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2407\n",
      "2/8, train_loss: 0.0121 step time: 0.2038\n",
      "3/8, train_loss: 0.0083 step time: 0.1978\n",
      "4/8, train_loss: 0.0079 step time: 0.2007\n",
      "5/8, train_loss: 0.0104 step time: 0.2030\n",
      "6/8, train_loss: 0.0102 step time: 0.1991\n",
      "7/8, train_loss: 0.0088 step time: 0.1812\n",
      "8/8, train_loss: 0.0096 step time: 0.1815\n",
      "epoch 397 average loss: 0.0097\n",
      "time consuming of epoch 397 is: 1.6089\n",
      "----------\n",
      "epoch 398/600\n",
      "1/8, train_loss: 0.0088 step time: 0.2416\n",
      "2/8, train_loss: 0.0098 step time: 0.2026\n",
      "3/8, train_loss: 0.0102 step time: 0.1996\n",
      "4/8, train_loss: 0.0092 step time: 0.2010\n",
      "5/8, train_loss: 0.0081 step time: 0.2045\n",
      "6/8, train_loss: 0.0083 step time: 0.1995\n",
      "7/8, train_loss: 0.0103 step time: 0.1837\n",
      "8/8, train_loss: 0.0082 step time: 0.1826\n",
      "epoch 398 average loss: 0.0091\n",
      "time consuming of epoch 398 is: 1.6168\n",
      "----------\n",
      "epoch 399/600\n",
      "1/8, train_loss: 0.0096 step time: 0.2401\n",
      "2/8, train_loss: 0.0087 step time: 0.2002\n",
      "3/8, train_loss: 0.0133 step time: 0.2021\n",
      "4/8, train_loss: 0.0106 step time: 0.1996\n",
      "5/8, train_loss: 0.0088 step time: 0.2008\n",
      "6/8, train_loss: 0.0080 step time: 0.2029\n",
      "7/8, train_loss: 0.0086 step time: 0.1824\n",
      "8/8, train_loss: 0.0113 step time: 0.1822\n",
      "epoch 399 average loss: 0.0099\n",
      "time consuming of epoch 399 is: 1.6120\n",
      "----------\n",
      "epoch 400/600\n",
      "1/8, train_loss: 0.0116 step time: 0.2404\n",
      "2/8, train_loss: 0.0108 step time: 0.2027\n",
      "3/8, train_loss: 0.0088 step time: 0.2004\n",
      "4/8, train_loss: 0.0081 step time: 0.1989\n",
      "5/8, train_loss: 0.0141 step time: 0.1991\n",
      "6/8, train_loss: 0.0086 step time: 0.2025\n",
      "7/8, train_loss: 0.0090 step time: 0.1834\n",
      "8/8, train_loss: 0.0102 step time: 0.1825\n",
      "epoch 400 average loss: 0.0101\n",
      "current epoch: 400 current mean dice: 0.9613 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 400 is: 2.3678\n",
      "----------\n",
      "epoch 401/600\n",
      "1/8, train_loss: 0.0106 step time: 0.2299\n",
      "2/8, train_loss: 0.0095 step time: 0.1936\n",
      "3/8, train_loss: 0.0089 step time: 0.1949\n",
      "4/8, train_loss: 0.0107 step time: 0.1971\n",
      "5/8, train_loss: 0.0102 step time: 0.1981\n",
      "6/8, train_loss: 0.0094 step time: 0.1947\n",
      "7/8, train_loss: 0.0109 step time: 0.1833\n",
      "8/8, train_loss: 0.0085 step time: 0.1824\n",
      "epoch 401 average loss: 0.0098\n",
      "time consuming of epoch 401 is: 1.5751\n",
      "----------\n",
      "epoch 402/600\n",
      "1/8, train_loss: 0.0100 step time: 0.2360\n",
      "2/8, train_loss: 0.0109 step time: 0.2024\n",
      "3/8, train_loss: 0.0103 step time: 0.2013\n",
      "4/8, train_loss: 0.0096 step time: 0.2003\n",
      "5/8, train_loss: 0.0096 step time: 0.2009\n",
      "6/8, train_loss: 0.0093 step time: 0.2050\n",
      "7/8, train_loss: 0.0081 step time: 0.1824\n",
      "8/8, train_loss: 0.0119 step time: 0.1839\n",
      "epoch 402 average loss: 0.0100\n",
      "time consuming of epoch 402 is: 1.6139\n",
      "----------\n",
      "epoch 403/600\n",
      "1/8, train_loss: 0.0096 step time: 0.2375\n",
      "2/8, train_loss: 0.0138 step time: 0.2000\n",
      "3/8, train_loss: 0.0080 step time: 0.1977\n",
      "4/8, train_loss: 0.0096 step time: 0.1958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8, train_loss: 0.0100 step time: 0.1967\n",
      "6/8, train_loss: 0.0124 step time: 0.1973\n",
      "7/8, train_loss: 0.0100 step time: 0.1842\n",
      "8/8, train_loss: 0.0087 step time: 0.1843\n",
      "epoch 403 average loss: 0.0103\n",
      "time consuming of epoch 403 is: 1.5954\n",
      "----------\n",
      "epoch 404/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2352\n",
      "2/8, train_loss: 0.0106 step time: 0.1994\n",
      "3/8, train_loss: 0.0095 step time: 0.1971\n",
      "4/8, train_loss: 0.0098 step time: 0.1947\n",
      "5/8, train_loss: 0.0099 step time: 0.1989\n",
      "6/8, train_loss: 0.0119 step time: 0.2032\n",
      "7/8, train_loss: 0.0086 step time: 0.1822\n",
      "8/8, train_loss: 0.0077 step time: 0.1821\n",
      "epoch 404 average loss: 0.0096\n",
      "time consuming of epoch 404 is: 1.5939\n",
      "----------\n",
      "epoch 405/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2396\n",
      "2/8, train_loss: 0.0095 step time: 0.2020\n",
      "3/8, train_loss: 0.0099 step time: 0.2003\n",
      "4/8, train_loss: 0.0090 step time: 0.1997\n",
      "5/8, train_loss: 0.0137 step time: 0.2017\n",
      "6/8, train_loss: 0.0083 step time: 0.2028\n",
      "7/8, train_loss: 0.0086 step time: 0.1848\n",
      "8/8, train_loss: 0.0113 step time: 0.1818\n",
      "epoch 405 average loss: 0.0101\n",
      "current epoch: 405 current mean dice: 0.9602 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 405 is: 2.3701\n",
      "----------\n",
      "epoch 406/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2388\n",
      "2/8, train_loss: 0.0121 step time: 0.2001\n",
      "3/8, train_loss: 0.0128 step time: 0.1996\n",
      "4/8, train_loss: 0.0086 step time: 0.1995\n",
      "5/8, train_loss: 0.0094 step time: 0.1996\n",
      "6/8, train_loss: 0.0094 step time: 0.2041\n",
      "7/8, train_loss: 0.0096 step time: 0.1844\n",
      "8/8, train_loss: 0.0091 step time: 0.1831\n",
      "epoch 406 average loss: 0.0100\n",
      "time consuming of epoch 406 is: 1.6103\n",
      "----------\n",
      "epoch 407/600\n",
      "1/8, train_loss: 0.0086 step time: 0.2411\n",
      "2/8, train_loss: 0.0106 step time: 0.2028\n",
      "3/8, train_loss: 0.0088 step time: 0.2004\n",
      "4/8, train_loss: 0.0144 step time: 0.2020\n",
      "5/8, train_loss: 0.0106 step time: 0.1997\n",
      "6/8, train_loss: 0.0086 step time: 0.2021\n",
      "7/8, train_loss: 0.0089 step time: 0.1840\n",
      "8/8, train_loss: 0.0074 step time: 0.1828\n",
      "epoch 407 average loss: 0.0098\n",
      "time consuming of epoch 407 is: 1.6162\n",
      "----------\n",
      "epoch 408/600\n",
      "1/8, train_loss: 0.0088 step time: 0.2381\n",
      "2/8, train_loss: 0.0078 step time: 0.2039\n",
      "3/8, train_loss: 0.0095 step time: 0.1992\n",
      "4/8, train_loss: 0.0101 step time: 0.2020\n",
      "5/8, train_loss: 0.0106 step time: 0.2007\n",
      "6/8, train_loss: 0.0107 step time: 0.2020\n",
      "7/8, train_loss: 0.0097 step time: 0.1828\n",
      "8/8, train_loss: 0.0100 step time: 0.1830\n",
      "epoch 408 average loss: 0.0096\n",
      "time consuming of epoch 408 is: 1.6135\n",
      "----------\n",
      "epoch 409/600\n",
      "1/8, train_loss: 0.0106 step time: 0.2432\n",
      "2/8, train_loss: 0.0087 step time: 0.2048\n",
      "3/8, train_loss: 0.0087 step time: 0.2081\n",
      "4/8, train_loss: 0.0086 step time: 0.2024\n",
      "5/8, train_loss: 0.0091 step time: 0.2013\n",
      "6/8, train_loss: 0.0085 step time: 0.2036\n",
      "7/8, train_loss: 0.0106 step time: 0.1828\n",
      "8/8, train_loss: 0.0126 step time: 0.1824\n",
      "epoch 409 average loss: 0.0097\n",
      "time consuming of epoch 409 is: 1.6304\n",
      "----------\n",
      "epoch 410/600\n",
      "1/8, train_loss: 0.0112 step time: 0.2395\n",
      "2/8, train_loss: 0.0108 step time: 0.2029\n",
      "3/8, train_loss: 0.0080 step time: 0.2018\n",
      "4/8, train_loss: 0.0091 step time: 0.1982\n",
      "5/8, train_loss: 0.0102 step time: 0.2014\n",
      "6/8, train_loss: 0.0107 step time: 0.2019\n",
      "7/8, train_loss: 0.0087 step time: 0.1849\n",
      "8/8, train_loss: 0.0095 step time: 0.1827\n",
      "epoch 410 average loss: 0.0098\n",
      "current epoch: 410 current mean dice: 0.9603 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 410 is: 2.3781\n",
      "----------\n",
      "epoch 411/600\n",
      "1/8, train_loss: 0.0089 step time: 0.2356\n",
      "2/8, train_loss: 0.0092 step time: 0.1970\n",
      "3/8, train_loss: 0.0084 step time: 0.1980\n",
      "4/8, train_loss: 0.0125 step time: 0.1998\n",
      "5/8, train_loss: 0.0099 step time: 0.2003\n",
      "6/8, train_loss: 0.0099 step time: 0.2016\n",
      "7/8, train_loss: 0.0086 step time: 0.1813\n",
      "8/8, train_loss: 0.0096 step time: 0.1813\n",
      "epoch 411 average loss: 0.0096\n",
      "time consuming of epoch 411 is: 1.5960\n",
      "----------\n",
      "epoch 412/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2393\n",
      "2/8, train_loss: 0.0115 step time: 0.2021\n",
      "3/8, train_loss: 0.0102 step time: 0.2023\n",
      "4/8, train_loss: 0.0079 step time: 0.2032\n",
      "5/8, train_loss: 0.0087 step time: 0.1981\n",
      "6/8, train_loss: 0.0091 step time: 0.2009\n",
      "7/8, train_loss: 0.0086 step time: 0.1824\n",
      "8/8, train_loss: 0.0081 step time: 0.1808\n",
      "epoch 412 average loss: 0.0093\n",
      "time consuming of epoch 412 is: 1.6107\n",
      "----------\n",
      "epoch 413/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2393\n",
      "2/8, train_loss: 0.0092 step time: 0.2019\n",
      "3/8, train_loss: 0.0089 step time: 0.1989\n",
      "4/8, train_loss: 0.0131 step time: 0.2009\n",
      "5/8, train_loss: 0.0102 step time: 0.1994\n",
      "6/8, train_loss: 0.0123 step time: 0.2031\n",
      "7/8, train_loss: 0.0088 step time: 0.1822\n",
      "8/8, train_loss: 0.0083 step time: 0.1819\n",
      "epoch 413 average loss: 0.0102\n",
      "time consuming of epoch 413 is: 1.6089\n",
      "----------\n",
      "epoch 414/600\n",
      "1/8, train_loss: 0.0095 step time: 0.2419\n",
      "2/8, train_loss: 0.0095 step time: 0.2025\n",
      "3/8, train_loss: 0.0111 step time: 0.1977\n",
      "4/8, train_loss: 0.0091 step time: 0.1967\n",
      "5/8, train_loss: 0.0094 step time: 0.1981\n",
      "6/8, train_loss: 0.0091 step time: 0.2031\n",
      "7/8, train_loss: 0.0085 step time: 0.1811\n",
      "8/8, train_loss: 0.0134 step time: 0.1822\n",
      "epoch 414 average loss: 0.0099\n",
      "time consuming of epoch 414 is: 1.6050\n",
      "----------\n",
      "epoch 415/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2393\n",
      "2/8, train_loss: 0.0094 step time: 0.1974\n",
      "3/8, train_loss: 0.0110 step time: 0.2004\n",
      "4/8, train_loss: 0.0093 step time: 0.2001\n",
      "5/8, train_loss: 0.0098 step time: 0.2013\n",
      "6/8, train_loss: 0.0101 step time: 0.1988\n",
      "7/8, train_loss: 0.0093 step time: 0.1817\n",
      "8/8, train_loss: 0.0093 step time: 0.1831\n",
      "epoch 415 average loss: 0.0099\n",
      "current epoch: 415 current mean dice: 0.9604 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 415 is: 2.3587\n",
      "----------\n",
      "epoch 416/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2382\n",
      "2/8, train_loss: 0.0082 step time: 0.2015\n",
      "3/8, train_loss: 0.0090 step time: 0.1982\n",
      "4/8, train_loss: 0.0077 step time: 0.1987\n",
      "5/8, train_loss: 0.0117 step time: 0.1970\n",
      "6/8, train_loss: 0.0140 step time: 0.1987\n",
      "7/8, train_loss: 0.0098 step time: 0.1820\n",
      "8/8, train_loss: 0.0103 step time: 0.1829\n",
      "epoch 416 average loss: 0.0100\n",
      "time consuming of epoch 416 is: 1.5985\n",
      "----------\n",
      "epoch 417/600\n",
      "1/8, train_loss: 0.0101 step time: 0.2398\n",
      "2/8, train_loss: 0.0093 step time: 0.2045\n",
      "3/8, train_loss: 0.0088 step time: 0.2020\n",
      "4/8, train_loss: 0.0091 step time: 0.2027\n",
      "5/8, train_loss: 0.0101 step time: 0.1981\n",
      "6/8, train_loss: 0.0101 step time: 0.1997\n",
      "7/8, train_loss: 0.0077 step time: 0.1827\n",
      "8/8, train_loss: 0.0130 step time: 0.1819\n",
      "epoch 417 average loss: 0.0098\n",
      "time consuming of epoch 417 is: 1.6128\n",
      "----------\n",
      "epoch 418/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2418\n",
      "2/8, train_loss: 0.0090 step time: 0.2020\n",
      "3/8, train_loss: 0.0117 step time: 0.1985\n",
      "4/8, train_loss: 0.0095 step time: 0.2008\n",
      "5/8, train_loss: 0.0097 step time: 0.1973\n",
      "6/8, train_loss: 0.0102 step time: 0.2007\n",
      "7/8, train_loss: 0.0083 step time: 0.1823\n",
      "8/8, train_loss: 0.0101 step time: 0.1828\n",
      "epoch 418 average loss: 0.0097\n",
      "time consuming of epoch 418 is: 1.6075\n",
      "----------\n",
      "epoch 419/600\n",
      "1/8, train_loss: 0.0085 step time: 0.2344\n",
      "2/8, train_loss: 0.0088 step time: 0.1973\n",
      "3/8, train_loss: 0.0103 step time: 0.1976\n",
      "4/8, train_loss: 0.0087 step time: 0.1966\n",
      "5/8, train_loss: 0.0117 step time: 0.1972\n",
      "6/8, train_loss: 0.0097 step time: 0.1969\n",
      "7/8, train_loss: 0.0103 step time: 0.1819\n",
      "8/8, train_loss: 0.0086 step time: 0.1830\n",
      "epoch 419 average loss: 0.0096\n",
      "time consuming of epoch 419 is: 1.5870\n",
      "----------\n",
      "epoch 420/600\n",
      "1/8, train_loss: 0.0082 step time: 0.2326\n",
      "2/8, train_loss: 0.0119 step time: 0.1953\n",
      "3/8, train_loss: 0.0084 step time: 0.1945\n",
      "4/8, train_loss: 0.0116 step time: 0.1956\n",
      "5/8, train_loss: 0.0106 step time: 0.1970\n",
      "6/8, train_loss: 0.0087 step time: 0.1959\n",
      "7/8, train_loss: 0.0089 step time: 0.1823\n",
      "8/8, train_loss: 0.0102 step time: 0.1820\n",
      "epoch 420 average loss: 0.0098\n",
      "current epoch: 420 current mean dice: 0.9601 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 420 is: 2.3313\n",
      "----------\n",
      "epoch 421/600\n",
      "1/8, train_loss: 0.0083 step time: 0.2384\n",
      "2/8, train_loss: 0.0112 step time: 0.1970\n",
      "3/8, train_loss: 0.0104 step time: 0.1986\n",
      "4/8, train_loss: 0.0092 step time: 0.1996\n",
      "5/8, train_loss: 0.0099 step time: 0.1992\n",
      "6/8, train_loss: 0.0100 step time: 0.1992\n",
      "7/8, train_loss: 0.0082 step time: 0.1810\n",
      "8/8, train_loss: 0.0116 step time: 0.1829\n",
      "epoch 421 average loss: 0.0099\n",
      "time consuming of epoch 421 is: 1.5970\n",
      "----------\n",
      "epoch 422/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0102 step time: 0.2406\n",
      "2/8, train_loss: 0.0088 step time: 0.2060\n",
      "3/8, train_loss: 0.0079 step time: 0.2001\n",
      "4/8, train_loss: 0.0093 step time: 0.2019\n",
      "5/8, train_loss: 0.0086 step time: 0.2022\n",
      "6/8, train_loss: 0.0102 step time: 0.1995\n",
      "7/8, train_loss: 0.0103 step time: 0.1836\n",
      "8/8, train_loss: 0.0102 step time: 0.1830\n",
      "epoch 422 average loss: 0.0094\n",
      "time consuming of epoch 422 is: 1.6180\n",
      "----------\n",
      "epoch 423/600\n",
      "1/8, train_loss: 0.0082 step time: 0.2411\n",
      "2/8, train_loss: 0.0101 step time: 0.2035\n",
      "3/8, train_loss: 0.0093 step time: 0.1990\n",
      "4/8, train_loss: 0.0107 step time: 0.2016\n",
      "5/8, train_loss: 0.0086 step time: 0.2018\n",
      "6/8, train_loss: 0.0091 step time: 0.2001\n",
      "7/8, train_loss: 0.0076 step time: 0.1826\n",
      "8/8, train_loss: 0.0076 step time: 0.1823\n",
      "epoch 423 average loss: 0.0089\n",
      "time consuming of epoch 423 is: 1.6137\n",
      "----------\n",
      "epoch 424/600\n",
      "1/8, train_loss: 0.0079 step time: 0.2429\n",
      "2/8, train_loss: 0.0103 step time: 0.2021\n",
      "3/8, train_loss: 0.0080 step time: 0.1975\n",
      "4/8, train_loss: 0.0092 step time: 0.2010\n",
      "5/8, train_loss: 0.0116 step time: 0.2021\n",
      "6/8, train_loss: 0.0089 step time: 0.1981\n",
      "7/8, train_loss: 0.0089 step time: 0.1824\n",
      "8/8, train_loss: 0.0101 step time: 0.1822\n",
      "epoch 424 average loss: 0.0094\n",
      "time consuming of epoch 424 is: 1.6098\n",
      "----------\n",
      "epoch 425/600\n",
      "1/8, train_loss: 0.0088 step time: 0.2394\n",
      "2/8, train_loss: 0.0099 step time: 0.2042\n",
      "3/8, train_loss: 0.0084 step time: 0.2037\n",
      "4/8, train_loss: 0.0104 step time: 0.1975\n",
      "5/8, train_loss: 0.0088 step time: 0.2015\n",
      "6/8, train_loss: 0.0109 step time: 0.2003\n",
      "7/8, train_loss: 0.0090 step time: 0.1836\n",
      "8/8, train_loss: 0.0096 step time: 0.1858\n",
      "epoch 425 average loss: 0.0095\n",
      "current epoch: 425 current mean dice: 0.9607 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 425 is: 2.3739\n",
      "----------\n",
      "epoch 426/600\n",
      "1/8, train_loss: 0.0084 step time: 0.2378\n",
      "2/8, train_loss: 0.0086 step time: 0.2056\n",
      "3/8, train_loss: 0.0098 step time: 0.2022\n",
      "4/8, train_loss: 0.0095 step time: 0.1998\n",
      "5/8, train_loss: 0.0102 step time: 0.2018\n",
      "6/8, train_loss: 0.0081 step time: 0.1988\n",
      "7/8, train_loss: 0.0099 step time: 0.1847\n",
      "8/8, train_loss: 0.0097 step time: 0.1829\n",
      "epoch 426 average loss: 0.0093\n",
      "time consuming of epoch 426 is: 1.6149\n",
      "----------\n",
      "epoch 427/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2395\n",
      "2/8, train_loss: 0.0106 step time: 0.1994\n",
      "3/8, train_loss: 0.0097 step time: 0.1969\n",
      "4/8, train_loss: 0.0071 step time: 0.1955\n",
      "5/8, train_loss: 0.0083 step time: 0.1940\n",
      "6/8, train_loss: 0.0111 step time: 0.1947\n",
      "7/8, train_loss: 0.0088 step time: 0.1830\n",
      "8/8, train_loss: 0.0098 step time: 0.1828\n",
      "epoch 427 average loss: 0.0093\n",
      "time consuming of epoch 427 is: 1.5872\n",
      "----------\n",
      "epoch 428/600\n",
      "1/8, train_loss: 0.0086 step time: 0.2298\n",
      "2/8, train_loss: 0.0081 step time: 0.1978\n",
      "3/8, train_loss: 0.0105 step time: 0.2037\n",
      "4/8, train_loss: 0.0090 step time: 0.2014\n",
      "5/8, train_loss: 0.0103 step time: 0.2018\n",
      "6/8, train_loss: 0.0106 step time: 0.2000\n",
      "7/8, train_loss: 0.0126 step time: 0.1845\n",
      "8/8, train_loss: 0.0088 step time: 0.1824\n",
      "epoch 428 average loss: 0.0098\n",
      "time consuming of epoch 428 is: 1.6032\n",
      "----------\n",
      "epoch 429/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2402\n",
      "2/8, train_loss: 0.0086 step time: 0.2016\n",
      "3/8, train_loss: 0.0093 step time: 0.1990\n",
      "4/8, train_loss: 0.0100 step time: 0.1993\n",
      "5/8, train_loss: 0.0101 step time: 0.1990\n",
      "6/8, train_loss: 0.0109 step time: 0.2013\n",
      "7/8, train_loss: 0.0089 step time: 0.1825\n",
      "8/8, train_loss: 0.0112 step time: 0.1833\n",
      "epoch 429 average loss: 0.0099\n",
      "time consuming of epoch 429 is: 1.6076\n",
      "----------\n",
      "epoch 430/600\n",
      "1/8, train_loss: 0.0086 step time: 0.2410\n",
      "2/8, train_loss: 0.0077 step time: 0.2037\n",
      "3/8, train_loss: 0.0089 step time: 0.2023\n",
      "4/8, train_loss: 0.0086 step time: 0.1999\n",
      "5/8, train_loss: 0.0084 step time: 0.2001\n",
      "6/8, train_loss: 0.0102 step time: 0.1991\n",
      "7/8, train_loss: 0.0086 step time: 0.1833\n",
      "8/8, train_loss: 0.0135 step time: 0.1824\n",
      "epoch 430 average loss: 0.0093\n",
      "current epoch: 430 current mean dice: 0.9620 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 430 is: 2.3702\n",
      "----------\n",
      "epoch 431/600\n",
      "1/8, train_loss: 0.0080 step time: 0.2375\n",
      "2/8, train_loss: 0.0087 step time: 0.2014\n",
      "3/8, train_loss: 0.0080 step time: 0.1983\n",
      "4/8, train_loss: 0.0097 step time: 0.2011\n",
      "5/8, train_loss: 0.0121 step time: 0.2002\n",
      "6/8, train_loss: 0.0095 step time: 0.1999\n",
      "7/8, train_loss: 0.0102 step time: 0.1814\n",
      "8/8, train_loss: 0.0116 step time: 0.1813\n",
      "epoch 431 average loss: 0.0097\n",
      "time consuming of epoch 431 is: 1.6024\n",
      "----------\n",
      "epoch 432/600\n",
      "1/8, train_loss: 0.0097 step time: 0.2407\n",
      "2/8, train_loss: 0.0101 step time: 0.2015\n",
      "3/8, train_loss: 0.0084 step time: 0.1997\n",
      "4/8, train_loss: 0.0105 step time: 0.2014\n",
      "5/8, train_loss: 0.0088 step time: 0.2014\n",
      "6/8, train_loss: 0.0080 step time: 0.2019\n",
      "7/8, train_loss: 0.0096 step time: 0.1826\n",
      "8/8, train_loss: 0.0090 step time: 0.1819\n",
      "epoch 432 average loss: 0.0093\n",
      "time consuming of epoch 432 is: 1.6126\n",
      "----------\n",
      "epoch 433/600\n",
      "1/8, train_loss: 0.0101 step time: 0.2405\n",
      "2/8, train_loss: 0.0101 step time: 0.2028\n",
      "3/8, train_loss: 0.0082 step time: 0.2013\n",
      "4/8, train_loss: 0.0095 step time: 0.2011\n",
      "5/8, train_loss: 0.0099 step time: 0.2003\n",
      "6/8, train_loss: 0.0082 step time: 0.1993\n",
      "7/8, train_loss: 0.0096 step time: 0.1826\n",
      "8/8, train_loss: 0.0085 step time: 0.1821\n",
      "epoch 433 average loss: 0.0093\n",
      "time consuming of epoch 433 is: 1.6121\n",
      "----------\n",
      "epoch 434/600\n",
      "1/8, train_loss: 0.0103 step time: 0.2380\n",
      "2/8, train_loss: 0.0080 step time: 0.1973\n",
      "3/8, train_loss: 0.0100 step time: 0.1976\n",
      "4/8, train_loss: 0.0080 step time: 0.1961\n",
      "5/8, train_loss: 0.0102 step time: 0.1973\n",
      "6/8, train_loss: 0.0087 step time: 0.1945\n",
      "7/8, train_loss: 0.0104 step time: 0.1847\n",
      "8/8, train_loss: 0.0093 step time: 0.1815\n",
      "epoch 434 average loss: 0.0094\n",
      "time consuming of epoch 434 is: 1.5884\n",
      "----------\n",
      "epoch 435/600\n",
      "1/8, train_loss: 0.0096 step time: 0.2374\n",
      "2/8, train_loss: 0.0090 step time: 0.1978\n",
      "3/8, train_loss: 0.0083 step time: 0.1945\n",
      "4/8, train_loss: 0.0101 step time: 0.1953\n",
      "5/8, train_loss: 0.0091 step time: 0.2032\n",
      "6/8, train_loss: 0.0095 step time: 0.1987\n",
      "7/8, train_loss: 0.0104 step time: 0.1823\n",
      "8/8, train_loss: 0.0102 step time: 0.1818\n",
      "epoch 435 average loss: 0.0095\n",
      "current epoch: 435 current mean dice: 0.9616 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 435 is: 2.3472\n",
      "----------\n",
      "epoch 436/600\n",
      "1/8, train_loss: 0.0110 step time: 0.2362\n",
      "2/8, train_loss: 0.0089 step time: 0.1988\n",
      "3/8, train_loss: 0.0093 step time: 0.1983\n",
      "4/8, train_loss: 0.0098 step time: 0.2019\n",
      "5/8, train_loss: 0.0089 step time: 0.1964\n",
      "6/8, train_loss: 0.0091 step time: 0.2015\n",
      "7/8, train_loss: 0.0108 step time: 0.1827\n",
      "8/8, train_loss: 0.0081 step time: 0.1834\n",
      "epoch 436 average loss: 0.0095\n",
      "time consuming of epoch 436 is: 1.6004\n",
      "----------\n",
      "epoch 437/600\n",
      "1/8, train_loss: 0.0109 step time: 0.2426\n",
      "2/8, train_loss: 0.0079 step time: 0.2003\n",
      "3/8, train_loss: 0.0088 step time: 0.2017\n",
      "4/8, train_loss: 0.0094 step time: 0.2022\n",
      "5/8, train_loss: 0.0082 step time: 0.2005\n",
      "6/8, train_loss: 0.0124 step time: 0.2050\n",
      "7/8, train_loss: 0.0087 step time: 0.1828\n",
      "8/8, train_loss: 0.0108 step time: 0.1823\n",
      "epoch 437 average loss: 0.0096\n",
      "time consuming of epoch 437 is: 1.6193\n",
      "----------\n",
      "epoch 438/600\n",
      "1/8, train_loss: 0.0077 step time: 0.2392\n",
      "2/8, train_loss: 0.0097 step time: 0.2026\n",
      "3/8, train_loss: 0.0085 step time: 0.2016\n",
      "4/8, train_loss: 0.0082 step time: 0.1990\n",
      "5/8, train_loss: 0.0083 step time: 0.2036\n",
      "6/8, train_loss: 0.0088 step time: 0.1985\n",
      "7/8, train_loss: 0.0084 step time: 0.1820\n",
      "8/8, train_loss: 0.0093 step time: 0.1824\n",
      "epoch 438 average loss: 0.0086\n",
      "time consuming of epoch 438 is: 1.6105\n",
      "----------\n",
      "epoch 439/600\n",
      "1/8, train_loss: 0.0081 step time: 0.2372\n",
      "2/8, train_loss: 0.0106 step time: 0.1994\n",
      "3/8, train_loss: 0.0083 step time: 0.2000\n",
      "4/8, train_loss: 0.0079 step time: 0.1995\n",
      "5/8, train_loss: 0.0082 step time: 0.2012\n",
      "6/8, train_loss: 0.0105 step time: 0.1977\n",
      "7/8, train_loss: 0.0115 step time: 0.1822\n",
      "8/8, train_loss: 0.0087 step time: 0.1822\n",
      "epoch 439 average loss: 0.0092\n",
      "time consuming of epoch 439 is: 1.6009\n",
      "----------\n",
      "epoch 440/600\n",
      "1/8, train_loss: 0.0082 step time: 0.2405\n",
      "2/8, train_loss: 0.0103 step time: 0.2037\n",
      "3/8, train_loss: 0.0098 step time: 0.1982\n",
      "4/8, train_loss: 0.0091 step time: 0.1997\n",
      "5/8, train_loss: 0.0119 step time: 0.2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/8, train_loss: 0.0079 step time: 0.2053\n",
      "7/8, train_loss: 0.0087 step time: 0.1828\n",
      "8/8, train_loss: 0.0084 step time: 0.1822\n",
      "epoch 440 average loss: 0.0093\n",
      "current epoch: 440 current mean dice: 0.9617 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 440 is: 2.3694\n",
      "----------\n",
      "epoch 441/600\n",
      "1/8, train_loss: 0.0117 step time: 0.2388\n",
      "2/8, train_loss: 0.0088 step time: 0.1972\n",
      "3/8, train_loss: 0.0083 step time: 0.2004\n",
      "4/8, train_loss: 0.0090 step time: 0.1990\n",
      "5/8, train_loss: 0.0099 step time: 0.1977\n",
      "6/8, train_loss: 0.0077 step time: 0.2028\n",
      "7/8, train_loss: 0.0081 step time: 0.1810\n",
      "8/8, train_loss: 0.0102 step time: 0.1813\n",
      "epoch 441 average loss: 0.0092\n",
      "time consuming of epoch 441 is: 1.5993\n",
      "----------\n",
      "epoch 442/600\n",
      "1/8, train_loss: 0.0097 step time: 0.2397\n",
      "2/8, train_loss: 0.0097 step time: 0.2015\n",
      "3/8, train_loss: 0.0105 step time: 0.1980\n",
      "4/8, train_loss: 0.0088 step time: 0.2006\n",
      "5/8, train_loss: 0.0100 step time: 0.2024\n",
      "6/8, train_loss: 0.0090 step time: 0.1985\n",
      "7/8, train_loss: 0.0093 step time: 0.1823\n",
      "8/8, train_loss: 0.0078 step time: 0.1825\n",
      "epoch 442 average loss: 0.0094\n",
      "time consuming of epoch 442 is: 1.6068\n",
      "----------\n",
      "epoch 443/600\n",
      "1/8, train_loss: 0.0097 step time: 0.2388\n",
      "2/8, train_loss: 0.0104 step time: 0.2002\n",
      "3/8, train_loss: 0.0097 step time: 0.2005\n",
      "4/8, train_loss: 0.0094 step time: 0.1992\n",
      "5/8, train_loss: 0.0089 step time: 0.1996\n",
      "6/8, train_loss: 0.0112 step time: 0.2022\n",
      "7/8, train_loss: 0.0093 step time: 0.1821\n",
      "8/8, train_loss: 0.0081 step time: 0.1838\n",
      "epoch 443 average loss: 0.0096\n",
      "time consuming of epoch 443 is: 1.6081\n",
      "----------\n",
      "epoch 444/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2408\n",
      "2/8, train_loss: 0.0095 step time: 0.1992\n",
      "3/8, train_loss: 0.0108 step time: 0.1991\n",
      "4/8, train_loss: 0.0098 step time: 0.2005\n",
      "5/8, train_loss: 0.0091 step time: 0.1999\n",
      "6/8, train_loss: 0.0100 step time: 0.2015\n",
      "7/8, train_loss: 0.0121 step time: 0.1831\n",
      "8/8, train_loss: 0.0088 step time: 0.1816\n",
      "epoch 444 average loss: 0.0099\n",
      "time consuming of epoch 444 is: 1.6073\n",
      "----------\n",
      "epoch 445/600\n",
      "1/8, train_loss: 0.0094 step time: 0.2396\n",
      "2/8, train_loss: 0.0100 step time: 0.2031\n",
      "3/8, train_loss: 0.0096 step time: 0.2016\n",
      "4/8, train_loss: 0.0107 step time: 0.1998\n",
      "5/8, train_loss: 0.0100 step time: 0.2085\n",
      "6/8, train_loss: 0.0120 step time: 0.2002\n",
      "7/8, train_loss: 0.0080 step time: 0.1823\n",
      "8/8, train_loss: 0.0087 step time: 0.1825\n",
      "epoch 445 average loss: 0.0098\n",
      "current epoch: 445 current mean dice: 0.9605 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 445 is: 2.3751\n",
      "----------\n",
      "epoch 446/600\n",
      "1/8, train_loss: 0.0113 step time: 0.2372\n",
      "2/8, train_loss: 0.0103 step time: 0.1970\n",
      "3/8, train_loss: 0.0111 step time: 0.2005\n",
      "4/8, train_loss: 0.0085 step time: 0.1994\n",
      "5/8, train_loss: 0.0106 step time: 0.1993\n",
      "6/8, train_loss: 0.0095 step time: 0.1987\n",
      "7/8, train_loss: 0.0098 step time: 0.1842\n",
      "8/8, train_loss: 0.0073 step time: 0.1809\n",
      "epoch 446 average loss: 0.0098\n",
      "time consuming of epoch 446 is: 1.5981\n",
      "----------\n",
      "epoch 447/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2363\n",
      "2/8, train_loss: 0.0086 step time: 0.2024\n",
      "3/8, train_loss: 0.0086 step time: 0.1985\n",
      "4/8, train_loss: 0.0109 step time: 0.2011\n",
      "5/8, train_loss: 0.0118 step time: 0.1998\n",
      "6/8, train_loss: 0.0123 step time: 0.1988\n",
      "7/8, train_loss: 0.0077 step time: 0.1820\n",
      "8/8, train_loss: 0.0100 step time: 0.1828\n",
      "epoch 447 average loss: 0.0099\n",
      "time consuming of epoch 447 is: 1.6030\n",
      "----------\n",
      "epoch 448/600\n",
      "1/8, train_loss: 0.0084 step time: 0.2405\n",
      "2/8, train_loss: 0.0082 step time: 0.2033\n",
      "3/8, train_loss: 0.0094 step time: 0.2004\n",
      "4/8, train_loss: 0.0083 step time: 0.2016\n",
      "5/8, train_loss: 0.0106 step time: 0.1970\n",
      "6/8, train_loss: 0.0108 step time: 0.2026\n",
      "7/8, train_loss: 0.0087 step time: 0.1822\n",
      "8/8, train_loss: 0.0119 step time: 0.1821\n",
      "epoch 448 average loss: 0.0095\n",
      "time consuming of epoch 448 is: 1.6114\n",
      "----------\n",
      "epoch 449/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2408\n",
      "2/8, train_loss: 0.0093 step time: 0.2052\n",
      "3/8, train_loss: 0.0123 step time: 0.2006\n",
      "4/8, train_loss: 0.0082 step time: 0.1997\n",
      "5/8, train_loss: 0.0087 step time: 0.2030\n",
      "6/8, train_loss: 0.0074 step time: 0.1999\n",
      "7/8, train_loss: 0.0088 step time: 0.1831\n",
      "8/8, train_loss: 0.0064 step time: 0.1810\n",
      "epoch 449 average loss: 0.0088\n",
      "time consuming of epoch 449 is: 1.6147\n",
      "----------\n",
      "epoch 450/600\n",
      "1/8, train_loss: 0.0088 step time: 0.2413\n",
      "2/8, train_loss: 0.0086 step time: 0.1996\n",
      "3/8, train_loss: 0.0089 step time: 0.2019\n",
      "4/8, train_loss: 0.0111 step time: 0.2025\n",
      "5/8, train_loss: 0.0091 step time: 0.2068\n",
      "6/8, train_loss: 0.0075 step time: 0.1995\n",
      "7/8, train_loss: 0.0090 step time: 0.1851\n",
      "8/8, train_loss: 0.0112 step time: 0.1836\n",
      "epoch 450 average loss: 0.0093\n",
      "current epoch: 450 current mean dice: 0.9611 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 450 is: 2.3785\n",
      "----------\n",
      "epoch 451/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2377\n",
      "2/8, train_loss: 0.0083 step time: 0.1987\n",
      "3/8, train_loss: 0.0078 step time: 0.1998\n",
      "4/8, train_loss: 0.0134 step time: 0.2002\n",
      "5/8, train_loss: 0.0090 step time: 0.2047\n",
      "6/8, train_loss: 0.0083 step time: 0.2058\n",
      "7/8, train_loss: 0.0124 step time: 0.1835\n",
      "8/8, train_loss: 0.0090 step time: 0.1833\n",
      "epoch 451 average loss: 0.0097\n",
      "time consuming of epoch 451 is: 1.6148\n",
      "----------\n",
      "epoch 452/600\n",
      "1/8, train_loss: 0.0079 step time: 0.2425\n",
      "2/8, train_loss: 0.0093 step time: 0.2031\n",
      "3/8, train_loss: 0.0100 step time: 0.2004\n",
      "4/8, train_loss: 0.0105 step time: 0.2008\n",
      "5/8, train_loss: 0.0109 step time: 0.2023\n",
      "6/8, train_loss: 0.0086 step time: 0.2019\n",
      "7/8, train_loss: 0.0074 step time: 0.1826\n",
      "8/8, train_loss: 0.0089 step time: 0.1835\n",
      "epoch 452 average loss: 0.0092\n",
      "time consuming of epoch 452 is: 1.6186\n",
      "----------\n",
      "epoch 453/600\n",
      "1/8, train_loss: 0.0086 step time: 0.2414\n",
      "2/8, train_loss: 0.0084 step time: 0.2028\n",
      "3/8, train_loss: 0.0115 step time: 0.1993\n",
      "4/8, train_loss: 0.0095 step time: 0.1998\n",
      "5/8, train_loss: 0.0083 step time: 0.1981\n",
      "6/8, train_loss: 0.0099 step time: 0.1998\n",
      "7/8, train_loss: 0.0097 step time: 0.1849\n",
      "8/8, train_loss: 0.0086 step time: 0.1828\n",
      "epoch 453 average loss: 0.0093\n",
      "time consuming of epoch 453 is: 1.6108\n",
      "----------\n",
      "epoch 454/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2406\n",
      "2/8, train_loss: 0.0074 step time: 0.2050\n",
      "3/8, train_loss: 0.0094 step time: 0.2002\n",
      "4/8, train_loss: 0.0089 step time: 0.2020\n",
      "5/8, train_loss: 0.0100 step time: 0.1993\n",
      "6/8, train_loss: 0.0100 step time: 0.2063\n",
      "7/8, train_loss: 0.0075 step time: 0.1819\n",
      "8/8, train_loss: 0.0117 step time: 0.1815\n",
      "epoch 454 average loss: 0.0092\n",
      "time consuming of epoch 454 is: 1.6185\n",
      "----------\n",
      "epoch 455/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2359\n",
      "2/8, train_loss: 0.0098 step time: 0.1974\n",
      "3/8, train_loss: 0.0076 step time: 0.1951\n",
      "4/8, train_loss: 0.0102 step time: 0.1974\n",
      "5/8, train_loss: 0.0101 step time: 0.2004\n",
      "6/8, train_loss: 0.0080 step time: 0.2002\n",
      "7/8, train_loss: 0.0097 step time: 0.1826\n",
      "8/8, train_loss: 0.0085 step time: 0.1825\n",
      "epoch 455 average loss: 0.0093\n",
      "current epoch: 455 current mean dice: 0.9608 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 455 is: 2.3495\n",
      "----------\n",
      "epoch 456/600\n",
      "1/8, train_loss: 0.0131 step time: 0.2317\n",
      "2/8, train_loss: 0.0107 step time: 0.1969\n",
      "3/8, train_loss: 0.0076 step time: 0.1949\n",
      "4/8, train_loss: 0.0099 step time: 0.1942\n",
      "5/8, train_loss: 0.0099 step time: 0.1950\n",
      "6/8, train_loss: 0.0117 step time: 0.1946\n",
      "7/8, train_loss: 0.0096 step time: 0.1811\n",
      "8/8, train_loss: 0.0091 step time: 0.1812\n",
      "epoch 456 average loss: 0.0102\n",
      "time consuming of epoch 456 is: 1.5707\n",
      "----------\n",
      "epoch 457/600\n",
      "1/8, train_loss: 0.0153 step time: 0.2333\n",
      "2/8, train_loss: 0.0081 step time: 0.1993\n",
      "3/8, train_loss: 0.0104 step time: 0.1981\n",
      "4/8, train_loss: 0.0107 step time: 0.1967\n",
      "5/8, train_loss: 0.0083 step time: 0.1967\n",
      "6/8, train_loss: 0.0089 step time: 0.1968\n",
      "7/8, train_loss: 0.0098 step time: 0.1824\n",
      "8/8, train_loss: 0.0087 step time: 0.1831\n",
      "epoch 457 average loss: 0.0100\n",
      "time consuming of epoch 457 is: 1.5878\n",
      "----------\n",
      "epoch 458/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2334\n",
      "2/8, train_loss: 0.0086 step time: 0.2001\n",
      "3/8, train_loss: 0.0109 step time: 0.1988\n",
      "4/8, train_loss: 0.0108 step time: 0.1956\n",
      "5/8, train_loss: 0.0111 step time: 0.1972\n",
      "6/8, train_loss: 0.0088 step time: 0.1966\n",
      "7/8, train_loss: 0.0105 step time: 0.1829\n",
      "8/8, train_loss: 0.0082 step time: 0.1825\n",
      "epoch 458 average loss: 0.0098\n",
      "time consuming of epoch 458 is: 1.5883\n",
      "----------\n",
      "epoch 459/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.0092 step time: 0.2352\n",
      "2/8, train_loss: 0.0093 step time: 0.1966\n",
      "3/8, train_loss: 0.0092 step time: 0.1981\n",
      "4/8, train_loss: 0.0099 step time: 0.1972\n",
      "5/8, train_loss: 0.0084 step time: 0.1986\n",
      "6/8, train_loss: 0.0102 step time: 0.1966\n",
      "7/8, train_loss: 0.0101 step time: 0.1825\n",
      "8/8, train_loss: 0.0117 step time: 0.1822\n",
      "epoch 459 average loss: 0.0097\n",
      "time consuming of epoch 459 is: 1.5885\n",
      "----------\n",
      "epoch 460/600\n",
      "1/8, train_loss: 0.0076 step time: 0.2311\n",
      "2/8, train_loss: 0.0099 step time: 0.1976\n",
      "3/8, train_loss: 0.0109 step time: 0.1978\n",
      "4/8, train_loss: 0.0085 step time: 0.1957\n",
      "5/8, train_loss: 0.0078 step time: 0.1963\n",
      "6/8, train_loss: 0.0081 step time: 0.1966\n",
      "7/8, train_loss: 0.0110 step time: 0.1823\n",
      "8/8, train_loss: 0.0113 step time: 0.1816\n",
      "epoch 460 average loss: 0.0094\n",
      "current epoch: 460 current mean dice: 0.9614 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 460 is: 2.3349\n",
      "----------\n",
      "epoch 461/600\n",
      "1/8, train_loss: 0.0095 step time: 0.2300\n",
      "2/8, train_loss: 0.0106 step time: 0.1904\n",
      "3/8, train_loss: 0.0076 step time: 0.1911\n",
      "4/8, train_loss: 0.0093 step time: 0.1907\n",
      "5/8, train_loss: 0.0115 step time: 0.1934\n",
      "6/8, train_loss: 0.0094 step time: 0.1916\n",
      "7/8, train_loss: 0.0086 step time: 0.1808\n",
      "8/8, train_loss: 0.0085 step time: 0.1815\n",
      "epoch 461 average loss: 0.0094\n",
      "time consuming of epoch 461 is: 1.5507\n",
      "----------\n",
      "epoch 462/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2438\n",
      "2/8, train_loss: 0.0083 step time: 0.2006\n",
      "3/8, train_loss: 0.0102 step time: 0.2001\n",
      "4/8, train_loss: 0.0109 step time: 0.2012\n",
      "5/8, train_loss: 0.0082 step time: 0.1996\n",
      "6/8, train_loss: 0.0088 step time: 0.2014\n",
      "7/8, train_loss: 0.0081 step time: 0.1824\n",
      "8/8, train_loss: 0.0101 step time: 0.1825\n",
      "epoch 462 average loss: 0.0094\n",
      "time consuming of epoch 462 is: 1.6132\n",
      "----------\n",
      "epoch 463/600\n",
      "1/8, train_loss: 0.0094 step time: 0.2382\n",
      "2/8, train_loss: 0.0086 step time: 0.2019\n",
      "3/8, train_loss: 0.0093 step time: 0.2074\n",
      "4/8, train_loss: 0.0082 step time: 0.2018\n",
      "5/8, train_loss: 0.0102 step time: 0.2011\n",
      "6/8, train_loss: 0.0093 step time: 0.2028\n",
      "7/8, train_loss: 0.0131 step time: 0.1823\n",
      "8/8, train_loss: 0.0078 step time: 0.1825\n",
      "epoch 463 average loss: 0.0095\n",
      "time consuming of epoch 463 is: 1.6197\n",
      "----------\n",
      "epoch 464/600\n",
      "1/8, train_loss: 0.0103 step time: 0.2415\n",
      "2/8, train_loss: 0.0110 step time: 0.2024\n",
      "3/8, train_loss: 0.0082 step time: 0.2021\n",
      "4/8, train_loss: 0.0072 step time: 0.2038\n",
      "5/8, train_loss: 0.0094 step time: 0.2004\n",
      "6/8, train_loss: 0.0110 step time: 0.2003\n",
      "7/8, train_loss: 0.0086 step time: 0.1831\n",
      "8/8, train_loss: 0.0100 step time: 0.1820\n",
      "epoch 464 average loss: 0.0095\n",
      "time consuming of epoch 464 is: 1.6171\n",
      "----------\n",
      "epoch 465/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2367\n",
      "2/8, train_loss: 0.0088 step time: 0.1982\n",
      "3/8, train_loss: 0.0085 step time: 0.1960\n",
      "4/8, train_loss: 0.0082 step time: 0.1924\n",
      "5/8, train_loss: 0.0099 step time: 0.1920\n",
      "6/8, train_loss: 0.0116 step time: 0.1934\n",
      "7/8, train_loss: 0.0085 step time: 0.1821\n",
      "8/8, train_loss: 0.0089 step time: 0.1826\n",
      "epoch 465 average loss: 0.0093\n",
      "current epoch: 465 current mean dice: 0.9611 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 465 is: 2.3296\n",
      "----------\n",
      "epoch 466/600\n",
      "1/8, train_loss: 0.0096 step time: 0.2394\n",
      "2/8, train_loss: 0.0117 step time: 0.2022\n",
      "3/8, train_loss: 0.0082 step time: 0.1995\n",
      "4/8, train_loss: 0.0099 step time: 0.2004\n",
      "5/8, train_loss: 0.0111 step time: 0.1973\n",
      "6/8, train_loss: 0.0084 step time: 0.2017\n",
      "7/8, train_loss: 0.0083 step time: 0.1816\n",
      "8/8, train_loss: 0.0097 step time: 0.1813\n",
      "epoch 466 average loss: 0.0096\n",
      "time consuming of epoch 466 is: 1.6045\n",
      "----------\n",
      "epoch 467/600\n",
      "1/8, train_loss: 0.0081 step time: 0.2384\n",
      "2/8, train_loss: 0.0109 step time: 0.2026\n",
      "3/8, train_loss: 0.0075 step time: 0.2069\n",
      "4/8, train_loss: 0.0112 step time: 0.1962\n",
      "5/8, train_loss: 0.0069 step time: 0.2009\n",
      "6/8, train_loss: 0.0131 step time: 0.1976\n",
      "7/8, train_loss: 0.0087 step time: 0.1821\n",
      "8/8, train_loss: 0.0093 step time: 0.1826\n",
      "epoch 467 average loss: 0.0095\n",
      "time consuming of epoch 467 is: 1.6086\n",
      "----------\n",
      "epoch 468/600\n",
      "1/8, train_loss: 0.0084 step time: 0.2401\n",
      "2/8, train_loss: 0.0083 step time: 0.2027\n",
      "3/8, train_loss: 0.0141 step time: 0.2017\n",
      "4/8, train_loss: 0.0103 step time: 0.1992\n",
      "5/8, train_loss: 0.0087 step time: 0.2004\n",
      "6/8, train_loss: 0.0077 step time: 0.2106\n",
      "7/8, train_loss: 0.0087 step time: 0.1826\n",
      "8/8, train_loss: 0.0094 step time: 0.1847\n",
      "epoch 468 average loss: 0.0094\n",
      "time consuming of epoch 468 is: 1.6233\n",
      "----------\n",
      "epoch 469/600\n",
      "1/8, train_loss: 0.0085 step time: 0.2373\n",
      "2/8, train_loss: 0.0109 step time: 0.2026\n",
      "3/8, train_loss: 0.0123 step time: 0.1989\n",
      "4/8, train_loss: 0.0080 step time: 0.2056\n",
      "5/8, train_loss: 0.0091 step time: 0.1982\n",
      "6/8, train_loss: 0.0077 step time: 0.2036\n",
      "7/8, train_loss: 0.0094 step time: 0.1825\n",
      "8/8, train_loss: 0.0091 step time: 0.1820\n",
      "epoch 469 average loss: 0.0094\n",
      "time consuming of epoch 469 is: 1.6127\n",
      "----------\n",
      "epoch 470/600\n",
      "1/8, train_loss: 0.0101 step time: 0.2412\n",
      "2/8, train_loss: 0.0076 step time: 0.2026\n",
      "3/8, train_loss: 0.0078 step time: 0.2029\n",
      "4/8, train_loss: 0.0110 step time: 0.2006\n",
      "5/8, train_loss: 0.0116 step time: 0.2037\n",
      "6/8, train_loss: 0.0097 step time: 0.2001\n",
      "7/8, train_loss: 0.0085 step time: 0.1825\n",
      "8/8, train_loss: 0.0080 step time: 0.1815\n",
      "epoch 470 average loss: 0.0093\n",
      "current epoch: 470 current mean dice: 0.9621 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 470 is: 2.3722\n",
      "----------\n",
      "epoch 471/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2402\n",
      "2/8, train_loss: 0.0084 step time: 0.1976\n",
      "3/8, train_loss: 0.0083 step time: 0.1996\n",
      "4/8, train_loss: 0.0089 step time: 0.1998\n",
      "5/8, train_loss: 0.0072 step time: 0.2025\n",
      "6/8, train_loss: 0.0103 step time: 0.1974\n",
      "7/8, train_loss: 0.0095 step time: 0.1808\n",
      "8/8, train_loss: 0.0095 step time: 0.1830\n",
      "epoch 471 average loss: 0.0091\n",
      "time consuming of epoch 471 is: 1.6019\n",
      "----------\n",
      "epoch 472/600\n",
      "1/8, train_loss: 0.0096 step time: 0.2408\n",
      "2/8, train_loss: 0.0084 step time: 0.1996\n",
      "3/8, train_loss: 0.0087 step time: 0.2006\n",
      "4/8, train_loss: 0.0090 step time: 0.1999\n",
      "5/8, train_loss: 0.0078 step time: 0.2007\n",
      "6/8, train_loss: 0.0129 step time: 0.2016\n",
      "7/8, train_loss: 0.0081 step time: 0.1825\n",
      "8/8, train_loss: 0.0110 step time: 0.1823\n",
      "epoch 472 average loss: 0.0094\n",
      "time consuming of epoch 472 is: 1.6099\n",
      "----------\n",
      "epoch 473/600\n",
      "1/8, train_loss: 0.0118 step time: 0.2401\n",
      "2/8, train_loss: 0.0079 step time: 0.2048\n",
      "3/8, train_loss: 0.0086 step time: 0.2056\n",
      "4/8, train_loss: 0.0092 step time: 0.1989\n",
      "5/8, train_loss: 0.0084 step time: 0.2013\n",
      "6/8, train_loss: 0.0072 step time: 0.1997\n",
      "7/8, train_loss: 0.0108 step time: 0.1835\n",
      "8/8, train_loss: 0.0096 step time: 0.1827\n",
      "epoch 473 average loss: 0.0092\n",
      "time consuming of epoch 473 is: 1.6181\n",
      "----------\n",
      "epoch 474/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2402\n",
      "2/8, train_loss: 0.0090 step time: 0.2048\n",
      "3/8, train_loss: 0.0095 step time: 0.1992\n",
      "4/8, train_loss: 0.0095 step time: 0.2015\n",
      "5/8, train_loss: 0.0071 step time: 0.2019\n",
      "6/8, train_loss: 0.0079 step time: 0.2021\n",
      "7/8, train_loss: 0.0087 step time: 0.1830\n",
      "8/8, train_loss: 0.0105 step time: 0.1813\n",
      "epoch 474 average loss: 0.0089\n",
      "time consuming of epoch 474 is: 1.6155\n",
      "----------\n",
      "epoch 475/600\n",
      "1/8, train_loss: 0.0117 step time: 0.2394\n",
      "2/8, train_loss: 0.0098 step time: 0.2066\n",
      "3/8, train_loss: 0.0089 step time: 0.2045\n",
      "4/8, train_loss: 0.0108 step time: 0.1991\n",
      "5/8, train_loss: 0.0080 step time: 0.2022\n",
      "6/8, train_loss: 0.0089 step time: 0.1990\n",
      "7/8, train_loss: 0.0074 step time: 0.1846\n",
      "8/8, train_loss: 0.0097 step time: 0.1837\n",
      "epoch 475 average loss: 0.0094\n",
      "current epoch: 475 current mean dice: 0.9621 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 475 is: 2.3769\n",
      "----------\n",
      "epoch 476/600\n",
      "1/8, train_loss: 0.0081 step time: 0.2402\n",
      "2/8, train_loss: 0.0095 step time: 0.1993\n",
      "3/8, train_loss: 0.0089 step time: 0.2018\n",
      "4/8, train_loss: 0.0093 step time: 0.1995\n",
      "5/8, train_loss: 0.0082 step time: 0.1995\n",
      "6/8, train_loss: 0.0088 step time: 0.1978\n",
      "7/8, train_loss: 0.0098 step time: 0.1835\n",
      "8/8, train_loss: 0.0093 step time: 0.1820\n",
      "epoch 476 average loss: 0.0090\n",
      "time consuming of epoch 476 is: 1.6047\n",
      "----------\n",
      "epoch 477/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2398\n",
      "2/8, train_loss: 0.0076 step time: 0.2025\n",
      "3/8, train_loss: 0.0082 step time: 0.1988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/8, train_loss: 0.0076 step time: 0.1996\n",
      "5/8, train_loss: 0.0086 step time: 0.2000\n",
      "6/8, train_loss: 0.0095 step time: 0.2013\n",
      "7/8, train_loss: 0.0104 step time: 0.1845\n",
      "8/8, train_loss: 0.0114 step time: 0.1807\n",
      "epoch 477 average loss: 0.0092\n",
      "time consuming of epoch 477 is: 1.6089\n",
      "----------\n",
      "epoch 478/600\n",
      "1/8, train_loss: 0.0076 step time: 0.2422\n",
      "2/8, train_loss: 0.0113 step time: 0.2042\n",
      "3/8, train_loss: 0.0094 step time: 0.1988\n",
      "4/8, train_loss: 0.0120 step time: 0.2011\n",
      "5/8, train_loss: 0.0088 step time: 0.1979\n",
      "6/8, train_loss: 0.0088 step time: 0.2020\n",
      "7/8, train_loss: 0.0079 step time: 0.1824\n",
      "8/8, train_loss: 0.0093 step time: 0.1827\n",
      "epoch 478 average loss: 0.0094\n",
      "time consuming of epoch 478 is: 1.6127\n",
      "----------\n",
      "epoch 479/600\n",
      "1/8, train_loss: 0.0085 step time: 0.2396\n",
      "2/8, train_loss: 0.0094 step time: 0.2024\n",
      "3/8, train_loss: 0.0079 step time: 0.2044\n",
      "4/8, train_loss: 0.0082 step time: 0.1997\n",
      "5/8, train_loss: 0.0088 step time: 0.1995\n",
      "6/8, train_loss: 0.0083 step time: 0.2016\n",
      "7/8, train_loss: 0.0112 step time: 0.1807\n",
      "8/8, train_loss: 0.0085 step time: 0.1821\n",
      "epoch 479 average loss: 0.0089\n",
      "time consuming of epoch 479 is: 1.6114\n",
      "----------\n",
      "epoch 480/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2355\n",
      "2/8, train_loss: 0.0083 step time: 0.1992\n",
      "3/8, train_loss: 0.0106 step time: 0.1942\n",
      "4/8, train_loss: 0.0089 step time: 0.1945\n",
      "5/8, train_loss: 0.0098 step time: 0.1952\n",
      "6/8, train_loss: 0.0104 step time: 0.1958\n",
      "7/8, train_loss: 0.0099 step time: 0.1826\n",
      "8/8, train_loss: 0.0091 step time: 0.1827\n",
      "epoch 480 average loss: 0.0096\n",
      "current epoch: 480 current mean dice: 0.9607 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 480 is: 2.3354\n",
      "----------\n",
      "epoch 481/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2389\n",
      "2/8, train_loss: 0.0098 step time: 0.2021\n",
      "3/8, train_loss: 0.0090 step time: 0.1972\n",
      "4/8, train_loss: 0.0089 step time: 0.2004\n",
      "5/8, train_loss: 0.0087 step time: 0.1992\n",
      "6/8, train_loss: 0.0095 step time: 0.1993\n",
      "7/8, train_loss: 0.0079 step time: 0.1813\n",
      "8/8, train_loss: 0.0121 step time: 0.1813\n",
      "epoch 481 average loss: 0.0095\n",
      "time consuming of epoch 481 is: 1.6008\n",
      "----------\n",
      "epoch 482/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2384\n",
      "2/8, train_loss: 0.0108 step time: 0.2032\n",
      "3/8, train_loss: 0.0101 step time: 0.2027\n",
      "4/8, train_loss: 0.0083 step time: 0.1975\n",
      "5/8, train_loss: 0.0092 step time: 0.1967\n",
      "6/8, train_loss: 0.0081 step time: 0.1969\n",
      "7/8, train_loss: 0.0101 step time: 0.1790\n",
      "8/8, train_loss: 0.0089 step time: 0.1793\n",
      "epoch 482 average loss: 0.0095\n",
      "time consuming of epoch 482 is: 1.5950\n",
      "----------\n",
      "epoch 483/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2426\n",
      "2/8, train_loss: 0.0108 step time: 0.2026\n",
      "3/8, train_loss: 0.0114 step time: 0.1995\n",
      "4/8, train_loss: 0.0094 step time: 0.2040\n",
      "5/8, train_loss: 0.0082 step time: 0.2011\n",
      "6/8, train_loss: 0.0093 step time: 0.2030\n",
      "7/8, train_loss: 0.0081 step time: 0.1807\n",
      "8/8, train_loss: 0.0085 step time: 0.1829\n",
      "epoch 483 average loss: 0.0094\n",
      "time consuming of epoch 483 is: 1.6177\n",
      "----------\n",
      "epoch 484/600\n",
      "1/8, train_loss: 0.0090 step time: 0.2361\n",
      "2/8, train_loss: 0.0113 step time: 0.1978\n",
      "3/8, train_loss: 0.0102 step time: 0.1963\n",
      "4/8, train_loss: 0.0085 step time: 0.1953\n",
      "5/8, train_loss: 0.0091 step time: 0.1975\n",
      "6/8, train_loss: 0.0121 step time: 0.1970\n",
      "7/8, train_loss: 0.0090 step time: 0.1825\n",
      "8/8, train_loss: 0.0082 step time: 0.1851\n",
      "epoch 484 average loss: 0.0097\n",
      "time consuming of epoch 484 is: 1.5888\n",
      "----------\n",
      "epoch 485/600\n",
      "1/8, train_loss: 0.0091 step time: 0.3339\n",
      "2/8, train_loss: 0.0076 step time: 0.1954\n",
      "3/8, train_loss: 0.0086 step time: 0.1972\n",
      "4/8, train_loss: 0.0094 step time: 0.1967\n",
      "5/8, train_loss: 0.0084 step time: 0.1988\n",
      "6/8, train_loss: 0.0087 step time: 0.1981\n",
      "7/8, train_loss: 0.0089 step time: 0.1825\n",
      "8/8, train_loss: 0.0089 step time: 0.1836\n",
      "epoch 485 average loss: 0.0087\n",
      "current epoch: 485 current mean dice: 0.9618 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 485 is: 2.4437\n",
      "----------\n",
      "epoch 486/600\n",
      "1/8, train_loss: 0.0079 step time: 0.2335\n",
      "2/8, train_loss: 0.0084 step time: 0.1998\n",
      "3/8, train_loss: 0.0106 step time: 0.1974\n",
      "4/8, train_loss: 0.0091 step time: 0.1976\n",
      "5/8, train_loss: 0.0074 step time: 0.1982\n",
      "6/8, train_loss: 0.0104 step time: 0.1996\n",
      "7/8, train_loss: 0.0090 step time: 0.1829\n",
      "8/8, train_loss: 0.0092 step time: 0.1812\n",
      "epoch 486 average loss: 0.0090\n",
      "time consuming of epoch 486 is: 1.5913\n",
      "----------\n",
      "epoch 487/600\n",
      "1/8, train_loss: 0.0086 step time: 0.2411\n",
      "2/8, train_loss: 0.0085 step time: 0.2055\n",
      "3/8, train_loss: 0.0104 step time: 0.1988\n",
      "4/8, train_loss: 0.0092 step time: 0.2016\n",
      "5/8, train_loss: 0.0091 step time: 0.1992\n",
      "6/8, train_loss: 0.0122 step time: 0.2010\n",
      "7/8, train_loss: 0.0085 step time: 0.1832\n",
      "8/8, train_loss: 0.0130 step time: 0.1817\n",
      "epoch 487 average loss: 0.0099\n",
      "time consuming of epoch 487 is: 1.6134\n",
      "----------\n",
      "epoch 488/600\n",
      "1/8, train_loss: 0.0120 step time: 0.2369\n",
      "2/8, train_loss: 0.0080 step time: 0.2041\n",
      "3/8, train_loss: 0.0147 step time: 0.2022\n",
      "4/8, train_loss: 0.0096 step time: 0.1975\n",
      "5/8, train_loss: 0.0108 step time: 0.1998\n",
      "6/8, train_loss: 0.0087 step time: 0.2021\n",
      "7/8, train_loss: 0.0078 step time: 0.1833\n",
      "8/8, train_loss: 0.0086 step time: 0.1817\n",
      "epoch 488 average loss: 0.0100\n",
      "time consuming of epoch 488 is: 1.6093\n",
      "----------\n",
      "epoch 489/600\n",
      "1/8, train_loss: 0.0107 step time: 0.2366\n",
      "2/8, train_loss: 0.0108 step time: 0.2040\n",
      "3/8, train_loss: 0.0116 step time: 0.2016\n",
      "4/8, train_loss: 0.0080 step time: 0.1995\n",
      "5/8, train_loss: 0.0091 step time: 0.2016\n",
      "6/8, train_loss: 0.0089 step time: 0.2003\n",
      "7/8, train_loss: 0.0081 step time: 0.1845\n",
      "8/8, train_loss: 0.0091 step time: 0.1828\n",
      "epoch 489 average loss: 0.0095\n",
      "time consuming of epoch 489 is: 1.6124\n",
      "----------\n",
      "epoch 490/600\n",
      "1/8, train_loss: 0.0084 step time: 0.2405\n",
      "2/8, train_loss: 0.0095 step time: 0.2066\n",
      "3/8, train_loss: 0.0085 step time: 0.2042\n",
      "4/8, train_loss: 0.0103 step time: 0.2056\n",
      "5/8, train_loss: 0.0118 step time: 0.2038\n",
      "6/8, train_loss: 0.0079 step time: 0.2044\n",
      "7/8, train_loss: 0.0094 step time: 0.1849\n",
      "8/8, train_loss: 0.0091 step time: 0.1820\n",
      "epoch 490 average loss: 0.0094\n",
      "current epoch: 490 current mean dice: 0.9613 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 490 is: 2.3896\n",
      "----------\n",
      "epoch 491/600\n",
      "1/8, train_loss: 0.0089 step time: 0.2409\n",
      "2/8, train_loss: 0.0088 step time: 0.1990\n",
      "3/8, train_loss: 0.0083 step time: 0.2014\n",
      "4/8, train_loss: 0.0114 step time: 0.1988\n",
      "5/8, train_loss: 0.0092 step time: 0.1990\n",
      "6/8, train_loss: 0.0081 step time: 0.1981\n",
      "7/8, train_loss: 0.0105 step time: 0.1810\n",
      "8/8, train_loss: 0.0093 step time: 0.1818\n",
      "epoch 491 average loss: 0.0093\n",
      "time consuming of epoch 491 is: 1.6012\n",
      "----------\n",
      "epoch 492/600\n",
      "1/8, train_loss: 0.0086 step time: 0.2401\n",
      "2/8, train_loss: 0.0087 step time: 0.2051\n",
      "3/8, train_loss: 0.0077 step time: 0.2044\n",
      "4/8, train_loss: 0.0092 step time: 0.2001\n",
      "5/8, train_loss: 0.0105 step time: 0.2009\n",
      "6/8, train_loss: 0.0101 step time: 0.2001\n",
      "7/8, train_loss: 0.0077 step time: 0.1838\n",
      "8/8, train_loss: 0.0115 step time: 0.1829\n",
      "epoch 492 average loss: 0.0092\n",
      "time consuming of epoch 492 is: 1.6188\n",
      "----------\n",
      "epoch 493/600\n",
      "1/8, train_loss: 0.0101 step time: 0.2400\n",
      "2/8, train_loss: 0.0096 step time: 0.2038\n",
      "3/8, train_loss: 0.0088 step time: 0.1999\n",
      "4/8, train_loss: 0.0076 step time: 0.2040\n",
      "5/8, train_loss: 0.0097 step time: 0.2026\n",
      "6/8, train_loss: 0.0092 step time: 0.1998\n",
      "7/8, train_loss: 0.0073 step time: 0.1834\n",
      "8/8, train_loss: 0.0089 step time: 0.1824\n",
      "epoch 493 average loss: 0.0089\n",
      "time consuming of epoch 493 is: 1.6174\n",
      "----------\n",
      "epoch 494/600\n",
      "1/8, train_loss: 0.0086 step time: 0.2441\n",
      "2/8, train_loss: 0.0080 step time: 0.2019\n",
      "3/8, train_loss: 0.0088 step time: 0.2023\n",
      "4/8, train_loss: 0.0086 step time: 0.1999\n",
      "5/8, train_loss: 0.0076 step time: 0.1999\n",
      "6/8, train_loss: 0.0095 step time: 0.2051\n",
      "7/8, train_loss: 0.0100 step time: 0.1832\n",
      "8/8, train_loss: 0.0088 step time: 0.1818\n",
      "epoch 494 average loss: 0.0087\n",
      "time consuming of epoch 494 is: 1.6198\n",
      "----------\n",
      "epoch 495/600\n",
      "1/8, train_loss: 0.0089 step time: 0.2404\n",
      "2/8, train_loss: 0.0085 step time: 0.2033\n",
      "3/8, train_loss: 0.0078 step time: 0.1994\n",
      "4/8, train_loss: 0.0083 step time: 0.2006\n",
      "5/8, train_loss: 0.0119 step time: 0.1985\n",
      "6/8, train_loss: 0.0097 step time: 0.2009\n",
      "7/8, train_loss: 0.0075 step time: 0.1836\n",
      "8/8, train_loss: 0.0072 step time: 0.1829\n",
      "epoch 495 average loss: 0.0087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 495 current mean dice: 0.9614 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 495 is: 2.3668\n",
      "----------\n",
      "epoch 496/600\n",
      "1/8, train_loss: 0.0096 step time: 0.2380\n",
      "2/8, train_loss: 0.0117 step time: 0.2048\n",
      "3/8, train_loss: 0.0077 step time: 0.2041\n",
      "4/8, train_loss: 0.0102 step time: 0.2009\n",
      "5/8, train_loss: 0.0087 step time: 0.2014\n",
      "6/8, train_loss: 0.0077 step time: 0.1993\n",
      "7/8, train_loss: 0.0102 step time: 0.1828\n",
      "8/8, train_loss: 0.0101 step time: 0.1820\n",
      "epoch 496 average loss: 0.0095\n",
      "time consuming of epoch 496 is: 1.6145\n",
      "----------\n",
      "epoch 497/600\n",
      "1/8, train_loss: 0.0085 step time: 0.2405\n",
      "2/8, train_loss: 0.0095 step time: 0.2037\n",
      "3/8, train_loss: 0.0101 step time: 0.2015\n",
      "4/8, train_loss: 0.0086 step time: 0.1999\n",
      "5/8, train_loss: 0.0112 step time: 0.2000\n",
      "6/8, train_loss: 0.0091 step time: 0.1976\n",
      "7/8, train_loss: 0.0092 step time: 0.1833\n",
      "8/8, train_loss: 0.0086 step time: 0.1828\n",
      "epoch 497 average loss: 0.0093\n",
      "time consuming of epoch 497 is: 1.6106\n",
      "----------\n",
      "epoch 498/600\n",
      "1/8, train_loss: 0.0089 step time: 0.2383\n",
      "2/8, train_loss: 0.0089 step time: 0.2004\n",
      "3/8, train_loss: 0.0102 step time: 0.1996\n",
      "4/8, train_loss: 0.0076 step time: 0.1984\n",
      "5/8, train_loss: 0.0092 step time: 0.2033\n",
      "6/8, train_loss: 0.0097 step time: 0.1983\n",
      "7/8, train_loss: 0.0088 step time: 0.1817\n",
      "8/8, train_loss: 0.0077 step time: 0.1825\n",
      "epoch 498 average loss: 0.0089\n",
      "time consuming of epoch 498 is: 1.6040\n",
      "----------\n",
      "epoch 499/600\n",
      "1/8, train_loss: 0.0086 step time: 0.2364\n",
      "2/8, train_loss: 0.0070 step time: 0.2017\n",
      "3/8, train_loss: 0.0108 step time: 0.1992\n",
      "4/8, train_loss: 0.0082 step time: 0.1999\n",
      "5/8, train_loss: 0.0085 step time: 0.2019\n",
      "6/8, train_loss: 0.0101 step time: 0.1989\n",
      "7/8, train_loss: 0.0107 step time: 0.1832\n",
      "8/8, train_loss: 0.0088 step time: 0.1834\n",
      "epoch 499 average loss: 0.0091\n",
      "time consuming of epoch 499 is: 1.6063\n",
      "----------\n",
      "epoch 500/600\n",
      "1/8, train_loss: 0.0109 step time: 0.2387\n",
      "2/8, train_loss: 0.0105 step time: 0.1981\n",
      "3/8, train_loss: 0.0088 step time: 0.1970\n",
      "4/8, train_loss: 0.0091 step time: 0.1968\n",
      "5/8, train_loss: 0.0086 step time: 0.1963\n",
      "6/8, train_loss: 0.0091 step time: 0.1957\n",
      "7/8, train_loss: 0.0094 step time: 0.1829\n",
      "8/8, train_loss: 0.0101 step time: 0.1824\n",
      "epoch 500 average loss: 0.0096\n",
      "current epoch: 500 current mean dice: 0.9620 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 500 is: 2.3446\n",
      "----------\n",
      "epoch 501/600\n",
      "1/8, train_loss: 0.0096 step time: 0.2399\n",
      "2/8, train_loss: 0.0091 step time: 0.2044\n",
      "3/8, train_loss: 0.0075 step time: 0.1984\n",
      "4/8, train_loss: 0.0096 step time: 0.1979\n",
      "5/8, train_loss: 0.0097 step time: 0.1979\n",
      "6/8, train_loss: 0.0086 step time: 0.2000\n",
      "7/8, train_loss: 0.0090 step time: 0.1838\n",
      "8/8, train_loss: 0.0104 step time: 0.1826\n",
      "epoch 501 average loss: 0.0092\n",
      "time consuming of epoch 501 is: 1.6060\n",
      "----------\n",
      "epoch 502/600\n",
      "1/8, train_loss: 0.0082 step time: 0.2395\n",
      "2/8, train_loss: 0.0085 step time: 0.2004\n",
      "3/8, train_loss: 0.0081 step time: 0.2001\n",
      "4/8, train_loss: 0.0085 step time: 0.1998\n",
      "5/8, train_loss: 0.0099 step time: 0.2014\n",
      "6/8, train_loss: 0.0103 step time: 0.2002\n",
      "7/8, train_loss: 0.0085 step time: 0.1829\n",
      "8/8, train_loss: 0.0096 step time: 0.1827\n",
      "epoch 502 average loss: 0.0089\n",
      "time consuming of epoch 502 is: 1.6084\n",
      "----------\n",
      "epoch 503/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2399\n",
      "2/8, train_loss: 0.0084 step time: 0.2023\n",
      "3/8, train_loss: 0.0097 step time: 0.1997\n",
      "4/8, train_loss: 0.0075 step time: 0.1988\n",
      "5/8, train_loss: 0.0107 step time: 0.2001\n",
      "6/8, train_loss: 0.0085 step time: 0.2012\n",
      "7/8, train_loss: 0.0084 step time: 0.1826\n",
      "8/8, train_loss: 0.0094 step time: 0.1829\n",
      "epoch 503 average loss: 0.0090\n",
      "time consuming of epoch 503 is: 1.6092\n",
      "----------\n",
      "epoch 504/600\n",
      "1/8, train_loss: 0.0079 step time: 0.2379\n",
      "2/8, train_loss: 0.0103 step time: 0.1977\n",
      "3/8, train_loss: 0.0075 step time: 0.1974\n",
      "4/8, train_loss: 0.0104 step time: 0.1959\n",
      "5/8, train_loss: 0.0094 step time: 0.1969\n",
      "6/8, train_loss: 0.0100 step time: 0.1946\n",
      "7/8, train_loss: 0.0105 step time: 0.1825\n",
      "8/8, train_loss: 0.0086 step time: 0.1829\n",
      "epoch 504 average loss: 0.0093\n",
      "time consuming of epoch 504 is: 1.5874\n",
      "----------\n",
      "epoch 505/600\n",
      "1/8, train_loss: 0.0081 step time: 0.2405\n",
      "2/8, train_loss: 0.0074 step time: 0.2033\n",
      "3/8, train_loss: 0.0090 step time: 0.1992\n",
      "4/8, train_loss: 0.0091 step time: 0.2069\n",
      "5/8, train_loss: 0.0115 step time: 0.2005\n",
      "6/8, train_loss: 0.0086 step time: 0.2010\n",
      "7/8, train_loss: 0.0104 step time: 0.1831\n",
      "8/8, train_loss: 0.0076 step time: 0.1822\n",
      "epoch 505 average loss: 0.0090\n",
      "current epoch: 505 current mean dice: 0.9620 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 505 is: 2.3747\n",
      "----------\n",
      "epoch 506/600\n",
      "1/8, train_loss: 0.0089 step time: 0.2374\n",
      "2/8, train_loss: 0.0087 step time: 0.1981\n",
      "3/8, train_loss: 0.0082 step time: 0.2001\n",
      "4/8, train_loss: 0.0106 step time: 0.2003\n",
      "5/8, train_loss: 0.0079 step time: 0.1993\n",
      "6/8, train_loss: 0.0084 step time: 0.1978\n",
      "7/8, train_loss: 0.0092 step time: 0.1818\n",
      "8/8, train_loss: 0.0106 step time: 0.1816\n",
      "epoch 506 average loss: 0.0091\n",
      "time consuming of epoch 506 is: 1.5975\n",
      "----------\n",
      "epoch 507/600\n",
      "1/8, train_loss: 0.0095 step time: 0.2368\n",
      "2/8, train_loss: 0.0085 step time: 0.1970\n",
      "3/8, train_loss: 0.0096 step time: 0.1963\n",
      "4/8, train_loss: 0.0100 step time: 0.1942\n",
      "5/8, train_loss: 0.0072 step time: 0.1954\n",
      "6/8, train_loss: 0.0080 step time: 0.1958\n",
      "7/8, train_loss: 0.0093 step time: 0.1834\n",
      "8/8, train_loss: 0.0081 step time: 0.1822\n",
      "epoch 507 average loss: 0.0088\n",
      "time consuming of epoch 507 is: 1.5825\n",
      "----------\n",
      "epoch 508/600\n",
      "1/8, train_loss: 0.0120 step time: 0.2292\n",
      "2/8, train_loss: 0.0076 step time: 0.1978\n",
      "3/8, train_loss: 0.0080 step time: 0.1949\n",
      "4/8, train_loss: 0.0091 step time: 0.1987\n",
      "5/8, train_loss: 0.0084 step time: 0.1997\n",
      "6/8, train_loss: 0.0089 step time: 0.2003\n",
      "7/8, train_loss: 0.0092 step time: 0.1835\n",
      "8/8, train_loss: 0.0111 step time: 0.1823\n",
      "epoch 508 average loss: 0.0093\n",
      "time consuming of epoch 508 is: 1.5877\n",
      "----------\n",
      "epoch 509/600\n",
      "1/8, train_loss: 0.0094 step time: 0.2391\n",
      "2/8, train_loss: 0.0088 step time: 0.2004\n",
      "3/8, train_loss: 0.0085 step time: 0.1948\n",
      "4/8, train_loss: 0.0088 step time: 0.1976\n",
      "5/8, train_loss: 0.0090 step time: 0.1980\n",
      "6/8, train_loss: 0.0076 step time: 0.1951\n",
      "7/8, train_loss: 0.0076 step time: 0.1840\n",
      "8/8, train_loss: 0.0093 step time: 0.1817\n",
      "epoch 509 average loss: 0.0086\n",
      "time consuming of epoch 509 is: 1.5921\n",
      "----------\n",
      "epoch 510/600\n",
      "1/8, train_loss: 0.0084 step time: 0.2325\n",
      "2/8, train_loss: 0.0089 step time: 0.1979\n",
      "3/8, train_loss: 0.0109 step time: 0.1965\n",
      "4/8, train_loss: 0.0090 step time: 0.1939\n",
      "5/8, train_loss: 0.0070 step time: 0.1947\n",
      "6/8, train_loss: 0.0096 step time: 0.1960\n",
      "7/8, train_loss: 0.0076 step time: 0.1822\n",
      "8/8, train_loss: 0.0087 step time: 0.1823\n",
      "epoch 510 average loss: 0.0088\n",
      "current epoch: 510 current mean dice: 0.9617 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 510 is: 2.3320\n",
      "----------\n",
      "epoch 511/600\n",
      "1/8, train_loss: 0.0089 step time: 0.2361\n",
      "2/8, train_loss: 0.0087 step time: 0.1986\n",
      "3/8, train_loss: 0.0083 step time: 0.1990\n",
      "4/8, train_loss: 0.0090 step time: 0.1963\n",
      "5/8, train_loss: 0.0097 step time: 0.1981\n",
      "6/8, train_loss: 0.0119 step time: 0.1997\n",
      "7/8, train_loss: 0.0069 step time: 0.1815\n",
      "8/8, train_loss: 0.0094 step time: 0.1814\n",
      "epoch 511 average loss: 0.0091\n",
      "time consuming of epoch 511 is: 1.5918\n",
      "----------\n",
      "epoch 512/600\n",
      "1/8, train_loss: 0.0073 step time: 0.2407\n",
      "2/8, train_loss: 0.0078 step time: 0.1995\n",
      "3/8, train_loss: 0.0102 step time: 0.1977\n",
      "4/8, train_loss: 0.0093 step time: 0.2024\n",
      "5/8, train_loss: 0.0093 step time: 0.1988\n",
      "6/8, train_loss: 0.0084 step time: 0.1987\n",
      "7/8, train_loss: 0.0075 step time: 0.1830\n",
      "8/8, train_loss: 0.0090 step time: 0.1821\n",
      "epoch 512 average loss: 0.0086\n",
      "time consuming of epoch 512 is: 1.6043\n",
      "----------\n",
      "epoch 513/600\n",
      "1/8, train_loss: 0.0135 step time: 0.2398\n",
      "2/8, train_loss: 0.0088 step time: 0.2011\n",
      "3/8, train_loss: 0.0095 step time: 0.1994\n",
      "4/8, train_loss: 0.0109 step time: 0.1998\n",
      "5/8, train_loss: 0.0095 step time: 0.2000\n",
      "6/8, train_loss: 0.0077 step time: 0.1985\n",
      "7/8, train_loss: 0.0096 step time: 0.1817\n",
      "8/8, train_loss: 0.0086 step time: 0.1829\n",
      "epoch 513 average loss: 0.0098\n",
      "time consuming of epoch 513 is: 1.6047\n",
      "----------\n",
      "epoch 514/600\n",
      "1/8, train_loss: 0.0099 step time: 0.2395\n",
      "2/8, train_loss: 0.0092 step time: 0.2020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8, train_loss: 0.0081 step time: 0.2045\n",
      "4/8, train_loss: 0.0101 step time: 0.1970\n",
      "5/8, train_loss: 0.0105 step time: 0.2006\n",
      "6/8, train_loss: 0.0090 step time: 0.1990\n",
      "7/8, train_loss: 0.0079 step time: 0.1849\n",
      "8/8, train_loss: 0.0087 step time: 0.1819\n",
      "epoch 514 average loss: 0.0092\n",
      "time consuming of epoch 514 is: 1.6109\n",
      "----------\n",
      "epoch 515/600\n",
      "1/8, train_loss: 0.0075 step time: 0.2377\n",
      "2/8, train_loss: 0.0080 step time: 0.2031\n",
      "3/8, train_loss: 0.0112 step time: 0.1997\n",
      "4/8, train_loss: 0.0129 step time: 0.2015\n",
      "5/8, train_loss: 0.0074 step time: 0.2002\n",
      "6/8, train_loss: 0.0086 step time: 0.2026\n",
      "7/8, train_loss: 0.0086 step time: 0.1811\n",
      "8/8, train_loss: 0.0096 step time: 0.1819\n",
      "epoch 515 average loss: 0.0092\n",
      "current epoch: 515 current mean dice: 0.9601 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 515 is: 2.3628\n",
      "----------\n",
      "epoch 516/600\n",
      "1/8, train_loss: 0.0088 step time: 0.2376\n",
      "2/8, train_loss: 0.0083 step time: 0.2013\n",
      "3/8, train_loss: 0.0092 step time: 0.1985\n",
      "4/8, train_loss: 0.0094 step time: 0.1985\n",
      "5/8, train_loss: 0.0100 step time: 0.2000\n",
      "6/8, train_loss: 0.0096 step time: 0.1999\n",
      "7/8, train_loss: 0.0099 step time: 0.1817\n",
      "8/8, train_loss: 0.0082 step time: 0.1814\n",
      "epoch 516 average loss: 0.0092\n",
      "time consuming of epoch 516 is: 1.6003\n",
      "----------\n",
      "epoch 517/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2385\n",
      "2/8, train_loss: 0.0090 step time: 0.2014\n",
      "3/8, train_loss: 0.0078 step time: 0.2058\n",
      "4/8, train_loss: 0.0092 step time: 0.2014\n",
      "5/8, train_loss: 0.0077 step time: 0.1985\n",
      "6/8, train_loss: 0.0088 step time: 0.2013\n",
      "7/8, train_loss: 0.0095 step time: 0.1831\n",
      "8/8, train_loss: 0.0086 step time: 0.1825\n",
      "epoch 517 average loss: 0.0088\n",
      "time consuming of epoch 517 is: 1.6141\n",
      "----------\n",
      "epoch 518/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2409\n",
      "2/8, train_loss: 0.0085 step time: 0.2031\n",
      "3/8, train_loss: 0.0083 step time: 0.1995\n",
      "4/8, train_loss: 0.0084 step time: 0.1991\n",
      "5/8, train_loss: 0.0095 step time: 0.1996\n",
      "6/8, train_loss: 0.0091 step time: 0.2012\n",
      "7/8, train_loss: 0.0097 step time: 0.1828\n",
      "8/8, train_loss: 0.0094 step time: 0.1824\n",
      "epoch 518 average loss: 0.0090\n",
      "time consuming of epoch 518 is: 1.6100\n",
      "----------\n",
      "epoch 519/600\n",
      "1/8, train_loss: 0.0087 step time: 0.2419\n",
      "2/8, train_loss: 0.0078 step time: 0.2005\n",
      "3/8, train_loss: 0.0094 step time: 0.2011\n",
      "4/8, train_loss: 0.0086 step time: 0.2014\n",
      "5/8, train_loss: 0.0084 step time: 0.1971\n",
      "6/8, train_loss: 0.0109 step time: 0.2012\n",
      "7/8, train_loss: 0.0090 step time: 0.1826\n",
      "8/8, train_loss: 0.0074 step time: 0.1840\n",
      "epoch 519 average loss: 0.0088\n",
      "time consuming of epoch 519 is: 1.6115\n",
      "----------\n",
      "epoch 520/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2406\n",
      "2/8, train_loss: 0.0081 step time: 0.2025\n",
      "3/8, train_loss: 0.0075 step time: 0.1985\n",
      "4/8, train_loss: 0.0098 step time: 0.2017\n",
      "5/8, train_loss: 0.0109 step time: 0.2047\n",
      "6/8, train_loss: 0.0076 step time: 0.1991\n",
      "7/8, train_loss: 0.0079 step time: 0.1830\n",
      "8/8, train_loss: 0.0103 step time: 0.1836\n",
      "epoch 520 average loss: 0.0089\n",
      "current epoch: 520 current mean dice: 0.9611 best mean dice: 0.9622 at epoch: 205\n",
      "time consuming of epoch 520 is: 2.3704\n",
      "----------\n",
      "epoch 521/600\n",
      "1/8, train_loss: 0.0090 step time: 0.2404\n",
      "2/8, train_loss: 0.0075 step time: 0.2019\n",
      "3/8, train_loss: 0.0077 step time: 0.2001\n",
      "4/8, train_loss: 0.0105 step time: 0.1974\n",
      "5/8, train_loss: 0.0076 step time: 0.1992\n",
      "6/8, train_loss: 0.0111 step time: 0.1985\n",
      "7/8, train_loss: 0.0073 step time: 0.1814\n",
      "8/8, train_loss: 0.0104 step time: 0.1828\n",
      "epoch 521 average loss: 0.0089\n",
      "time consuming of epoch 521 is: 1.6026\n",
      "----------\n",
      "epoch 522/600\n",
      "1/8, train_loss: 0.0080 step time: 0.2401\n",
      "2/8, train_loss: 0.0089 step time: 0.2042\n",
      "3/8, train_loss: 0.0085 step time: 0.2016\n",
      "4/8, train_loss: 0.0092 step time: 0.2004\n",
      "5/8, train_loss: 0.0094 step time: 0.2012\n",
      "6/8, train_loss: 0.0091 step time: 0.1995\n",
      "7/8, train_loss: 0.0085 step time: 0.1853\n",
      "8/8, train_loss: 0.0072 step time: 0.1833\n",
      "epoch 522 average loss: 0.0086\n",
      "time consuming of epoch 522 is: 1.6169\n",
      "----------\n",
      "epoch 523/600\n",
      "1/8, train_loss: 0.0076 step time: 0.2404\n",
      "2/8, train_loss: 0.0072 step time: 0.2016\n",
      "3/8, train_loss: 0.0084 step time: 0.1991\n",
      "4/8, train_loss: 0.0074 step time: 0.1995\n",
      "5/8, train_loss: 0.0113 step time: 0.2013\n",
      "6/8, train_loss: 0.0086 step time: 0.1996\n",
      "7/8, train_loss: 0.0094 step time: 0.1837\n",
      "8/8, train_loss: 0.0082 step time: 0.1820\n",
      "epoch 523 average loss: 0.0085\n",
      "time consuming of epoch 523 is: 1.6089\n",
      "----------\n",
      "epoch 524/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2388\n",
      "2/8, train_loss: 0.0082 step time: 0.1988\n",
      "3/8, train_loss: 0.0123 step time: 0.2021\n",
      "4/8, train_loss: 0.0089 step time: 0.2003\n",
      "5/8, train_loss: 0.0070 step time: 0.2000\n",
      "6/8, train_loss: 0.0075 step time: 0.1983\n",
      "7/8, train_loss: 0.0098 step time: 0.1825\n",
      "8/8, train_loss: 0.0090 step time: 0.1824\n",
      "epoch 524 average loss: 0.0090\n",
      "time consuming of epoch 524 is: 1.6048\n",
      "----------\n",
      "epoch 525/600\n",
      "1/8, train_loss: 0.0076 step time: 0.2472\n",
      "2/8, train_loss: 0.0091 step time: 0.2033\n",
      "3/8, train_loss: 0.0088 step time: 0.1997\n",
      "4/8, train_loss: 0.0096 step time: 0.1997\n",
      "5/8, train_loss: 0.0075 step time: 0.2006\n",
      "6/8, train_loss: 0.0085 step time: 0.2009\n",
      "7/8, train_loss: 0.0095 step time: 0.1822\n",
      "8/8, train_loss: 0.0075 step time: 0.1840\n",
      "epoch 525 average loss: 0.0085\n",
      "saved new best metric model\n",
      "current epoch: 525 current mean dice: 0.9623 best mean dice: 0.9623 at epoch: 525\n",
      "time consuming of epoch 525 is: 2.5147\n",
      "----------\n",
      "epoch 526/600\n",
      "1/8, train_loss: 0.0084 step time: 0.2406\n",
      "2/8, train_loss: 0.0085 step time: 0.1990\n",
      "3/8, train_loss: 0.0078 step time: 0.2008\n",
      "4/8, train_loss: 0.0077 step time: 0.1979\n",
      "5/8, train_loss: 0.0100 step time: 0.1996\n",
      "6/8, train_loss: 0.0092 step time: 0.1984\n",
      "7/8, train_loss: 0.0103 step time: 0.1812\n",
      "8/8, train_loss: 0.0082 step time: 0.1814\n",
      "epoch 526 average loss: 0.0088\n",
      "time consuming of epoch 526 is: 1.6000\n",
      "----------\n",
      "epoch 527/600\n",
      "1/8, train_loss: 0.0091 step time: 0.2417\n",
      "2/8, train_loss: 0.0088 step time: 0.2023\n",
      "3/8, train_loss: 0.0080 step time: 0.1996\n",
      "4/8, train_loss: 0.0086 step time: 0.2021\n",
      "5/8, train_loss: 0.0088 step time: 0.1996\n",
      "6/8, train_loss: 0.0110 step time: 0.2001\n",
      "7/8, train_loss: 0.0121 step time: 0.1824\n",
      "8/8, train_loss: 0.0094 step time: 0.1826\n",
      "epoch 527 average loss: 0.0095\n",
      "time consuming of epoch 527 is: 1.6119\n",
      "----------\n",
      "epoch 528/600\n",
      "1/8, train_loss: 0.0096 step time: 0.2388\n",
      "2/8, train_loss: 0.0078 step time: 0.2031\n",
      "3/8, train_loss: 0.0072 step time: 0.1994\n",
      "4/8, train_loss: 0.0094 step time: 0.2008\n",
      "5/8, train_loss: 0.0076 step time: 0.1983\n",
      "6/8, train_loss: 0.0092 step time: 0.2004\n",
      "7/8, train_loss: 0.0085 step time: 0.1826\n",
      "8/8, train_loss: 0.0087 step time: 0.1818\n",
      "epoch 528 average loss: 0.0085\n",
      "time consuming of epoch 528 is: 1.6065\n",
      "----------\n",
      "epoch 529/600\n",
      "1/8, train_loss: 0.0076 step time: 0.2410\n",
      "2/8, train_loss: 0.0082 step time: 0.2018\n",
      "3/8, train_loss: 0.0089 step time: 0.2005\n",
      "4/8, train_loss: 0.0083 step time: 0.1998\n",
      "5/8, train_loss: 0.0082 step time: 0.1995\n",
      "6/8, train_loss: 0.0140 step time: 0.2002\n",
      "7/8, train_loss: 0.0082 step time: 0.1827\n",
      "8/8, train_loss: 0.0102 step time: 0.1828\n",
      "epoch 529 average loss: 0.0092\n",
      "time consuming of epoch 529 is: 1.6098\n",
      "----------\n",
      "epoch 530/600\n",
      "1/8, train_loss: 0.0085 step time: 0.2434\n",
      "2/8, train_loss: 0.0092 step time: 0.2041\n",
      "3/8, train_loss: 0.0091 step time: 0.2014\n",
      "4/8, train_loss: 0.0106 step time: 0.2002\n",
      "5/8, train_loss: 0.0098 step time: 0.2016\n",
      "6/8, train_loss: 0.0079 step time: 0.2002\n",
      "7/8, train_loss: 0.0085 step time: 0.1826\n",
      "8/8, train_loss: 0.0082 step time: 0.1838\n",
      "epoch 530 average loss: 0.0090\n",
      "current epoch: 530 current mean dice: 0.9620 best mean dice: 0.9623 at epoch: 525\n",
      "time consuming of epoch 530 is: 2.3745\n",
      "----------\n",
      "epoch 531/600\n",
      "1/8, train_loss: 0.0086 step time: 0.2407\n",
      "2/8, train_loss: 0.0091 step time: 0.1976\n",
      "3/8, train_loss: 0.0080 step time: 0.2012\n",
      "4/8, train_loss: 0.0084 step time: 0.1988\n",
      "5/8, train_loss: 0.0102 step time: 0.1997\n",
      "6/8, train_loss: 0.0115 step time: 0.1988\n",
      "7/8, train_loss: 0.0085 step time: 0.1817\n",
      "8/8, train_loss: 0.0086 step time: 0.1814\n",
      "epoch 531 average loss: 0.0091\n",
      "time consuming of epoch 531 is: 1.6010\n",
      "----------\n",
      "epoch 532/600\n",
      "1/8, train_loss: 0.0090 step time: 0.2403\n",
      "2/8, train_loss: 0.0082 step time: 0.2036\n",
      "3/8, train_loss: 0.0096 step time: 0.1996\n",
      "4/8, train_loss: 0.0077 step time: 0.2019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8, train_loss: 0.0094 step time: 0.2022\n",
      "6/8, train_loss: 0.0088 step time: 0.2016\n",
      "7/8, train_loss: 0.0073 step time: 0.1821\n",
      "8/8, train_loss: 0.0107 step time: 0.1819\n",
      "epoch 532 average loss: 0.0088\n",
      "time consuming of epoch 532 is: 1.6145\n",
      "----------\n",
      "epoch 533/600\n",
      "1/8, train_loss: 0.0076 step time: 0.2416\n",
      "2/8, train_loss: 0.0086 step time: 0.2027\n",
      "3/8, train_loss: 0.0113 step time: 0.2051\n",
      "4/8, train_loss: 0.0103 step time: 0.2004\n",
      "5/8, train_loss: 0.0091 step time: 0.2030\n",
      "6/8, train_loss: 0.0081 step time: 0.1994\n",
      "7/8, train_loss: 0.0090 step time: 0.1842\n",
      "8/8, train_loss: 0.0080 step time: 0.1833\n",
      "epoch 533 average loss: 0.0090\n",
      "time consuming of epoch 533 is: 1.6211\n",
      "----------\n",
      "epoch 534/600\n",
      "1/8, train_loss: 0.0102 step time: 0.2402\n",
      "2/8, train_loss: 0.0080 step time: 0.1990\n",
      "3/8, train_loss: 0.0085 step time: 0.1997\n",
      "4/8, train_loss: 0.0076 step time: 0.1978\n",
      "5/8, train_loss: 0.0074 step time: 0.2005\n",
      "6/8, train_loss: 0.0084 step time: 0.1992\n",
      "7/8, train_loss: 0.0085 step time: 0.1822\n",
      "8/8, train_loss: 0.0087 step time: 0.1814\n",
      "epoch 534 average loss: 0.0084\n",
      "time consuming of epoch 534 is: 1.6015\n",
      "----------\n",
      "epoch 535/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2397\n",
      "2/8, train_loss: 0.0074 step time: 0.2006\n",
      "3/8, train_loss: 0.0092 step time: 0.2014\n",
      "4/8, train_loss: 0.0109 step time: 0.2045\n",
      "5/8, train_loss: 0.0077 step time: 0.1976\n",
      "6/8, train_loss: 0.0081 step time: 0.2014\n",
      "7/8, train_loss: 0.0089 step time: 0.1822\n",
      "8/8, train_loss: 0.0089 step time: 0.1819\n",
      "epoch 535 average loss: 0.0088\n",
      "current epoch: 535 current mean dice: 0.9616 best mean dice: 0.9623 at epoch: 525\n",
      "time consuming of epoch 535 is: 2.3652\n",
      "----------\n",
      "epoch 536/600\n",
      "1/8, train_loss: 0.0082 step time: 0.2324\n",
      "2/8, train_loss: 0.0085 step time: 0.1971\n",
      "3/8, train_loss: 0.0104 step time: 0.1914\n",
      "4/8, train_loss: 0.0078 step time: 0.1942\n",
      "5/8, train_loss: 0.0090 step time: 0.1955\n",
      "6/8, train_loss: 0.0089 step time: 0.1924\n",
      "7/8, train_loss: 0.0085 step time: 0.1810\n",
      "8/8, train_loss: 0.0076 step time: 0.1808\n",
      "epoch 536 average loss: 0.0086\n",
      "time consuming of epoch 536 is: 1.5658\n",
      "----------\n",
      "epoch 537/600\n",
      "1/8, train_loss: 0.0084 step time: 0.2319\n",
      "2/8, train_loss: 0.0075 step time: 0.1966\n",
      "3/8, train_loss: 0.0075 step time: 0.1962\n",
      "4/8, train_loss: 0.0104 step time: 0.2021\n",
      "5/8, train_loss: 0.0087 step time: 0.2012\n",
      "6/8, train_loss: 0.0080 step time: 0.2011\n",
      "7/8, train_loss: 0.0084 step time: 0.1816\n",
      "8/8, train_loss: 0.0108 step time: 0.1814\n",
      "epoch 537 average loss: 0.0087\n",
      "time consuming of epoch 537 is: 1.5933\n",
      "----------\n",
      "epoch 538/600\n",
      "1/8, train_loss: 0.0084 step time: 0.2390\n",
      "2/8, train_loss: 0.0091 step time: 0.2012\n",
      "3/8, train_loss: 0.0091 step time: 0.1997\n",
      "4/8, train_loss: 0.0098 step time: 0.2006\n",
      "5/8, train_loss: 0.0078 step time: 0.2031\n",
      "6/8, train_loss: 0.0077 step time: 0.2022\n",
      "7/8, train_loss: 0.0128 step time: 0.1828\n",
      "8/8, train_loss: 0.0085 step time: 0.1829\n",
      "epoch 538 average loss: 0.0092\n",
      "time consuming of epoch 538 is: 1.6130\n",
      "----------\n",
      "epoch 539/600\n",
      "1/8, train_loss: 0.0097 step time: 0.2427\n",
      "2/8, train_loss: 0.0095 step time: 0.1974\n",
      "3/8, train_loss: 0.0082 step time: 0.2021\n",
      "4/8, train_loss: 0.0095 step time: 0.2013\n",
      "5/8, train_loss: 0.0068 step time: 0.1991\n",
      "6/8, train_loss: 0.0081 step time: 0.2013\n",
      "7/8, train_loss: 0.0084 step time: 0.1827\n",
      "8/8, train_loss: 0.0104 step time: 0.1847\n",
      "epoch 539 average loss: 0.0088\n",
      "time consuming of epoch 539 is: 1.6130\n",
      "----------\n",
      "epoch 540/600\n",
      "1/8, train_loss: 0.0078 step time: 0.2372\n",
      "2/8, train_loss: 0.0073 step time: 0.2027\n",
      "3/8, train_loss: 0.0093 step time: 0.2033\n",
      "4/8, train_loss: 0.0078 step time: 0.1995\n",
      "5/8, train_loss: 0.0079 step time: 0.2006\n",
      "6/8, train_loss: 0.0084 step time: 0.1997\n",
      "7/8, train_loss: 0.0107 step time: 0.1855\n",
      "8/8, train_loss: 0.0092 step time: 0.1820\n",
      "epoch 540 average loss: 0.0086\n",
      "current epoch: 540 current mean dice: 0.9612 best mean dice: 0.9623 at epoch: 525\n",
      "time consuming of epoch 540 is: 2.3685\n",
      "----------\n",
      "epoch 541/600\n",
      "1/8, train_loss: 0.0085 step time: 0.2270\n",
      "2/8, train_loss: 0.0080 step time: 0.1980\n",
      "3/8, train_loss: 0.0096 step time: 0.1953\n",
      "4/8, train_loss: 0.0069 step time: 0.1934\n",
      "5/8, train_loss: 0.0125 step time: 0.1976\n",
      "6/8, train_loss: 0.0092 step time: 0.1932\n",
      "7/8, train_loss: 0.0078 step time: 0.1815\n",
      "8/8, train_loss: 0.0077 step time: 0.1829\n",
      "epoch 541 average loss: 0.0088\n",
      "time consuming of epoch 541 is: 1.5700\n",
      "----------\n",
      "epoch 542/600\n",
      "1/8, train_loss: 0.0105 step time: 0.2384\n",
      "2/8, train_loss: 0.0096 step time: 0.1994\n",
      "3/8, train_loss: 0.0079 step time: 0.2010\n",
      "4/8, train_loss: 0.0083 step time: 0.2000\n",
      "5/8, train_loss: 0.0070 step time: 0.2008\n",
      "6/8, train_loss: 0.0091 step time: 0.1996\n",
      "7/8, train_loss: 0.0084 step time: 0.1830\n",
      "8/8, train_loss: 0.0095 step time: 0.1827\n",
      "epoch 542 average loss: 0.0088\n",
      "time consuming of epoch 542 is: 1.6068\n",
      "----------\n",
      "epoch 543/600\n",
      "1/8, train_loss: 0.0088 step time: 0.2404\n",
      "2/8, train_loss: 0.0103 step time: 0.2019\n",
      "3/8, train_loss: 0.0085 step time: 0.2003\n",
      "4/8, train_loss: 0.0085 step time: 0.2009\n",
      "5/8, train_loss: 0.0080 step time: 0.2018\n",
      "6/8, train_loss: 0.0106 step time: 0.1980\n",
      "7/8, train_loss: 0.0096 step time: 0.1828\n",
      "8/8, train_loss: 0.0081 step time: 0.1825\n",
      "epoch 543 average loss: 0.0090\n",
      "time consuming of epoch 543 is: 1.6099\n",
      "----------\n",
      "epoch 544/600\n",
      "1/8, train_loss: 0.0088 step time: 0.2407\n",
      "2/8, train_loss: 0.0093 step time: 0.2016\n",
      "3/8, train_loss: 0.0099 step time: 0.2017\n",
      "4/8, train_loss: 0.0098 step time: 0.2001\n",
      "5/8, train_loss: 0.0074 step time: 0.1992\n",
      "6/8, train_loss: 0.0092 step time: 0.1994\n",
      "7/8, train_loss: 0.0070 step time: 0.1829\n",
      "8/8, train_loss: 0.0094 step time: 0.1827\n",
      "epoch 544 average loss: 0.0089\n",
      "time consuming of epoch 544 is: 1.6099\n",
      "----------\n",
      "epoch 545/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2401\n",
      "2/8, train_loss: 0.0096 step time: 0.2016\n",
      "3/8, train_loss: 0.0084 step time: 0.1991\n",
      "4/8, train_loss: 0.0086 step time: 0.2010\n",
      "5/8, train_loss: 0.0100 step time: 0.2019\n",
      "6/8, train_loss: 0.0068 step time: 0.2025\n",
      "7/8, train_loss: 0.0085 step time: 0.1829\n",
      "8/8, train_loss: 0.0072 step time: 0.1823\n",
      "epoch 545 average loss: 0.0087\n",
      "current epoch: 545 current mean dice: 0.9616 best mean dice: 0.9623 at epoch: 525\n",
      "time consuming of epoch 545 is: 2.3682\n",
      "----------\n",
      "epoch 546/600\n",
      "1/8, train_loss: 0.0112 step time: 0.2375\n",
      "2/8, train_loss: 0.0072 step time: 0.2020\n",
      "3/8, train_loss: 0.0099 step time: 0.1985\n",
      "4/8, train_loss: 0.0080 step time: 0.1991\n",
      "5/8, train_loss: 0.0101 step time: 0.1976\n",
      "6/8, train_loss: 0.0099 step time: 0.1998\n",
      "7/8, train_loss: 0.0072 step time: 0.1814\n",
      "8/8, train_loss: 0.0093 step time: 0.1839\n",
      "epoch 546 average loss: 0.0091\n",
      "time consuming of epoch 546 is: 1.6009\n",
      "----------\n",
      "epoch 547/600\n",
      "1/8, train_loss: 0.0095 step time: 0.2431\n",
      "2/8, train_loss: 0.0078 step time: 0.2027\n",
      "3/8, train_loss: 0.0100 step time: 0.1989\n",
      "4/8, train_loss: 0.0083 step time: 0.2013\n",
      "5/8, train_loss: 0.0124 step time: 0.2017\n",
      "6/8, train_loss: 0.0077 step time: 0.2002\n",
      "7/8, train_loss: 0.0074 step time: 0.1832\n",
      "8/8, train_loss: 0.0075 step time: 0.1826\n",
      "epoch 547 average loss: 0.0088\n",
      "time consuming of epoch 547 is: 1.6150\n",
      "----------\n",
      "epoch 548/600\n",
      "1/8, train_loss: 0.0089 step time: 0.2385\n",
      "2/8, train_loss: 0.0098 step time: 0.1995\n",
      "3/8, train_loss: 0.0101 step time: 0.2011\n",
      "4/8, train_loss: 0.0081 step time: 0.2005\n",
      "5/8, train_loss: 0.0102 step time: 0.2016\n",
      "6/8, train_loss: 0.0081 step time: 0.1978\n",
      "7/8, train_loss: 0.0098 step time: 0.1838\n",
      "8/8, train_loss: 0.0108 step time: 0.1845\n",
      "epoch 548 average loss: 0.0095\n",
      "time consuming of epoch 548 is: 1.6087\n",
      "----------\n",
      "epoch 549/600\n",
      "1/8, train_loss: 0.0113 step time: 0.2412\n",
      "2/8, train_loss: 0.0087 step time: 0.2033\n",
      "3/8, train_loss: 0.0073 step time: 0.2022\n",
      "4/8, train_loss: 0.0111 step time: 0.1958\n",
      "5/8, train_loss: 0.0076 step time: 0.1959\n",
      "6/8, train_loss: 0.0081 step time: 0.1945\n",
      "7/8, train_loss: 0.0075 step time: 0.1822\n",
      "8/8, train_loss: 0.0103 step time: 0.1821\n",
      "epoch 549 average loss: 0.0090\n",
      "time consuming of epoch 549 is: 1.5985\n",
      "----------\n",
      "epoch 550/600\n",
      "1/8, train_loss: 0.0078 step time: 0.2396\n",
      "2/8, train_loss: 0.0100 step time: 0.1983\n",
      "3/8, train_loss: 0.0098 step time: 0.2006\n",
      "4/8, train_loss: 0.0099 step time: 0.1963\n",
      "5/8, train_loss: 0.0098 step time: 0.1951\n",
      "6/8, train_loss: 0.0093 step time: 0.1963\n",
      "7/8, train_loss: 0.0074 step time: 0.1828\n",
      "8/8, train_loss: 0.0074 step time: 0.1823\n",
      "epoch 550 average loss: 0.0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 550 current mean dice: 0.9607 best mean dice: 0.9623 at epoch: 525\n",
      "time consuming of epoch 550 is: 2.3482\n",
      "----------\n",
      "epoch 551/600\n",
      "1/8, train_loss: 0.0078 step time: 0.2374\n",
      "2/8, train_loss: 0.0065 step time: 0.1992\n",
      "3/8, train_loss: 0.0107 step time: 0.2007\n",
      "4/8, train_loss: 0.0089 step time: 0.1996\n",
      "5/8, train_loss: 0.0106 step time: 0.2003\n",
      "6/8, train_loss: 0.0071 step time: 0.1997\n",
      "7/8, train_loss: 0.0082 step time: 0.1818\n",
      "8/8, train_loss: 0.0119 step time: 0.1814\n",
      "epoch 551 average loss: 0.0090\n",
      "time consuming of epoch 551 is: 1.6011\n",
      "----------\n",
      "epoch 552/600\n",
      "1/8, train_loss: 0.0074 step time: 0.2368\n",
      "2/8, train_loss: 0.0078 step time: 0.1989\n",
      "3/8, train_loss: 0.0080 step time: 0.1987\n",
      "4/8, train_loss: 0.0076 step time: 0.1976\n",
      "5/8, train_loss: 0.0115 step time: 0.1981\n",
      "6/8, train_loss: 0.0077 step time: 0.1967\n",
      "7/8, train_loss: 0.0100 step time: 0.1825\n",
      "8/8, train_loss: 0.0106 step time: 0.1840\n",
      "epoch 552 average loss: 0.0088\n",
      "time consuming of epoch 552 is: 1.5946\n",
      "----------\n",
      "epoch 553/600\n",
      "1/8, train_loss: 0.0075 step time: 0.2431\n",
      "2/8, train_loss: 0.0092 step time: 0.2035\n",
      "3/8, train_loss: 0.0070 step time: 0.2016\n",
      "4/8, train_loss: 0.0082 step time: 0.2000\n",
      "5/8, train_loss: 0.0096 step time: 0.2035\n",
      "6/8, train_loss: 0.0113 step time: 0.2048\n",
      "7/8, train_loss: 0.0078 step time: 0.1822\n",
      "8/8, train_loss: 0.0088 step time: 0.1824\n",
      "epoch 553 average loss: 0.0087\n",
      "time consuming of epoch 553 is: 1.6227\n",
      "----------\n",
      "epoch 554/600\n",
      "1/8, train_loss: 0.0072 step time: 0.2407\n",
      "2/8, train_loss: 0.0074 step time: 0.2026\n",
      "3/8, train_loss: 0.0088 step time: 0.1990\n",
      "4/8, train_loss: 0.0112 step time: 0.2030\n",
      "5/8, train_loss: 0.0094 step time: 0.1997\n",
      "6/8, train_loss: 0.0075 step time: 0.2033\n",
      "7/8, train_loss: 0.0081 step time: 0.1842\n",
      "8/8, train_loss: 0.0104 step time: 0.1831\n",
      "epoch 554 average loss: 0.0087\n",
      "time consuming of epoch 554 is: 1.6170\n",
      "----------\n",
      "epoch 555/600\n",
      "1/8, train_loss: 0.0094 step time: 0.2415\n",
      "2/8, train_loss: 0.0078 step time: 0.2030\n",
      "3/8, train_loss: 0.0086 step time: 0.2000\n",
      "4/8, train_loss: 0.0090 step time: 0.2030\n",
      "5/8, train_loss: 0.0080 step time: 0.2004\n",
      "6/8, train_loss: 0.0081 step time: 0.2024\n",
      "7/8, train_loss: 0.0087 step time: 0.1819\n",
      "8/8, train_loss: 0.0087 step time: 0.1827\n",
      "epoch 555 average loss: 0.0085\n",
      "current epoch: 555 current mean dice: 0.9613 best mean dice: 0.9623 at epoch: 525\n",
      "time consuming of epoch 555 is: 2.3747\n",
      "----------\n",
      "epoch 556/600\n",
      "1/8, train_loss: 0.0086 step time: 0.2413\n",
      "2/8, train_loss: 0.0097 step time: 0.1984\n",
      "3/8, train_loss: 0.0073 step time: 0.1994\n",
      "4/8, train_loss: 0.0086 step time: 0.1997\n",
      "5/8, train_loss: 0.0102 step time: 0.2022\n",
      "6/8, train_loss: 0.0073 step time: 0.2013\n",
      "7/8, train_loss: 0.0091 step time: 0.1817\n",
      "8/8, train_loss: 0.0077 step time: 0.1812\n",
      "epoch 556 average loss: 0.0086\n",
      "time consuming of epoch 556 is: 1.6065\n",
      "----------\n",
      "epoch 557/600\n",
      "1/8, train_loss: 0.0078 step time: 0.2382\n",
      "2/8, train_loss: 0.0080 step time: 0.2026\n",
      "3/8, train_loss: 0.0090 step time: 0.1999\n",
      "4/8, train_loss: 0.0087 step time: 0.2007\n",
      "5/8, train_loss: 0.0105 step time: 0.2018\n",
      "6/8, train_loss: 0.0091 step time: 0.2030\n",
      "7/8, train_loss: 0.0088 step time: 0.1825\n",
      "8/8, train_loss: 0.0089 step time: 0.1824\n",
      "epoch 557 average loss: 0.0089\n",
      "time consuming of epoch 557 is: 1.6125\n",
      "----------\n",
      "epoch 558/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2399\n",
      "2/8, train_loss: 0.0088 step time: 0.2013\n",
      "3/8, train_loss: 0.0098 step time: 0.1986\n",
      "4/8, train_loss: 0.0110 step time: 0.2009\n",
      "5/8, train_loss: 0.0079 step time: 0.2005\n",
      "6/8, train_loss: 0.0080 step time: 0.2004\n",
      "7/8, train_loss: 0.0079 step time: 0.1832\n",
      "8/8, train_loss: 0.0094 step time: 0.1824\n",
      "epoch 558 average loss: 0.0091\n",
      "time consuming of epoch 558 is: 1.6091\n",
      "----------\n",
      "epoch 559/600\n",
      "1/8, train_loss: 0.0085 step time: 0.2410\n",
      "2/8, train_loss: 0.0078 step time: 0.2016\n",
      "3/8, train_loss: 0.0085 step time: 0.2020\n",
      "4/8, train_loss: 0.0103 step time: 0.2070\n",
      "5/8, train_loss: 0.0078 step time: 0.2018\n",
      "6/8, train_loss: 0.0085 step time: 0.1997\n",
      "7/8, train_loss: 0.0112 step time: 0.1827\n",
      "8/8, train_loss: 0.0097 step time: 0.1823\n",
      "epoch 559 average loss: 0.0090\n",
      "time consuming of epoch 559 is: 1.6199\n",
      "----------\n",
      "epoch 560/600\n",
      "1/8, train_loss: 0.0112 step time: 0.2429\n",
      "2/8, train_loss: 0.0109 step time: 0.2063\n",
      "3/8, train_loss: 0.0107 step time: 0.2043\n",
      "4/8, train_loss: 0.0075 step time: 0.2000\n",
      "5/8, train_loss: 0.0078 step time: 0.2012\n",
      "6/8, train_loss: 0.0078 step time: 0.2000\n",
      "7/8, train_loss: 0.0087 step time: 0.1823\n",
      "8/8, train_loss: 0.0081 step time: 0.1822\n",
      "epoch 560 average loss: 0.0091\n",
      "current epoch: 560 current mean dice: 0.9619 best mean dice: 0.9623 at epoch: 525\n",
      "time consuming of epoch 560 is: 2.3759\n",
      "----------\n",
      "epoch 561/600\n",
      "1/8, train_loss: 0.0090 step time: 0.2374\n",
      "2/8, train_loss: 0.0089 step time: 0.1978\n",
      "3/8, train_loss: 0.0081 step time: 0.1997\n",
      "4/8, train_loss: 0.0086 step time: 0.1992\n",
      "5/8, train_loss: 0.0070 step time: 0.1995\n",
      "6/8, train_loss: 0.0091 step time: 0.1975\n",
      "7/8, train_loss: 0.0083 step time: 0.1807\n",
      "8/8, train_loss: 0.0096 step time: 0.1812\n",
      "epoch 561 average loss: 0.0086\n",
      "time consuming of epoch 561 is: 1.5941\n",
      "----------\n",
      "epoch 562/600\n",
      "1/8, train_loss: 0.0080 step time: 0.2395\n",
      "2/8, train_loss: 0.0081 step time: 0.1979\n",
      "3/8, train_loss: 0.0104 step time: 0.1992\n",
      "4/8, train_loss: 0.0093 step time: 0.2021\n",
      "5/8, train_loss: 0.0083 step time: 0.1993\n",
      "6/8, train_loss: 0.0134 step time: 0.2016\n",
      "7/8, train_loss: 0.0077 step time: 0.1830\n",
      "8/8, train_loss: 0.0079 step time: 0.1830\n",
      "epoch 562 average loss: 0.0091\n",
      "time consuming of epoch 562 is: 1.6071\n",
      "----------\n",
      "epoch 563/600\n",
      "1/8, train_loss: 0.0094 step time: 0.2361\n",
      "2/8, train_loss: 0.0077 step time: 0.1944\n",
      "3/8, train_loss: 0.0080 step time: 0.2039\n",
      "4/8, train_loss: 0.0092 step time: 0.1991\n",
      "5/8, train_loss: 0.0075 step time: 0.1986\n",
      "6/8, train_loss: 0.0094 step time: 0.1939\n",
      "7/8, train_loss: 0.0080 step time: 0.1842\n",
      "8/8, train_loss: 0.0101 step time: 0.1823\n",
      "epoch 563 average loss: 0.0087\n",
      "time consuming of epoch 563 is: 1.5941\n",
      "----------\n",
      "epoch 564/600\n",
      "1/8, train_loss: 0.0079 step time: 0.2379\n",
      "2/8, train_loss: 0.0089 step time: 0.2019\n",
      "3/8, train_loss: 0.0075 step time: 0.1987\n",
      "4/8, train_loss: 0.0091 step time: 0.2006\n",
      "5/8, train_loss: 0.0110 step time: 0.2025\n",
      "6/8, train_loss: 0.0095 step time: 0.1985\n",
      "7/8, train_loss: 0.0082 step time: 0.1842\n",
      "8/8, train_loss: 0.0081 step time: 0.1819\n",
      "epoch 564 average loss: 0.0088\n",
      "time consuming of epoch 564 is: 1.6075\n",
      "----------\n",
      "epoch 565/600\n",
      "1/8, train_loss: 0.0082 step time: 0.2403\n",
      "2/8, train_loss: 0.0077 step time: 0.1981\n",
      "3/8, train_loss: 0.0091 step time: 0.1962\n",
      "4/8, train_loss: 0.0078 step time: 0.1974\n",
      "5/8, train_loss: 0.0088 step time: 0.1966\n",
      "6/8, train_loss: 0.0096 step time: 0.1962\n",
      "7/8, train_loss: 0.0086 step time: 0.1835\n",
      "8/8, train_loss: 0.0091 step time: 0.1824\n",
      "epoch 565 average loss: 0.0086\n",
      "current epoch: 565 current mean dice: 0.9623 best mean dice: 0.9623 at epoch: 525\n",
      "time consuming of epoch 565 is: 2.3482\n",
      "----------\n",
      "epoch 566/600\n",
      "1/8, train_loss: 0.0071 step time: 0.2369\n",
      "2/8, train_loss: 0.0092 step time: 0.1939\n",
      "3/8, train_loss: 0.0072 step time: 0.1968\n",
      "4/8, train_loss: 0.0087 step time: 0.1973\n",
      "5/8, train_loss: 0.0104 step time: 0.1977\n",
      "6/8, train_loss: 0.0092 step time: 0.1973\n",
      "7/8, train_loss: 0.0086 step time: 0.1794\n",
      "8/8, train_loss: 0.0089 step time: 0.1791\n",
      "epoch 566 average loss: 0.0087\n",
      "time consuming of epoch 566 is: 1.5793\n",
      "----------\n",
      "epoch 567/600\n",
      "1/8, train_loss: 0.0089 step time: 0.2339\n",
      "2/8, train_loss: 0.0080 step time: 0.1950\n",
      "3/8, train_loss: 0.0096 step time: 0.1983\n",
      "4/8, train_loss: 0.0075 step time: 0.1936\n",
      "5/8, train_loss: 0.0086 step time: 0.1972\n",
      "6/8, train_loss: 0.0077 step time: 0.1979\n",
      "7/8, train_loss: 0.0094 step time: 0.1795\n",
      "8/8, train_loss: 0.0071 step time: 0.1793\n",
      "epoch 567 average loss: 0.0084\n",
      "time consuming of epoch 567 is: 1.5757\n",
      "----------\n",
      "epoch 568/600\n",
      "1/8, train_loss: 0.0085 step time: 0.2329\n",
      "2/8, train_loss: 0.0082 step time: 0.1937\n",
      "3/8, train_loss: 0.0112 step time: 0.1979\n",
      "4/8, train_loss: 0.0102 step time: 0.1977\n",
      "5/8, train_loss: 0.0081 step time: 0.1973\n",
      "6/8, train_loss: 0.0081 step time: 0.1984\n",
      "7/8, train_loss: 0.0096 step time: 0.1791\n",
      "8/8, train_loss: 0.0092 step time: 0.1791\n",
      "epoch 568 average loss: 0.0092\n",
      "time consuming of epoch 568 is: 1.5772\n",
      "----------\n",
      "epoch 569/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2350\n",
      "2/8, train_loss: 0.0113 step time: 0.1962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8, train_loss: 0.0077 step time: 0.1949\n",
      "4/8, train_loss: 0.0085 step time: 0.1950\n",
      "5/8, train_loss: 0.0078 step time: 0.1962\n",
      "6/8, train_loss: 0.0123 step time: 0.1955\n",
      "7/8, train_loss: 0.0087 step time: 0.1792\n",
      "8/8, train_loss: 0.0078 step time: 0.1794\n",
      "epoch 569 average loss: 0.0092\n",
      "time consuming of epoch 569 is: 1.5725\n",
      "----------\n",
      "epoch 570/600\n",
      "1/8, train_loss: 0.0084 step time: 0.2322\n",
      "2/8, train_loss: 0.0110 step time: 0.1952\n",
      "3/8, train_loss: 0.0102 step time: 0.1959\n",
      "4/8, train_loss: 0.0079 step time: 0.1971\n",
      "5/8, train_loss: 0.0083 step time: 0.1972\n",
      "6/8, train_loss: 0.0082 step time: 0.1971\n",
      "7/8, train_loss: 0.0110 step time: 0.1792\n",
      "8/8, train_loss: 0.0095 step time: 0.1791\n",
      "epoch 570 average loss: 0.0093\n",
      "current epoch: 570 current mean dice: 0.9622 best mean dice: 0.9623 at epoch: 525\n",
      "time consuming of epoch 570 is: 2.3259\n",
      "----------\n",
      "epoch 571/600\n",
      "1/8, train_loss: 0.0086 step time: 0.2337\n",
      "2/8, train_loss: 0.0082 step time: 0.1945\n",
      "3/8, train_loss: 0.0090 step time: 0.1970\n",
      "4/8, train_loss: 0.0093 step time: 0.1968\n",
      "5/8, train_loss: 0.0066 step time: 0.1987\n",
      "6/8, train_loss: 0.0099 step time: 0.1966\n",
      "7/8, train_loss: 0.0117 step time: 0.1794\n",
      "8/8, train_loss: 0.0092 step time: 0.1795\n",
      "epoch 571 average loss: 0.0091\n",
      "time consuming of epoch 571 is: 1.5772\n",
      "----------\n",
      "epoch 572/600\n",
      "1/8, train_loss: 0.0090 step time: 0.2336\n",
      "2/8, train_loss: 0.0098 step time: 0.1945\n",
      "3/8, train_loss: 0.0084 step time: 0.1968\n",
      "4/8, train_loss: 0.0144 step time: 0.1978\n",
      "5/8, train_loss: 0.0075 step time: 0.1963\n",
      "6/8, train_loss: 0.0073 step time: 0.1969\n",
      "7/8, train_loss: 0.0076 step time: 0.1791\n",
      "8/8, train_loss: 0.0076 step time: 0.1792\n",
      "epoch 572 average loss: 0.0089\n",
      "time consuming of epoch 572 is: 1.5753\n",
      "----------\n",
      "epoch 573/600\n",
      "1/8, train_loss: 0.0099 step time: 0.2346\n",
      "2/8, train_loss: 0.0075 step time: 0.1941\n",
      "3/8, train_loss: 0.0087 step time: 0.1973\n",
      "4/8, train_loss: 0.0081 step time: 0.1973\n",
      "5/8, train_loss: 0.0091 step time: 0.1968\n",
      "6/8, train_loss: 0.0085 step time: 0.1966\n",
      "7/8, train_loss: 0.0121 step time: 0.1793\n",
      "8/8, train_loss: 0.0087 step time: 0.1792\n",
      "epoch 573 average loss: 0.0091\n",
      "time consuming of epoch 573 is: 1.5762\n",
      "----------\n",
      "epoch 574/600\n",
      "1/8, train_loss: 0.0099 step time: 0.2339\n",
      "2/8, train_loss: 0.0100 step time: 0.1937\n",
      "3/8, train_loss: 0.0080 step time: 0.1972\n",
      "4/8, train_loss: 0.0083 step time: 0.1985\n",
      "5/8, train_loss: 0.0100 step time: 0.2043\n",
      "6/8, train_loss: 0.0081 step time: 0.2029\n",
      "7/8, train_loss: 0.0102 step time: 0.1838\n",
      "8/8, train_loss: 0.0088 step time: 0.1834\n",
      "epoch 574 average loss: 0.0092\n",
      "time consuming of epoch 574 is: 1.5988\n",
      "----------\n",
      "epoch 575/600\n",
      "1/8, train_loss: 0.0104 step time: 0.2416\n",
      "2/8, train_loss: 0.0099 step time: 0.2006\n",
      "3/8, train_loss: 0.0096 step time: 0.2020\n",
      "4/8, train_loss: 0.0092 step time: 0.2022\n",
      "5/8, train_loss: 0.0096 step time: 0.2036\n",
      "6/8, train_loss: 0.0089 step time: 0.1986\n",
      "7/8, train_loss: 0.0084 step time: 0.1831\n",
      "8/8, train_loss: 0.0076 step time: 0.1821\n",
      "epoch 575 average loss: 0.0092\n",
      "current epoch: 575 current mean dice: 0.9622 best mean dice: 0.9623 at epoch: 525\n",
      "time consuming of epoch 575 is: 2.3719\n",
      "----------\n",
      "epoch 576/600\n",
      "1/8, train_loss: 0.0087 step time: 0.2378\n",
      "2/8, train_loss: 0.0085 step time: 0.1989\n",
      "3/8, train_loss: 0.0088 step time: 0.1980\n",
      "4/8, train_loss: 0.0071 step time: 0.2027\n",
      "5/8, train_loss: 0.0118 step time: 0.1975\n",
      "6/8, train_loss: 0.0086 step time: 0.2020\n",
      "7/8, train_loss: 0.0077 step time: 0.1840\n",
      "8/8, train_loss: 0.0094 step time: 0.1826\n",
      "epoch 576 average loss: 0.0088\n",
      "time consuming of epoch 576 is: 1.6046\n",
      "----------\n",
      "epoch 577/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2413\n",
      "2/8, train_loss: 0.0091 step time: 0.1992\n",
      "3/8, train_loss: 0.0086 step time: 0.1985\n",
      "4/8, train_loss: 0.0095 step time: 0.2004\n",
      "5/8, train_loss: 0.0095 step time: 0.1992\n",
      "6/8, train_loss: 0.0077 step time: 0.1990\n",
      "7/8, train_loss: 0.0083 step time: 0.1835\n",
      "8/8, train_loss: 0.0082 step time: 0.1819\n",
      "epoch 577 average loss: 0.0088\n",
      "time consuming of epoch 577 is: 1.6042\n",
      "----------\n",
      "epoch 578/600\n",
      "1/8, train_loss: 0.0090 step time: 0.2407\n",
      "2/8, train_loss: 0.0096 step time: 0.1957\n",
      "3/8, train_loss: 0.0109 step time: 0.1979\n",
      "4/8, train_loss: 0.0089 step time: 0.1981\n",
      "5/8, train_loss: 0.0095 step time: 0.1955\n",
      "6/8, train_loss: 0.0072 step time: 0.1957\n",
      "7/8, train_loss: 0.0077 step time: 0.1822\n",
      "8/8, train_loss: 0.0080 step time: 0.1824\n",
      "epoch 578 average loss: 0.0089\n",
      "time consuming of epoch 578 is: 1.5896\n",
      "----------\n",
      "epoch 579/600\n",
      "1/8, train_loss: 0.0078 step time: 0.2435\n",
      "2/8, train_loss: 0.0061 step time: 0.2016\n",
      "3/8, train_loss: 0.0113 step time: 0.1997\n",
      "4/8, train_loss: 0.0101 step time: 0.2064\n",
      "5/8, train_loss: 0.0098 step time: 0.2028\n",
      "6/8, train_loss: 0.0088 step time: 0.2023\n",
      "7/8, train_loss: 0.0084 step time: 0.1837\n",
      "8/8, train_loss: 0.0091 step time: 0.1839\n",
      "epoch 579 average loss: 0.0089\n",
      "time consuming of epoch 579 is: 1.6256\n",
      "----------\n",
      "epoch 580/600\n",
      "1/8, train_loss: 0.0076 step time: 0.2404\n",
      "2/8, train_loss: 0.0086 step time: 0.2030\n",
      "3/8, train_loss: 0.0087 step time: 0.2000\n",
      "4/8, train_loss: 0.0077 step time: 0.2014\n",
      "5/8, train_loss: 0.0079 step time: 0.2020\n",
      "6/8, train_loss: 0.0069 step time: 0.2027\n",
      "7/8, train_loss: 0.0079 step time: 0.1843\n",
      "8/8, train_loss: 0.0120 step time: 0.1840\n",
      "epoch 580 average loss: 0.0084\n",
      "current epoch: 580 current mean dice: 0.9619 best mean dice: 0.9623 at epoch: 525\n",
      "time consuming of epoch 580 is: 2.3768\n",
      "----------\n",
      "epoch 581/600\n",
      "1/8, train_loss: 0.0074 step time: 0.2408\n",
      "2/8, train_loss: 0.0087 step time: 0.2014\n",
      "3/8, train_loss: 0.0102 step time: 0.1988\n",
      "4/8, train_loss: 0.0113 step time: 0.1992\n",
      "5/8, train_loss: 0.0077 step time: 0.1993\n",
      "6/8, train_loss: 0.0083 step time: 0.2015\n",
      "7/8, train_loss: 0.0075 step time: 0.1806\n",
      "8/8, train_loss: 0.0086 step time: 0.1813\n",
      "epoch 581 average loss: 0.0087\n",
      "time consuming of epoch 581 is: 1.6041\n",
      "----------\n",
      "epoch 582/600\n",
      "1/8, train_loss: 0.0098 step time: 0.2399\n",
      "2/8, train_loss: 0.0083 step time: 0.2023\n",
      "3/8, train_loss: 0.0067 step time: 0.1999\n",
      "4/8, train_loss: 0.0078 step time: 0.2035\n",
      "5/8, train_loss: 0.0097 step time: 0.2093\n",
      "6/8, train_loss: 0.0078 step time: 0.2111\n",
      "7/8, train_loss: 0.0075 step time: 0.1826\n",
      "8/8, train_loss: 0.0097 step time: 0.1822\n",
      "epoch 582 average loss: 0.0084\n",
      "time consuming of epoch 582 is: 1.6324\n",
      "----------\n",
      "epoch 583/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2395\n",
      "2/8, train_loss: 0.0075 step time: 0.2018\n",
      "3/8, train_loss: 0.0087 step time: 0.1989\n",
      "4/8, train_loss: 0.0074 step time: 0.2004\n",
      "5/8, train_loss: 0.0078 step time: 0.1995\n",
      "6/8, train_loss: 0.0086 step time: 0.2009\n",
      "7/8, train_loss: 0.0083 step time: 0.1823\n",
      "8/8, train_loss: 0.0104 step time: 0.1821\n",
      "epoch 583 average loss: 0.0085\n",
      "time consuming of epoch 583 is: 1.6068\n",
      "----------\n",
      "epoch 584/600\n",
      "1/8, train_loss: 0.0092 step time: 0.2347\n",
      "2/8, train_loss: 0.0080 step time: 0.2001\n",
      "3/8, train_loss: 0.0078 step time: 0.1987\n",
      "4/8, train_loss: 0.0080 step time: 0.1984\n",
      "5/8, train_loss: 0.0090 step time: 0.1978\n",
      "6/8, train_loss: 0.0100 step time: 0.2001\n",
      "7/8, train_loss: 0.0082 step time: 0.1833\n",
      "8/8, train_loss: 0.0083 step time: 0.1821\n",
      "epoch 584 average loss: 0.0086\n",
      "time consuming of epoch 584 is: 1.5967\n",
      "----------\n",
      "epoch 585/600\n",
      "1/8, train_loss: 0.0081 step time: 0.2389\n",
      "2/8, train_loss: 0.0097 step time: 0.2037\n",
      "3/8, train_loss: 0.0082 step time: 0.2003\n",
      "4/8, train_loss: 0.0096 step time: 0.1960\n",
      "5/8, train_loss: 0.0107 step time: 0.1975\n",
      "6/8, train_loss: 0.0083 step time: 0.1972\n",
      "7/8, train_loss: 0.0083 step time: 0.1792\n",
      "8/8, train_loss: 0.0081 step time: 0.1792\n",
      "epoch 585 average loss: 0.0089\n",
      "current epoch: 585 current mean dice: 0.9621 best mean dice: 0.9623 at epoch: 525\n",
      "time consuming of epoch 585 is: 2.3456\n",
      "----------\n",
      "epoch 586/600\n",
      "1/8, train_loss: 0.0088 step time: 0.2361\n",
      "2/8, train_loss: 0.0079 step time: 0.1947\n",
      "3/8, train_loss: 0.0088 step time: 0.1974\n",
      "4/8, train_loss: 0.0084 step time: 0.1955\n",
      "5/8, train_loss: 0.0096 step time: 0.1976\n",
      "6/8, train_loss: 0.0085 step time: 0.1981\n",
      "7/8, train_loss: 0.0117 step time: 0.1795\n",
      "8/8, train_loss: 0.0082 step time: 0.1793\n",
      "epoch 586 average loss: 0.0090\n",
      "time consuming of epoch 586 is: 1.5793\n",
      "----------\n",
      "epoch 587/600\n",
      "1/8, train_loss: 0.0093 step time: 0.2343\n",
      "2/8, train_loss: 0.0080 step time: 0.1944\n",
      "3/8, train_loss: 0.0077 step time: 0.1973\n",
      "4/8, train_loss: 0.0074 step time: 0.1982\n",
      "5/8, train_loss: 0.0089 step time: 0.1978\n",
      "6/8, train_loss: 0.0082 step time: 0.1980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/8, train_loss: 0.0096 step time: 0.1790\n",
      "8/8, train_loss: 0.0113 step time: 0.1791\n",
      "epoch 587 average loss: 0.0088\n",
      "time consuming of epoch 587 is: 1.5791\n",
      "----------\n",
      "epoch 588/600\n",
      "1/8, train_loss: 0.0096 step time: 0.2337\n",
      "2/8, train_loss: 0.0072 step time: 0.1953\n",
      "3/8, train_loss: 0.0086 step time: 0.1974\n",
      "4/8, train_loss: 0.0102 step time: 0.1984\n",
      "5/8, train_loss: 0.0101 step time: 0.1986\n",
      "6/8, train_loss: 0.0083 step time: 0.1981\n",
      "7/8, train_loss: 0.0094 step time: 0.1794\n",
      "8/8, train_loss: 0.0075 step time: 0.1791\n",
      "epoch 588 average loss: 0.0089\n",
      "time consuming of epoch 588 is: 1.5811\n",
      "----------\n",
      "epoch 589/600\n",
      "1/8, train_loss: 0.0088 step time: 0.2340\n",
      "2/8, train_loss: 0.0086 step time: 0.1943\n",
      "3/8, train_loss: 0.0088 step time: 0.2028\n",
      "4/8, train_loss: 0.0118 step time: 0.2103\n",
      "5/8, train_loss: 0.0082 step time: 0.2039\n",
      "6/8, train_loss: 0.0098 step time: 0.2011\n",
      "7/8, train_loss: 0.0088 step time: 0.1836\n",
      "8/8, train_loss: 0.0080 step time: 0.1839\n",
      "epoch 589 average loss: 0.0091\n",
      "time consuming of epoch 589 is: 1.6152\n",
      "----------\n",
      "epoch 590/600\n",
      "1/8, train_loss: 0.0085 step time: 0.2399\n",
      "2/8, train_loss: 0.0076 step time: 0.2031\n",
      "3/8, train_loss: 0.0090 step time: 0.1990\n",
      "4/8, train_loss: 0.0102 step time: 0.1999\n",
      "5/8, train_loss: 0.0085 step time: 0.2043\n",
      "6/8, train_loss: 0.0088 step time: 0.1998\n",
      "7/8, train_loss: 0.0083 step time: 0.1818\n",
      "8/8, train_loss: 0.0077 step time: 0.1818\n",
      "epoch 590 average loss: 0.0086\n",
      "saved new best metric model\n",
      "current epoch: 590 current mean dice: 0.9626 best mean dice: 0.9626 at epoch: 590\n",
      "time consuming of epoch 590 is: 2.5070\n",
      "----------\n",
      "epoch 591/600\n",
      "1/8, train_loss: 0.0083 step time: 0.2424\n",
      "2/8, train_loss: 0.0077 step time: 0.2013\n",
      "3/8, train_loss: 0.0073 step time: 0.2012\n",
      "4/8, train_loss: 0.0099 step time: 0.2004\n",
      "5/8, train_loss: 0.0081 step time: 0.2012\n",
      "6/8, train_loss: 0.0085 step time: 0.1974\n",
      "7/8, train_loss: 0.0092 step time: 0.1826\n",
      "8/8, train_loss: 0.0093 step time: 0.1834\n",
      "epoch 591 average loss: 0.0085\n",
      "time consuming of epoch 591 is: 1.6113\n",
      "----------\n",
      "epoch 592/600\n",
      "1/8, train_loss: 0.0080 step time: 0.2386\n",
      "2/8, train_loss: 0.0080 step time: 0.1979\n",
      "3/8, train_loss: 0.0089 step time: 0.1974\n",
      "4/8, train_loss: 0.0111 step time: 0.2002\n",
      "5/8, train_loss: 0.0101 step time: 0.1989\n",
      "6/8, train_loss: 0.0086 step time: 0.2028\n",
      "7/8, train_loss: 0.0113 step time: 0.1817\n",
      "8/8, train_loss: 0.0082 step time: 0.1818\n",
      "epoch 592 average loss: 0.0093\n",
      "time consuming of epoch 592 is: 1.6007\n",
      "----------\n",
      "epoch 593/600\n",
      "1/8, train_loss: 0.0076 step time: 0.2339\n",
      "2/8, train_loss: 0.0122 step time: 0.2003\n",
      "3/8, train_loss: 0.0103 step time: 0.1962\n",
      "4/8, train_loss: 0.0084 step time: 0.1994\n",
      "5/8, train_loss: 0.0100 step time: 0.1939\n",
      "6/8, train_loss: 0.0116 step time: 0.1951\n",
      "7/8, train_loss: 0.0094 step time: 0.1825\n",
      "8/8, train_loss: 0.0124 step time: 0.1825\n",
      "epoch 593 average loss: 0.0103\n",
      "time consuming of epoch 593 is: 1.5853\n",
      "----------\n",
      "epoch 594/600\n",
      "1/8, train_loss: 0.0095 step time: 0.2392\n",
      "2/8, train_loss: 0.0085 step time: 0.2089\n",
      "3/8, train_loss: 0.0116 step time: 0.2013\n",
      "4/8, train_loss: 0.0100 step time: 0.2018\n",
      "5/8, train_loss: 0.1568 step time: 0.1916\n",
      "6/8, train_loss: 0.0277 step time: 0.2064\n",
      "7/8, train_loss: 0.0105 step time: 0.1823\n",
      "8/8, train_loss: 0.0116 step time: 0.1823\n",
      "epoch 594 average loss: 0.0308\n",
      "time consuming of epoch 594 is: 1.6157\n",
      "----------\n",
      "epoch 595/600\n",
      "1/8, train_loss: 0.0185 step time: 0.2398\n",
      "2/8, train_loss: 0.0244 step time: 0.2027\n",
      "3/8, train_loss: 0.0183 step time: 0.2049\n",
      "4/8, train_loss: 0.0210 step time: 0.2012\n",
      "5/8, train_loss: 0.0167 step time: 0.1982\n",
      "6/8, train_loss: 0.0410 step time: 0.1990\n",
      "7/8, train_loss: 0.0310 step time: 0.1822\n",
      "8/8, train_loss: 0.0206 step time: 0.1821\n",
      "epoch 595 average loss: 0.0239\n",
      "current epoch: 595 current mean dice: 0.3226 best mean dice: 0.9626 at epoch: 590\n",
      "time consuming of epoch 595 is: 2.3674\n",
      "----------\n",
      "epoch 596/600\n",
      "1/8, train_loss: 0.0235 step time: 0.2339\n",
      "2/8, train_loss: 0.0318 step time: 0.1962\n",
      "3/8, train_loss: 0.0333 step time: 0.1960\n",
      "4/8, train_loss: 0.0261 step time: 0.1952\n",
      "5/8, train_loss: 0.0256 step time: 0.1965\n",
      "6/8, train_loss: 0.0298 step time: 0.1951\n",
      "7/8, train_loss: 0.0255 step time: 0.1812\n",
      "8/8, train_loss: 0.0249 step time: 0.1822\n",
      "epoch 596 average loss: 0.0276\n",
      "time consuming of epoch 596 is: 1.5774\n",
      "----------\n",
      "epoch 597/600\n",
      "1/8, train_loss: 0.0206 step time: 0.2423\n",
      "2/8, train_loss: 0.0201 step time: 0.2032\n",
      "3/8, train_loss: 0.0203 step time: 0.1987\n",
      "4/8, train_loss: 0.0305 step time: 0.2002\n",
      "5/8, train_loss: 0.1941 step time: 0.1979\n",
      "6/8, train_loss: 0.0986 step time: 0.2003\n",
      "7/8, train_loss: 0.0906 step time: 0.1821\n",
      "8/8, train_loss: 0.1580 step time: 0.1823\n",
      "epoch 597 average loss: 0.0791\n",
      "time consuming of epoch 597 is: 1.6086\n",
      "----------\n",
      "epoch 598/600\n",
      "1/8, train_loss: 0.2204 step time: 0.2387\n",
      "2/8, train_loss: 0.0536 step time: 0.1979\n",
      "3/8, train_loss: 0.3122 step time: 0.2009\n",
      "4/8, train_loss: 0.0878 step time: 0.1988\n",
      "5/8, train_loss: 0.2671 step time: 0.1993\n",
      "6/8, train_loss: 0.1398 step time: 0.2015\n",
      "7/8, train_loss: 0.1585 step time: 0.1825\n",
      "8/8, train_loss: 0.1076 step time: 0.1811\n",
      "epoch 598 average loss: 0.1684\n",
      "time consuming of epoch 598 is: 1.6022\n",
      "----------\n",
      "epoch 599/600\n",
      "1/8, train_loss: 0.1258 step time: 0.2353\n",
      "2/8, train_loss: 0.1146 step time: 0.1993\n",
      "3/8, train_loss: 0.1364 step time: 0.1930\n",
      "4/8, train_loss: 0.1370 step time: 0.1989\n",
      "5/8, train_loss: 0.1109 step time: 0.1980\n",
      "6/8, train_loss: 0.1330 step time: 0.1974\n",
      "7/8, train_loss: 0.3919 step time: 0.1813\n",
      "8/8, train_loss: 0.1513 step time: 0.1817\n",
      "epoch 599 average loss: 0.1626\n",
      "time consuming of epoch 599 is: 1.5865\n",
      "----------\n",
      "epoch 600/600\n",
      "1/8, train_loss: 0.1059 step time: 0.2391\n",
      "2/8, train_loss: 0.1771 step time: 0.2036\n",
      "3/8, train_loss: 0.2619 step time: 0.1958\n",
      "4/8, train_loss: 0.1859 step time: 0.2003\n",
      "5/8, train_loss: 0.0641 step time: 0.1999\n",
      "6/8, train_loss: 0.1746 step time: 0.2021\n",
      "7/8, train_loss: 0.1851 step time: 0.1823\n",
      "8/8, train_loss: 0.1490 step time: 0.1827\n",
      "epoch 600 average loss: 0.1629\n",
      "current epoch: 600 current mean dice: 0.1629 best mean dice: 0.9626 at epoch: 590\n",
      "time consuming of epoch 600 is: 2.3632\n",
      "train completed, best_metric: 0.9626 at epoch: 590 total time: 1055.6900\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "times: [1061.2309420108795, 1057.999614238739, 1055.689969778061]\n",
      "Average time: 1058.3068420092266\n",
      "times per load operation: [0.0052551844716072086, 0.005239255477984746, 0.005237527986367544]\n",
      "Average time per load operation: 0.005243989311986499\n"
     ]
    }
   ],
   "source": [
    "name = 'orig'\n",
    "max_epochs = 600\n",
    "repeats = 3\n",
    "tlpo_sum, total_time_sum, tlpo_list, time_list, losses, metrics = 0, 0, [], [], np.zeros((max_epochs)), np.zeros((max_epochs // 5))\n",
    "for _ in range(repeats):\n",
    "    total_time, loss, metric, tlpo = func()\n",
    "    total_time_sum += total_time\n",
    "    time_list.append(total_time)\n",
    "    metrics += metric\n",
    "    losses += loss\n",
    "    tlpo_list.append(tlpo)\n",
    "    tlpo_sum += tlpo\n",
    "\n",
    "print('\\n\\n\\n')\n",
    "print(f\"times: {time_list}\")\n",
    "print(f\"Average time: {total_time_sum / 3}\")\n",
    "print(f\"times per load operation: {tlpo_list}\")\n",
    "print(f\"Average time per load operation: {tlpo_sum / 3}\")\n",
    "\n",
    "time_dict[name] = total_time_sum / 3\n",
    "metric_dict[name] = metrics / 3\n",
    "loss_dict[name] = losses / 3\n",
    "tlpo_dict[name] = tlpo_sum / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thread3': 1237.1164457798004,\n",
       " 'thread2': 1142.810050725937,\n",
       " 'thread1': 1068.8605738480885,\n",
       " 'thread4': 1323.9301082293193,\n",
       " 'instance': 903.4545698165894,\n",
       " 'instance_nvfuser': 888.926282564799,\n",
       " 'orig': 1058.3068420092266}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thread3': 0.028458230362998115,\n",
       " 'thread2': 0.0172835976878802,\n",
       " 'thread1': 0.008170056641101837,\n",
       " 'thread4': 0.04543388206097815,\n",
       " 'instance': 0.005219863222704994,\n",
       " 'instance_nvfuser': 0.00524735818306605,\n",
       " 'orig': 0.005243989311986499}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlpo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f89c856c040>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEWCAYAAABollyxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABZhElEQVR4nO2dd5xcVdnHv8/MbN9sye6md4oQSgIJAQm9BoyAvEFBAQMiqCCirwUEpYiKYkNAQKQJaF6KSJGigDQRSAgJpEE66dt3dnZ2+nn/OHd2Zzdb7u7O7Mw93O/nM5+dufX5zZl97nOfe85zRCmFi4uLi4u5eLJtgIuLi4tLZnEdvYuLi4vhuI7excXFxXBcR+/i4uJiOK6jd3FxcTEc19G7uLi4GI7r6F0ciYgoEdkz23a4uDgB19G7DBkR2SQi7SISSHndlm27uiMiC60LxBeybctQEZEplhZftm1xyX1cR++SLj6rlCpNeV2WbYN64MtAI3B+Jg7uOl2XXMV19C4ZxYqi/yMit4lIi4isEZHjU9aPE5GnRKRRRNaJyFdT1nlF5Icisl5EWkXkXRGZmHL4E0RkrYg0i8jtIiJ92DEZOBq4GDhZRMZYy+8QkV912/ZJEflOin2Pi0idiGwUkctTtrtORB4TkYdExA8sFJE5IvJfy6Ydlu78lH1OEpEPre/iDyLyqohclLL+QhFZLSJNIvKCZfdAv/O+vtM5IrJERPwisktEfmMtL7R0NFi2LxaR0QM9t0uOopRyX+5rSC9gE3BCL+sWAjHg20Ae8AWgBRhprX8N+ANQCMwE6oDjrHXfAz4APgUIMAOostYp4BmgAphk7TevDxt/BLxjvf8A+F/r/VHAFkCsz5VAOzAOHQi9C/wYyAemARuAk61trwOiwBnWtkXALOAwwAdMAVYDV1jbVwN+4Exr/bes/S+y1p8OrAP2tdZfA7zZi54p1nfg62FdX9/pf4HzrPelwGHW+0uAp4FiwGvpKMv2b8t9peeVdQPcl/NflqMPAM0pr69a6xYC25OO1Fr2DnAeMBGIAyNS1v0cuN96/yFwei/nVMARKZ8fAa7sw8a1KQ73KmC59V6Aj4GjrM9fBV623h8KfNztOFcB91nvrwNe6+e7uQJ4wnp/PvDflHWCvsgkHf1zwFdS1nuAIDC5h+P26OhtfKevAdcD1d32uxB4Ezgw278n95X+l5u6cUkXZyilKlJed6es26Ysb2KxGR0xjwMalVKt3daNt95PBNb3cc6dKe+D6Ah1N0RkLjAVWGQt+gtwgIjMtOxaBJxjrfsi8LD1fjIwzkplNItIM/BDIDWlsaXbufYWkWdEZKeVzvkZOpLH0tuxvXXurSm7TwZuSTlXI/piMB779PedfgXYG1hjpWfmW8sfBF4AFonIdhH5pYjkDeC8LjmM6+hdhoPx3fLnk9BR/nZgpIiM6LZum/V+C7BHGs7/ZbTDXCYiO4G3U5YD/BVYYOXDDwUeTzn/xm4XsBFKqVNTjt29/OsdwBpgL6VUGfrCkNS+A5iQ3ND6Tiak7LsFuKTb+YqUUm8OQGuf36lSaq1S6hxgFPAL4DERKVFKRZVS1yulpgOHA/PJ0ENrl+HHdfQuw8Eo4HIRyRORs9A56GeVUlvQ6YKfWw8DD0RHnA9Z+/0J+ImI7CWaA0WkaiAnFpFC4PPoh7AzU17fBL4oIj6l1HtAvXW+F5RSzdbu7wCtIvIDESmyHg7vLyKH9HHKEeg8fEBE9gG+nrLuH+g7iTOsHjqXAmNS1t8JXCUi+1m2l1vfV18UWN9doaV1G318pyJyrojUKKUS6BQbQEJEjhWRA0TEa9kfBRL9nNvFIbiO3iVdPC1d+9E/kbLubWAvtDP9KbBAKdVgrTsHnW/eDjwBXKuUetFa9xt07v2faOdzD/qB50A4A/1w9c9KqZ3JF3Av+oHnPGu7vwAnWH8BUErF0ZHtTGAjnReD8j7O9110+qcVuBv4v5Tj1QNnAb8EGoDpwBIgbK1/Ah1lL7LSPiuAU/rRF7D0JV/H0fd3Og9YKSIB4BbgbKVUO/qC8xj6e14NvIpO57gYQLKngYtLRhCRheiHjUdk25ZcQ0Q86Bz9l5RS/862PS7m4kb0Li7DiIicLCIVIlJAZ/7+rSyb5WI4rqN3cRlePo3uSVQPfBbdW6k9uya5mI6bunFxcXExHDeid3FxcTGcnCvCVF1draZMmZJtM1xcXFwcxbvvvluvlKrpaV3OOfopU6awZMmSQe3r9/spKytLs0XZwdWSm5iixRQd4GpJIiKbe1tnVOqmoKAg2yakDVdLbmKKFlN0gKvFDkY5+lgslm0T0oarJTcxRYspOsDVYgejHH0f5cgdh6slNzFFiyk6wNVih5zL0Q8Fj8ec65arJTfJRS3RaJStW7cSCoVs76OUMsZBftK0FBYWMmHCBPLy7BcXNcrRR6NRCgsLs21GWnC15Ca5qGXr1q2MGDGCKVOm2HZ48Xgcr9ebYcuGh0+SFqUUDQ0NbN26lalTp9o+bu6FJ0Mg1/4Bh4KrJTfJRS2hUIiqqqoBRbWmRMDwydIiIlRVVQ3o7g0Mc/RtbW3ZNiFtuFpyk1zVMlBnl0iYU4H4k6ZlMBc2oxy9KX1pAUpKS7jvvfuIJ+LZNmXImNQupmgxJdUBrhY7GOXom5qasm1C2vjVa7/iwqcu5K5378q2KUPGpHYxRUs8nt4Awuv1MnPmTGbMmMHBBx/Mm2/2PSlWc3Mzf/jDH/o97jHHHNPvAMp0a8kmmdJilKOvqhrQ5EM5TZAgAA3Bhn62zH1MahdTtPh86e2HUVRUxLJly1i+fDk///nPueqqq/rc3q6jt0O6tWSTTGkxytHX1dVl24S0EQwGs21C2jCpXUzREo1GM3Zsv99PZWUlAIFAgOOPP56DDz6YAw44gCeffBKAK6+8kvXr1zNz5ky+973vAfCLX/yCAw44gBkzZnDllVd2HO/RRx9lzpw57L333rz++uvDqmW4yZQWcy6FQE1Nj/V8HElR8UBnzMtdTGqXnNdyxRWwbFm/m9nvgQ3MnAm/+12fm7S3tzNz5kxCoRA7duzg5ZdfBnQvpSeeeIKysjLq6+s57LDDOO2007jppptYsWIFyyxbn3vuOZ588knefvttiouLaWxs7Dh2LBbjnXfe4dlnn+X666/nxRdf7HLugfQnz3UypcWN6HOUXO3dMRhMahdTtCTSPA9FMnWzZs0ann/+ec4//3yUUiil+OEPf8iBBx7ICSecwLZt29i1a9du+7/44otccMEFFBcXAzBy5MiOdWeeeSYAs2bNYtOmTbvt60b0/WMroheReeiJhL3An5RSN3Vb/x3gIiAG1AEXKqU2W+viwAfWph8rpU5Lk+27kfPR1gBI/uBN6CNsUrvkvJZ+Iu8kmYzwPv3pT1NfX09dXR3PPvssdXV1vPvuu+Tl5TFlypQB9wFPFvryer091oJxI/r+6be9RcQL3I6ejX46cI6ITO+22XvAbKXUgeiZ5H+Zsq5dKTXTemXMyQNdbvecTntIzy4nON/Rm9QupmjJZCGwNWvWEI/HqaqqoqWlhVGjRpGXl8e///1vNm/WlXRHjBhBa2trxz4nnngi9913X8ezqYF8z25Rs/6xE9HPAdYppTYAiMgi4HRgVXKDbjPYvwWcm04j7VJeXp6N02YEk0qvmtQupmhJd3/tZI4e9DD9Bx54AK/Xy5e+9CU++9nPcsABBzB79mz22WcfQPdemjt3Lvvvvz+nnHIKN998M8uWLWP27Nnk5+dz6qmn8rOf/SwrWrJJxrQk82i9vYAF6HRN8vN5wG19bH8bcE3K5xiwBH0BOKOXfS62tlkyceJE1d7ertra2lQgEFChUEi1tLSoaDSqGhsbVSKRUHV1dUoppWpra5VSStXV1alEIqE+/vhjFY1GVUtLiwqFQioQCKi2tjbV3t6u/H6/ikQiqqmpScXjcVVfX9/lGMm/DQ0NKhaLqebmZhUOh1Vra6sKBoMqGAyq1tZWFQ6HVXNzs4rFYqqhoaHHY9TX16t4PK6amppUJBJRfr9/wJq+8fg3FNehrn7hasdr2rhxY5d2amxsdKympJbuv71salq1apWKRCJKKaWi0ahKJBIqGo2qeDyuYrFYx9/U99FotGPb5L6pf5PHSCQSvR4jHo93OV/3Y/RlTzqOkbQnEomoWCzWxWanakpqSS7rTdOqVat2++0BS1QvfrnfycFFZAEwTyl1kfX5POBQpdRlPWx7LnAZcLRSKmwtG6+U2iYi04CXgeOVUut7O9/s2bPVYGeYikQi5OfnD2rfXOMH//wBv/zvL7nx2Bu5+qirs23OkDCpXXJRy+rVq9l3330HtE8ikcjJSpyD4ZOopac2F5F3lVKze9rezrezDZiY8nmCtaz7SU4ArgZOSzp5AKXUNuvvBuAV4CAb5xwUkUgkU4cedpIj5Ex4GGtSu5iipb8Az0m4WvrHjqNfDOwlIlNFJB84G3gqdQMROQi4C+3ka1OWV4pIgfW+GphLSm4/3ZiUqxOP8x18EpPaxRQtJgQQSVwt/dPvw1ilVExELgNeQHevvFcptVJEbkDnhJ4CbgZKgUctQ5PdKPcF7hKRBPqicpNSKmOO3sXFxcVld2z1o1dKPQs8223Zj1Pen9DLfm8CBwzFwIFgUnEjk0qvmtQupmhx0x25STZTN44h1x6SDQVTUgRgVruYosVNd+QmmdJilKNvb2/PtglpIxbVAydMGDBlUruYoiXdd4ylpaWD2u/vf/87q1YNLZtr0t1vprQY5egH+2PLRfLyzRnWbVK7mKIlV+4Y0+Hoc0VLOnAnHrFBS0tLtk1IG+FwuP+NHIJJ7WKKlkw9a3jllVc45phjWLBgAfvssw9f+tKXOvLOV155JdOnT+fAAw/ku9/9Lm+++SZPPfUU3/ve95g5cybr16/n7rvv5pBDDmHGjBn8z//8T0dJhIULF3L55Zdz+OGHM23aNB577LGOc9500027lTdev3498+bNY9asWRx55JGsWbMmI3rTTabaxagyxakV75xOLk5CPVhMapdc12KzSjED+de3UaW4C++99x4rV65k3LhxzJ07l//85z/su+++PPHEE6xZswYRobm5mYqKCk477TTmz5/PggULAKioqOCrX/0qANdccw333HMP3/zmNwHYsWMHb7zxBmvWrOG0005jwYIFPPfcczz99NO7lTe++OKLufPOO9lrr714++23+cY3vtFROjmXydTEI0Y5+rq6utyvLmgT0yYeMaVdTNGiVAKRzNzQz5kzhwkTJgAwc+ZMNm3axGGHHUZhYSFf+cpXmD9/PvPnz+9x3xUrVnDNNdfQ3NxMIBDg5JNP7lh3xhln4PF4mD59ekep4xdffJHzzz+/S3njQCDAm2++yVlnndWxr1PukKPRaEYqWBrl6E34B0yS/OEmlPMfNJnULrmuxX7knbmsbWpBvmRpYZ/PxzvvvMNLL73EY489xm233dZjhL1w4UL+/ve/M2PGDO6//35eeeWVHo+b2g2xe147kUhQUVHRMamJk3AnHrGBKZNCALQF9cQjceX8ftsmtYspWoZ7so5AIEBLSwunnnoqv/3tb1m+fDmwe7ni1tZWxo4dSzQa5eGHH+73uCeeeCL33ntvl/LGZWVlTJ06lUcffRTQF4Xk+XKdTLWLUY4+16OtgVBUpKcSdCP63MIULcM9WUdrayvz58/nwAMP5IgjjuA3v/kNAGeffTY333wzBx10EOvXr+cnP/kJhx56KHPnzu0oadwX8+bN4/TTT2f27NnMnDmTX/3qVwA8/PDD3HPPPcyYMYP99tuvY67aXCdT7dJv9crhZijVKxsaGqiqqkqzRdnh0icv5Q/L/sA1R17DT477SbbNGRImtUsuahlM9cpkOsUEPolaMlG90jEkZ543AV++bmwTUjcmtYspWty+57mJ24/eBn6/P9smpI32sB6BGU8439Gb1C6maDGlZg+4WuxglKMvKSnJtglpw+PVTWNCRG9Su5iixZSJOsDVYuu4GTlqlhjo7PK5TCSqJ7gwIaI3qV1M0ZJrz+aGgqulf4xy9MPdkyCTKNENbkJEb1K7mKLFrfiYm7jVK21gUhW7aFz3pzUhojepXUzR4kbBuYkb0dvApAZPRvImRPQmtYtJWlw+ORjl6E3pSwuQQEeOJkT0JrWLKVrSnSLIZj36oWq57rrrKC4upra2Y7rrDj3HHnssL7zwQpftf/e73/H1r3+dTZs2UVRUxMyZMzteQ5083k3d2MAphYvsEI1ZqRsDInqT2sUULblyZ5IOR58OLdXV1fz617/ebfk555zDokWLuixbtGgR55xzDgB77LEHy5Yt63gNdQaynrTEYrEhHRMMK2qWLARmAuLRV3YTHL1J7ZLrWq54/gqW7VyW1mPOHDOT3837na1tX3nlFa677jqqq6tZsWIFs2bN4qGHHkJEuPLKK3nqqafw+XycdNJJnHnmmTz11FO8+uqr3HjjjTz++OO8/PLL/PGPfyQSibDnnnvy4IMPUlxczMKFCykrK2PJkiXs3LmTX/7ylx2ljW+++WYefvhhPB4Pp5xyCjfddBPr16/n0ksvpa6ujuLiYu6+++4+SypceOGF3H///fzgBz/oUop6wYIFXHPNNUQiEfLz89m0aRPbt2/nyCOPZPPmzT0eq7S0lEAgAMBjjz3GM888w/3338+jjz7K9ddfj9frpby8nNdee414PM6VV17JK6+8Qjgc5hvf+AZf+9rXeOWVV/jRj35EZWUla9as4aOPPrLZWj1jlKNvbW01ZuRiKKK78ZmQujGpXUzRopTKWJpguOvRP/nkk0OuR19aWsqFF17ILbfcwvXXX9+xfOTIkcyZM4fnnnuO008/nUWLFvH5z3++47tbv349M2fOBGDu3LncfvvtvZ7jhhtu4IUXXmD8+PE0NzcDcM8991BeXs7ixYsJh8McfvjhHaWZly5dyooVK5g6deogWqErRjn6ioqKbJuQNkwaMGVSu+S6FruRdyYd/XDXo7/gggvSUo/+8ssvZ+bMmXz3u9/tsjyZvkk6+nvuuadjXTJ1Y4e5c+eycOFCPv/5z3PmmWcC8M9//pP333+/Y8aslpYW1q5dS35+PnPmzEmLkwfDcvQNDQ3ZNiFtmFQCwaR2MUVLOvK+vdFXPfoFCxbwzDPPMG/evB73XbhwIbfddhsffPAB1157bZcBar3Vo+/e5TW1Hn3ytXr16n7trqio4Itf/OJuUfnpp5/OSy+9xNKlSwkGg8yaNavP46ReQFPtv/POO7nxxhvZsmULs2bNoqGhAaUUt956a4edH330ESeddBKQ3lHYRjn66urqbJuQNrx5uriRCRG9Se1iipbhHviVyXr0f/7zn9NWj/473/kOd911V5cLYWlpKcceeywXXnhhx0PYvhg9ejSrV68mkUjwxBNPdCxfv349hx56KDfccAM1NTVs2bKFk08+mTvuuKOjDv3GjRtpa2uzZetAMMrRmzIpBJgV0ZvULqZoGe6JRzJZj/4zn/lM2urRV1dX87nPfW63VM8555zD8uXLbTn6m266ifnz53P44YczduzYjuXf+973OOCAA9h///05/PDDmTFjBhdddBHTp0/n4IMPZv/99+fiiy/OyN2WUfXoTeKY+4/h1c2vMn/v+Tx9ztPZNsclhxlMPXoXZ/OJrkdfX1+fbRPSRrLXjQkzTJnULqZoGe6IPpO4WvrHqF43uTbzz1BITkBgQurGpHYxRYspI3zBvpaf/vSnHXn7JGeddRZXX311JswaFJlqF3NaG2hubjaijzOYNTLWpHbJVS0D7S4Zj8eNcfZ2tVx99dU55dR7wo6WwaTbjUrdjBgxItsmpI2OfvQGRPQmtUsuaiksLOzoqmcXd/q93KQ/LUopGhoaKCwsHNBxbV3SRWQecAvgBf6klLqp2/rvABcBMaAOuFAptdla92XgGmvTG5VSDwzIwgEQDAYpKyvL1OGHleSUYtGE8/OPJrVLLmqZMGECW7duHVCPoEQiYczMTJ80LYWFhR0D0uzSr6MXES9wO3AisBVYLCJPKaVSKxG9B8xWSgVF5OvAL4EviMhI4FpgNqCAd619mwZkpU1SB1Q4neRteDAazLIlQ8ekdslFLXl5eQMeQRkOh3NSy2BwtfSPncvgHGCdUmqDUioCLAJOT91AKfVvpVTSI70FJC83JwP/Uko1Ws79X0DPQ+LSQCZH+w03yd42gUggy5YMHZPaxRQtpugAV4sd7Dj68cCWlM9brWW98RXguYHsKyIXi8gSEVlSW1tLKBQiGAzS1tZGOBzG7/cTi8VoampCKdXRxS15q1pfX49SqmM7v99POBymra2NYDBIKBSitbWVaDRKc3MziUSiYyh78hjJv42NjcTjcVpaWohEIgQCAdrb22lvbycQCBCJRGhpaSEej3cUUOp+jIaGBhKJBM3NzUSjUVpbWwesKfkwtjXU6nhNTU1NXdqpqanJsZqSWrr/9pymKR6P9/v/5BRN0WjUto/IdU2hUGjAfi+pqS/6HTAlIguAeUqpi6zP5wGHKqUu62Hbc4HLgKOVUmER+S5QqJS60Vr/I6BdKfWr3s43lAFToVCIwtdeg8MOgxzLow6UWXfNYunOpZQVlNFyZUu2zRkSoVBowA+PchVTtJiiA1wtSYY6YGobMDHl8wRrWfeTnABcDZymlAoPZN90Edu0CU4+Gc4/P1OnGDaSF+C2SFvOTBIxWNwBLbmHKTrA1WIHO45+MbCXiEwVkXzgbOCp1A1E5CDgLrSTr01Z9QJwkohUikglcJK1LCMUJIsBrVuXqVMMH1aX6LiKE447e1YjU6ItMEeLKTrA1WKHfh29UiqGTse8AKwGHlFKrRSRG0TkNGuzm4FS4FERWSYiT1n7NgI/QV8sFgM3WMsyws6GbayuBgxo+GT3SnD+A9lMVOPLFqZoMUUHuFrsYKsfvVLqWeDZbst+nPL+hD72vRe4d7AGDoSDl5xP/WWg/uV8R5/alzYQCVBd7NzyuLnW73womKLFFB3garGDGaMM0P3N66P6oaUqdH6f2li88yl6W8TZEUuyp4oJmKLFFB3garGDMY6+JdTZM6WteHgnVcgEHq+HPI/W4fTUjSmFwMAcLaboAFeLHYxx9GNHjOW3xV8AoKXY+bUvotEoIwp0XRWnO3pTJusAc7SYogNcLXYwxtEDjPEUAdBS7HxZXp+XQp9+1hCJR7JszdCoqanJtglpwxQtpugAV4sdnO8RU8hv0ZN1+AszM7v9cBKLxSjw6mcNTnf0bsSVe5iiA1wtdjDK0Y9O6Jx2i8/5pX09Xg8FPu3ond6P3o24cg9TdICrxQ7mOPr2dkre0KUTWghl2ZihE4vFjEndJOt9mIApWkzRAa4WO5jj6GtrGblF3/a0qPYsGzN0PB6P41M3zc3w+utQXl6ebVPShilaTNEBrhY7mOPoJ09GPf8yAG3KmY4xlXgi3pm6iTkzdXP66XDUUVBb6+xeQ6kEAmZoMUUHuFrsYI6jB0rHjAMgZsCsTAiOT90sW6b/+nxFWbUjnRQVmaHFFB3garGDUY4+EdOTdZgwz2pCJRyfuknOVd3e7kz7eyISMUOLKTrA1WIHoxx9QZ52jDHlfEePoiN141RHnyzXo5TzB7AlMWUialN0gKvFDkY5eq9Hf0mxhPOnFlMo8r35gHO7VyYdvUHlwl1cHIlRjl4lFB5lRkSvlEIQ8r35jo/ow+FEdg1JI6nlo52MKTrA1WIHoxx9fn4+PiXEDMjRK1GICAXeAsc7enB+kbkk+fn52TYhLZiiA1wtdjDK0be3t+NVYkREn0gkOiJ6p3avTDr6QMCZ9vdEe7vzx2iAOTrA1WIHoxx9aWmpjuhxvqMXEUTMSN3k5RVn15A0Ulpamm0T0oIpOsDVYgejHH1LSws+PEZ0r4wn4ghCga+ASMLZjr6pyZwBLS0tLf1v5ABM0QGuFjsY5ehHjhxpRfTOf/iXGtE7PXVTUmLOEPWRI0dm24S0YIoOcLXYwShHX1dXhw+PETn6eDzu+F43yQFTdXXNWbUjnZhSEtcUHeBqsYNRjr6mpkY7ehMieo/o1I2De90kHX1JSUVW7UgnppTENUUHuFrsYJSjr6urw4sZqZt4It6ZunH4gCk3os89TNEBrhY7GOXojYroRRyfuunM0Vdk1Y50Ykr0aIoOcLXYwShH39DQYIyjT0b0RXlFBKPBbJszKJKOvrGxNbuGpJGGhoZsm5AWTNEBrhY7GOXoKysr8eElboCjT0b05QXltISc2X0s6ejz80uya0gaqayszLYJacEUHeBqsYNRjt7v9+MTMyL6RCKBiOXow8529K2t5oxc9Pv92TYhLZiiA1wtdjDK0ZeUlODz+HT3SqWybc7QEHREX+j8iN7jKciuIWmkpMSMuxNTdICrxQ5GOfpQKITPm0cMBSFnTxCeUJ0RfTgeduSgqaSjb293ftnoJCGH/66SmKIDXC12MMrR5+Xl4fXmEfMABgyLFoSKwgoAR6Zvkv3oEwlzJobIyzOjEqcpOsDVYgejHH0ikcDnyzfC0SulyxSXF+ryAU5M3yQj+kjE4Wm0FBIJ5z//AXN0gKvFDkY5eqUUvrwCMxw9qqPXDTg7oo9GzXH0yunPfixM0QGuFjvYcvQiMk9EPhSRdSJyZQ/rjxKRpSISE5EF3dbFRWSZ9XoqXYb3hM/nw5dXQNwDNDdn8lQZx6SIPh43J3Xj8/mybUJaMEUHuFrs0K+jFxEvcDtwCjAdOEdEpnfb7GNgIfCXHg7RrpSaab1OG6K9fRIOh/HlF7oRfY7QOZWgOQ9jw2HnPRTvCVN0gKvFDnYuH3OAdUqpDQAisgg4HViV3EAptclal9VkWXFxsVmO3uERfSfmTPVWXGzGJCqm6ABXix3spG7GA1tSPm+1ltmlUESWiMhbInJGTxuIyMXWNktqa2sJhUIEg0Ha2toIh8P4/X5isRhNTU0opaivrwc6CwDV19ejlGLbtm14rRx9rLaWtrY2gsEgoVCI1tZWotEozc3NJBKJjqHGyWMk/zY2NhKPx2lpaSESiRAIBGhvb6e9vZ1AIEAkEqGlpYV4PE5jY2OPx2hoaCCRSNDc3Ew0GqW1tXXAmpIPZVS7ztntatlFOBx2lKZwOGq1j79LOzU1NRGLxfD7/Y7TtGXLlh5/e07T1Nzc3O//k1M0NTQ02PYRua6prq5uwH4vqalPlFJ9voAFwJ9SPp8H3NbLtvcDC7otG2/9nQZsAvbo63yzZs1SgyWRSKjPP/p59anLPUpdcsmgj5MLlP6sVH37+W+rWDymuA517b+vzbZJA+agg5QCpS64IJFtU9JGImGGFlN0KOVqSQIsUb34VTsR/TZgYsrnCdYyWyiltll/NwCvAAfZ3XegNDQ06JGxBXmwbl2mTjMsJCcH93q8lOaXOjJ1E7fmf1m7NppdQ9KIKQW0TNEBrhY72HH0i4G9RGSqiOQDZwO2es+ISKWIFFjvq4G5pOT20011dTU+j494vg/Wrs3UaYYH0YXNAMfWu0k6+q1bzcnRV1dXZ9uEtGCKDnC12KFfR6+UigGXAS8Aq4FHlFIrReQGETkNQEQOEZGtwFnAXSKy0tp9X2CJiCwH/g3cpJTKmKOvq6vDJz5iPi9s2eLoMghK6V43ABWFFY529B9/rIg4s6T+bpgyyYUpOsDVYgdbnTaVUs8Cz3Zb9uOU94vRKZ3u+70JHDBEG21TU1OjUzc+0UXNNmyA6d17gjqDZK8bwLGFzeJxKCiAcFh45x044ohsWzR0TJnkwhQd4Gqxg1EjY+vr67Wj91hDMh2cvkmN6MsLyvGHnVeKNR6H448Hj0dx++3ZtiY9JHs+OB1TdICrxQ5GOfqqqirL0VvDiFesyK5BQyA1oi/JL6Et2pZliwZOPA41NbBwISxaBLW12bZo6FRVVWXbhLRgig5wtdjBKEff3NyM1+PV9ejnzIHHHsu2SYMmNaIvySuhLeI8Rx+LgdcLRx2lbd++PcsGpYFmh5fWSGKKDnC12MEoRz9ixAgd0SdicOyx5kT0ec6N6L1emDatEIAdO7JsUBoYMWJEtk1IC6boAFeLHYxy9MFgUHevTMQhL6+z24cD6RLR5zszok86+ooKPZWgCRF9MOjMidq7Y4oOcLXYwShHX1BQ0BnRe726541Da1V3j+jbY+0klLO0JB39pEm6H70JEX1BgRnTIpqiA1wtdjDK0cdiMXweHwpFItnzxqFRffeIHuD3b/8e0NMMxhO5ryvp6H2+GGPHwvLl2bZo6PRbU8QhmKIDXC12MMrRiwg+jx4aEPM63NF3i+gBvv3Ct1FKcfyfj8f3k9yvwZ109CLCmWfC00+D0++yk23idEzRAa4WOxjl6D0eT6ej93XMepFFi4ZG94ge4O9r/s4rm17JkkUDI+noPR4Phx4K4TBss10lKTfxeMz4lzFFB7habB03I0fNEtFoFK/o2YycHNErazqx7hE9wJmPnJkVmwZD0tFHo1HGjNHLdu7Mrk1DJRo1o0CbKTrA1WIHoxx9YWFhZ0SfVOZER4/l6On7Ni4cy+2ZdZKOvrCwsMPR79qVXZuGSmFhYbZNSAum6ABXix2McvRtbW0djj5uUETfW/mDXC90ppSeTrCtrY3Ro/Uyp0f0bW3O6+baE6boAFeLHYxy9GVlZSkRvYMdfbeI/sQ9TiTPk7fbdrle6CyRABHdLlVVOrp3uqMvKyvLtglpwRQd4Gqxg1GOvqmpKaXXjbXQgV2vukf0E8omEPnR7nV+m0PNw2nWgLAk4PHodvF6oaoKnF5RtqmpKdsmpAVTdICrxQ5GOfpkUTOA9+JW9w4DIvreyOXUTdLRi3QWaiotBaffZZtSQMsUHeBqsYNRjr6urq7D0Z/eaNXFdaKj7xbR90Yup25SHX1yMgUTHL0pk1yYogNcLXYwytHX1NTg9Xi7LnSio+8lor/skMu6fM7lQmepqZvkZAolJRAIZNGoNGDKJBem6ABXix2McvSpET2g3aUTHX0vEf2tp97Kr0/6dcfnaDx3+w8nSwx1j+id7uhNiR5N0QGuFjsY5eiTUwkmiXpxpqPvI0ef7+2caDuayF1H31NEb0LqxpTo0RQd4Gqxg1GOvrGxsauj9+BMR99Hjr7A21ndzikRfWNjI2BG6iapxemYogNcLXYwytGXl5d3cfQRAyP6Al+Ko3dARC+i2wXMiOiTWpyOKTrA1WIHoxx9IBDYPXXjwH70feGUiD41dROwwngTIvqA0wVYmKIDXC12MMrRFxUVmRHR95G6Se1VlMsRfWrqpqioCNARfTDo2LlggE4tTscUHeBqsYNRjj4SiXRUrwRozceZjt7mgCmnRPSRiB7VW2IV4XRyTfqkFqdjig5wtdjBKEfv9Xq7RPTTL8OZjt7mgCmnRPRer774Juc99vdco80RJLU4HVN0gKvFDkY5eqCLowdIxHLXGfZGXxF96jKnRPRJkj3H6uuH3x4Xl08yRjn6eDy+m6MPRduzZM3g6SuiT13mlIg+bt1VJR19bW2WjEoDcQfeIfaEKTrA1WIHoxx9fn7+bo6+3YmO3qAcvYhuF4BRo/QyJzv6pBanY4oOcLXYwShH397e3oOjd96Tv74i+tnjZne8z+WIPjV1096uL7ZJR+/kEetJLU7HFB3garGDUY6+tLTU+Ih+Uvkk1LWKCWUTctrRp6ZuSktLAaioAJ/P2RF9UovTMUUHuFrsYJSjb2lp2a16ZXvMgY7eRq+bPE+eI1I3Ho9ul+T7qipnP4xNanE6pugAV4sdbDl6EZknIh+KyDoRubKH9UeJyFIRiYnIgm7rviwia63Xl9NleE+MHDly94jeiY7eRo4+z5vnmIh+5MiRHcudXsEyVYuTMUUHuFrs0K+jFxEvcDtwCjAdOEdEpnfb7GNgIfCXbvuOBK4FDgXmANeKSOXQze6Z7mWKAUKxcKZOlzFMiuhTyxSDHjTl5Ho3ppTENUUHuFrsYCeinwOsU0ptUEpFgEXA6akbKKU2KaXeB7oPbj8Z+JdSqlEp1QT8C5iXBrt7pKampsvIWID2eChTp8sYdiP6WCJ36/j0VKYYnO/oTSmJa4oOcLXYwY6jHw9sSfm81VpmB1v7isjFIrJERJbU1tYSCoUIBoO0tbURDofx+/3EYjGamppQSlFvJXmTV7/6+nqUUmzYsIFotwFS/lAroVCI1tZWotEozc3NJBIJGhoauhwj+bexsZF4PE5LSwuRSIRAIEB7ezvt7e0EAgEikQgtLS3E4/GOkqLdj9HQ0EAikaC5uZloNEpra+uANCUjetCTBcdiMfx+P+FwmLa2NoLBIF7x0h5pz1lN8XjyrgTWrVvX0U4lJYqWlliPmpzQTkkt3X97vbVTrmrauXNnv/9PTtG0bds22z4i1zVt2bJlwH4vqakvJNWp9LiBzrnPU0pdZH0+DzhUKXVZD9veDzyjlHrM+vxdoFApdaP1+UdAu1LqV72db/bs2WrJkiV92tQXDcEGqm+u7vj8cPUlfPHSOwd9vGywvXU7438znjs/cyeXzL6kx23m3juXIl8RL57/4jBbZ4/Nm2HKFLj3Xrjggs7lZ5wBGzfC8uXZsszFxUxE5F2l1Oye1tmJ6LcBE1M+T7CW2WEo+w6YhoYGqoqreOhzD3Usa4+H2Ny82VHdLG3n6B3yMDYZGYHza9KnanEypugAV4sd7Dj6xcBeIjJVRPKBs4GnbB7/BeAkEam0HsKeZC3LCJWV+jnvKXud0rEsGA8x5ZYpnPXoWZk6bdqx3evGAQ9jPZ7OdgHn16RP1eJkTNEBrhY79OvolVIx4DK0g14NPKKUWikiN4jIaQAicoiIbAXOAu4SkZXWvo3AT9AXi8XADdayjOC3yiJ6pFNWY1x7lX+s/UemTpt2TIvo/SnlKp3+MNbv5NKbKZiiA1wtdvD1vwkopZ4Fnu227Mcp7xej0zI97XsvcO8QbLRNiVXwvKygjBMnHM2/tr7KtlgT0HVS7VzHpIhepLNdoNPRK6XXOY1ULU7GFB3garGDUSNjQyHdldIjHv75ub9R3QYb4vpJdeoUfLmOCRF9auom2S6gHb1SEHJer1egqxYnY4oOcLXYwShHn5eX1/nB62VUG6xPOnqfgxz9ACP6xdsWc8/Se4bFNrukpm5S2yUZsDg1fdPlN+ZgTNEBrhY7GOXoE6mTkXq91ARhk/VIwLSIvsBbQCimr/5z/jSHi56+aFhss0tqRJ/aLslZplpbs2BUGkg4ecLbFEzRAa4WOxjl6LuMCfD5qEmJGk2L6MsKymiN5K63TI3oU9ulokL/bW4edpPSQn/jTpyCKTrA1WIHoxy9z5fybNmK6JOYFtGXFZThD/tz9kee+jA2tV2SvceamrJgVBro8htzMKboAFeLHYxy9OFwSgEzn4/qlDFShb7C4TdokNiN6BMqQTBlYpVccvqpqZvUdnF6RN/lN+ZgTNEBrhY7GOXoi4uLOz+IUB7vfLDhqNSNzYgewB/u7HcbV7kzd2Zq6ia1XZzu6Lv8xhyMKTrA1WIHoxx9a7cnfGWJTkef53HOk3m7ET10dfSReCSzhg2A1Ig+tV2cnrrp/htzKqboAFeLHYxy9BXJcNGiTHVG8bnc57w7g43oc8nRp0b0qe1SWqqdv1Mj+u6/Madiig5wtdjBKEffvSBQOZ2OPpecYH8MJKJvaO/UnEsaUx/GpraLxwPl5c6N6E0poGWKDnC12MEoR19dXd3lc5l0PoANO2imqYFE9HcvvbtjWS6VREhN3XRvl5EjoTFjFY8yS3ctTsUUHeBqsYNRjr77NFxlnqKO97kU7fbHQCL6v63+W8eyXNKYmrrp3i41NeDU2d9MmbbOFB3garGDUY6++zRcZd7OJ9i55AT7w05EX+Qr2m1ZLmnsbSpB0I6+tjYLRqUBU6atM0UHuFrsYJSjT061laTM11kJLpecYH/YiehTxwWcvf/ZQG5pTI3ou7eLkyP67lqciik6wNViB6McfVVVVZfPI/JKO97nkhPsDzsRfaqjL8vXaZxc0pga0Xdvl1GjoL6+cxsn0V2LUzFFB7ha7GCUo2/u1mfPW1jE2mf35JJZl+SUE+wPOxF96gCwZL4+l7qQpkb03dulpgaiUWhpGX67hkp3LU7FFB3garGDUY5+RLI0YpLCQvZsUFQUVjjL0duI6FNn0Uo6+lzSmNq9snu7JNOQTkzf7PYbcyim6ABXix2McvTBYLDrgsJCCIXI9+YTjodzqhZMX9iJ6FMZUaB/HLno6D2e3dsl1dE/9hi88cYwGzcEdvuNORRTdICrxQ7mlH0DCgq61bNJcfSgHaETat7YiehTycWIPjV1071dUh39Wdac7Q65Bu/+G3MopugAV4sdjIroY7FY1wWWo68p1p6lLuiMXMFAI/pcdPSpEX33dkk6+t66WL7+eu5G+bv9xhyKKTrA1WIHoyL63SLgkhIIBhlfPBqAbf5tTCjrcQ7znGKwEX0ujYxNjei76+gvR3/UUfpvLkb5dtsk1zFFB7ha7GBURO/xdJMzfTooxbhdOu+1vXV7FqwaOCZF9CK7t0tRkS5u5sSHsbv9xhyKKTrAEC1//CP8+tcZ02JURB+NRiksTJlgZPZsAMav0Q5+W+u2bJg1YAYa0Y/Iz+2Hsbu1CzBmDGxzRnN0oSctTsQUHWCIlksuAUCNHw9nn532wxtwKexkt8aeNk1PKbilAa94jY3oc7HXTWrqpqd/wv33h/ffH2aj0oDjHYqFKTrAEC0jRwJQcMstGTm8UY6+ra2t6wLdiRtPoI2KwgqaQ81ZsWugDDSiL83XI4DbY+39bDl8pEb0u7ULMGMGfPTRMBuVBnrS4kRM0QGGaJk2DY45hsAdd2Tk8EY5+rKyst0XlpZCIEB5YTktYWcMxRxoRF9RWEGeJ4+dgZ2ZNGtApEb0PbWL9fjEcfT4G3MgpugAQ7REo1BeTumBB2bk8EY5+qaeZrNIOvqC8i6zMeUyA43oPeJh7IixOZWaSn0Y21O7TJrU836R3Mk+9UiPvzEHYooOMERLJAJ5eRnTYpSj77Eg0IgR0NqqI/qQWRF9SV5ndc7xI8bz4PsPUtuWG/V/kxF9T0XNACZO7Hm/XL8LN6WAlik6wBAt0Sjk57tFzezQY9H+lIjeMakbmxH9usvXseLrKwD4sOFDAH708o8ya5xNUiP6ntplzJie98t1R2/KJBem6ABDtFgRvTvxiA16LNpvOfqygjLjIvoxpWPYb9R+AJx7wLkZt2sg9DXxCIDX2/N+qaU+cnHAoymTXJiiAwzRYkX0WZ14RETmiciHIrJORK7sYX2BiPyftf5tEZliLZ8iIu0issx63Zlm+7vQ49UwmbopKGdzy2ZG3TyKUCyUSTOGzEBz9AC/Ofk3jC0dmzN3LX1NJZikpGT3ZakRfSgHm8mI6BFzdIAhWrId0YuIF7gdOAWYDpwjItO7bfYVoEkptSfwW+AXKevWK6VmWq+vpcnuHukroi8vLAd0vZu1DWszacaQGWivGwCvx8teVXvlTM+b/iJ60KWIupPq6MM5OJ+7EdEj5ugAQ7TkQEQ/B1inlNqglIoAi4DTu21zOvCA9f4x4HjJQgGKxsbG3ReWlkJrK6M2dT6k/KghtztwDyaiB53K2RHYkQmTBkxqRN9ju9Czo29PGQqQi46+Ny1OwxQdYIgWK6LPlBY7jn48sCXl81ZrWY/bKKViQAuQfHw8VUTeE5FXReTIIdrbJ+Xl5bsvHDECgkGOverujkXJB5e5ymAieoAxJWNyLqIX6aVd6OrokxeG1HRNLqZuetPiNEzRAYZosSL6TGnJ9MPYHcAkpdRBwHeAv4jIbqMbRORiEVkiIktqa2sJhUIEg0Ha2toIh8P4/X5isRhNTU0opTom0E3ms+rr61FKsX37dmKxGH6/n3A4TFtbGxErEbx/LcyzMjabmzfT0NDQ5RjJv42NjcTjcVpaWohEIgQCAdrb22lvbycQCBCJRGhpaSEej3dcfbsfo6GhgUQiQXNzM9FolNbW1gFpSp0gpampaTdNwWCQUChEa2sr0WiU5uZmEokERRThD/vZvnN71jUlElqDxwNbtmzp0k5JTfn58Q6dLS1aU3NzZ0jf3p7IuXZKaun+2xtIO+WCpubm5n7/n5yiqbGx0baPyElN4TDE40RFqK+vH7DfS2rqE6VUny/g08ALKZ+vAq7qts0LwKet9z6gHpAejvUKMLuv882aNUsNlnA4vPvCBx9USgeYSomofW/bVy14ZMGgzzEcvLThJcV1qFc2vjKg/W59+1bFdajaQG2GLLPPX/+qv/JVq3ppF6XU7NmdTeP362UPPdS5bOnSYTTYJr1pcRqm6FDKAC2hkP7B//SnQ9ICLFG9+FU7Ef1iYC8RmSoi+cDZwFPdtnkK+LL1fgHwslJKiUiN9TAXEZkG7AVssHHOQRHpaVilVSwIgKIiqourqQ/WZ8qEtKAGmaMfWaS1NrZnP2eZ+jC2x3aha+omuUlqXj4Xc/S9aXEapugAA7Qk7c/Pz5iWfssUK6ViInIZOmr3AvcqpVaKyA3oK8hTwD3AgyKyDmhEXwwAjgJuEJEokAC+ppTKmBfy9tQ5O3WkWWEhVcVVrG9cnykT0sJgc/S55OhTH8b22C707+jbc6dGWwe9aXEapugAA7RErQmD8vIypsVWPXql1LPAs92W/TjlfQg4q4f9HgceH6KNQ6Obo68uqubt4Nu60P/++8Phh2fPtl4wKaLvS8LcufDii/p98ree6uibmzNimotLbpES0WcKo0bGxuPx3Rempm6siL6hvQF1ySXa0+QgQ43o5/91ftZr3qSmbnpsF+BHP4Jvf1u/T/7WU3va1Odghq03LU7DFB1ggJaUiD5TWoxy9Pk9XRErKjrfx+NUF1cTiUcIZO7iOWRiCf0E3ecZ2ARgSUcP8Md3/5hWmwZKauqmx3ZBl0E47DD9PjlQKjWitzo95BS9aXEapugAA7SkRPSZ0mKUo2/vKanr8cDbb8OXvgSBAFVFOpWzsRIiOZraS5ZoKPQNbOacysJKfnLsTwD4uOXjtNs1EFIj+h7bxcKa7ZEXXtB/w2Hw+fS8srno6PvS4iRM0QEGaEmJ6DOlxShHX1pa2vOKOXNg/Hjt6Iu1o5/xdTj1S0Br6/AZaJNwTIe1Bb6CAe0nIlxz1DUcNOagrM+PmxrR99ou6Il1Dj4Y/vEP/TkchoIC/WglF1M3fWlxEqboAAO0pET0mdJilKNvaemjoFdpKYTDVDd3dl96aRrwn/9k3rABEo5bjt47MEefZHzZeLb5s+voUyP6PtsF/Tz83XchHu/q6HMxou9Pi1MwRQcYoCUlos+UFqMc/cjUB6/dGT0agKr7FnVd/vzzGbRocCQj+oGmbpKMKx2XUxF9n+0CHHqoztG/916no6+uzs2Ivj8tTsEUHWCAlpSIPlNajHL0fZb43HtvAKof7dJLlKsDT2bSpEGRzNEPNHWTZGrlVOqD9VmdDL2/iUdSOeUUyMuDRYt6j+g/+CA35pg1oiQu5ugAA7SkRPTuxCM26LPEp+XoK5q6Puz42cRNu2163hPn8d1/fjedpg2IoaZuDhytJxh+ck32LmJ2yhQnqarSUf2bb8KSJZ0RfdLRv/kmHHgg3Hprho22QX9aovHo8I28fucduP32Qe1qRGlfC8drST6ALS7O7sQjTqHPq+HYsTB2LN5uUWFZCFRK5+1wLMxjqx7j5Y0vZ8jK/hnsw9gkM8fMBGDhkwtpj/bxFL+pCS68EPbdF/70p0GdqzfsTDySypQp8N//wurV8OGH2vk3Nuq8/caNepvXXkuriYOiPy0XPX0RNTfXEE8MQ9/uQw+Fyy4bVK0Ix0fBKTheS3JateJiN6K3Q59XQxFYuRL8fjZfsZnXFr7G78ZdiL8Qap/8C7zxBqxaxdI3HiUUC7G5ZfPwGd6NUCyEV7wD7kefZGzpWOaMnwPAyrqVNLU38cxHz+y+4Q03wH33wZo18OCDQzF5NwYS0cPuk4VXV+tjNDd3/h/kQu2b/rQ8uFx/j/6wfzjM0axePeBdHB8Fp+B4LckfeFGRG9HboaG/bhqVlTBiBJPKJ3Hk5CPZ75jPA7Dq6XvgyCNhv/144+rzAF1GoDWcna6X4Xh40Gkb0N0s/3LmXwD4x0f/4MQHT+Szf/0sdW3dooXUwRlpLqaUGtH32y7sXns+WbniiSfg/vt73iYb9KcleXEeljIU1dX67wcfDHhXO23iFByvJSWiz5QWoxx9ZWXlgLafPuYAAFaufbNj2RuTOtcno3qlFIu3LSahEkM30gbhWHjQaZskUyunMmP0DK5/9Xre3fEu0M+EK01NQzpfd1Ifxtppl/PO0wOlAIqLO33YV7+qc/Sg8/c7sjyBVn9a8rx5ADSF0vt99mKM/vvhwCfSGej/Si7jeC0pjj5TWoxy9H7/wG6Xx5aOpYJC3h8NCYGlY+E/k2Af9O3T5h9fDpdfzpLtS5jzpzlc+o9LM2H2bgw1ogfwiIfXL3i9o24OwPu73u+6UUOD9qgXXQS7dumEeJpITd3YaZeDDtKdD+rqYMsW/fC1++Thzc3wVPcC2cNMf1ryPJajbx8GR5+s+rZ+4NVYB/q/kss4XkuKo8+UFqMcfUl3z9APIsIxe57A3bPAey3MugQaiuFLL+sUx+al/4Zbb2Vjs34aeOe7d6bd5p4IxUKD7kOfyoiCERT5ijo+X/rspV27XNbX64fUNTXaaRx77JDPmSQ1dTOQdqmu1nXoxo6FL36xc/kxx+gxbytXps3EQdGflmREn/HUTSKhn1aD7pcqMqD+pwP9X8llHK8lGNTtV1CQMS1GOfrQIJK4X53z9S6fK9rh/OWQrzxstqZv3LZzbcf6YDQ4JBvtEI6HOyLDofL8uc/zxQO+yHVHXwfA3e/ezQ9f+iENwQYd0VdVaQ8K8PrraTkndI3oB9MuANdd15nC+eY3Yfp0WLGi6/GHm/60JHP0GU/dtLTsfge2ZUvP2/bAYNskF3G8lvZ2na8UyZgWoxy9z5c34J4Zp+51Kpu/tYnlpz7N+pob2TLnr0ySCsY3J/jlEbB9BGz75TUd25f8rERXhoxGO2+50kw4FqYor6j/DW1w1OSjePjMh7nmqGsYWzqW77/4fX7+xs/51vPf6nD0m+vX0ZA8XYoHVUPwpqkRfV7e4C5a48bpVE4gAGeeCTNm6Hz9Zz6jLyDPPtv/MdJNf1qSjj7jfemTQ+VT78I++EAXDZozB375S1i3rtff6GDbJBdxvJZgUFfxI3NajHH0mzfDHnvkM3PmwPedVDGZAw+Zz7RvXE3pmWfDN7/JOVZHhs9cWMDrk3R/+1k1M5hcOoHvPPstlu1bSeLoo3Y/WDSq+zffccfghHzzm4RWLCPfm95ypV6Pl1+f9OuOzw9/8DATTl2DHPA4U8rvY965+jnFplVvct7fzuOWt26h7KYyPvd/n9PRv00i8QiH3H0I3w0I7L8IEUgkhvYQO3k3e9hhuotl0sE/8siQDjso+tMSjetRjn9a+id2BnZmzpCko//CFzqX3XUXzJ8PixfDD34Ae+0FP/xhj7sPtU1yCcdrCQZ1RE/mtBjj6EeNgh07PKxZk4aZiW64gZ8+sIUn/+cxllWGeWcCHL0Zlqw5ij/cX0dbIsRB57WxYI93+ceLf+gY4ATApk16xOI3vjHwgmlKwW23Ed66mcKPtw9RxO6cc8A5vHT+SzxzzjMcWLM/20Z0RuxLxsP478DxfzyChz54iCteuIJJRWP4+5q/U31zNfv9YT/OWHQGOwM7++x99NKGl1iyfYn+cMIP2Niyrtc7g1c2vcK3nvsWb299G4AtLVv4/KOf370bqMXRR+u/M2bAySfDo4/qoHXrVvj+92Ht2h53Syv93eUEIgEOn3g4u9p28Z0XvpM5Q5IP7fbYQ9/2HHccPP307tvdckuPX8xQ7tZyDcdrSXH0mdJijKMvKoJHHtHR1FtvaV8LejTlt741iJzuhAmctv//sOSrSzhq8lH8rHIB3HorJ6wOU2al0Z7YF+b/51L2u7aax2/7Bm1Ntex44DY2l8ObE9EnDgY7o6/+sPoOBvKhaMuOjJRvPG7qcXxm78+w/ITHWX4HvD/hpwSuCvCz435G/QgP1UH49n/hJy/Df/4Y51fjFnLi1BNYVbeKJz98krG/Hstet+7FohWLuPk/N3P9K9ezum41Dy5/kLe3vs39y++nrKCM473XQsXHzL5vOktrl5JQCZpDzR2Tqry34z2OfeBYfv/O75n/1/k89eFTTPrdJB5d9SjnPnEuwWhwtx/9HnvoNPSSJXDjjbpf/Smn6MFWN/86ynfufJpdgV1p/85S8fl6H8T26qZXaYu2ccqep3DZIZfx1xV/5Xdv/S5t/7zJkihA52+qvFw/yDj//I5VES+sGJWy7U9/utux+tLhNByt5dFH9cty9JnSIrl2NZw9e7ZasmTJoPZ9++0Ahx3WWc+5vr7zYd66ddpRDJpQqCOP1vLZE/nCZ8O8sP01LtxQzr8rW9hSBiMi0JSSWv/sh3DkZvj0VpjyjauItQWYMut4bcjUqR05iUg8wobNywh++zL2fn4xlT/08J03Evzi9QJdG2D//XVkNn78EAR04+WX4fjj9V8rzxtPxPE2NMJLL+kf39/+pre97DJ2/fSHfPUfl7Bs5zKaQk0EIoFeD33ugeey75oHuHrRw3CmdkA+j494Qs/wdea+Z3LfsvuIxqP8+XN/5mvPfI22aNtux/lU1af47N6fZXTpaGaPm41XvOwM7GRKxRT2GLkHX7+wjEfefAtO/D5M/G/HfhXBgzlh0ml8/8QLaGiOcOdzb3DN+Z/m+Ucm8torPi7+Sh4LFuhpGuNxWL5cd++0M0Wv3++nrKysx3VnP3Y2z697nrXfXIvP4+OQuw9hfdN69qneh9cWvobP46OisKLfuYAfXP4gOwM7+d/D/xeP6Fhs8WI44gh9gfvud0H++hc9mc6aNfCpT+moftQonlp4GKdPeQuAR05/iLO+d7+OerZt63zo3o8Op+FoLcnfwty58MYbQ9IiIu8qpWb3uM4kRx8MxthnH19H54M999QOHuD00+HLX4bHHoOf/xwmTer9OL3ywQc6kjriCBIqQSwRI3/5CnYePYu5l/jYU40kGmrj8DVtLPmfT/NC3X93O8SxG6G5ED4YBeV5pXgLi2kONRNJdB2Z+tJr0zju5Q2dC/bdF77zHdiwAZYu1R3Nf/AD3WsmGtXlHwfCvffCV74CH32kc7ndaW/Xx09WEisvR11yMXLJ14iOruGJl26jfPKnmJJfw5uhdSRUAo94WFG7gosOvogn/rgPV18jrNq5gX9ueJraYC3/3frfjgvF3IlzufWUWzlo7EF8WP8h33r+W8weN5sbj7uR7//r+3zY8CFPfdh3p/kCb0FHAbiZJfOoXzmDpsoXaRvxHnj6yHVGSsiPjyTeXoZX5RGpncq0fVuYOK6QwqI440eMJ5KIMLJwJFMrprEzsIuq4krmTppLW7iN37z9G97e+jZHTT6KtY1rOWv6WRwz5RjOWHQGp+x1Cn/9n78C+sJ5++LbueL5KzrGM+xRuQejSkYxb895hGNhWiOtfNjwIQeOOpDJFZPxh/1c/fLVAEyrnMalh1zKQWMO4ofXB3jriZlQXM/3rxhB4p2VnPfcN5i+9i12Fpbw+HsvMi2xi8tX/ppNfj3Qb1L5JL61YxJfuOMNymfMIf/fr5FvDcSLxWLOjoRTcLSWpKO/+GK4664hafnEOPqmpiaCwUreew8uv1wXw9p3Xz3isvso8a99Df73f/XFYKg8+5s1HH3BNEoq8yEWA78fVVnJfcvu4+33nmGPDU0ESvJ4ZzzsrN3A8jY9wOVzq6E1H8YGYFoTvHXEFEJTJvC5/Rbw5YKjqLjvPp18fv99OPfcztGrkyfrp8+pHHmkdtiNjXDGGfqBcCIB27fryD3ZzzoQ0CHs/ffriL2+Xndh6Y1YDK69Fn72s963mT5d3234fDqRfscd/HTzl7iGnxJZuoK24jwqvF59ezpiBP58xYi8UqSxUS9ratK3Xu3tOuG+334gwtIdSwnFQpQVlLGqbhUF3gJCsRDtsXa2+bfx2sevMapkFL844ReMKxnToWP1uiBf+fWjLGt7jvadE9m38mBqxz7A6OLxHH3ANJ586wO274hD+ccw4R2IFIN/IhQ2Q+kuvJGR+CSPcF7vaSBpr8aTFyHu6zrA5br9F/HNY7/QZU762/75D16p/yujysr5y4qHaQnrtItXvMTV7oPUygrK+Nqsr/HPDf9k2c5lvX/vQKGnmFCia8+a+XvP59JDLuXCJy9kR2AHngQIMCrsY9bkT7MqspWR8QKa82L4w372KjuA0rxy/IkdeMTDhqYN1JTUMKFsAqX5pVQWVhKNRzlg9AHUFNewsXkjY0vHMrp0NNv82whGg1QVVzG6ZDR1wTpGFo3koDEHsapuFftU78PG5o1UFlayqm4V1cXVTCyfiEc8lBeUk+/Npy3axoraFYwfMZ6XN77M0VOORhD2qd4Hr6f3+T4TKkFbpI1YMNbjiNLmUDMNwQb2GLkHSql+76SGnVisM0BraICRI2lqahr06NhPjKNPbUy/H378Yz20ftYsXbvrwgu7bl9crC+kl12mB+hYabKU43W9na+v189YR4zQ/vS663SJmDlztC/9wx/0haMvvwkQrd3Jir/ewkHBMn2H8PDD+tbt4Yf1jNndtAA6x7B5szZo6lT44x/h//5PF2OrqIDa2t5PWF6uJ14JBrUjTfLZz9ofavr00zp/kEjoc5WWwiuv6NlCDj+8s04BECGPi/kjD7CQKD58pDgzEX1BikT0g+u8PH1HUlGhlwWD+up8wAF6xGdDgx7qP3o0jBmjG6qgoHM28dZWvd1rr+kuOfvtp2/fpkyBtjZ2NORTue8YChNBfZHzeqGiAn/JWG7/+3g2UchV527n1UUx7nlzb1aGPya+Y39aWryQF2Tk6CYmV5Wyvrkef+FKCJdB2yio2xd8Ichrh9KdsMcLoLzw9jfx+YS999bpoPXr9TOjJJ8+XHHYp6PUfryLlte3M96zg8C4QuoKS8ifuQtvvIAjph/B+KpKdjYEeDXyezz+yTxx/wTmXvAPDtl/JPfd46OloRBKd8CoFdC4J/gnQGAMMw9v5My9P8+MvWqYMgU2hZZz51v30rJ0Of74R7SWttNSEkI8UZpKrHYJaU1jpIISb4itZWsokxEU5efTmgjSFMtOzafivGKmVExhaoWeX6EuWEc8EUehGFUyitq2WuqD9exTvQ/b/NsoKyjD5/ERioX4uOXjLhdRn8fHYRMOY1L5JErySlhRu4It/i1MKJtAnieP9trxbK1vRASkIMgJB+/BmobVFPoKKc0vpdBXiM/jw+fx0RBsYJ/qfdjVtotYIkZVURXReJTKokp8Hh9VRVXsDOykJL+EkUUjWde4jtElo3nywyf1+uIqjptyHJMTI6j/9iUUfvF8wkcezqbmTRw39ThO3OPEQX1fnxhHX19fT3UyKd8Dv/oVHHUUHHKITltee23npNQA++wDJ52kfc/OnfDMMzpQnjxZO/JHHtGDEPti8mR9YdljD+3Pxo/Xfjka1WnSuXP1haJLcNH9imJDSwfJJ/bvvKNz+a+/ro/14Yf64qCUdtDPPqsd6KRJOoKePVvnePfbr/9z2KGpST9MHjGC864YyUN/088fYrfcTntLI6VlZdpB19bqO5RYTF85J0/WNqxdC4WF+snqG2/AsmXaue+/v76q7tqlG2VbLzNnHXOMvuikYSo2BaxmX8axnQr08YLVk3i4YR5j1Hbm8h9i+KihnuXMYDX7MJNleD2wIX8fHlULeD+xH0uiMzmg8CPKIvVMy9vCkugMdjCWYKKQGuoow89a9sJHjBB9j5sQErx09E849qBmKChAPf43VjaM4Y5zXuOMM/Rvdc0a/RXYq3SrYMR2aO187lNEkHa6RjuVNFJZsJngqPXEipuobz6U0rYCqgo2s6syxDRZw2da15I/DWrDQQiPJTzpQ9ZGQ7QEx8HITewXHo2URvDWHkdL6w52jGlhnNfPzpF1tJXuYHpiNBvzajk4OJ6J/iK2R/MZNS2fZYl6wjX1rA42UiJeCoKVxPKguqiMoLQSjzbR6g1THIswoWZfVF4+nsJ8vMrPxKpPMTFRAE2tPNm+lGZviPxEAZtaP0apOHuMmMSYirG0RttoDrewYusmaJkMnigUtkBJLSNaDqW1bDE1vnGUlBSyqXUtBVKMx6sIxUIoFDX5lfhjbYQTEXweX0dng9S04kDYr3w2K65YPOD94BPk6AeKUjql8/vf62CwthZefVUvLyzs7MGWype/rP3j5Mn6eeWqVXDqqXqfxkZ46CEdxSVHp/eE16svJj6fDjyT/m/iRN11MPm5uVkHtDU1+oIxfrz2daC3TfpKpXSwn5+ve6E0NurgVyntfysrYWR5nCa/l1GjdEpr3Ditb9s2fWEqLtYTde/cqbX7fLrcQEmJXu/1wuOPQ1mZvlDV1envbI89tH1tbdrmJUv0nRToG4Ynn7T3kNM2yQFAhYX6gjFxor4TGDNGL29t7bxSt7Toi8XOnVpAZWVnL6j6+s5Ukd+vZyhvbNR3JqNH6y8gGtUXy2QRnqYmnRLz+fR+IvpOZNw4fY5QSB+zvR38fgLxIkobNuvzbtsGM2eiXnwJmpqQ88+Ds85CTZ2G+ngLH/5zM1Ma3qX2rQ1sWBEkWl7FmP2qqYzVwdKl+MbWMDaxTT90Uko3wm9+AwsXdvl6lNLz77a0aJPq6rSZRx+t22vDBv2beuMNfVN23nnQsGwLn6t6DTlkNn+5P8ITK/fm8D1raVu/g63+cvx5VcSa/OwMljOmIkRhqIl1G72sDYxldGkbK5t27yTgkQRjS/xsC1T02pRCApWBjn95RIiSTyHtKIQwhZTTTJBiouhUiZc4PmKMpJF6qomSz8VVj/Hbpgv4e2I+DxScw5bo3jR4iqmNWQ/0Rq6FpmmIEso99RTSTiAxkoC3APIDFMSEQ9Ri6sugsLWG/MId5BfHiUgJ1SO2MK4+SKQ5n4QIWyZ6qY6soTocZeuJp/HmimKaPprOvofsZOUb0wb1P/OJcfR1dXVDruccCnU6YtDOtL1dT4oxZYqO0u00QiSiHf7KldoBRqP6n6yqSq+LRLQj/+9/9T9lMsrftCn5fxxn1y6dxpkyRW/b3KydeWpF4ZISnU1RKrNlfLufty/OOAMeeEBfFCA97ZIrZF1LLKZ/oEO8eqZTx9at+iJSXq5/x2vW6Ecu48bp/53kzd6UKVAQaCAQL8JXVkxhfoJgyMP6lSGKChU7dwkqv4CaUcLGxfWMqk7wn9cTHD6jjUgogRo7jj3L66hfuYv2jTvwj59OY2seryz28anqAOObVhCsa2ODdy8qi8M0FYyhLZLHhII61q6DndEqIi3tTK4JUja2lPxIgFp/ASNLIpS2bOPKMfdTfOCe+ofb1gbRKLEYPN12HOveqseXiDBpXIz3mybSkD+WUMxHaYWXd7eMItgYosIbIFRQjiceJZzI4+PASKq9jdT4mtnYPpqAKqXIp/+JiqWdj9omADqu2G8/fZN93HFNnHyym6P/xBGLdZbvbW3V7yMR7diLinT0n8z8tLXpDEdpqb64JBL6whIM6iguPx8+/lj/A65fr48zapS+QCil56+YOlX/0yqlLyIbNujj1tfr1PeYMfqf1uPR/7ibNumOOzU1MGGCPva0aWmO4l1cDMTv1zemqdNCDIVPjKO3ndd2AK6W3MQULaboAFdLkr4cvTEjYwGqktMSGYCrJTcxRYspOsDVYgejHH3zkIvc5A6ultzEFC2m6ABXix2McvQjRozItglpw9WSm5iixRQd4Gqxgy1HLyLzRORDEVknIlf2sL5ARP7PWv+2iExJWXeVtfxDETk5jbbvRjBD9eGzgaslNzFFiyk6wNVih34dvYh4gduBU4DpwDkiMr3bZl8BmpRSewK/BX5h7TsdOBvYD5gH/ME6XkYoKBjaPKu5hKslNzFFiyk6wNViBzsR/RxgnVJqg1IqAiwCTu+2zenAA9b7x4DjRY/fPx1YpJQKK6U2Auus42WEWCyWqUMPO66W3MQULaboAFeLHew4+vFA6mSUW61lPW6jlIoBLUCVzX0RkYtFZImILKmtrSUUChEMBmlrayMcDuP3+4nFYjQ1NaGUor5eT9NWZ431rq+vRynVsZ3f7yccDtPW1kYwGCQUCtHa2ko0GqW5uZlEIkGDVes9eYzk38bGRuLxOC0tLUQiEQKBAO3t7bS3txMIBIhEIrS0tBCPx2m0hr92P0ZDQwOJRILm5mai0Sitra0D1pRc3tTU5HhNTVYxtmQ7OVlTUkv3357TNMXj8X7/n5yiKRqN2vYRua4pFAoN2O8lNfVFv/3oRWQBME8pdZH1+TzgUKXUZSnbrLC22Wp9Xg8cClwHvKWUeshafg/wnFLqsd7ON5R+9KFQiMLCwkHtm2u4WnITU7SYogNcLUn66kdvp/DxNmBiyucJ1rKettkqIj6gHGiwuW8X3n333XoR2dzXNn1QDWR4VuZhw9WSm5iixRQd4GpJMrm3FXYc/WJgLxGZinbSZwNf7LbNU8CXgf8CC4CXlVJKRJ4C/iIivwHGAXsB7/R1MqXUoAtwiMiS3q5oTsPVkpuYosUUHeBqsUO/jl4pFRORy4AXAC9wr1JqpYjcACxRSj0F3AM8KCLrgEb0xQBru0eAVUAMuFSpHmZacHFxcXHJGLbmrFJKPQs8223Zj1Peh4Czetn3p8DusxO7uLi4uAwLRo2MBf6YbQPSiKslNzFFiyk6wNXSLzlXvdLFxcXFJb2YFtG7uLi4uHTDdfQuLi4uhmOMo++v8FquISL3ikitNdgsuWykiPxLRNZafyut5SIiv7e0vS8iB2fP8q6IyEQR+beIrBKRlSLyLWu5E7UUisg7IrLc0nK9tXyqVaxvnVW8L99a3msxv1xARLwi8p6IPGN9dqQOABHZJCIfiMgyEVliLXPib6xCRB4TkTUislpEPj0cOoxw9GKv8FqucT+60FsqVwIvKaX2Al6yPoPWtZf1uhi4Y5hstEMM+F+l1HTgMOBS67t3opYwcJxSagYwE5gnIoehi/T91ira14Qu4ge9FPPLIb4FrE757FQdSY5VSs1M6WfuxN/YLcDzSql9gBno9sm8DqWU41/Ap4EXUj5fBVyVbbts2D0FWJHy+UNgrPV+LPCh9f4u4Jyetsu1F/AkcKLTtQDFwFJ0KY96wNf9t4YeW/Jp673P2k6ybbtlzwTLaRwHPAOIE3Wk6NkEVHdb5qjfGLpiwMbu3+1w6DAiosdm8TQHMFoptcN6vxMYbb13hD7rlv8g4G0cqsVKdywDaoF/AeuBZqWL9UFXe3sr5pcL/A74PpCwPlfhTB1JFPBPEXlXRC62ljntNzYVqAPus1JqfxKREoZBhymO3jiUvoQ7pu+riJQCjwNXKKX8qeucpEUpFVdKzURHxHOAfbJr0cARkflArVLq3WzbkkaOUEodjE5nXCoiR6WudMhvzAccDNyhlDoIaKMzTQNkTocpjn7AxdNylF0iMhbA+ltrLc9pfSKSh3byDyul/mYtdqSWJEqpZuDf6BRHhehifdDV3g4t0rWYX7aZC5wmIpvQ80cch84NO01HB0qpbdbfWuAJ9EXYab+xrcBWpdTb1ufH0I4/4zpMcfQdhdesngRnowutOY1kcTisv0+mLD/fegp/GNCScquXVURE0LWOViulfpOyyolaakSkwnpfhH7WsBrt8BdYm3XXktTYUcxv2AzuBaXUVUqpCUqpKej/hZeVUl/CYTqSiEiJiIxIvgdOAlbgsN+YUmonsEVEPmUtOh5dByzzOrL9gCKNDzpOBT5C51SvzrY9Nuz9K7ADiKKv9F9B50VfAtYCLwIjrW0F3atoPfABMDvb9qfoOAJ9q/k+sMx6nepQLQcC71laVgA/tpZPQ1ddXQc8ChRYywutz+us9dOyraEHTccAzzhZh2X3cuu1Mvn/7dDf2ExgifUb+ztQORw63BIILi4uLoZjSurGxcXFxaUXXEfv4uLiYjiuo3dxcXExHNfRu7i4uBiO6+hdXFxcDMd19C4uaUREjklWi3RxyRVcR+/i4uJiOK6jd/lEIiLniq49v0xE7rKKmQVE5Leia9G/JCI11rYzReQtqyb4Eyn1wvcUkRdF169fKiJ7WIcvTak5/rA1etjFJWu4jt7lE4eI7At8AZirdAGzOPAloARYopTaD3gVuNba5c/AD5RSB6JHKCaXPwzcrnT9+sPRI51BV/C8Aj03wjR07RkXl6zh638TFxfjOB6YBSy2gu0idCGpBPB/1jYPAX8TkXKgQin1qrX8AeBRq/bKeKXUEwBKqRCAdbx3lFJbrc/L0PMOvJFxVS4uveA6epdPIgI8oJS6qstCkR91226w9UHCKe/juP9nLlnGTd24fBJ5CVggIqOgY+7Ryej/h2R1xy8CbyilWoAmETnSWn4e8KpSqhXYKiJnWMcoEJHi4RTh4mIXN9Jw+cShlFolItegZyzyoCuIXoqeCGKOta4WnccHXTr2TsuRbwAusJafB9wlIjdYxzhrGGW4uNjGrV7p4mIhIgGlVGm27XBxSTdu6sbFxcXFcNyI3sXFxcVw3IjexcXFxXBcR+/i4uJiOK6jd3FxcTEc19G7uLi4GI7r6F1cXFwM5/8B143xIdfvwZ0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(max_epochs)]\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.plot(x, loss_dict['orig'], label='Batch', color=\"red\")\n",
    "plt.plot(x, loss_dict['instance'], label='Instance', color=\"blue\")\n",
    "plt.plot(x, loss_dict['instance_nvfuser'], label='Instance_NVFuser', color=\"green\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f89c8476250>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Val Mean Dice\")\n",
    "x = [(i + 1) * 5 for i in range(max_epochs // 5)]\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.plot(x, metric_dict['orig'], label='Batch', color=\"red\")\n",
    "plt.plot(x, metric_dict['instance'], label='Instance', color=\"blue\")\n",
    "plt.plot(x, metric_dict['instance_nvfuser'], label='Instance_NVFuser', color=\"green\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    load_ops, load_time = 0, 0\n",
    "    post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=2)])\n",
    "    post_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])\n",
    "\n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "\n",
    "    if fast:\n",
    "        # SGD prefer to much bigger learning rate\n",
    "        optimizer = SGD(\n",
    "            model.parameters(),\n",
    "            lr=learning_rate * 1000,\n",
    "            momentum=0.9,\n",
    "            weight_decay=0.00004,\n",
    "        )\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "    else:\n",
    "        optimizer = Adam(model.parameters(), learning_rate)\n",
    "\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    best_metrics_epochs_and_time = [[], [], []]\n",
    "    epoch_loss_values = []\n",
    "    metric_values = []\n",
    "    epoch_times = []\n",
    "    total_start = time.time()\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "\n",
    "        # profiling: full epoch\n",
    "        with nvtx.annotate(\"epoch\", color=\"red\") if profiling else no_profiling:\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            train_loader_iterator = iter(train_loader)\n",
    "\n",
    "            # using step instead of iterate through train_loader directly to track data loading time\n",
    "            # steps are 1-indexed for printing and calculation purposes\n",
    "            for step in range(1, len(train_loader) + 1):\n",
    "                step_start = time.time()\n",
    "\n",
    "                # profiling: train dataload\n",
    "                with nvtx.annotate(\"dataload\", color=\"red\") if profiling else no_profiling:\n",
    "                    # rng_train_dataload = nvtx.start_range(message=\"dataload\", color=\"red\")\n",
    "                    load_start = time.time()\n",
    "                    batch_data = next(train_loader_iterator)\n",
    "                    load_time += time.time() - load_start\n",
    "                    load_ops += 1\n",
    "                    inputs, labels = (\n",
    "                        batch_data[\"image\"].to(device),\n",
    "                        batch_data[\"label\"].to(device),\n",
    "                    )\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                # set AMP for MONAI training\n",
    "                # profiling: forward\n",
    "                with nvtx.annotate(\"forward\", color=\"green\") if profiling else no_profiling:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = model(inputs)\n",
    "                        loss = loss_function(outputs, labels)\n",
    "\n",
    "                # profiling: backward\n",
    "                with nvtx.annotate(\"backward\", color=\"blue\") if profiling else no_profiling:\n",
    "                    scaler.scale(loss).backward()\n",
    "\n",
    "                # profiling: update\n",
    "                with nvtx.annotate(\"update\", color=\"yellow\") if profiling else no_profiling:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_len = math.ceil(len(train_ds) / train_loader.batch_size)\n",
    "                print(\n",
    "                    f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\"\n",
    "                    f\" step time: {(time.time() - step_start):.4f}\"\n",
    "                )\n",
    "            epoch_loss /= step\n",
    "            epoch_loss_values.append(epoch_loss)\n",
    "            print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "            if (epoch + 1) % val_interval == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_loader_iterator = iter(val_loader)\n",
    "\n",
    "                    for val_step in range(len(val_loader)):\n",
    "                        # profiling: val dataload\n",
    "                        with nvtx.annotate(\"dataload\", color=\"red\") if profiling else no_profiling:\n",
    "                            val_data = next(val_loader_iterator)\n",
    "                            val_inputs, val_labels = (\n",
    "                                val_data[\"image\"].to(device),\n",
    "                                val_data[\"label\"].to(device),\n",
    "                            )\n",
    "\n",
    "                        roi_size = (160, 160, 160)\n",
    "                        sw_batch_size = 4\n",
    "\n",
    "                        # profiling: sliding window\n",
    "                        with nvtx.annotate(\"sliding window\", color=\"green\") if profiling else no_profiling:\n",
    "                            # set AMP for MONAI validation\n",
    "                            if fast:\n",
    "                                with torch.cuda.amp.autocast():\n",
    "                                    val_outputs = sliding_window_inference(\n",
    "                                        val_inputs, roi_size, sw_batch_size, model\n",
    "                                    )\n",
    "                            else:\n",
    "                                val_outputs = sliding_window_inference(\n",
    "                                    val_inputs, roi_size, sw_batch_size, model\n",
    "                                )\n",
    "\n",
    "                        # profiling: decollate batch\n",
    "                        with nvtx.annotate(\"decollate batch\", color=\"blue\") if profiling else no_profiling:\n",
    "                            val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                            val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "\n",
    "                        # profiling: compute metric\n",
    "                        with nvtx.annotate(\"compute metric\", color=\"yellow\") if profiling else no_profiling:\n",
    "                            dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "                    metric = dice_metric.aggregate().item()\n",
    "                    dice_metric.reset()\n",
    "                    metric_values.append(metric)\n",
    "                    if metric > best_metric:\n",
    "                        best_metric = metric\n",
    "                        best_metric_epoch = epoch + 1\n",
    "                        best_metrics_epochs_and_time[0].append(best_metric)\n",
    "                        best_metrics_epochs_and_time[1].append(best_metric_epoch)\n",
    "                        best_metrics_epochs_and_time[2].append(\n",
    "                            time.time() - total_start\n",
    "                        )\n",
    "                        torch.save(model.state_dict(), os.path.join(root_dir, \"best_metric_model.pt\"))\n",
    "                        print(\"saved new best metric model\")\n",
    "                    print(\n",
    "                        f\"current epoch: {epoch + 1} current\"\n",
    "                        f\" mean dice: {metric:.4f}\"\n",
    "                        f\" best mean dice: {best_metric:.4f}\"\n",
    "                        f\" at epoch: {best_metric_epoch}\"\n",
    "                    )\n",
    "\n",
    "        print(\n",
    "            f\"time consuming of epoch {epoch + 1} is:\"\n",
    "            f\" {(time.time() - epoch_start):.4f}\"\n",
    "        )\n",
    "        epoch_times.append(time.time() - epoch_start)\n",
    "\n",
    "    total_time = time.time() - total_start\n",
    "    print(\n",
    "        f\"train completed, best_metric: {best_metric:.4f}\"\n",
    "        f\" at epoch: {best_metric_epoch}\"\n",
    "        f\" total time: {total_time:.4f}\"\n",
    "    )\n",
    "    \n",
    "    return total_time, epoch_loss_values, metric_values, load_time / load_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we give a brief overview of key observations from the `nsys-rep` output file when opened in Nsight systems (2022.2.1).\n",
    "\n",
    "In the GUI, select File -> Open -> output_base.nsys-rep. Here is a sample of the display:\n",
    "\n",
    "![png](figures/nsys-all-annotated.png)\n",
    "- To get a better view of details, you can left-click and select a horizontal section, then right-click and \"Zoom into Selection.\" To return, right-click and select \"Reset Zoom.\"\n",
    "- Sections B and C show training before and after acceleration (when fast=False and fast=True, accordingly). Clearly, MONAI optimized training is much faster than regular PyTorch training. B and C both contain two rows; the upper row shows per-epoch time, and the lower row shows per-action time (user-defined, like dataloading, forward, backward, etc.).\n",
    "- Section A shows GPU utilization, where the height of the blue bars represents utilization rate. Regular PyTorch training shows sporadic and varying levels of GPU utilization, while MONAI optimized training shows consistent and high levels of GPU utilization.\n",
    "\n",
    "Expanding one more thread in the lower left corner and several more threads below \\[4648\\], we see the following:\n",
    "\n",
    "![png](figures/nsys-transforms-annotated.png)\n",
    "\n",
    "Sections D and E both include information on the transform chain.\n",
    "- Section E: In MONAI optimized training, results of all transforms in the chain until the first randomized transform is stored to prevent repeated operations. This explains why E is chronologically before any of the training epochs in the figure.\n",
    "- Section D: In regular PyTorch training, CacheDataset is not in use, and the transform chain is performed every epoch on all data used.\n",
    "\n",
    "Here is the display of the transform chain when zoomed in:\n",
    "![png](figures/nsys-fast-transform.png)\n",
    "\n",
    "And a display of one training epoch of MONAI optimized training when zoomed in:\n",
    "![png](figures/nsys-epoch-short.png)\n",
    "Notice that the per-epoch time is >20 times faster than the regular PyTorch training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training loss and validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not profiling:\n",
    "    plt.figure(\"train\", (12, 12))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.title(\"Regular Epoch Average Loss\")\n",
    "    x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "    y = epoch_loss_values\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.grid(alpha=0.4, linestyle=\":\")\n",
    "    plt.plot(x, y, color=\"red\")\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.title(\"Regular Val Mean Dice\")\n",
    "    x = [(i + 1) * 5 for i in range(len(metric_values))]\n",
    "    y = metric_values\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(alpha=0.4, linestyle=\":\")\n",
    "    plt.plot(x, y, color=\"red\")\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.title(\"Fast Epoch Average Loss\")\n",
    "    x = [i + 1 for i in range(len(m_epoch_loss_values))]\n",
    "    y = m_epoch_loss_values\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.grid(alpha=0.4, linestyle=\":\")\n",
    "    plt.plot(x, y, color=\"green\")\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.title(\"Fast Val Mean Dice\")\n",
    "    x = [(i + 1) * 5 for i in range(len(m_metric_values))]\n",
    "    y = m_metric_values\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(alpha=0.4, linestyle=\":\")\n",
    "    plt.plot(x, y, color=\"green\")\n",
    "    plt.savefig(\"outputs/loss_dice_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot total time and every epoch time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not profiling:\n",
    "    plt.figure(\"train\", (12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Total Train Time(600 epochs)\")\n",
    "    plt.bar(\n",
    "        \"regular PyTorch\", total_time, 1, label=\"Regular training\", color=\"red\"\n",
    "    )\n",
    "    plt.bar(\"Fast\", m_total_time, 1, label=\"Fast training\", color=\"green\")\n",
    "    plt.ylabel(\"secs\")\n",
    "    plt.grid(alpha=0.4, linestyle=\":\")\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Epoch Time\")\n",
    "    x = [i + 1 for i in range(len(epoch_times))]\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"secs\")\n",
    "    plt.plot(x, epoch_times, label=\"Regular training\", color=\"red\")\n",
    "    plt.plot(x, m_epoch_times, label=\"Fast training\", color=\"green\")\n",
    "    plt.grid(alpha=0.4, linestyle=\":\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(\"outputs/total_epoch_time_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot total time to achieve metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_best_metric_time(threshold, best_values):\n",
    "    for i, v in enumerate(best_values[0]):\n",
    "        if round(v, 4) >= threshold:\n",
    "            return best_values[2][i]\n",
    "    return -1\n",
    "\n",
    "\n",
    "def get_best_metric_epochs(threshold, best_values):\n",
    "    for i, v in enumerate(best_values[0]):\n",
    "        if round(v, 4) >= threshold:\n",
    "            return best_values[1][i]\n",
    "    return -1\n",
    "\n",
    "\n",
    "def get_label(index):\n",
    "    if index == 0:\n",
    "        return \"Regular training\"\n",
    "    elif index == 1:\n",
    "        return \"Fast training\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "if not profiling:\n",
    "    plt.figure(\"train\", (18, 6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Metrics Time\")\n",
    "    plt.xlabel(\"secs\")\n",
    "    plt.ylabel(\"best mean_dice\")\n",
    "    plt.plot(best[2], best[0], label=\"Regular training\", color=\"red\")\n",
    "    plt.plot(m_best[2], m_best[0], label=\"Fast training\", color=\"green\")\n",
    "    plt.grid(alpha=0.4, linestyle=\":\")\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Typical Metrics Time\")\n",
    "    plt.xlabel(\"best mean_dice\")\n",
    "    plt.ylabel(\"secs\")\n",
    "    labels = [\"0.80\", \"0.80 \", \"0.90\", \"0.90 \", \"0.92\", \"0.92 \", \"0.94\", \"0.94 \"]\n",
    "    x_values = [0.8, 0.8, 0.9, 0.9, 0.92, 0.92, 0.94, 0.94]\n",
    "    for i, (l, x) in enumerate(zip(labels, x_values)):\n",
    "        value = int(get_best_metric_time(x, best if i % 2 == 0 else m_best))\n",
    "        color = \"red\" if i % 2 == 0 else \"green\"\n",
    "        plt.bar(l, value, 0.5, label=get_label(i), color=color)\n",
    "        plt.text(l, value, \"%s\" % value, ha=\"center\", va=\"bottom\")\n",
    "    plt.grid(alpha=0.4, linestyle=\":\")\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Typical Metrics Epochs\")\n",
    "    plt.xlabel(\"best mean_dice\")\n",
    "    plt.ylabel(\"epochs\")\n",
    "    for i, (l, x) in enumerate(zip(labels, x_values)):\n",
    "        value = int(get_best_metric_epochs(x, best if i % 2 == 0 else m_best))\n",
    "        color = \"red\" if i % 2 == 0 else \"green\"\n",
    "        plt.bar(l, value, 0.5, label=get_label(i), color=color)\n",
    "        plt.text(l, value, \"%s\" % value, ha=\"center\", va=\"bottom\")\n",
    "    plt.grid(alpha=0.4, linestyle=\":\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(\"outputs/metric_time_epochs.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup data directory\n",
    "\n",
    "Remove directory if a temporary was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "if directory is None:\n",
    "    shutil.rmtree(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<sup id=\"fn1\">1</sup>](#fn1-back) Acknowledgement: This usage is inspired by [Conditional with statement in Python](https://stackoverflow.com/a/68682614) by [Lucas Vasquez](https://stackoverflow.com/users/10712525/lucas-vazquez), used with adaptations under [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/), accessed June 14, 2022.</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
