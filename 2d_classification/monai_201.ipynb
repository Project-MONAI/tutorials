{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) MONAI Consortium  \n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  \n",
    "you may not use this file except in compliance with the License.  \n",
    "You may obtain a copy of the License at  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;http://www.apache.org/licenses/LICENSE-2.0  \n",
    "Unless required by applicable law or agreed to in writing, software  \n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,  \n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \n",
    "See the License for the specific language governing permissions and  \n",
    "limitations under the License.\n",
    "\n",
    "# MONAI 201 Tutorial: Advanced Training Techniques\n",
    "\n",
    "Welcome to MONAI 201! This tutorial builds upon [MONAI 101](https://github.com/Project-MONAI/tutorials/blob/main/2d_classification/monai_101.ipynb) and introduces advanced training techniques and best practices for production-ready medical AI models.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "This intermediate tutorial covers advanced concepts that are essential for building robust medical AI systems:\n",
    "\n",
    "- **Advanced Training Workflow**: Enhanced training with validation monitoring\n",
    "- **Model Evaluation**: Comprehensive evaluation using `SupervisedEvaluator`\n",
    "- **Experiment Tracking**: TensorBoard integration for training visualization\n",
    "- **Model Checkpointing**: Save and restore model states during training\n",
    "- **Production Best Practices**: Techniques used in real-world medical AI applications\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Complete [MONAI 101](https://github.com/Project-MONAI/tutorials/blob/main/2d_classification/monai_101.ipynb) or have basic MONAI knowledge\n",
    "- Understanding of deep learning concepts (training, validation, etc.)\n",
    "- Familiarity with PyTorch basics\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- **GPU Memory**: Approximately 7GB\n",
    "- **Runtime**: About 10 minutes\n",
    "- **Level**: Intermediate\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Project-MONAI/tutorials/blob/main/2d_classification/monai_201.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[ignite, tqdm, tensorboard]\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import tempfile\n",
    "import torch\n",
    "import ignite\n",
    "\n",
    "from monai.apps import MedNISTDataset\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader\n",
    "from monai.engines import SupervisedTrainer, SupervisedEvaluator\n",
    "from monai.handlers import (\n",
    "    StatsHandler,\n",
    "    TensorBoardStatsHandler,\n",
    "    ValidationHandler,\n",
    "    CheckpointSaver,\n",
    "    CheckpointLoader,\n",
    "    ClassificationSaver,\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.inferers import SimpleInferer\n",
    "from monai.networks.nets import densenet121\n",
    "from monai.transforms import LoadImageD, EnsureChannelFirstD, ScaleIntensityD, Compose, AsDiscreted\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data directory\n",
    "\n",
    "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.  \n",
    "This allows you to save results and reuse downloads.  \n",
    "If not specified a temporary directory will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Data\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "if directory is not None:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data with MONAI Transforms\n",
    "\n",
    "We'll prepare our data using the same transforms as MONAI 101, but this time we'll also create a validation dataset. This separation is crucial for monitoring training progress and preventing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-27 08:31:31,955 - INFO - Verified 'MedNIST.tar.gz', md5: 0bc7306e7427e00ad1c5526a6677552d.\n",
      "2024-02-27 08:31:31,955 - INFO - File exists: /workspace/Data/MedNIST.tar.gz, skipped downloading.\n",
      "2024-02-27 08:31:31,956 - INFO - Non-empty folder exists in /workspace/Data/MedNIST, skipped extracting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:   0%|          | 0/47164 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 47164/47164 [00:19<00:00, 2393.21it/s]\n",
      "Loading dataset: 100%|██████████| 5895/5895 [00:02<00:00, 2465.05it/s]\n"
     ]
    }
   ],
   "source": [
    "transform = Compose(\n",
    "    [\n",
    "        LoadImageD(keys=\"image\", image_only=True),\n",
    "        EnsureChannelFirstD(keys=\"image\"),\n",
    "        ScaleIntensityD(keys=\"image\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# If you use the MedNIST dataset, please acknowledge the source.\n",
    "dataset = MedNISTDataset(root_dir=root_dir, transform=transform, section=\"training\", download=True)\n",
    "valdata = MedNISTDataset(root_dir=root_dir, transform=transform, section=\"validation\", download=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Training Setup with Evaluation and Monitoring\n",
    "\n",
    "Now we'll create a more sophisticated training setup that includes validation monitoring and experiment tracking. This represents production-level best practices for medical AI development.\n",
    "\n",
    "### Key Components\n",
    "\n",
    "1. **`SupervisedEvaluator`**: Handles validation during training to monitor model performance\n",
    "2. **`TensorBoardStatsHandler`**: Logs training metrics for visualization\n",
    "3. **`CheckpointSaver`**: Automatically saves model checkpoints during training\n",
    "4. **`ValidationHandler`**: Coordinates validation runs at specified intervals\n",
    "\n",
    "This setup provides real-time monitoring of your model's learning progress and helps identify issues like overfitting early in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 5\n",
    "save_interval = 2\n",
    "out_dir = \"./eval\"\n",
    "model = densenet121(spatial_dims=2, in_channels=1, out_channels=6).to(\"cuda:0\")\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "evaluator = SupervisedEvaluator(\n",
    "    device=torch.device(\"cuda:0\"),\n",
    "    val_data_loader=DataLoader(valdata, batch_size=512, shuffle=False, num_workers=4),\n",
    "    network=model,\n",
    "    inferer=SimpleInferer(),\n",
    "    key_val_metric={\"val_acc\": ignite.metrics.Accuracy(from_engine([\"pred\", \"label\"]))},\n",
    "    val_handlers=[StatsHandler(iteration_log=False), TensorBoardStatsHandler(iteration_log=False)],\n",
    ")\n",
    "\n",
    "trainer = SupervisedTrainer(\n",
    "    device=torch.device(\"cuda:0\"),\n",
    "    max_epochs=max_epochs,\n",
    "    train_data_loader=DataLoader(dataset, batch_size=512, shuffle=True, num_workers=4),\n",
    "    network=model,\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=1e-5),\n",
    "    loss_function=torch.nn.CrossEntropyLoss(),\n",
    "    inferer=SimpleInferer(),\n",
    "    train_handlers=[\n",
    "        ValidationHandler(validator=evaluator, epoch_level=True, interval=1),\n",
    "        CheckpointSaver(\n",
    "            save_dir=out_dir,\n",
    "            save_dict={\"model\": model},\n",
    "            save_interval=save_interval,\n",
    "            save_final=True,\n",
    "            final_filename=\"checkpoint.pt\",\n",
    "        ),\n",
    "        StatsHandler(),\n",
    "        TensorBoardStatsHandler(tag_name=\"train_loss\", output_transform=from_engine([\"loss\"], first=True)),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training Progress with TensorBoard\n",
    "\n",
    "TensorBoard provides powerful visualization tools to monitor your training progress. You can view:\n",
    "- Training and validation loss curves\n",
    "- Model performance metrics over time\n",
    "- Learning rate schedules\n",
    "- Model architecture graphs\n",
    "\n",
    "To view the results, uncomment and run the following cell. TensorBoard will open in your browser showing real-time training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir ./runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "First thing to do is to prepare the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(root_dir, \"MedNIST\")\n",
    "class_names = sorted(f\"{x.name}\" for x in dataset_dir.iterdir() if x.is_dir())\n",
    "testdata = MedNISTDataset(root_dir=root_dir, transform=transform, section=\"test\", download=False, runtime_cache=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to establish a `SupervisedEvaluator`. This evaluator will process all the files in the specified directory and persist the results into a CSV file. Validation handlers (val_handlers) will be utilized to load the checkpoint file, providing an error if any file is unavailable, and they will also save the classification outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ignite.engine.engine.SupervisedEvaluator:Engine run resuming from iteration 0, epoch 0 until 1 epochs\n",
      "INFO:ignite.engine.engine.SupervisedEvaluator:Restored all variables from ./eval/checkpoint.pt\n",
      "INFO:ignite.engine.engine.SupervisedEvaluator:Epoch[1] Complete. Time taken: 00:01:24.338\n",
      "INFO:ignite.engine.engine.SupervisedEvaluator:Engine run complete. Time taken: 00:01:24.390\n"
     ]
    }
   ],
   "source": [
    "evaluator = SupervisedEvaluator(\n",
    "    device=torch.device(\"cuda:0\"),\n",
    "    val_data_loader=DataLoader(testdata, batch_size=1, num_workers=0),\n",
    "    network=model,\n",
    "    inferer=SimpleInferer(),\n",
    "    postprocessing=AsDiscreted(keys=\"pred\", argmax=True),\n",
    "    val_handlers=[\n",
    "        CheckpointLoader(load_path=f\"{out_dir}/checkpoint.pt\", load_dict={\"model\": model}),\n",
    "        ClassificationSaver(\n",
    "            batch_transform=lambda batch: batch[0][\"image\"].meta, output_transform=from_engine([\"pred\"])\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "evaluator.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the inference results are stored in a file named \"predictions.csv\". However, this output filename can be customized within the `ClassificationSaver` handler, according to your preferences.\n",
    "Upon examining the output, one can note that the second column corresponds to the predicted class. A more discernable interpretation can be achieved by using these values as indices mapped to our predefined list of class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Data/MedNIST/AbdomenCT/006070.jpeg AbdomenCT\n",
      "/workspace/Data/MedNIST/BreastMRI/006574.jpeg BreastMRI\n",
      "/workspace/Data/MedNIST/ChestCT/009858.jpeg ChestCT\n",
      "/workspace/Data/MedNIST/CXR/007398.jpeg CXR\n",
      "/workspace/Data/MedNIST/Hand/005663.jpeg Hand\n",
      "/workspace/Data/MedNIST/HeadCT/006896.jpeg HeadCT\n",
      "/workspace/Data/MedNIST/HeadCT/007179.jpeg HeadCT\n",
      "/workspace/Data/MedNIST/CXR/001190.jpeg CXR\n",
      "/workspace/Data/MedNIST/ChestCT/005138.jpeg ChestCT\n",
      "/workspace/Data/MedNIST/BreastMRI/000023.jpeg BreastMRI\n"
     ]
    }
   ],
   "source": [
    "max_items_to_print = 10\n",
    "for fn, idx in np.loadtxt(\"./predictions.csv\", delimiter=\",\", dtype=str):\n",
    "    print(fn, class_names[int(float(idx))])\n",
    "    max_items_to_print -= 1\n",
    "    if max_items_to_print == 0:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
