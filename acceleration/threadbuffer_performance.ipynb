{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ThreadBuffer Performance\n",
    "\n",
    "This notebook demonstrates the use of `ThreadBuffer` to generate batches of data asynchronously from the training thread. \n",
    "\n",
    "Under certain circumstances the main thread can be busy with the training operations, that is interacting with GPU memory and invoking CUDA operations, which is independent of batch generation operations. If the time taken to generate a batch is significant compared to the time taken to train the network for an iteration, and assuming operations can be done in parallel given the limitations of the GIL or other factors, this should speed up the whole training process. The efficiency gains will be relative to the proportion of these two times, so if batch generation is lengthy but training is very fast then very little parallel computation is possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.3.0+31.gde37494\n",
      "Python version: 3.7.7 (default, Mar 23 2020, 22:36:06)  [GCC 7.3.0]\n",
      "OS version: Linux (4.4.0-143-generic)\n",
      "Numpy version: 1.19.1\n",
      "Pytorch version: 1.6.0\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.3.0\n",
      "Nibabel version: 3.1.1\n",
      "scikit-image version: 0.17.2\n",
      "Pillow version: 7.2.0\n",
      "Tensorboard version: 2.3.0\n",
      "gdown version: 3.12.2\n",
      "TorchVision version: 0.7.0\n",
      "ITK version: 5.1.1\n",
      "tqdm version: 4.48.2\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import monai\n",
    "from monai.data import Dataset, DataLoader, ThreadBuffer, create_test_image_2d\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import Dice\n",
    "from monai.transforms import Compose, MapTransform, AddChanneld, ToTensord\n",
    "\n",
    "monai.utils.set_determinism(seed=0)\n",
    "\n",
    "monai.config.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data pipeline is given here which creates random 2D segmentation training pairs. It is artificially slowed by setting the number of worker processes to 0 (often necessary under Windows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomGenerator(MapTransform):\n",
    "    \"\"\"Generates a dictionary containing image and segmentation images from a given seed value.\"\"\"\n",
    "\n",
    "    def __call__(self, seed):\n",
    "        rs = np.random.RandomState(seed)\n",
    "        im, seg = create_test_image_2d(256, 256, num_seg_classes=1, random_state=rs)\n",
    "\n",
    "        return {self.keys[0]: im, self.keys[1]: seg}\n",
    "\n",
    "\n",
    "data = np.random.randint(0, monai.utils.MAX_SEED, 1000)\n",
    "\n",
    "trans = Compose(\n",
    "    [\n",
    "        RandomGenerator(keys=(\"im\", \"seg\")),\n",
    "        AddChanneld(keys=(\"im\", \"seg\")),\n",
    "        ToTensord(keys=(\"im\", \"seg\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_ds = Dataset(data, trans)\n",
    "train_loader = DataLoader(train_ds, batch_size=20, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network, loss, and optimizers defined as normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "net = UNet(2, 1, 1, (8, 16, 32), (2, 2, 2), num_res_units=2).to(device)\n",
    "loss_function = Dice(sigmoid=True)\n",
    "optimizer = torch.optim.Adam(net.parameters(), 1e-5)\n",
    "epoch_num = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple training function is defined which only performs step optimization of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch):\n",
    "    inputs, labels = batch[\"im\"].to(device), batch[\"seg\"].to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs)\n",
    "    loss = loss_function(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "def train(use_buffer):\n",
    "    # wrap the loader in the ThreadBuffer if selected\n",
    "    src = ThreadBuffer(train_loader, 1) if use_buffer else train_loader\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        for batch in src:\n",
    "            train_step(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing how long it takes to generate a single batch versus the time taken to optimize the network for one step reveals the proportion of time taken by each during each full training iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.9 ms ± 1.83 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "36.6 ms ± 2.07 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "it = iter(train_loader)\n",
    "batch = next(it)\n",
    "\n",
    "%timeit -n 1 next(it)\n",
    "%timeit -n 1 train_step(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without using an asynchronous buffer for batch generation these operations must be sequential:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.7 s ± 2.35 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With overlap we see a significant speedup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.1 s ± 833 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 train(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:monai]",
   "language": "python",
   "name": "conda-env-monai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
