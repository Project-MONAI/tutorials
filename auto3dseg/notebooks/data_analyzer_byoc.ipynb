{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write your own data analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Perform analysis on a different image meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.auto3dseg.analyzer import Analyzer\n",
    "from monai.auto3dseg import SegSummarizer, concat_val_to_np, SampleOperations\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class DimsAnalyzer(Analyzer):\n",
    "    def __init__(self, image_key=\"image\", stats_name=\"user_stats\"):\n",
    "        self.image_key = image_key\n",
    "        report_format = {\"ndims\": None}\n",
    "        super().__init__(stats_name, report_format)\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        report = deepcopy(self.get_report_format())\n",
    "        report[\"ndims\"] = d[self.image_key].ndim\n",
    "        d[self.stats_name] = report\n",
    "        return d\n",
    "\n",
    "class DimsSummaryAnalyzer(Analyzer):\n",
    "    def __init__(self, stats_name=\"user_stats\"):\n",
    "        report_format = {\"ndims\": None}\n",
    "        super().__init__(stats_name, report_format)\n",
    "        self.update_ops(\"ndims\", SampleOperations())\n",
    "    def __call__(self, data):\n",
    "        report = deepcopy(self.get_report_format())\n",
    "        v_np = concat_val_to_np(data, [self.stats_name, \"ndims\"])\n",
    "        report[\"ndims\"] = self.ops[\"ndims\"].evaluate(v_np)\n",
    "        return report\n",
    "\n",
    "summarizer = SegSummarizer(\"image\", \"label\")  # it has the three default analyzers (ImageStats, FgImageStats, LabelStats)\n",
    "summarizer.add_analyzer(DimsAnalyzer(), DimsSummaryAnalyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 28.33it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from monai.data import DataLoader, Dataset\n",
    "from monai.data.utils import no_collation\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureTyped,\n",
    "    Lambdad,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    SqueezeDimd,\n",
    "    ToDeviced,\n",
    ")\n",
    "from monai.utils import StrEnum, min_version, optional_import\n",
    "from monai.utils.enums import DataStatsKeys, ImageStatsKeys\n",
    "from monai.auto3dseg import datafold_read\n",
    "\n",
    "def _argmax_if_multichannel(x):\n",
    "    return torch.argmax(x, dim=0, keepdim=True) if x.shape[0] > 1 else x\n",
    "\n",
    "def my_analyzer(datalist, dataroot, my_summarizer):\n",
    "    keys = [\"image\", \"label\"]\n",
    "    transform_list = [\n",
    "        LoadImaged(keys=keys),\n",
    "        EnsureChannelFirstd(keys=keys),  # this creates label to be (1,H,W,D)\n",
    "        Orientationd(keys=keys, axcodes=\"RAS\"),\n",
    "        EnsureTyped(keys=keys, data_type=\"tensor\"),\n",
    "        Lambdad(keys=\"label\", func=_argmax_if_multichannel),\n",
    "        SqueezeDimd(keys=[\"label\"], dim=0),\n",
    "        ToDeviced(keys=keys, device=\"cuda\"),\n",
    "        my_summarizer,\n",
    "    ]\n",
    "\n",
    "    transform = Compose(transforms=list(filter(None, transform_list)))\n",
    "\n",
    "    files, _ = datafold_read(datalist=datalist, basedir=dataroot, fold=-1)\n",
    "    dataset = Dataset(data=files, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0, collate_fn=no_collation)\n",
    "    result = {DataStatsKeys.SUMMARY: {}, DataStatsKeys.BY_CASE: []}\n",
    "\n",
    "    for batch_data in tqdm(dataloader):\n",
    "        d = batch_data[0]\n",
    "        stats_by_cases = {\n",
    "            DataStatsKeys.BY_CASE_IMAGE_PATH: d[DataStatsKeys.BY_CASE_IMAGE_PATH],\n",
    "            DataStatsKeys.BY_CASE_LABEL_PATH: d[DataStatsKeys.BY_CASE_LABEL_PATH],\n",
    "            DataStatsKeys.IMAGE_STATS: d[DataStatsKeys.IMAGE_STATS],\n",
    "            DataStatsKeys.FG_IMAGE_STATS: d[DataStatsKeys.FG_IMAGE_STATS],\n",
    "            DataStatsKeys.LABEL_STATS: d[DataStatsKeys.LABEL_STATS],\n",
    "            \"user_stats\": d[\"user_stats\"]\n",
    "        }\n",
    "\n",
    "\n",
    "    result[DataStatsKeys.BY_CASE].append(stats_by_cases)\n",
    "    result[DataStatsKeys.SUMMARY] = summarizer.summarize(result[DataStatsKeys.BY_CASE])\n",
    "    return result\n",
    "\n",
    "result = my_analyzer(sim_datalist, sim_dataroot, summarizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ndims': 4}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(result[DataStatsKeys.BY_CASE][0]['user_stats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ndims': {'max': 4, 'mean': 4.0, 'median': 4.0, 'min': 4, 'stdev': 0.0, 'percentile': [4, 4, 4, 4], 'percentile_00_5': 4, 'percentile_10_0': 4, 'percentile_90_0': 4, 'percentile_99_5': 4}}\n"
     ]
    }
   ],
   "source": [
    "print(result[DataStatsKeys.SUMMARY]['user_stats'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Add a new stat operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 29.79it/s]\n"
     ]
    }
   ],
   "source": [
    "from monai.auto3dseg import SampleOperations\n",
    "import torch\n",
    "\n",
    "op = SampleOperations()\n",
    "# add a new operation\n",
    "op.update({\"sum\": np.sum})\n",
    "\n",
    "class NewDimsSummaryAnalyzer(Analyzer):\n",
    "    def __init__(self, stats_name=\"user_stats\"):\n",
    "        report_format = {\"ndims\": None}\n",
    "        super().__init__(stats_name, report_format)\n",
    "        self.update_ops(\"ndims\", op)\n",
    "    def __call__(self, data):\n",
    "        report = deepcopy(self.get_report_format())\n",
    "        v_np = concat_val_to_np(data, [self.stats_name, \"ndims\"])\n",
    "        report[\"ndims\"] = self.ops[\"ndims\"].evaluate(v_np)\n",
    "        return report\n",
    "\n",
    "summarizer = SegSummarizer(\"image\", \"label\")  # it has the three default analyzers (ImageStats, FgImageStats, LabelStats)\n",
    "summarizer.add_analyzer(DimsAnalyzer(), NewDimsSummaryAnalyzer())\n",
    "result = my_analyzer(sim_datalist, sim_dataroot, summarizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ndims': {'max': 4, 'mean': 4.0, 'median': 4.0, 'min': 4, 'stdev': 0.0, 'percentile': [4, 4, 4, 4], 'sum': 4, 'percentile_00_5': 4, 'percentile_10_0': 4, 'percentile_90_0': 4, 'percentile_99_5': 4}}\n"
     ]
    }
   ],
   "source": [
    "print(result[DataStatsKeys.SUMMARY]['user_stats'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
