{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) MONAI Consortium  \n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  \n",
    "you may not use this file except in compliance with the License.  \n",
    "You may obtain a copy of the License at  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;http://www.apache.org/licenses/LICENSE-2.0  \n",
    "Unless required by applicable law or agreed to in writing, software  \n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,  \n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \n",
    "See the License for the specific language governing permissions and  \n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MONAI pipeline with PyTorch 2.0 Features\n",
    "\n",
    "This notebook introduces how to use `torch.compile` in the MONAI pipeline. `torch.compile` is the main API for PyTorch 2.0, which wraps your model and returns a compiled model. It is a fully additive (and optional) feature and hence 2.0 is 100% backward compatible by definition. We also run an end-to-end pipeline based on [\"fast_training_tutorial.ipynb\"](https://github.com/Project-MONAI/tutorials/blob/main/acceleration/fast_training_tutorial.ipynb), and the speed up is 1.16x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, matplotlib]\"\n",
    "!pip install -q torch>=2.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import tempfile\n",
    "import numpy as np\n",
    "\n",
    "import monai\n",
    "import monai.transforms as mt\n",
    "from monai.config import print_config\n",
    "from monai.utils import set_determinism\n",
    "from monai.bundle import download, create_workflow\n",
    "from monai.engines import SupervisedTrainer\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data directory\n",
    "\n",
    "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.  \n",
    "This allows you to save results and reuse downloads.  \n",
    "If not specified, a temporary directory will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/data\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-16 05:55:56,446 - INFO - Expected md5 is None, skip md5 check for file samples.zip.\n",
      "2024-01-16 05:55:56,447 - INFO - File exists: samples.zip, skipped downloading.\n",
      "2024-01-16 05:55:56,448 - INFO - Writing into directory: /workspace/data.\n"
     ]
    }
   ],
   "source": [
    "sample_url = \"https://github.com/Project-MONAI/MONAI-extra-test-data/releases\"\n",
    "sample_url += \"/download/0.8.1/totalSegmentator_mergedLabel_samples.zip\"\n",
    "monai.apps.download_and_extract(sample_url, output_dir=root_dir, filepath=\"samples.zip\")\n",
    "\n",
    "base_name = os.path.join(root_dir, \"totalSegmentator_mergedLabel_samples\")\n",
    "input_data = []\n",
    "for filename in os.listdir(os.path.join(base_name, \"imagesTr\")):\n",
    "    input_data.append(\n",
    "        {\n",
    "            \"image\": os.path.join(base_name, \"imagesTr\", filename),\n",
    "            \"label\": os.path.join(base_name, \"labelsTr\", filename),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set deterministic for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up timing and training functions\n",
    "\n",
    "For best accuracies, we use CUDA events and synchronization to measure the forward and backward propagations in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timed(fn):\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    result = fn()\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    return result, start.elapsed_time(end) / 1000\n",
    "\n",
    "\n",
    "def train(model, inputs, labels):\n",
    "    outputs = model(inputs)\n",
    "    loss_function = monai.losses.DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "    loss = loss_function(outputs, labels)\n",
    "    loss.backward()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up model\n",
    "\n",
    "Here we used `create_workflow` to get the network instance from the bundle. You can also initialize your own network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-16 05:55:59,615 - INFO - --- input summary of monai.bundle.scripts.download ---\n",
      "2024-01-16 05:55:59,617 - INFO - > name: 'wholeBody_ct_segmentation'\n",
      "2024-01-16 05:55:59,617 - INFO - > bundle_dir: './bundle'\n",
      "2024-01-16 05:55:59,618 - INFO - > source: 'monaihosting'\n",
      "2024-01-16 05:55:59,619 - INFO - > remove_prefix: 'monai_'\n",
      "2024-01-16 05:55:59,619 - INFO - > progress: True\n",
      "2024-01-16 05:55:59,620 - INFO - ---\n",
      "\n",
      "\n",
      "2024-01-16 05:55:59,797 - INFO - Expected md5 is None, skip md5 check for file bundle/wholeBody_ct_segmentation_v0.2.1.zip.\n",
      "2024-01-16 05:55:59,798 - INFO - File exists: bundle/wholeBody_ct_segmentation_v0.2.1.zip, skipped downloading.\n",
      "2024-01-16 05:55:59,799 - INFO - Writing into directory: bundle.\n",
      "2024-01-16 05:56:00,729 - INFO - --- input summary of monai.bundle.scripts.run ---\n",
      "2024-01-16 05:56:00,729 - INFO - > config_file: './bundle/wholeBody_ct_segmentation/configs/train.json'\n",
      "2024-01-16 05:56:00,730 - INFO - > workflow_type: 'train'\n",
      "2024-01-16 05:56:00,731 - INFO - ---\n",
      "\n",
      "\n",
      "2024-01-16 05:56:00,732 - INFO - Setting logging properties based on config: bundle/wholeBody_ct_segmentation/configs/logging.conf.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "bundle_dir = \"./bundle\"\n",
    "os.makedirs(bundle_dir, exist_ok=True)\n",
    "\n",
    "bundle = download(\"wholeBody_ct_segmentation\", bundle_dir=bundle_dir)\n",
    "config_file = os.path.join(bundle_dir, \"wholeBody_ct_segmentation/configs/train.json\")\n",
    "train_workflow = create_workflow(config_file=str(config_file), workflow_type=\"train\")\n",
    "\n",
    "\n",
    "def init_model(device):\n",
    "    return train_workflow.network_def.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up DataLoader and train transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 20/20 [00:05<00:00,  3.85it/s]\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "transform = mt.Compose(\n",
    "    [\n",
    "        mt.LoadImageD(keys=(\"image\", \"label\"), image_only=True, ensure_channel_first=True),\n",
    "        mt.SpacingD(keys=(\"image\", \"label\"), pixdim=1.5),\n",
    "        mt.EnsureTypeD(keys=(\"image\", \"label\"), device=device),\n",
    "        mt.RandRotateD(\n",
    "            keys=(\"image\", \"label\"),\n",
    "            prob=1.0,\n",
    "            range_x=0.1,\n",
    "            range_y=0.1,\n",
    "            range_z=0.3,\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        mt.RandZoomD(keys=(\"image\", \"label\"), prob=1.0, min_zoom=0.8, max_zoom=1.2, mode=(\"trilinear\", \"nearest\")),\n",
    "        mt.ResizeWithPadOrCropD(keys=(\"image\", \"label\"), spatial_size=(96, 96, 96)),\n",
    "        # add `FromMetaTensorD` to convert `MetaTensor` to `torch.Tensor`\n",
    "        mt.FromMetaTensorD(keys=(\"image\", \"label\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = monai.data.CacheDataset(data=input_data, transform=transform, cache_rate=1.0, num_workers=4)\n",
    "data_loader = monai.data.DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training in eager mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/20 average loss: 5.3744, time: 0.0841\n",
      "epoch 2/20 average loss: 4.9033, time: 0.0835\n",
      "epoch 3/20 average loss: 4.2363, time: 0.0837\n",
      "epoch 4/20 average loss: 3.7749, time: 0.0838\n",
      "epoch 5/20 average loss: 3.4824, time: 0.0844\n",
      "median training time per iteration: 0.0838 seconds\n"
     ]
    }
   ],
   "source": [
    "# start a typical PyTorch training\n",
    "epoch_num = 20\n",
    "model = init_model(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "\n",
    "epoch_loss_values = []\n",
    "eager_time = []\n",
    "for epoch in range(epoch_num):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in data_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss, train_time = timed(lambda: train(model, inputs, labels))\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        eager_time.append(train_time)\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    if epoch < 5:\n",
    "        print(f\"epoch {epoch + 1}/{epoch_num} average loss: {epoch_loss:.4f}, time: {train_time:.4f}\")\n",
    "print(f\"median training time per iteration: {np.median(eager_time):.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model with torch.compile\n",
    "\n",
    "The only difference is that we wrap the model with `torch.compile`. You may also see different speedup results depending on the chosen mode argument. The \"reduce-overhead\" mode uses CUDA graphs to further reduce the overhead of Python. For your own models, you may need to experiment with different modes to maximize speedup. You can read more about modes [here](https://pytorch.org/get-started/pytorch-2.0/#user-experience)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt = torch.compile(init_model(device), mode=\"reduce-overhead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using FallbackKernel: aten.upsample_trilinear3d\n",
      "Using FallbackKernel: aten.upsample_trilinear3d_backward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/20 average loss: 3.0229, time: 0.0529\n",
      "epoch 2/20 average loss: 2.9459, time: 0.0530\n",
      "epoch 3/20 average loss: 2.9603, time: 0.0529\n",
      "epoch 4/20 average loss: 2.9253, time: 0.0529\n",
      "epoch 5/20 average loss: 2.8783, time: 0.0531\n",
      "median training time per iteration after compilation: 0.0529 seconds\n"
     ]
    }
   ],
   "source": [
    "# start a typical PyTorch training\n",
    "optimizer = torch.optim.Adam(model_opt.parameters(), 1e-3)\n",
    "\n",
    "epoch_loss_values = []\n",
    "compile_time = []\n",
    "for epoch in range(epoch_num):\n",
    "    model_opt.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in data_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss, train_time = timed(lambda: train(model_opt, inputs, labels))\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        compile_time.append(train_time)\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    if epoch < 5:\n",
    "        print(f\"epoch {epoch + 1}/{epoch_num} average loss: {epoch_loss:.4f}, time: {train_time:.4f}\")\n",
    "print(f\"median training time per iteration after compilation: {np.median(compile_time):.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate the speedups\n",
    "As [torch](https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html) mentioned, we can see that `torch.compile` takes longer in the first epoch, as it must compile the model, but in subsequent iterations, we can see a significant improvement compared to eager. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first iteration: 2.767s(eager mode) vs. 22.391s(compile mode)\n",
      "eager median: 0.08376780700683595, compile median: 0.05292851257324219, speedup: 1.5826593821414972x\n"
     ]
    }
   ],
   "source": [
    "print(f\"first iteration: {eager_time[0]:.3f}s(eager mode) vs. {compile_time[0]:.3f}s(compile mode)\")\n",
    "\n",
    "speedup = np.median(eager_time) / np.median(compile_time)\n",
    "print(f\"eager median: {np.median(eager_time)}, compile median: {np.median(compile_time)}, speedup: {speedup}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also tried `torch.compile` in [fast_training_tutorial.ipynb](https://github.com/Project-MONAI/tutorials/blob/main/acceleration/fast_training_tutorial.ipynb).\n",
    "The total training time for fast and compile is as follows: 354.9534s and 305.6460s, speedup: 1.16x.\n",
    "\n",
    "![compile_benchmark_total_epoch_time_comparison](../figures/total_epoch_time_comparison-compile.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the `torch.compile` in the bundle\n",
    "\n",
    "We can simply set `compile=True` in the `SupervisedTrainer` and `SupervisedEvaluator`. Here we convert data to `torch.Tensor` internally if set `compile=True`. Here is the [ticket](https://github.com/pytorch/pytorch/issues/117026) we can track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = monai.losses.DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "trainer = SupervisedTrainer(\n",
    "    device=device,\n",
    "    max_epochs=epoch_num,\n",
    "    train_data_loader=data_loader,\n",
    "    network=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    # postprocessing=post_transform,\n",
    "    # amp=args.amp,\n",
    "    # key_train_metric={\n",
    "    #     \"train_dice\": MeanDice(\n",
    "    #         include_background=False,\n",
    "    #         output_transform=from_engine([\"pred\", \"label\"]),\n",
    "    #     )\n",
    "    # },\n",
    "    compile=True,\n",
    "    # you can also add `compile_kwargs` dict of the args for `torch.compile()` API\n",
    "    compile_kwargs={},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
