{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MONAI Auto3DSeg Hyper-parameter Optimization with Optuna\n",
    "\n",
    "This notebook provides an example to perform hype-parameter optimization(HPO) on learning rate with grid search method for hippocampus segmentation using Optuna.\n",
    "\n",
    "Note: if you have used other notebooks under `auto3dseg`, for examples: \n",
    "- `auto_runner.ipynb`\n",
    "- `auto3dseg_autorunner_ref_api.ipynb`\n",
    "- `auto3dseg_hello_world.ipynb`\n",
    "- `hpo_nni.ipynb`\n",
    "\n",
    "You may have already generated the algorithm templates in MONAI bundle formats (hint: find them in the working directory). \n",
    "\n",
    "Please feel free to skip step 1-5 if the bundles are already generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries for HPO and pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import optuna\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.apps.auto3dseg import BundleGen, DataAnalyzer, OptunaGen\n",
    "from monai.apps.auto3dseg.utils import export_bundle_algo_history, import_bundle_algo_history\n",
    "from monai.bundle.config_parser import ConfigParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define experiment file pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset pathes\n",
    "data_root = str(Path(\".\"))\n",
    "msd_task = \"Task04_Hippocampus\"\n",
    "dataroot = os.path.join(data_root, msd_task)\n",
    "\n",
    "# User created files\n",
    "datalist_file = os.path.join(\"..\", \"tasks\", \"msd\", msd_task, \"msd_\" + msd_task.lower() + \"_folds.json\")\n",
    "input_yaml = './input.yaml'\n",
    "\n",
    "# Experiment setup\n",
    "test_path = \"./\"\n",
    "work_dir = os.path.join(test_path, \"hpo_optuna_work_dir\")\n",
    "optuna_dir = './optuna_learningrate_grid'\n",
    "da_output_yaml = os.path.join(work_dir, \"datastats.yaml\")\n",
    "if not os.path.isdir(work_dir):\n",
    "    os.makedirs(work_dir)\n",
    "\n",
    "# Algorithm selected to do HPO. Refer to bundle history for the mapping between\n",
    "# algorithm name and index\n",
    "selected_algorithm_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download one of MSD datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/\" + msd_task + \".tar\"\n",
    "compressed_file = os.path.join(data_root, msd_task + \".tar\")\n",
    "if not os.path.exists(dataroot):\n",
    "    os.makedirs(dataroot)\n",
    "    download_and_extract(resource, compressed_file, data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate input yaml and datafolds yaml. (User should generate their own)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {\n",
    "    \"name\": msd_task,\n",
    "    \"task\": \"segmentation\",\n",
    "    \"modality\": \"MRI\",\n",
    "    \"datalist\": datalist_file,\n",
    "    \"dataroot\": dataroot,\n",
    "    \"multigpu\": True,\n",
    "    \"class_names\": [\"val_acc_pz\", \"val_acc_tz\"]\n",
    "}\n",
    "\n",
    "with open(input_yaml, 'w') as f:\n",
    "    yaml.dump(input_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Bundle Generators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 79.05it/s]\n",
      "algo_templates.tar.gz: 296kB [00:01, 164kB/s]                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-18 08:43:01,671 - INFO - Downloaded: /tmp/tmpapjtatl0/algo_templates.tar.gz\n",
      "2022-10-18 08:43:01,673 - INFO - Expected md5 is None, skip md5 check for file /tmp/tmpapjtatl0/algo_templates.tar.gz.\n",
      "2022-10-18 08:43:01,676 - INFO - Writing into directory: ./hpo_optuna_work_dir.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-18 08:43:01,997 - INFO - ./hpo_optuna_work_dir/segresnet2d_0\n",
      "2022-10-18 08:43:02,252 - INFO - ./hpo_optuna_work_dir/segresnet2d_1\n",
      "2022-10-18 08:43:02,622 - INFO - ./hpo_optuna_work_dir/segresnet2d_2\n",
      "2022-10-18 08:43:02,896 - INFO - ./hpo_optuna_work_dir/segresnet2d_3\n",
      "2022-10-18 08:43:03,165 - INFO - ./hpo_optuna_work_dir/segresnet2d_4\n",
      "2022-10-18 08:43:03,441 - INFO - ./hpo_optuna_work_dir/dints_0\n",
      "2022-10-18 08:43:03,819 - INFO - ./hpo_optuna_work_dir/dints_1\n",
      "2022-10-18 08:43:04,092 - INFO - ./hpo_optuna_work_dir/dints_2\n",
      "2022-10-18 08:43:04,375 - INFO - ./hpo_optuna_work_dir/dints_3\n",
      "2022-10-18 08:43:04,760 - INFO - ./hpo_optuna_work_dir/dints_4\n",
      "2022-10-18 08:43:05,023 - INFO - ./hpo_optuna_work_dir/swinunetr_0\n",
      "2022-10-18 08:43:05,293 - INFO - ./hpo_optuna_work_dir/swinunetr_1\n",
      "2022-10-18 08:43:05,559 - INFO - ./hpo_optuna_work_dir/swinunetr_2\n",
      "2022-10-18 08:43:05,913 - INFO - ./hpo_optuna_work_dir/swinunetr_3\n",
      "2022-10-18 08:43:06,167 - INFO - ./hpo_optuna_work_dir/swinunetr_4\n",
      "2022-10-18 08:43:06,450 - INFO - ./hpo_optuna_work_dir/segresnet_0\n",
      "2022-10-18 08:43:06,726 - INFO - ./hpo_optuna_work_dir/segresnet_1\n",
      "2022-10-18 08:43:07,140 - INFO - ./hpo_optuna_work_dir/segresnet_2\n",
      "2022-10-18 08:43:07,413 - INFO - ./hpo_optuna_work_dir/segresnet_3\n",
      "2022-10-18 08:43:07,693 - INFO - ./hpo_optuna_work_dir/segresnet_4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cfg = ConfigParser.load_config_file(input_yaml)\n",
    "\n",
    "# data analysis\n",
    "if not os.path.exists(da_output_yaml):\n",
    "    da = DataAnalyzer(datalist_file, dataroot, output_path=da_output_yaml)\n",
    "    da.get_all_case_stats()\n",
    "\n",
    "# algorithm generation\n",
    "bundle_generator = BundleGen(\n",
    "    algo_path=work_dir,\n",
    "    data_stats_filename=da_output_yaml,\n",
    "    data_src_cfg_name=input_yaml,\n",
    ")\n",
    "\n",
    "bundle_generator.generate(work_dir, num_fold=5)\n",
    "history = bundle_generator.get_history()\n",
    "export_bundle_algo_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Algo object from bundle_generator history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can get history from bundle_generator. It can also be acquired by reading bundles saved on disk\n",
    "\n",
    "history = bundle_generator.get_history()\n",
    "if len(history) == 0:\n",
    "    history = import_bundle_algo_history(work_dir, only_trained=False)\n",
    "\n",
    "algo_dict = history[selected_algorithm_index]\n",
    "algo_name = list(algo_dict.keys())[selected_algorithm_index]\n",
    "algo = algo_dict[algo_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"override_params\" is used to update algorithm hyperparameters \n",
    "# like num_epochs, which are not in the HPO search space. We set num_epochs=2\n",
    "# to shorten the training time as an example\n",
    "\n",
    "max_epochs = 2\n",
    "\n",
    "# safeguard to ensure max_epochs is greater or equal to 2\n",
    "max_epochs = max(max_epochs, 2)\n",
    "\n",
    "num_gpus = 1 if \"multigpu\" in input_dict and not input_dict[\"multigpu\"] else torch.cuda.device_count()\n",
    "\n",
    "num_epoch = max_epochs\n",
    "num_images_per_batch = 2\n",
    "n_data = 24  # total is 30 images, hold out one set (6 images) for cross fold val.\n",
    "n_iter = int(num_epoch * n_data / num_images_per_batch / num_gpus)\n",
    "n_iter_val = int(n_iter / 2)\n",
    "\n",
    "override_param = {\n",
    "    \"num_iterations\": n_iter,\n",
    "    \"num_iterations_per_validation\": n_iter_val,\n",
    "    \"num_images_per_batch\": num_images_per_batch,\n",
    "    \"num_epochs\": num_epoch,\n",
    "    \"num_warmup_iterations\": n_iter_val,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Optuna Generator class and overwrite get_hyperparameters() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-18 08:43:08,171 - INFO - ./hpo_optuna_work_dir/segresnet2d_0_override\n"
     ]
    }
   ],
   "source": [
    "class OptunaGenLearningRate(OptunaGen):\n",
    "    def get_hyperparameters(self):\n",
    "        return {'learning_rate': self.trial.suggest_float(\"learning_rate\", 0.00001, 0.1)}\n",
    "\n",
    "\n",
    "optuna_gen = OptunaGenLearningRate(algo=algo, params=override_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run Optuna optimization (with grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-18 08:43:08,301]\u001b[0m A new study created in memory with name: no-name-2c662b87-ae33-42e4-a7a2-6ec258d89b5a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-18 08:43:08,341 - INFO - ./optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.1\n",
      "2022-10-18 08:43:08,341 - INFO - Launching: torchrun --nnodes=1 --nproc_per_node=2 ./optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.1/scripts/train.py run --config_file='optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.1/configs/transforms_validate.yaml','optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.1/configs/transforms_train.yaml','optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.1/configs/transforms_infer.yaml','optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.1/configs/network.yaml','optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.1/configs/hyper_parameters.yaml' --learning_rate=0.1\n",
      "2022-10-18 08:43:19,047 - INFO - CompletedProcess(args=['torchrun', '--nnodes=1', '--nproc_per_node=2', './optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.1/scripts/train.py', 'run', \"--config_file='optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.1/configs/transforms_validate.yaml','optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.1/configs/transforms_train.yaml','optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.1/configs/transforms_infer.yaml','optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.1/configs/network.yaml','optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.1/configs/hyper_parameters.yaml'\", '--learning_rate=0.1'], returncode=0, stdout=b\"[info] number of GPUs: 2\n",
      "2022-10-18 08:43:11,691 - Added key: store_based_barrier_key:1 to store for rank: 1\n",
      "[info] number of GPUs: 2\n",
      "2022-10-18 08:43:11,825 - Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "2022-10-18 08:43:11,825 - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n",
      "[info] world_size: 2\n",
      "train_files: 12\n",
      "val_files: 3\n",
      "2022-10-18 08:43:11,834 - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n",
      "[info] world_size: 2\n",
      "train_files: 12\n",
      "val_files: 3\n",
      "num_epochs 2\n",
      "num_epochs_per_validation 1\n",
      "[info] training from scratch[info] training from scratch\n",
      "\n",
      "[info] amp enabled\n",
      "----------\n",
      "epoch 1/2\n",
      "learning rate is set to 0.1\n",
      "[2022-10-18 08:43:14] 1/6, train_loss: 1.0068\n",
      "2022-10-18 08:43:14,298 - Reducer buckets have been rebuilt in this iteration.\n",
      "2022-10-18 08:43:14,298 - Reducer buckets have been rebuilt in this iteration.\n",
      "[2022-10-18 08:43:14] 2/6, train_loss: 0.8218\n",
      "[2022-10-18 08:43:14] 3/6, train_loss: 0.7328\n",
      "[2022-10-18 08:43:14] 4/6, train_loss: 0.7411\n",
      "[2022-10-18 08:43:14] 5/6, train_loss: 0.6738\n",
      "[2022-10-18 08:43:14] 6/6, train_loss: 0.7053\n",
      "epoch 1 average loss: 0.8018, best mean dice: -1.0000 at epoch -1\n",
      "1 / 3 tensor([[0., 0.]], device='cuda:1')\n",
      "1 / 3 tensor([[0., 0.]], device='cuda:0')\n",
      "2 / 3 tensor([[0., 0.]], device='cuda:1')\n",
      "2 / 3 tensor([[0., 0.]], device='cuda:0')\n",
      "3 / 3 tensor([[0., 0.]], device='cuda:1')\n",
      "3 / 3 tensor([[0., 0.]], device='cuda:0')\n",
      "evaluation metric - class 1: 0.0\n",
      "evaluation metric - class 2: 0.0\n",
      "avg_metric 0.0\n",
      "saved new best metric model\n",
      "current epoch: 1 current mean dice: 0.0000 best mean dice: 0.0000 at epoch 1\n",
      "----------\n",
      "epoch 2/2\n",
      "learning rate is set to 0.0125\n",
      "[2022-10-18 08:43:16] 1/6, train_loss: 0.6629\n",
      "[2022-10-18 08:43:16] 2/6, train_loss: 0.7294\n",
      "[2022-10-18 08:43:16] 3/6, train_loss: 0.6376\n",
      "[2022-10-18 08:43:16] 4/6, train_loss: 0.6884\n",
      "[2022-10-18 08:43:16] 5/6, train_loss: 0.6723\n",
      "[2022-10-18 08:43:16] 6/6, train_loss: 0.6182\n",
      "epoch 2 average loss: 0.6574, best mean dice: 0.0000 at epoch 1\n",
      "1 / 3 tensor([[0., 0.]], device='cuda:1')\n",
      "1 / 3 tensor([[0., 0.]], device='cuda:0')\n",
      "2 / 3 tensor([[0., 0.]], device='cuda:1')\n",
      "2 / 3 tensor([[0., 0.]], device='cuda:0')\n",
      "3 / 3 tensor([[0., 0.]], device='cuda:1')\n",
      "3 / 3 tensor([[0., 0.]], device='cuda:0')\n",
      "evaluation metric - class 1: 0.0\n",
      "evaluation metric - class 2: 0.0\n",
      "avg_metric 0.0\n",
      "current epoch: 2 current mean dice: 0.0000 best mean dice: 0.0000 at epoch 1\n",
      "train completed, best_metric: 0.0000 at epoch: 1\n",
      "0.0\n",
      "-1\n",
      "\", stderr=b'WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "is_namedtuple is deprecated, please use the python checks instead\n",
      "is_namedtuple is deprecated, please use the python checks instead\n",
      "')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-18 08:43:19,053]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'learning_rate': 0.1}. Best is trial 0 with value: 0.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-18 08:43:19,079 - INFO - ./optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.001\n",
      "2022-10-18 08:43:19,079 - INFO - Launching: torchrun --nnodes=1 --nproc_per_node=2 ./optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.001/scripts/train.py run --config_file='optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.001/configs/transforms_validate.yaml','optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.001/configs/transforms_train.yaml','optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.001/configs/transforms_infer.yaml','optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.001/configs/network.yaml','optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.001/configs/hyper_parameters.yaml' --learning_rate=0.001\n",
      "2022-10-18 08:43:29,806 - INFO - CompletedProcess(args=['torchrun', '--nnodes=1', '--nproc_per_node=2', './optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.001/scripts/train.py', 'run', \"--config_file='optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.001/configs/transforms_validate.yaml','optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.001/configs/transforms_train.yaml','optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.001/configs/transforms_infer.yaml','optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.001/configs/network.yaml','optuna_learningrate_grid/segresnet2d_0_override_learning_rate_0.001/configs/hyper_parameters.yaml'\", '--learning_rate=0.001'], returncode=0, stdout=b\"[info] number of GPUs: 2\n",
      "[info] number of GPUs: 2\n",
      "2022-10-18 08:43:22,501 - Added key: store_based_barrier_key:1 to store for rank: 1\n",
      "2022-10-18 08:43:22,501 - Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "2022-10-18 08:43:22,501 - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n",
      "2022-10-18 08:43:22,501 - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n",
      "[info] world_size: 2\n",
      "[info] world_size: 2\n",
      "train_files:train_files:  1212\n",
      "\n",
      "val_files: val_files:3\n",
      " 3\n",
      "num_epochs 2\n",
      "num_epochs_per_validation 1\n",
      "[info] training from scratch\n",
      "[info] amp enabled\n",
      "[info] training from scratch\n",
      "----------\n",
      "epoch 1/2\n",
      "learning rate is set to 0.001\n",
      "[2022-10-18 08:43:24] 1/6, train_loss: 0.8798\n",
      "2022-10-18 08:43:24,374 - Reducer buckets have been rebuilt in this iteration.\n",
      "2022-10-18 08:43:24,458 - Reducer buckets have been rebuilt in this iteration.\n",
      "[2022-10-18 08:43:24] 2/6, train_loss: 0.9273\n",
      "[2022-10-18 08:43:24] 3/6, train_loss: 0.8508\n",
      "[2022-10-18 08:43:24] 4/6, train_loss: 0.7524\n",
      "[2022-10-18 08:43:24] 5/6, train_loss: 1.0487\n",
      "[2022-10-18 08:43:24] 6/6, train_loss: 0.8540\n",
      "epoch 1 average loss: 0.8866, best mean dice: -1.0000 at epoch -1\n",
      "1 / 3 tensor([[0.0344, 0.0453]], device='cuda:1')\n",
      "1 / 3 tensor([[0.0226, 0.0548]], device='cuda:0')\n",
      "2 / 3 tensor([[0.0288, 0.0440]], device='cuda:1')\n",
      "2 / 3 tensor([[0.0297, 0.0363]], device='cuda:0')\n",
      "3 / 3 tensor([[0.0335, 0.0560]], device='cuda:1')\n",
      "3 / 3 tensor([[0.0175, 0.0511]], device='cuda:0')\n",
      "evaluation metric - class 1: 0.027750035127003986\n",
      "evaluation metric - class 2: 0.0479105810324351\n",
      "avg_metric 0.03783030807971954\n",
      "saved new best metric model\n",
      "current epoch: 1 current mean dice: 0.0378 best mean dice: 0.0378 at epoch 1\n",
      "----------\n",
      "epoch 2/2\n",
      "learning rate is set to 0.000125\n",
      "[2022-10-18 08:43:26] 1/6, train_loss: 0.9405\n",
      "[2022-10-18 08:43:26] 2/6, train_loss: 0.8476\n",
      "[2022-10-18 08:43:26] 3/6, train_loss: 0.8416\n",
      "[2022-10-18 08:43:26] 4/6, train_loss: 0.8531\n",
      "[2022-10-18 08:43:26] 5/6, train_loss: 0.8536\n",
      "[2022-10-18 08:43:26] 6/6, train_loss: 0.8033\n",
      "epoch 2 average loss: 0.8692, best mean dice: 0.0378 at epoch 1\n",
      "1 / 3 tensor([[0.0355, 0.0456]], device='cuda:1')\n",
      "1 / 3 tensor([[0.0217, 0.0551]], device='cuda:0')\n",
      "2 / 3 tensor([[0.0291, 0.0444]], device='cuda:1')\n",
      "2 / 3 tensor([[0.0299, 0.0364]], device='cuda:0')\n",
      "3 / 3 tensor([[0.0331, 0.0563]], device='cuda:1')\n",
      "3 / 3 tensor([[0.0174, 0.0515]], device='cuda:0')\n",
      "evaluation metric - class 1: 0.027793101966381073\n",
      "evaluation metric - class 2: 0.048210546374320984\n",
      "avg_metric 0.03800182417035103\n",
      "saved new best metric model\n",
      "current epoch: 2 current mean dice: 0.0380 best mean dice: 0.0380 at epoch 2\n",
      "train completed, best_metric: 0.0380 at epoch: 2\n",
      "0.03800182417035103\n",
      "-1\n",
      "\", stderr=b'WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "is_namedtuple is deprecated, please use the python checks instead\n",
      "is_namedtuple is deprecated, please use the python checks instead\n",
      "')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-18 08:43:29,812]\u001b[0m Trial 1 finished with value: 0.03800182417035103 and parameters: {'learning_rate': 0.001}. Best is trial 1 with value: 0.03800182417035103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value: 0.03800182417035103 (params: {'learning_rate': 0.001})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_space = {'learning_rate': [0.0001, 0.001, 0.01, 0.1]}\n",
    "study = optuna.create_study(sampler=optuna.samplers.GridSampler(search_space), direction='maximize')\n",
    "study.optimize(partial(optuna_gen, obj_filename=optuna_gen.get_obj_filename(), output_folder=optuna_dir), n_trials=2)\n",
    "print(\"Best value: {} (params: {})\\n\".format(study.best_value, study.best_params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
