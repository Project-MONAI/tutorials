{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) MONAI Consortium  \n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  \n",
    "you may not use this file except in compliance with the License.  \n",
    "You may obtain a copy of the License at  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;http://www.apache.org/licenses/LICENSE-2.0  \n",
    "Unless required by applicable law or agreed to in writing, software  \n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,  \n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \n",
    "See the License for the specific language governing permissions and  \n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From 3D Segmentation to Immersive Visualization: A Complete Workflow for Mesh Conversion, USD Export, and NVIDIA Omniverse Integration\n",
    "In this tutorial, weâ€™ll cover:\n",
    "\n",
    "- Utilizing 3D Segmentation Results: How to extract and prepare segmentation data from VISTA-3D or MAISI for mesh conversion.\n",
    "- Converting to Mesh Format: Step-by-step instructions on transforming segmentation results into mesh models.\n",
    "- Exporting to USD: A guide to exporting meshes as Universal Scene Description (USD) files, optimized for Omniverse workflows.\n",
    "- Visualizing in NVIDIA Omniverse: Instructions on importing USD files into Omniverse for high-quality 3D visualization and manipulation.\n",
    "This end-to-end process enables efficient, high-quality visualization in NVIDIA Omniverse from raw segmentation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel]\"\n",
    "!apt update\n",
    "!apt install -y libgl1-mesa-glx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data directory\n",
    "\n",
    "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.  \n",
    "This allows you to save results and reuse downloads.  \n",
    "If not specified a temporary directory will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Data\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "if directory is not None:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic data from MAISI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-13 08:00:17,717 - INFO - --- input summary of monai.bundle.scripts.download ---\n",
      "2024-11-13 08:00:17,721 - INFO - > name: 'maisi_ct_generative'\n",
      "2024-11-13 08:00:17,723 - INFO - > bundle_dir: '/workspace/Data'\n",
      "2024-11-13 08:00:17,725 - INFO - > source: 'monaihosting'\n",
      "2024-11-13 08:00:17,727 - INFO - > remove_prefix: 'monai_'\n",
      "2024-11-13 08:00:17,728 - INFO - > progress: True\n",
      "2024-11-13 08:00:17,729 - INFO - ---\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "maisi_ct_generative_v0.4.5.zip: 13.0GB [09:43, 23.8MB/s]                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-13 08:10:07,983 - INFO - Downloaded: /workspace/Data/maisi_ct_generative_v0.4.5.zip\n",
      "2024-11-13 08:10:07,984 - INFO - Expected md5 is None, skip md5 check for file /workspace/Data/maisi_ct_generative_v0.4.5.zip.\n",
      "2024-11-13 08:10:07,984 - INFO - Writing into directory: /workspace/Data.\n"
     ]
    }
   ],
   "source": [
    "from monai.bundle import download\n",
    "\n",
    "download(name=\"maisi_ct_generative\", bundle_dir=root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.bundle.scripts import create_workflow\n",
    "\n",
    "bundle_root = os.path.join(root_dir, \"maisi_ct_generative\")\n",
    "workflow = create_workflow(config_file=os.path.join(bundle_root,\"configs/inference.json\"), workflow_type=\"inference\", bundle_root=bundle_root)\n",
    "workflow.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJ file saved to /workspace/Data/maisi_ct_generative/datasets/glTF/maisi/IntegrationTest-AbdomenCT/output_file.obj\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from skimage import measure\n",
    "\n",
    "input_nii_path = \"/workspace/Data/maisi_ct_generative/datasets/IntegrationTest-AbdomenCT.nii.gz\"\n",
    "def nii_to_obj(input_nii_path, output_obj_path):\n",
    "    # Load the NIfTI file\n",
    "    nii_img = nib.load(input_nii_path)\n",
    "    nii_data = nii_img.get_fdata()\n",
    "\n",
    "    # Threshold the NIfTI data to create a binary mask (assumes non-zero values are the object)\n",
    "    threshold = 0.5  # Adjust threshold as necessary\n",
    "    binary_mask = nii_data > threshold\n",
    "\n",
    "    # Find the vertices and faces of the surface mesh using marching cubes\n",
    "    verts, faces, _, _ = measure.marching_cubes(binary_mask, level=0)\n",
    "\n",
    "    # Create a Trimesh object\n",
    "    mesh = trimesh.Trimesh(vertices=verts, faces=faces)\n",
    "\n",
    "    # Export the mesh to an OBJ file\n",
    "    mesh.export(output_obj_path)\n",
    "    print(f\"OBJ file saved to {output_obj_path}\")\n",
    "\n",
    "# Example usage\n",
    "output_obj_path = '/workspace/Data/maisi_ct_generative/datasets/glTF/maisi/IntegrationTest-AbdomenCT/output_file.obj'  # Replace with the desired output path\n",
    "nii_to_obj(input_nii_path, output_obj_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from skimage import measure\n",
    "def save_obj_file(data, output_obj_file):\n",
    "    # Step 2: Generate a mesh using the marching cubes algorithm\n",
    "    # iso_value = np.mean(data)  # Adjust this value based on your data\n",
    "    vertices, faces, normals, values = measure.marching_cubes(\n",
    "        volume=data\n",
    "    )\n",
    "\n",
    "    # Step 3: Create a Trimesh mesh\n",
    "    mesh = trimesh.Trimesh(\n",
    "        vertices=vertices, faces=faces, vertex_normals=normals\n",
    "    )\n",
    "\n",
    "    # Step 4: Define and assign material properties\n",
    "    material = trimesh.visual.material.SimpleMaterial(\n",
    "        name='SurfaceMaterial',\n",
    "        ambient=[1.0, 0.0, 0.0],   # Red ambient color\n",
    "        diffuse=[1.0, 0.0, 0.0],   # Red diffuse color\n",
    "        specular=[1.0, 1.0, 1.0],  # White specular color\n",
    "        specular_weight=0.5\n",
    "    )\n",
    "    mesh.visual.material = material\n",
    "\n",
    "    mesh.export(output_obj_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for file: IntegrationTest-AbdomenCT\n",
      "Merging labels ...\n",
      "Assigning index 1 to label Liver\n",
      "2024-11-18 06:31:49,659 INFO image_writer.py:197 - writing: /workspace/Data/maisi_ct_generative/datasets/monai/Liver.nrrd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:`mesh.smoothed()` is deprecated and will be removed in March 2024: use `mesh.smooth_shaded` or `trimesh.graph.smooth_shade(mesh)`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<trimesh.Trimesh(vertices.shape=(203432, 3), faces.shape=(411228, 3))>\n",
      "after smooth <trimesh.Trimesh(vertices.shape=(787030, 3), faces.shape=(411228, 3))>\n",
      "2024-11-18 06:31:57,288 INFO image_writer.py:197 - writing: /workspace/Data/maisi_ct_generative/datasets/monai/all_organs.nrrd\n",
      "Saved whole segmentation IntegrationTest-AbdomenCT.nrrd\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from monai.transforms import LoadImage, SaveImage\n",
    "import glob\n",
    "import os\n",
    "import nrrd\n",
    "# from OpenAnatomyExport import OpenAnatomyExportLogic\n",
    "path_to_maisi_preds = \"/workspace/Data/maisi_ct_generative/datasets/\"\n",
    "path_to_obj_gltfs = \"/workspace/Data/maisi_ct_generative/datasets/monai/\"\n",
    "\n",
    "all_preds = glob.glob(os.path.join(path_to_maisi_preds, \"*.nii.gz\"))\n",
    "color_map = {\n",
    "    1: [1.0, 0.0, 0.0],\n",
    "    2: [0.0, 1.0, 0.0],\n",
    "    3: [0.0, 0.0, 1.0],\n",
    "    4: [1.0, 1.0, 0.0],\n",
    "    5: [1.0, 0.0, 1.0],\n",
    "    6: [0.0, 1.0, 1.0],\n",
    "    7: [1.0, 0.5, 0.0],\n",
    "    8: [0.5, 0.0, 1.0],\n",
    "    9: [0.0, 0.5, 1.0],\n",
    "    10: [0.5, 1.0, 0.0],\n",
    "    11: [1.0, 0.0, 0.5],\n",
    "    12: [0.0, 1.0, 0.5],\n",
    "    13: [0.5, 0.5, 0.0],\n",
    "    14: [0.5, 0.0, 0.5],\n",
    "    15: [0.0, 0.5, 0.5],\n",
    "    16: [0.75, 0.75, 0.75],\n",
    "    17: [0.25, 0.25, 0.25],\n",
    "}\n",
    "\n",
    "# 17 groupings that cover 101 segments/regions out of 140\n",
    "labels = {\n",
    "            \"Liver\": 1,\n",
    "            \"Spleen\": 3,\n",
    "            \"Pancreas\": 4,\n",
    "            \"Heart\": 115,\n",
    "            \"Body\": 200,\n",
    "            \"Gallbladder\": 10,\n",
    "            \"Stomach\": 12,\n",
    "            \"Small_bowel\": 19,\n",
    "            \"Colon\": 62,\n",
    "            \"Kidney\": {\"right_kidney\": 5,\n",
    "                       \"left_kidney\": 14\n",
    "                       },\n",
    "            \"Veins\": {\"aorta\": 6,\n",
    "                      \"inferior_vena_cava\": 7,\n",
    "                      \"portal_vein_and_splenic_vein\": 17,\n",
    "                      \"left_iliac_artery\": 58,\n",
    "                      \"right_iliac_artery\": 59,\n",
    "                      \"left_iliac_vena\": 60,\n",
    "                      \"right_iliac_vena\": 61,\n",
    "                      \"pulmonary_vein\": 119,\n",
    "                      \"left_subclavian_artery\": 123,\n",
    "                      \"right_subclavian_artery\": 124,\n",
    "                      \"superior_vena_cava\": 125,\n",
    "                      \"brachiocephalic_trunk\": 109,\n",
    "                      \"left_brachiocephalic_vein\": 110,\n",
    "                      \"right_brachiocephalic_vein\": 111,\n",
    "                      \"left_common_carotid_artery\": 112,\n",
    "                      \"right_common_carotid_artery\": 113,\n",
    "                      },\n",
    "            \"Lungs\": {\"left_lung_upper_lobe\": 28,\n",
    "                      \"left_lung_lower_lobe\": 29,\n",
    "                      \"right_lung_upper_lobe\": 30,\n",
    "                      \"right_lung_middle_lobe\": 31,\n",
    "                      \"right_lung_lower_lobe\": 32\n",
    "                      },\n",
    "            \"Spine\": {\n",
    "                    \"vertebrae_L6\": 131,\n",
    "                    \"vertebrae_L5\": 33,\n",
    "                    \"vertebrae_L4\": 34,\n",
    "                    \"vertebrae_L3\": 35,\n",
    "                    \"vertebrae_L2\": 36,\n",
    "                    \"vertebrae_L1\": 37,\n",
    "                    \"vertebrae_T12\": 38,\n",
    "                    \"vertebrae_T11\": 39,\n",
    "                    \"vertebrae_T10\": 40,\n",
    "                    \"vertebrae_T9\": 41,\n",
    "                    \"vertebrae_T8\": 42,\n",
    "                    \"vertebrae_T7\": 43,\n",
    "                    \"vertebrae_T6\": 44,\n",
    "                    \"vertebrae_T5\": 45,\n",
    "                    \"vertebrae_T4\": 46,\n",
    "                    \"vertebrae_T3\": 47,\n",
    "                    \"vertebrae_T2\": 48,\n",
    "                    \"vertebrae_T1\": 49,\n",
    "                    \"vertebrae_C7\": 50,\n",
    "                    \"vertebrae_C6\": 51,\n",
    "                    \"vertebrae_C5\": 52,\n",
    "                    \"vertebrae_C4\": 53,\n",
    "                    \"vertebrae_C3\": 54,\n",
    "                    \"vertebrae_C2\": 55,\n",
    "                    \"vertebrae_C1\": 56,\n",
    "                    \"sacrum\": 97,\n",
    "                    \"vertebrae_S1\": 127,\n",
    "                    },\n",
    "            \"Ribs\": {\n",
    "                    \"left_rib_1\": 63,\n",
    "                    \"left_rib_2\": 64,\n",
    "                    \"left_rib_3\": 65,\n",
    "                    \"left_rib_4\": 66,\n",
    "                    \"left_rib_5\": 67,\n",
    "                    \"left_rib_6\": 68,\n",
    "                    \"left_rib_7\": 69,\n",
    "                    \"left_rib_8\": 70,\n",
    "                    \"left_rib_9\": 71,\n",
    "                    \"left_rib_10\": 72,\n",
    "                    \"left_rib_11\": 73,\n",
    "                    \"left_rib_12\": 74,\n",
    "                    \"right_rib_1\": 75,\n",
    "                    \"right_rib_2\": 76,\n",
    "                    \"right_rib_3\": 77,\n",
    "                    \"right_rib_4\": 78,\n",
    "                    \"right_rib_5\": 79,\n",
    "                    \"right_rib_6\": 80,\n",
    "                    \"right_rib_7\": 81,\n",
    "                    \"right_rib_8\": 82,\n",
    "                    \"right_rib_9\": 83,\n",
    "                    \"right_rib_10\": 84,\n",
    "                    \"right_rib_11\": 85,\n",
    "                    \"right_rib_12\": 86,\n",
    "                    \"costal_cartilages\": 114,\n",
    "                    \"sternum\": 122,\n",
    "                    },\n",
    "            \"Shoulders\": {\n",
    "                        \"left_scapula\": 89,\n",
    "                        \"right_scapula\": 90,\n",
    "                        \"left_clavicula\": 91,\n",
    "                        \"right_clavicula\": 92\n",
    "            },\n",
    "            \"Hips\": {\n",
    "                    \"left_hip\": 95,\n",
    "                    \"right_hip\": 96\n",
    "                    },\n",
    "            \"Back_muscles\": {\n",
    "                            \"left_gluteus_maximus\": 98,\n",
    "                            \"right_gluteus_maximus\": 99,\n",
    "                            \"left_gluteus_medius\": 100,\n",
    "                            \"right_gluteus_medius\": 101,\n",
    "                            \"left_gluteus_minimus\": 102,\n",
    "                            \"right_gluteus_minimus\": 103,\n",
    "                            \"left_autochthon\": 104,\n",
    "                            \"right_autochthon\": 105,\n",
    "                            \"left_iliopsoas\": 106,\n",
    "                            \"right_iliopsoas\": 107\n",
    "                            }\n",
    "}\n",
    "\n",
    "for pred in all_preds:\n",
    "    filename = os.path.basename(pred).split('.')[0]\n",
    "    path_filename = os.path.join(path_to_maisi_preds, filename) # for NRRD files\n",
    "    obj_gltf_path = os.path.join(path_to_obj_gltfs, filename) # for independent OBJ files\n",
    "    if not os.path.exists(path_filename):\n",
    "        os.makedirs(path_filename)\n",
    "\n",
    "    if not os.path.exists(obj_gltf_path):\n",
    "        os.makedirs(obj_gltf_path)\n",
    "    print(f\"Running for file: {filename}\")\n",
    "\n",
    "    orig_seg = LoadImage()(pred)\n",
    "\n",
    "    final_seg = np.zeros_like(orig_seg, dtype=np.uint8)\n",
    "    organ_np = np.zeros_like(orig_seg, dtype=np.uint8)\n",
    "\n",
    "    print(\"Merging labels ...\")\n",
    "\n",
    "    save_trans = SaveImage(path_filename, output_ext=\"nrrd\", output_dtype=np.uint8)\n",
    "    save_trans.set_options(write_kwargs = {\"compression\":True})\n",
    "    labels_dict = dict()\n",
    "    meshes = []\n",
    "    scene = trimesh.Scene()\n",
    "    for j, (organ_name, labelVal) in enumerate(labels.items(), start=1):\n",
    "        print(f\"Assigning index {j} to label {organ_name}\")\n",
    "        if isinstance(labelVal, dict):\n",
    "            for _, i in labelVal.items():\n",
    "                final_seg[orig_seg == i] = j\n",
    "                organ_np[orig_seg == i] = j\n",
    "        else:\n",
    "            final_seg[orig_seg == labelVal] = j\n",
    "            organ_np[orig_seg == labelVal] = j\n",
    "        save_trans(organ_np[None], filename=f\"{path_to_maisi_preds}monai/{organ_name}\")\n",
    "    \n",
    "        try:\n",
    "            verts, faces, norms, vals = measure.marching_cubes(organ_np, level=j-1)\n",
    "        except:\n",
    "            print(f\"Error in marching cubes for {organ_name}\")\n",
    "            continue    \n",
    "        # create mesh\n",
    "        mesh = trimesh.Trimesh(vertices=verts, faces=faces, vertex_normals=norms)\n",
    "        print(mesh)\n",
    "        mesh = mesh.smoothed(filter='laplacian', iterations=10, lamb=0.5)\n",
    "        print('after smooth', mesh)\n",
    "        color = color_map.get(j, [1.0, 1.0, 1.0])\n",
    "        material = trimesh.visual.material.SimpleMaterial(\n",
    "            name=organ_name,\n",
    "            diffuse=color,\n",
    "            ambient=color,\n",
    "            specular=[1.0, 1.0, 1.0],\n",
    "            specular_weight=0.5\n",
    "        )\n",
    "        \n",
    "        mesh.visual.material = material\n",
    "        \n",
    "        scene.add_geometry(mesh, geom_name=organ_name)\n",
    "        break\n",
    "\n",
    "    save_trans(final_seg[None], meta_data=orig_seg.meta, filename=f\"{path_to_maisi_preds}monai/all_organs\")\n",
    "    # save_obj_file(final_seg, os.path.join(obj_gltf_path, f\"all_organs.obj\"))\n",
    "    scene.export(os.path.join(obj_gltf_path, f\"all_organs.obj\"))\n",
    "    print(f\"Saved whole segmentation {filename}.nrrd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh successfully exported to segmentation_model_new-03-09.obj\n"
     ]
    }
   ],
   "source": [
    "import vtk\n",
    "import os\n",
    "\n",
    "# Function to perform segmentation-to-mesh conversion and smoothing\n",
    "def convert_segmentation_to_mesh(segmentation_path, output_folder, filename, smoothing_factor=0.5):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Step 1: Load segmentation (binary labelmap, e.g., NRRD file)\n",
    "    reader = vtk.vtkNrrdReader()\n",
    "    reader.SetFileName(segmentation_path)\n",
    "    reader.Update()\n",
    "\n",
    "    # Step 2: Create Closed Surface Representation using vtkDiscreteFlyingEdges3D\n",
    "    flying_edges = vtk.vtkDiscreteFlyingEdges3D()\n",
    "    flying_edges.SetInputConnection(reader.GetOutputPort())\n",
    "    flying_edges.ComputeGradientsOff()\n",
    "    flying_edges.ComputeNormalsOff()\n",
    "    flying_edges.SetValue(0, 1)  # Assuming label 1 for segmentation surface\n",
    "    flying_edges.Update()\n",
    "\n",
    "    decimation_filter = vtk.vtkDecimatePro()\n",
    "    decimation_filter.SetInputConnection(flying_edges.GetOutputPort())\n",
    "    decimation_filter.SetFeatureAngle(60)\n",
    "    decimation_filter.SplittingOff()\n",
    "    decimation_filter.PreserveTopologyOn()\n",
    "    decimation_filter.SetMaximumError(1)\n",
    "    decimation_filter.SetTargetReduction(0.9)  # Adjust reduction level (0.0 to 1.0)\n",
    "    decimation_filter.Update()\n",
    "\n",
    "    # Step 3: Smooth the resulting mesh\n",
    "    smoothing_filter = vtk.vtkWindowedSincPolyDataFilter()\n",
    "    numberOfIterations = int(20 + smoothing_factor * 40)\n",
    "    passBand = pow(10.0, -4.0 * smoothing_factor)\n",
    "    smoothing_filter.SetInputConnection(decimation_filter.GetOutputPort())\n",
    "    smoothing_filter.SetNumberOfIterations(numberOfIterations)  # Smooth iterations\n",
    "    smoothing_filter.SetPassBand(passBand)  # Smoothing passband\n",
    "    smoothing_filter.FeatureEdgeSmoothingOff()\n",
    "    smoothing_filter.NonManifoldSmoothingOn()\n",
    "    smoothing_filter.NormalizeCoordinatesOn()\n",
    "    smoothing_filter.Update()\n",
    "\n",
    "    # Step 4: Generate normals for better shading\n",
    "    normals_filter = vtk.vtkPolyDataNormals()\n",
    "    normals_filter.SetInputConnection(smoothing_filter.GetOutputPort())\n",
    "    normals_filter.ConsistencyOn()\n",
    "    normals_filter.SplittingOff()\n",
    "    normals_filter.Update()\n",
    "\n",
    "    polydata = normals_filter.GetOutput()\n",
    "    # Step 5: Export the smoothed mesh to glTF\n",
    "    writer = vtk.vtkOBJWriter()\n",
    "    writer.SetFileName(os.path.join(output_folder, filename))\n",
    "    writer.SetInputData(polydata)  # Use the polydata object\n",
    "    writer.Write()\n",
    "\n",
    "    print(f\"Mesh successfully exported to {filename}\")\n",
    "\n",
    "# Input segmentation file (e.g., NRRD file path) and output folder\n",
    "seg_path = \"/workspace/Data/maisi_ct_generative/datasets/monai/Liver.nrrd\"\n",
    "output_folder = \"/workspace/Data/maisi_ct_generative/datasets/monai/\"\n",
    "filename = \"segmentation_model_new-03-09.obj\"\n",
    "# Perform conversion\n",
    "convert_segmentation_to_mesh(seg_path, output_folder, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pxr import Usd, UsdGeom, Gf, Sdf\n",
    "import sys\n",
    "\n",
    "def convert_obj_to_usd(obj_filename, usd_filename):\n",
    "    # Create a new USD stage\n",
    "    stage = Usd.Stage.CreateNew(usd_filename)\n",
    "\n",
    "    # Define a mesh at the root of the stage\n",
    "    mesh = UsdGeom.Mesh.Define(stage, '/RootMesh')\n",
    "\n",
    "    # Lists to hold OBJ data\n",
    "    vertices = []\n",
    "    normals = []\n",
    "    texcoords = []\n",
    "    face_vertex_indices = []\n",
    "    face_vertex_counts = []\n",
    "\n",
    "    # Mapping for OBJ indices (since they can be specified per face-vertex)\n",
    "    vertex_indices = []\n",
    "    normal_indices = []\n",
    "    texcoord_indices = []\n",
    "\n",
    "    # Read the OBJ file\n",
    "    with open(obj_filename, 'r') as obj_file:\n",
    "        for line in obj_file:\n",
    "            if line.startswith('v '):\n",
    "                # Vertex position\n",
    "                _, x, y, z = line.strip().split()\n",
    "                vertices.append((float(x), float(y), float(z)))\n",
    "            elif line.startswith('vn '):\n",
    "                # Vertex normal\n",
    "                _, nx, ny, nz = line.strip().split()\n",
    "                normals.append((float(nx), float(ny), float(nz)))\n",
    "            elif line.startswith('vt '):\n",
    "                # Texture coordinate\n",
    "                _, u, v = line.strip().split()\n",
    "                texcoords.append((float(u), float(v)))\n",
    "            elif line.startswith('f '):\n",
    "                # Face\n",
    "                face_elements = line.strip().split()[1:]\n",
    "                vertex_count = len(face_elements)\n",
    "                face_vertex_counts.append(vertex_count)\n",
    "                for elem in face_elements:\n",
    "                    indices = elem.split('/')\n",
    "                    # OBJ indices are 1-based; subtract 1 for 0-based indexing\n",
    "                    vi = int(indices[0]) - 1\n",
    "                    ti = int(indices[1]) - 1 if len(indices) > 1 and indices[1] else None\n",
    "                    ni = int(indices[2]) - 1 if len(indices) > 2 and indices[2] else None\n",
    "                    face_vertex_indices.append(vi)\n",
    "                    if ni is not None:\n",
    "                        normal_indices.append(ni)\n",
    "                    if ti is not None:\n",
    "                        texcoord_indices.append(ti)\n",
    "\n",
    "    # Set the mesh's points\n",
    "    mesh.CreatePointsAttr([Gf.Vec3f(*v) for v in vertices])\n",
    "\n",
    "    # Set the face vertex indices and counts\n",
    "    mesh.CreateFaceVertexIndicesAttr(face_vertex_indices)\n",
    "    mesh.CreateFaceVertexCountsAttr(face_vertex_counts)\n",
    "\n",
    "    # Optionally set normals if they exist\n",
    "    if normals and normal_indices:\n",
    "        # Reorder normals according to face vertices\n",
    "        ordered_normals = [normals[i] for i in normal_indices]\n",
    "        mesh.CreateNormalsAttr([Gf.Vec3f(*n) for n in ordered_normals])\n",
    "        mesh.SetNormalsInterpolation('faceVarying')  # Adjust based on how normals are specified\n",
    "\n",
    "    # Optionally set texture coordinates if they exist\n",
    "    if texcoords and texcoord_indices:\n",
    "        # Reorder texcoords according to face vertices\n",
    "        ordered_texcoords = [texcoords[i] for i in texcoord_indices]\n",
    "        stPrimvar = mesh.CreatePrimvar('st', Sdf.ValueTypeNames.TexCoord2fArray, UsdGeom.Tokens.faceVarying)\n",
    "        stPrimvar.Set([Gf.Vec2f(*tc) for tc in ordered_texcoords])\n",
    "\n",
    "    # Save the stage\n",
    "    stage.GetRootLayer().Save()\n",
    "\n",
    "obj_filename = \"/workspace/Data/maisi_ct_generative/datasets/monai/segmentation_model_new-03-09.obj\"\n",
    "usd_filename = \"/workspace/Data/maisi_ct_generative/datasets/monai/segmentation_model_new-03-09.obj.usda\"\n",
    "\n",
    "convert_obj_to_usd(obj_filename, usd_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import DisplayUSD\n",
    "\n",
    "usd_filename = \"/workspace/Data/maisi_ct_generative/datasets/monai/segmentation_model_new-03-09.obj.usda\"\n",
    "DisplayUSD(usd_filename, show_usd_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
