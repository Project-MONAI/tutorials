{"data_mtime": 1654704405, "dep_lines": [6, 19, 7, 8, 20, 21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "dep_prios": [10, 10, 5, 5, 5, 5, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 30, 30, 30, 30, 30, 30, 30, 30], "dependencies": ["torch", "re", "torch.nn", "torch.ao.quantization.observer", "abc", "typing", "builtins", "os", "warnings", "inspect", "contextlib", "threading", "pickle", "multiprocessing.reduction", "collections", "logging", "io", "functools", "time", "torch.nn.qat.dynamic", "torch.ao.nn", "torch.nn.functional", "torch.nn.intrinsic.quantized.dynamic", "torch.nn.intrinsic.quantized", "torch.nn.quantized", "enum", "torch.nn.quantized.dynamic", "torch.nn.qat", "torch.nn.intrinsic", "copy", "torch.nn.intrinsic.qat", "torch.nn.quantized._reference", "itertools", "torch._C", "torch._C._VariableFunctions", "torch._jit_internal", "torch._tensor", "torch.jit", "torch.jit._script", "torch.nn.modules", "torch.nn.modules.module"], "hash": "51ccdc479af3ab67fcf68a0815fda22fddc7979fb492ebb9ba039bccdfb736f5", "id": "torch.ao.quantization.fake_quantize", "ignore_all": true, "interface_hash": "d71703511e681a5b958e09a102bb1f3bc8491b3f62e6c08194667c188116a46c", "mtime": 1651551419, "options": {"allow_redefinition": false, "allow_untyped_globals": false, "always_false": [], "always_true": [], "bazel": false, "check_untyped_defs": false, "disallow_any_decorated": false, "disallow_any_explicit": false, "disallow_any_expr": false, "disallow_any_generics": false, "disallow_any_unimported": false, "disallow_incomplete_defs": false, "disallow_subclassing_any": false, "disallow_untyped_calls": false, "disallow_untyped_decorators": false, "disallow_untyped_defs": false, "follow_imports": "normal", "follow_imports_for_stubs": false, "ignore_errors": false, "ignore_missing_imports": false, "implicit_reexport": true, "local_partial_types": false, "mypyc": false, "no_implicit_optional": false, "platform": "linux", "plugins": [], "show_none_errors": true, "strict_concatenate": false, "strict_equality": false, "strict_optional": true, "strict_optional_whitelist": null, "warn_no_return": true, "warn_return_any": false, "warn_unreachable": false, "warn_unused_ignores": false}, "path": "/home/canz/.local/lib/python3.8/site-packages/torch/ao/quantization/fake_quantize.py", "plugin_data": null, "size": 20690, "suppressed": [], "version_id": "0.950"}