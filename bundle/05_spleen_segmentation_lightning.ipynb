{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e8ae3d7-3e2e-4755-a0b6-709ef4180719",
   "metadata": {},
   "source": [
    "Copyright (c) MONAI Consortium  \n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  \n",
    "you may not use this file except in compliance with the License.  \n",
    "You may obtain a copy of the License at  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;http://www.apache.org/licenses/LICENSE-2.0  \n",
    "Unless required by applicable law or agreed to in writing, software  \n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,  \n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \n",
    "See the License for the specific language governing permissions and  \n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191c5d77-8ae5-49ab-be22-45f5ba41641f",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "886952c4-0be4-459d-9c53-b81b29199c76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T15:11:33.216652778Z",
     "start_time": "2023-10-06T15:11:24.054035178Z"
    }
   },
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[ignite,pyyaml]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20e1274-0a27-4e37-95d7-fb813243c34c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T15:07:19.730871161Z",
     "start_time": "2023-10-06T15:07:11.317018521Z"
    }
   },
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1144d87-ec2f-4b9b-907a-16ea2da279c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T15:11:48.797015283Z",
     "start_time": "2023-10-06T15:11:42.300276550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.3.dev2340\n",
      "Numpy version: 1.26.0\n",
      "Pytorch version: 2.0.1+cu117\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 8d89083eeb8005babd7b5f76df83c1c80276cc10\n",
      "MONAI __file__: /home/<username>/miniconda3/envs/monai_tutorial/lib/python3.9/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.11\n",
      "ITK version: 5.3.0\n",
      "Nibabel version: 5.1.0\n",
      "scikit-image version: 0.21.0\n",
      "scipy version: 1.11.3\n",
      "Pillow version: 10.0.1\n",
      "Tensorboard version: 2.14.1\n",
      "gdown version: 4.7.1\n",
      "TorchVision version: 0.15.2+cu117\n",
      "tqdm version: 4.66.1\n",
      "lmdb version: 1.4.1\n",
      "psutil version: 5.9.0\n",
      "pandas version: 2.1.1\n",
      "einops version: 0.7.0\n",
      "transformers version: 4.21.3\n",
      "mlflow version: 2.7.1\n",
      "pynrrd version: 1.0.0\n",
      "clearml version: 1.13.1\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n"
     ]
    }
   ],
   "source": [
    "from monai.config import print_config\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c572d8b6-3dca-4487-80ad-928090b3e8ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T15:07:34.380130283Z",
     "start_time": "2023-10-06T15:07:34.330086596Z"
    }
   },
   "source": [
    "# Spleen Segmentation Lightning Bundle\n",
    "\n",
    "In this tutorial we'll describe how to create a bundle for a segmentation network. This will include how to train and apply the network on the command line. Medical  will be used as the dataset with the bundle based off the [Spleen 3D segmentation with MONAI](https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/spleen_segmentation_3d_lightning.ipynb) from Spleen segmentation using Task_09 subset from the Medical Segmentation Decathlon.\n",
    "\n",
    "This work is licensed under the Creative Commons Attribution-ShareAlike 4.0 International License. To view a copy of this license, visit http://creativecommons.org/licenses/by-sa/4.0/.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a18d5cd-6338-4b41-87fd-4e119723bfee",
   "metadata": {},
   "source": [
    "You can run this cell or save it to a file and run it on the command line. A `DenseNet` based network will be trained to classify MedNIST images into one of six categories. Mostly this script uses Ignite-based classes such as `SupervisedTrainer` which is great for converting into a bundle. Let's start by initialising a bundle directory structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb9dc6ec-13da-4a37-8afa-28e2766b9343",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T16:06:06.565667654Z",
     "start_time": "2023-10-02T16:05:58.393714835Z"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python -m monai.bundle init_bundle SpleenSegLightning\n",
    "which tree && tree SpleenSegLightning || true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5888c9bd-5022-40b5-9dec-84d9f737f868",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "\n",
    "We'll first replace the `metadata.json` file with our description of what the network will do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b29f053b-cf16-4ffc-bbe7-d9433fdfa872",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T13:44:00.353521550Z",
     "start_time": "2023-10-09T13:44:00.303104538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting SpleenSegLightning/configs/metadata.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile SpleenSegLightning/configs/metadata.json\n",
    "\n",
    "{\n",
    "    \"version\": \"0.0.1\",\n",
    "    \"changelog\": {\n",
    "        \"0.0.1\": \"Initial version\"\n",
    "    },\n",
    "    \"monai_version\": \"1.2.0\",\n",
    "    \"pytorch_version\": \"2.0.0\",\n",
    "    \"numpy_version\": \"1.23.5\",\n",
    "    \"optional_packages_version\": {},\n",
    "    \"name\": \"SpleenSegLightning\",\n",
    "    \"task\": \"3D Spleen segmentation network using MONAI and Pytorch Lightning\",\n",
    "    \"description\": \"This is a demo network for segmentation of the spleen from 3D MRI images.\",\n",
    "    \"authors\": \"Oeslle Lucena\",\n",
    "    \"copyright\": \"Copyright (c) Oeslle Lucena\",\n",
    "    \"data_source\": \"Task_09 subset from the Medical Segmentation Decathlon\",\n",
    "    \"data_type\": \"Nifti\",\n",
    "    \"intended_use\": \"This is suitable for demonstration only\",\n",
    "    \"network_data_format\":{\n",
    "        \"inputs\": {\n",
    "            \"image\": {\n",
    "                \"type\": \"image\",\n",
    "                \"format\": \"magnitude\",\n",
    "                \"modality\": \"MR\",\n",
    "                \"num_channels\": 1,\n",
    "                \"spatial_shape\": [160, 160, 160],\n",
    "                \"dtype\": \"float32\",\n",
    "                \"value_range\": [0, 1],\n",
    "                \"is_patch_data\": false,\n",
    "                \"channel_def\": {\"0\": \"image\"}\n",
    "            }\n",
    "        },\n",
    "        \"outputs\":{\n",
    "            \"pred\": {\n",
    "                \"type\": \"image\",\n",
    "                \"format\": \"labels\",\n",
    "                \"num_channels\": 2,\n",
    "                \"spatial_shape\": [160, 160, 160],\n",
    "                \"dtype\": \"float32\",\n",
    "                \"value_range\": [],\n",
    "                \"is_patch_data\": false,\n",
    "                \"channel_def\": {\"0\": \"background\", \"1\": \"spleen\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f208bf8-0c3a-4def-ab0f-6091cebcd532",
   "metadata": {},
   "source": [
    "This contains more information compared to the previous tutorial's file. For inputs the network, a tensor \"image\" is given as a 64x64 sized single-channel image. This is one of the MedNIST images whose modality varies but will have a value range of `[0, 1]` after rescaling in the transform pipeline. The channel definition states the meaning of each channel, this input has only one which is the greyscale image itself. For network outputs there is only one, \"pred\", representing the prediction of the network as a tensor of size 6. Each of the six values is a prediction of that class which is described in `channel_def`.\n",
    "\n",
    "## Common Definitions\n",
    "\n",
    "What we'll now do is construct the bundle configuration scripts to implement training, testing, and inference based off the original script file given above. Common definitions should be placed in a common file used with other scripts to reduce duplication. In our original script, the network definition and transform sequence will be used in multiple places so should go in this common file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting SpleenSegLightning/configs/common.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile SpleenSegLightning/configs/common.yaml\n",
    "\n",
    "# common imports\n",
    "imports: \n",
    "- $import glob\n",
    "- $import os\n",
    "\n",
    "# define a default root directory value, this can overridden on the command line\n",
    "bundle_dir: .\n",
    "data_dir: $@bundle_dir+\"/Task09_Spleen\"\n",
    "\n",
    "# define hyperparameters for the lightning trainer\n",
    "max_epochs: 2\n",
    "default_root_dir: $@bundle_dir+\"/lightning_logs\"\n",
    "check_val_every_n_epoch: 1\n",
    "\n",
    "lightninig_param:  '${\n",
    "    ''max_epochs'': @max_epochs,\n",
    "    ''default_root_dir'': @default_root_dir,\n",
    "    ''check_val_every_n_epoch'': @check_val_every_n_epoch,\n",
    "}'\n",
    "\n",
    "# define a train and validation files from the data directory\n",
    "train_images: '$sorted(glob.glob(os.path.join(@data_dir, ''imagesTr'', ''*.nii.gz'')))'\n",
    "train_labels: '$sorted(glob.glob(os.path.join(@data_dir, ''labelsTr'', ''*.nii.gz'')))'\n",
    "\n",
    "data_dicts: '$[{''image'': img, ''label'': lbl} for img, lbl in zip(@train_images, @train_labels)]'\n",
    "train_files: '$@data_dicts[:-9]'\n",
    "val_files: '$@data_dicts[-9:]'\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T14:50:53.681260408Z",
     "start_time": "2023-10-09T14:50:53.637491864Z"
    }
   },
   "id": "d11681af-3210-4b2b-b7bd-8ad8dedfe230"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scripts for training and evaluation\n",
    "\n",
    "We'll define the training and evaluation yaml files and scripts contained the Pytorch Lightning based network.\n",
    "First we'll create a script directory and a `model.py` file to contain the network definition:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60ee968cb538d983"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘SpleenSegLightning/scripts’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir SpleenSegLightning/scripts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-06T15:16:47.012796374Z"
    }
   },
   "id": "fbad1a21-4dda-4b80-8e81-7d7e75307f9c"
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting SpleenSegLightning/scripts/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile SpleenSegLightning/scripts/model.py\n",
    "\n",
    "import pytorch_lightning\n",
    "from monai.utils import set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import decollate_batch\n",
    "import torch\n",
    "\n",
    "\n",
    "class MySegNet(pytorch_lightning.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._model = UNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=2,\n",
    "            channels=(16, 32, 64, 128, 256),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,\n",
    "            norm=Norm.BATCH,\n",
    "        )\n",
    "        self.learning_rate = 1e-4\n",
    "        self.loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "        self.post_pred = Compose([EnsureType(\"tensor\", device=\"cpu\"),\n",
    "                                  AsDiscrete(argmax=True, to_onehot=2)])\n",
    "        self.post_label = Compose([EnsureType(\"tensor\", device=\"cpu\"),\n",
    "                                   AsDiscrete(to_onehot=2)])\n",
    "        self.dice_metric = DiceMetric(include_background=False, reduction=\"mean\",\n",
    "                                      get_not_nans=False)\n",
    "        self.best_val_dice = 0\n",
    "        self.best_val_epoch = 0\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        print(\"configure_optimizers\", self.learning_rate)\n",
    "        optimizer = torch.optim.Adam(self._model.parameters(), self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch[\"image\"], batch[\"label\"]\n",
    "        output = self.forward(images)\n",
    "        loss = self.loss_function(output, labels)\n",
    "        tensorboard_logs = {\"train_loss\": loss.item()}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch[\"image\"], batch[\"label\"]\n",
    "        roi_size = (160, 160, 160)\n",
    "        sw_batch_size = 4\n",
    "        outputs = sliding_window_inference(images, roi_size, sw_batch_size, self.forward)\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        outputs = [self.post_pred(i) for i in decollate_batch(outputs)]\n",
    "        labels = [self.post_label(i) for i in decollate_batch(labels)]\n",
    "        self.dice_metric(y_pred=outputs, y=labels)\n",
    "        d = {\"val_loss\": loss, \"val_number\": len(outputs)}\n",
    "        self.validation_step_outputs.append(d)\n",
    "        return d\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        val_loss, num_items = 0, 0\n",
    "        for output in self.validation_step_outputs:\n",
    "            val_loss += output[\"val_loss\"].sum().item()\n",
    "            num_items += output[\"val_number\"]\n",
    "        mean_val_dice = self.dice_metric.aggregate().item()\n",
    "        self.dice_metric.reset()\n",
    "        mean_val_loss = torch.tensor(val_loss / num_items)\n",
    "        tensorboard_logs = {\n",
    "            \"val_dice\": mean_val_dice,\n",
    "            \"val_loss\": mean_val_loss,\n",
    "        }\n",
    "        if mean_val_dice > self.best_val_dice:\n",
    "            self.best_val_dice = mean_val_dice\n",
    "            self.best_val_epoch = self.current_epoch\n",
    "        print(\n",
    "            f\"current epoch: {self.current_epoch} \"\n",
    "            f\"current mean dice: {mean_val_dice:.4f}\"\n",
    "            f\"\\nbest mean dice: {self.best_val_dice:.4f} \"\n",
    "            f\"at epoch: {self.best_val_epoch}\"\n",
    "        )\n",
    "        self.validation_step_outputs.clear()  # free memory\n",
    "        return {\"log\": tensorboard_logs}\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T14:29:42.811066618Z",
     "start_time": "2023-10-09T14:29:42.767420256Z"
    }
   },
   "id": "2c15149785c2192"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we'll create a `main.py` file to contain the training and evaluation scripts:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92e303feb8d4edca"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting SpleenSegLightning/scripts/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile SpleenSegLightning/scripts/main.py\n",
    "\n",
    "from scripts.model import MySegNet\n",
    "import pytorch_lightning\n",
    "\n",
    "\n",
    "def train(lightninig_param, train_dl, val_dl):\n",
    "    net = MySegNet()\n",
    "    trainer = pytorch_lightning.Trainer(lightninig_param['max_epochs'], \n",
    "                                        lightninig_param['default_root_dir'],\n",
    "                                        lightninig_param['check_val_every_n_epoch'])\n",
    "    trainer.fit(model=net, train_dataloaders=train_dl, val_dataloaders=val_dl)\n",
    "\n",
    "def evaluate(ckpt_file, val_dl):\n",
    "    net = MySegNet().load_from_checkpoint(ckpt_file)\n",
    "    trainer = pytorch_lightning.Trainer(devices=1, num_nodes=1)\n",
    "    trainer.validate(model=net, dataloaders=val_dl)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T14:46:32.291302638Z",
     "start_time": "2023-10-09T14:46:32.232088634Z"
    }
   },
   "id": "d49daec7d4ce0b75"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "Now, we'll define a `train.yaml` file to be used to set the configurations for the training stage:\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eaf81ea7-9ea3-4548-a32e-992f0b9bc0ab"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting SpleenSegLightning/configs/train.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile SpleenSegLightning/configs/train.yaml\n",
    "\n",
    "imports:\n",
    "- $import glob\n",
    "- $import os\n",
    "- $from scripts.main import train\n",
    "\n",
    "# define a default root directory value, this can overridden on the command line\n",
    "bundle_dir: .\n",
    "data_dir: $@bundle_dir+\"/Task09_Spleen\"\n",
    "\n",
    "# define hyperparameters for the lightning trainer\n",
    "max_epochs: 2\n",
    "default_root_dir: $@bundle_dir+\"/lightning_logs\"\n",
    "check_val_every_n_epoch: 1\n",
    "\n",
    "lightninig_param:  '${\n",
    "    ''max_epochs'': @max_epochs,\n",
    "    ''default_root_dir'': @default_root_dir,\n",
    "    ''check_val_every_n_epoch'': @check_val_every_n_epoch,\n",
    "}'\n",
    "\n",
    "# define a train and validation files from the data directory\n",
    "train_images: '$sorted(glob.glob(os.path.join(@data_dir, ''imagesTr'', ''*.nii.gz'')))'\n",
    "train_labels: '$sorted(glob.glob(os.path.join(@data_dir, ''labelsTr'', ''*.nii.gz'')))'\n",
    "\n",
    "data_dicts: '$[{''image'': img, ''label'': lbl} for img, lbl in zip(@train_images, @train_labels)]'\n",
    "train_files: '$@data_dicts[:-9]'\n",
    "val_files: '$@data_dicts[-9:]'\n",
    "\n",
    "\n",
    "# define a transform sequence by instantiating a Compose instance with a transform sequence\n",
    "train_transform:\n",
    "  _target_: Compose\n",
    "  transforms:\n",
    "  - _target_: LoadImaged\n",
    "    keys: ['image','label']\n",
    "    image_only: true\n",
    "  - _target_: EnsureChannelFirstd\n",
    "    keys: ['image','label']\n",
    "  - _target_: Orientationd\n",
    "    keys: ['image','label']\n",
    "    axcodes: 'RAS'\n",
    "  - _target_: Spacingd\n",
    "    keys: ['image','label']\n",
    "    pixdim: [1.5, 1.5, 2.0]\n",
    "  - _target_: ScaleIntensityRanged\n",
    "    keys: ['image']\n",
    "    a_min: -57\n",
    "    a_max: 164\n",
    "    b_min: 0.0\n",
    "    b_max: 1.0\n",
    "    clip: True\n",
    "  - _target_: CropForegroundd\n",
    "    keys: ['image','label']\n",
    "    source_key: 'image'\n",
    "  - _target_: RandCropByPosNegLabeld\n",
    "    keys: ['image','label']\n",
    "    label_key: 'label'\n",
    "    spatial_size: [96, 96, 96]\n",
    "    pos: 1\n",
    "    neg: 1\n",
    "    num_samples: 4\n",
    "    image_key: 'image'\n",
    "    image_threshold: 0\n",
    "\n",
    "val_transform:\n",
    "  _target_: Compose\n",
    "  transforms:\n",
    "  - _target_: LoadImaged\n",
    "    keys: ['image','label']\n",
    "    image_only: true\n",
    "  - _target_: EnsureChannelFirstd\n",
    "    keys: ['image','label']\n",
    "  - _target_: Orientationd\n",
    "    keys: ['image','label']\n",
    "    axcodes: 'RAS'\n",
    "  - _target_: Spacingd\n",
    "    keys: ['image','label']\n",
    "    pixdim: [1.5, 1.5, 2.0]\n",
    "  - _target_: ScaleIntensityRanged\n",
    "    keys: ['image']\n",
    "    a_min: -57\n",
    "    a_max: 164\n",
    "    b_min: 0.0\n",
    "    b_max: 1.0\n",
    "    clip: True\n",
    "  - _target_: CropForegroundd\n",
    "    keys: ['image','label']\n",
    "    source_key: 'image'\n",
    "\n",
    "val_dataset:\n",
    "  _target_: CacheDataset\n",
    "  data: '@val_files'\n",
    "  transform: '@val_transform'\n",
    "  cache_rate: 1.0\n",
    "  num_workers: 4\n",
    "\n",
    "train_dataset:\n",
    "  _target_: CacheDataset\n",
    "  data: '@train_files'\n",
    "  transform: '@train_transform'\n",
    "  cache_rate: 1.0\n",
    "  num_workers: 4\n",
    "  \n",
    "train_dl:\n",
    "  _target_: DataLoader\n",
    "  dataset: '@train_dataset'\n",
    "  batch_size: 1\n",
    "  shuffle: true\n",
    "  num_workers: 4\n",
    "  \n",
    "val_dl:\n",
    "  _target_: DataLoader\n",
    "  dataset: '@val_dataset'\n",
    "  batch_size: 1\n",
    "  shuffle: false\n",
    "  num_workers: 4\n",
    "\n",
    "train:\n",
    "- '$train(@lightninig_param, @train_dl, @val_dl)'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-09T13:36:39.318439946Z"
    }
   },
   "id": "4dfd052e-abe7-473a-bbf4-25674a3b20ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is a lot going on here but hopefully you see how this replicates the object definitions in the original source file. A few specific points:\n",
    "* References are made to objects defined in `common.yaml` such as `@root_dir`, so this file needs to be used in conjunction with this one.\n",
    "* A `max_epochs` hyperparameter is provided whose value you can change on the command line, eg. `--max_epochs 5`.\n",
    "* Definitions for the `optimizer`, `loss_function`, and `inferer` arguments of `trainer` are provided inline but it would be better practice to define these separately.\n",
    "* The learning rate is hard-coded as `1e-5`, it would again be better practice to define a separate `lr` hyperparameter, although it can be changed on the command line with `'--trainer#optimizer#lr' 0.001`.\n",
    "* The trained network is saved using Pytorch's `jit` module directly, better practice would be to provide a handler, such as `CheckpointSaver`, to the trainer or to an evaluator object, see other tutorial examples on how to do this. This was kept here to match the original example.\n",
    "\n",
    "Now the network can be trained by running the bundle:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de752181-80b1-4221-9e4a-315e5f7f22a6"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workflow_name None\n",
      "config_file ./SpleenSegLightning/configs/train.yaml\n",
      "meta_file None\n",
      "logging_file None\n",
      "init_id None\n",
      "run_id train\n",
      "final_id None\n",
      "tracking None\n",
      "bundle_dir ./SpleenSegLightning\n",
      "max_epochs 2\n",
      "2023-10-09 14:36:53,640 - INFO - --- input summary of monai.bundle.scripts.run ---\n",
      "2023-10-09 14:36:53,640 - INFO - > config_file: './SpleenSegLightning/configs/train.yaml'\n",
      "2023-10-09 14:36:53,640 - INFO - > run_id: 'train'\n",
      "2023-10-09 14:36:53,640 - INFO - > bundle_dir: './SpleenSegLightning'\n",
      "2023-10-09 14:36:53,641 - INFO - > max_epochs: 2\n",
      "2023-10-09 14:36:53,641 - INFO - ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.bundle.workflows ConfigWorkflow.__init__:workflow_type: Current default value of argument `workflow_type=None` has been deprecated since version 1.2. It will be changed to `workflow_type=train` in version 1.4.\n",
      "Default logging file in SpleenSegLightning/configs/logging.conf does not exist, skipping logging.\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "Loading dataset: 100%|██████████| 32/32 [00:44<00:00,  1.38s/it]\n",
      "Loading dataset: 100%|██████████| 9/9 [00:11<00:00,  1.30s/it]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workflow_name None\n",
      "config_file ./SpleenSegLightning/configs/train.yaml\n",
      "meta_file None\n",
      "logging_file None\n",
      "init_id None\n",
      "run_id train\n",
      "final_id None\n",
      "tracking None\n",
      "bundle_dir ./SpleenSegLightning\n",
      "max_epochs 2\n",
      "2023-10-09 14:37:57,731 - INFO - --- input summary of monai.bundle.scripts.run ---\n",
      "2023-10-09 14:37:57,732 - INFO - > config_file: './SpleenSegLightning/configs/train.yaml'\n",
      "2023-10-09 14:37:57,732 - INFO - > run_id: 'train'\n",
      "2023-10-09 14:37:57,732 - INFO - > bundle_dir: './SpleenSegLightning'\n",
      "2023-10-09 14:37:57,732 - INFO - > max_epochs: 2\n",
      "2023-10-09 14:37:57,732 - INFO - ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.bundle.workflows ConfigWorkflow.__init__:workflow_type: Current default value of argument `workflow_type=None` has been deprecated since version 1.2. It will be changed to `workflow_type=train` in version 1.4.\n",
      "Default logging file in SpleenSegLightning/configs/logging.conf does not exist, skipping logging.\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "Loading dataset: 100%|██████████| 32/32 [00:46<00:00,  1.46s/it]\n",
      "Loading dataset: 100%|██████████| 9/9 [00:09<00:00,  1.09s/it]\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name          | Type     | Params\n",
      "-------------------------------------------\n",
      "0 | _model        | UNet     | 4.8 M \n",
      "1 | loss_function | DiceLoss | 0     \n",
      "-------------------------------------------\n",
      "4.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.8 M     Total params\n",
      "19.236    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configure_optimizers 0.0001\n",
      "Sanity Checking: 0it [00:00, ?it/s]configure_optimizers 0.0001\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:06<00:00,  3.44s/it]current epoch: 0 current mean dice: 0.0431\n",
      "best mean dice: 0.0431 at epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           current epoch: 0 current mean dice: 0.0431\n",
      "best mean dice: 0.0431 at epoch: 0\n",
      "Epoch 0: 100%|██████████| 16/16 [00:19<00:00,  1.21s/it, v_num=7]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:01<00:04,  1.04s/it]\u001B[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:03<00:04,  1.57s/it]\u001B[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:07<00:04,  2.35s/it]\u001B[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:09<00:02,  2.25s/it]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:10<00:00,  2.06s/it]\u001B[Acurrent epoch: 0 current mean dice: 0.0196\n",
      "best mean dice: 0.0431 at epoch: 0\n",
      "\n",
      "Epoch 0: 100%|██████████| 16/16 [00:54<00:00,  3.39s/it, v_num=7]current epoch: 0 current mean dice: 0.0196\n",
      "best mean dice: 0.0431 at epoch: 0\n",
      "Epoch 1: 100%|██████████| 16/16 [00:18<00:00,  1.18s/it, v_num=7]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:03,  1.18it/s]\u001B[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:03<00:04,  1.61s/it]\u001B[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:07<00:04,  2.50s/it]\u001B[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:09<00:02,  2.37s/it]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:10<00:00,  2.19s/it]\u001B[Acurrent epoch: 1 current mean dice: 0.0357\n",
      "best mean dice: 0.0431 at epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 16/16 [00:54<00:00,  3.42s/it, v_num=7]current epoch: 1 current mean dice: 0.0357\n",
      "best mean dice: 0.0431 at epoch: 0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "BUNDLE=\"./SpleenSegLightning\"\n",
    "\n",
    "export PYTHONPATH=\"$BUNDLE\"\n",
    "\n",
    "# run the bundle with epochs set to 2 for speed during testing, change this to get a better result\n",
    "python -m monai.bundle run train \\\n",
    "    --bundle_dir \"$BUNDLE\" \\\n",
    "    --meta_file \"$BUNDLE/configs/metadata.json\" \\\n",
    "    --config_file \"$BUNDLE/configs/train.yaml\" \\\n",
    "    --max_epochs 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T13:41:08.302222850Z",
     "start_time": "2023-10-09T13:36:46.674913560Z"
    }
   },
   "id": "1d8ac6fd81493874"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbf58fac-b6d5-424d-9e98-1a30937f2116"
  },
  {
   "cell_type": "markdown",
   "id": "abf40c4f-3349-4c40-9eef-811388ffd704",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T15:08:30.839184117Z",
     "start_time": "2023-10-06T15:08:30.804583579Z"
    }
   },
   "source": [
    "The `scripts` directory has to be a valid Python module so needs a `__init__.py` file, you can include other files and import them separately or import their members into this file. Here we defined `evaluate` to enclose the loop from the original script. This can then be called as part of a expression sequence \"program\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b4e1f99a-a68b-4aeb-bcf2-842f26609b52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T14:50:58.940003998Z",
     "start_time": "2023-10-09T14:50:58.874941674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting SpleenSegLightning/configs/evaluate.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile SpleenSegLightning/configs/evaluate.yaml\n",
    "\n",
    "# common imports\n",
    "imports: \n",
    "- $from scripts.main import evaluate\n",
    "\n",
    "ckpt_file: \"\"\n",
    "\n",
    "val_transform:\n",
    "  _target_: Compose\n",
    "  transforms:\n",
    "  - _target_: LoadImaged\n",
    "    keys: ['image','label']\n",
    "    image_only: true\n",
    "  - _target_: EnsureChannelFirstd\n",
    "    keys: ['image','label']\n",
    "  - _target_: Orientationd\n",
    "    keys: ['image','label']\n",
    "    axcodes: 'RAS'\n",
    "  - _target_: Spacingd\n",
    "    keys: ['image','label']\n",
    "    pixdim: [1.5, 1.5, 2.0]\n",
    "  - _target_: ScaleIntensityRanged\n",
    "    keys: ['image']\n",
    "    a_min: -57\n",
    "    a_max: 164\n",
    "    b_min: 0.0\n",
    "    b_max: 1.0\n",
    "    clip: True\n",
    "  - _target_: CropForegroundd\n",
    "    keys: ['image','label']\n",
    "    source_key: 'image'\n",
    "\n",
    "val_dataset:\n",
    "  _target_: CacheDataset\n",
    "  data: '@val_files'\n",
    "  transform: '@val_transform'\n",
    "  cache_rate: 1.0\n",
    "  num_workers: 4\n",
    "  \n",
    "val_dl:\n",
    "  _target_: DataLoader\n",
    "  dataset: '@val_dataset'\n",
    "  batch_size: 1\n",
    "  shuffle: false\n",
    "  num_workers: 4\n",
    "  \n",
    "# loads the weights from the given file (which needs to be set on the command line) then calls \"evaluate\"\n",
    "evaluate:\n",
    "- '$evaluate(@ckpt_file, @val_dl)'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bb2286-3107-49e9-8dbe-66fe1a2ae08c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T15:08:57.169262881Z",
     "start_time": "2023-10-06T15:08:35.934836977Z"
    }
   },
   "source": [
    "Evaluation is then run on the command line, using \"evaluate\" as the program to run and providing a path to the model weights with the `ckpt_file` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3c5fa39f-8798-4e41-8e2a-3a70a6be3906",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T14:51:08.612916360Z",
     "start_time": "2023-10-09T14:50:59.849483787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workflow_name None\n",
      "config_file ['./SpleenSegLightning/configs/common.yaml', './SpleenSegLightning/configs/evaluate.yaml']\n",
      "meta_file ./SpleenSegLightning/configs/metadata.json\n",
      "logging_file None\n",
      "init_id None\n",
      "run_id evaluate\n",
      "final_id None\n",
      "tracking None\n",
      "ckpt_file ./SpleenSegLightning/models/epoch=599-step=9600.ckpt\n",
      "2023-10-09 15:51:06,913 - INFO - --- input summary of monai.bundle.scripts.run ---\n",
      "2023-10-09 15:51:06,913 - INFO - > config_file: ['./SpleenSegLightning/configs/common.yaml',\n",
      " './SpleenSegLightning/configs/evaluate.yaml']\n",
      "2023-10-09 15:51:06,913 - INFO - > meta_file: './SpleenSegLightning/configs/metadata.json'\n",
      "2023-10-09 15:51:06,913 - INFO - > run_id: 'evaluate'\n",
      "2023-10-09 15:51:06,913 - INFO - > ckpt_file: './SpleenSegLightning/models/epoch=599-step=9600.ckpt'\n",
      "2023-10-09 15:51:06,913 - INFO - ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.bundle.workflows ConfigWorkflow.__init__:workflow_type: Current default value of argument `workflow_type=None` has been deprecated since version 1.2. It will be changed to `workflow_type=train` in version 1.4.\n",
      "Default logging file in SpleenSegLightning/configs/logging.conf does not exist, skipping logging.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ol18/miniconda3/envs/monai_tutorial/lib/python3.9/site-packages/monai/bundle/config_item.py\", line 377, in evaluate\n",
      "    return eval(value[len(self.prefix) :], globals_, locals)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "NameError: name 'glob' is not defined\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ol18/miniconda3/envs/monai_tutorial/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ol18/miniconda3/envs/monai_tutorial/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ol18/miniconda3/envs/monai_tutorial/lib/python3.9/site-packages/monai/bundle/__main__.py\", line 31, in <module>\n",
      "    fire.Fire()\n",
      "  File \"/home/ol18/miniconda3/envs/monai_tutorial/lib/python3.9/site-packages/fire/core.py\", line 141, in Fire\n",
      "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
      "  File \"/home/ol18/miniconda3/envs/monai_tutorial/lib/python3.9/site-packages/fire/core.py\", line 475, in _Fire\n",
      "    component, remaining_args = _CallAndUpdateTrace(\n",
      "  File \"/home/ol18/miniconda3/envs/monai_tutorial/lib/python3.9/site-packages/fire/core.py\", line 691, in _CallAndUpdateTrace\n",
      "    component = fn(*varargs, **kwargs)\n",
      "  File \"/home/ol18/miniconda3/envs/monai_tutorial/lib/python3.9/site-packages/monai/bundle/scripts.py\", line 774, in run\n",
      "    workflow.run()\n",
      "  File \"/home/ol18/miniconda3/envs/monai_tutorial/lib/python3.9/site-packages/monai/bundle/workflows.py\", line 308, in run\n",
      "    return self._run_expr(id=self.run_id)\n",
      "  File \"/home/ol18/miniconda3/envs/monai_tutorial/lib/python3.9/site-packages/monai/bundle/workflows.py\", line 342, in _run_expr\n",
      "    return self.parser.get_parsed_content(id, **kwargs) if id in self.parser else None\n",
      "  File \"/home/ol18/miniconda3/envs/monai_tutorial/lib/python3.9/site-packages/monai/bundle/config_parser.py\", line 290, in get_parsed_content\n",
      "    return self.ref_resolver.get_resolved_content(id=id, **kwargs)\n",
      "  File \"/home/ol18/miniconda3/envs/monai_tutorial/lib/python3.9/site-packages/monai/bundle/reference_resolver.py\", line 193, in get_resolved_content\n",
      "    return self._resolve_one_item(id=id, **kwargs)\n",
      "  File \"/home/ol18/miniconda3/envs/monai_tutorial/lib/python3.9/site-packages/monai/bundle/reference_resolver.py\", line 163, in _resolve_one_item\n",
      "    self._resolve_one_item(id=d, waiting_list=waiting_list, **kwargs)\n",
      "  File \"/home/ol18/miniconda3/envs/monai_tutorial/lib/python3.9/site-packages/monai/bundle/reference_resolver.py\", line 163, in _resolve_one_item\n",
      "    self._resolve_one_item(id=d, waiting_list=waiting_list, **kwargs)\n",
      "  File \"/home/ol18/miniconda3/envs/monai_tutorial/lib/python3.9/site-packages/monai/bundle/reference_resolver.py\", line 163, in _resolve_one_item\n",
      "    self._resolve_one_item(id=d, waiting_list=waiting_list, **kwargs)\n",
      "  [Previous line repeated 3 more times]\n",
      "  File \"/home/ol18/miniconda3/envs/monai_tutorial/lib/python3.9/site-packages/monai/bundle/reference_resolver.py\", line 175, in _resolve_one_item\n",
      "    item.evaluate(globals={f\"{self._vars}\": self.resolved_content}) if run_eval else item\n",
      "  File \"/home/ol18/miniconda3/envs/monai_tutorial/lib/python3.9/site-packages/monai/bundle/config_item.py\", line 379, in evaluate\n",
      "    raise RuntimeError(f\"Failed to evaluate {self}\") from e\n",
      "RuntimeError: Failed to evaluate ConfigExpression: \n",
      "(\"$sorted(glob.glob(os.path.join(__local_refs['data_dir'], 'imagesTr', \"\n",
      " \"'*.nii.gz')))\")\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'\\nBUNDLE=\"./SpleenSegLightning\"\\nexport PYTHONPATH=\"$BUNDLE\"\\n\\npython -m monai.bundle run evaluate \\\\\\n    --meta_file \"$BUNDLE/configs/metadata.json\" \\\\\\n    --config_file \"[\\'$BUNDLE/configs/common.yaml\\',\\'$BUNDLE/configs/evaluate.yaml\\']\" \\\\\\n    --ckpt_file \"$BUNDLE/models/epoch=599-step=9600.ckpt\"\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mCalledProcessError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[147], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_cell_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbash\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43mBUNDLE=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./SpleenSegLightning\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43mexport PYTHONPATH=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m$BUNDLE\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43mpython -m monai.bundle run evaluate \u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m    --meta_file \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m$BUNDLE/configs/metadata.json\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m    --config_file \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m[\u001B[39;49m\u001B[38;5;130;43;01m\\'\u001B[39;49;00m\u001B[38;5;124;43m$BUNDLE/configs/common.yaml\u001B[39;49m\u001B[38;5;130;43;01m\\'\u001B[39;49;00m\u001B[38;5;124;43m,\u001B[39;49m\u001B[38;5;130;43;01m\\'\u001B[39;49;00m\u001B[38;5;124;43m$BUNDLE/configs/evaluate.yaml\u001B[39;49m\u001B[38;5;130;43;01m\\'\u001B[39;49;00m\u001B[38;5;124;43m]\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m    --ckpt_file \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m$BUNDLE/models/epoch=599-step=9600.ckpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/monai_tutorial/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2493\u001B[0m, in \u001B[0;36mInteractiveShell.run_cell_magic\u001B[0;34m(self, magic_name, line, cell)\u001B[0m\n\u001B[1;32m   2491\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[1;32m   2492\u001B[0m     args \u001B[38;5;241m=\u001B[39m (magic_arg_s, cell)\n\u001B[0;32m-> 2493\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2495\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[1;32m   2496\u001B[0m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[1;32m   2497\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[1;32m   2498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[0;32m~/miniconda3/envs/monai_tutorial/lib/python3.9/site-packages/IPython/core/magics/script.py:154\u001B[0m, in \u001B[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001B[0;34m(line, cell)\u001B[0m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    153\u001B[0m     line \u001B[38;5;241m=\u001B[39m script\n\u001B[0;32m--> 154\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshebang\u001B[49m\u001B[43m(\u001B[49m\u001B[43mline\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcell\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/monai_tutorial/lib/python3.9/site-packages/IPython/core/magics/script.py:314\u001B[0m, in \u001B[0;36mScriptMagics.shebang\u001B[0;34m(self, line, cell)\u001B[0m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39mraise_error \u001B[38;5;129;01mand\u001B[39;00m p\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    310\u001B[0m     \u001B[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001B[39;00m\n\u001B[1;32m    311\u001B[0m     \u001B[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001B[39;00m\n\u001B[1;32m    312\u001B[0m     \u001B[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001B[39;00m\n\u001B[1;32m    313\u001B[0m     rc \u001B[38;5;241m=\u001B[39m p\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m9\u001B[39m\n\u001B[0;32m--> 314\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CalledProcessError(rc, cell)\n",
      "\u001B[0;31mCalledProcessError\u001B[0m: Command 'b'\\nBUNDLE=\"./SpleenSegLightning\"\\nexport PYTHONPATH=\"$BUNDLE\"\\n\\npython -m monai.bundle run evaluate \\\\\\n    --meta_file \"$BUNDLE/configs/metadata.json\" \\\\\\n    --config_file \"[\\'$BUNDLE/configs/common.yaml\\',\\'$BUNDLE/configs/evaluate.yaml\\']\" \\\\\\n    --ckpt_file \"$BUNDLE/models/epoch=599-step=9600.ckpt\"\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "BUNDLE=\"./SpleenSegLightning\"\n",
    "export PYTHONPATH=\"$BUNDLE\"\n",
    "\n",
    "python -m monai.bundle run evaluate \\\n",
    "    --meta_file \"$BUNDLE/configs/metadata.json\" \\\n",
    "    --config_file \"['$BUNDLE/configs/common.yaml','$BUNDLE/configs/evaluate.yaml']\" \\\n",
    "    --ckpt_file \"$BUNDLE/models/epoch=599-step=9600.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd62905-4ea8-4f08-bcea-823074fc4ce4",
   "metadata": {},
   "source": [
    "## Summary and Next\n",
    "\n",
    "This tutorial has covered:\n",
    "* Creating full training scripts in bundles\n",
    "* Training a network then evaluating it's performance with scripts\n",
    "\n",
    "That's it to creating a bundle to match an existing script. It was mentioned in a number of places that best practice wasn't followed to stick to the original script's structure, so further tutorials will cover this in greater detail. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
