{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MONAI Auto3Dseg Reference Python APIs\n",
    "\n",
    "In this notebook, we will break down the Auto3Dseg by the modules in the pipeline and introduce the API calls in Python and CLI commands. Particularly, if you have used the AutoRunner class, we will map the AutoRunner commands and configurations to each of the Auto3Dseg module APIs\n",
    "\n",
    "![workflow](../figures/workflow.png)\n",
    "\n",
    "## 1 Set up environment, imports and datasets\n",
    "\n",
    "If you have set up MONAI and run the AutoRunner notebooks in simulated and real-world datasets, you may skip this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Set up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Set up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "os.environ[\"MONAI_ALGO_HASH\"] = \"3a39a8c\"  # Changes the algorithm_template version and download link\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.apps.auto3dseg import (\n",
    "    DataAnalyzer,\n",
    "    BundleGen,\n",
    "    AlgoEnsembleBestN,\n",
    "    AlgoEnsembleBuilder,\n",
    "    export_bundle_algo_history,\n",
    "    import_bundle_algo_history,\n",
    ")\n",
    "from monai.auto3dseg import algo_to_pickle, datafold_read\n",
    "from monai.bundle.config_parser import ConfigParser\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Download public datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-20 09:05:04,729 - INFO - Expected md5 is None, skip md5 check for file Task05_Prostate.tar.\n",
      "2022-09-20 09:05:04,729 - INFO - File exists: Task05_Prostate.tar, skipped downloading.\n",
      "2022-09-20 09:05:04,730 - INFO - Non-empty folder exists in Task05_Prostate, skipped extracting.\n"
     ]
    }
   ],
   "source": [
    "root = \"./\"\n",
    "work_dir = os.path.join(root, 'auto3dseg_work_dir')\n",
    "if not os.path.isdir(work_dir):\n",
    "    os.makedirs(work_dir)\n",
    "\n",
    "msd_task = \"Task05_Prostate\"\n",
    "dataroot = os.path.join(root, msd_task)\n",
    "datalist_file = \"../tasks/msd/Task05_Prostate/msd_task05_prostate_folds.json\"\n",
    "\n",
    "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/\" + msd_task + \".tar\"\n",
    "compressed_file = os.path.join(root, msd_task + \".tar\")\n",
    "if os.path.exists(root):\n",
    "    download_and_extract(resource, compressed_file, root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Prepare a input YAML configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_src_cfg = {\n",
    "    \"name\": \"Task05_Prostate\",\n",
    "    \"task\": \"segmentation\",\n",
    "    \"modality\": \"MRI\",\n",
    "    \"datalist\": datalist_file,\n",
    "    \"dataroot\": dataroot,\n",
    "}\n",
    "input = os.path.join(root, 'input.yaml')\n",
    "ConfigParser.export_config_file(data_src_cfg, input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Breaking down the AutoRunner\n",
    "\n",
    "Below is the typical usage of AutoRunner\n",
    "```python\n",
    "runner = AutoRunner(input=input)\n",
    "runner.run() \n",
    "```\n",
    "\n",
    "The two lines cover the typical settings in Auto3Dseg and now we are going through the internal APIs calls inside these two lines\n",
    "\n",
    "### 2.1 Data Analysis\n",
    "\n",
    "When the `analyze` flag is set to `True`, `AutoRunner` will call `DataAnalyzer` to analyze the datasets and generate a statisical report in YAML. Below is the equivalent Python API calls of `DataAnalyzer`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File ./auto3dseg_work_dir/data_stats.yaml already exists and will be overwritten.\n",
      "100%|██████████| 30/30 [00:04<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-20 09:05:24,356 - WARNING - Data is not completely uniform. MONAI transforms may provide unexpected result\n"
     ]
    }
   ],
   "source": [
    "datastats_file = os.path.join(work_dir, 'data_stats.yaml')\n",
    "analyser = DataAnalyzer(datalist_file, dataroot, output_path=datastats_file)\n",
    "datastat = analyser.get_all_case_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the Python API call, user can also use command line interface (CLI) provided by the user's OS. One example is the following bash commands:\n",
    "\n",
    "```bash\n",
    "python -m monai.apps.auto3dseg DataAnalyzer get_all_case_stats --datalist=\"../tasks/msd/Task05_Prostate/msd_task05_prostate_folds.json\" --dataroot=\"./Task05_Prostate\" --output_path=\"./auto3dseg_work_dir/data_stats.yaml\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Algorithm Generation (algo_gen)\n",
    "\n",
    "When the `algo_gen` flag is set to `True`, `AutoRunner` will use `BundleGen` to generate monai bundles from templated algorithms in the working directory. \n",
    "\n",
    "The templated algorithms are customized for the datasets when the `generate` method is called. In detail, the `generate` method will fill the templates using information from the data_stats report. Also, it will copy the necessary scripts (train.py/infer.py) to the algorithm folder. Finally, it will create an algo_object.pkl to save the `Algo` so that it can be instantiated in the local or remote machine. Cross validation is used by default, and `num_fold` can be set to 1 if the users do not want cross validation.\n",
    "\n",
    "Below is the equivalent Python API calls of `BundleGen`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "algo_templates.tar.gz: 100%|██████████| 280k/280k [00:01<00:00, 234kB/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-20 09:05:29,021 - INFO - Downloaded: /tmp/tmpk9dr6xe5/algo_templates.tar.gz\n",
      "2022-09-20 09:05:29,023 - INFO - Expected md5 is None, skip md5 check for file /tmp/tmpk9dr6xe5/algo_templates.tar.gz.\n",
      "2022-09-20 09:05:29,025 - INFO - Writing into directory: ./auto3dseg_work_dir.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-20 09:05:29,502 - INFO - ./auto3dseg_work_dir/segresnet2d_0\n",
      "2022-09-20 09:05:30,005 - INFO - ./auto3dseg_work_dir/segresnet2d_1\n",
      "2022-09-20 09:05:30,423 - INFO - ./auto3dseg_work_dir/segresnet2d_2\n",
      "2022-09-20 09:05:30,928 - INFO - ./auto3dseg_work_dir/segresnet2d_3\n",
      "2022-09-20 09:05:31,337 - INFO - ./auto3dseg_work_dir/segresnet2d_4\n",
      "2022-09-20 09:05:31,846 - INFO - ./auto3dseg_work_dir/dints_0\n",
      "2022-09-20 09:05:32,264 - INFO - ./auto3dseg_work_dir/dints_1\n",
      "2022-09-20 09:05:32,771 - INFO - ./auto3dseg_work_dir/dints_2\n",
      "2022-09-20 09:05:33,188 - INFO - ./auto3dseg_work_dir/dints_3\n",
      "2022-09-20 09:05:33,698 - INFO - ./auto3dseg_work_dir/dints_4\n",
      "2022-09-20 09:05:34,103 - INFO - ./auto3dseg_work_dir/swinunetr_0\n",
      "2022-09-20 09:05:34,599 - INFO - ./auto3dseg_work_dir/swinunetr_1\n",
      "2022-09-20 09:05:35,004 - INFO - ./auto3dseg_work_dir/swinunetr_2\n",
      "2022-09-20 09:05:35,502 - INFO - ./auto3dseg_work_dir/swinunetr_3\n",
      "2022-09-20 09:05:35,909 - INFO - ./auto3dseg_work_dir/swinunetr_4\n",
      "2022-09-20 09:05:36,421 - INFO - ./auto3dseg_work_dir/segresnet_0\n",
      "2022-09-20 09:05:36,833 - INFO - ./auto3dseg_work_dir/segresnet_1\n",
      "2022-09-20 09:05:37,249 - INFO - ./auto3dseg_work_dir/segresnet_2\n",
      "2022-09-20 09:05:37,754 - INFO - ./auto3dseg_work_dir/segresnet_3\n",
      "2022-09-20 09:05:38,266 - INFO - ./auto3dseg_work_dir/segresnet_4\n"
     ]
    }
   ],
   "source": [
    "bundle_generator = BundleGen(\n",
    "    algo_path=work_dir,\n",
    "    data_stats_filename=datastats_file,\n",
    "    data_src_cfg_name=input,\n",
    ")\n",
    "\n",
    "bundle_generator.generate(work_dir, num_fold=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the Python API call, user can also use command line interface (CLI) provided by the user's OS. One example is the following bash commands:\n",
    "\n",
    "```bash\n",
    "python -m monai.apps.auto3dseg BundleGen generate \n",
    "--algo_path=\"./auto3dseg_work_dir/\" --data_stats_filename=\"./auto3dseg_work_dir/data_stats.yaml\" --data_src_cfg_name=\"./auto3dseg_work_dir/input.yaml\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Getting and Saving the history to hard drive\n",
    "\n",
    "If the users continue to train the algorithms on local system, The history of the algorithm generation can be fetched via `get_history` method of the `BundleGen` object. There also are scenarios that users need to stop the Python process after the `algo_gen`. For example, the users may need to transfer the files to a remote cluster to start the training. `Auto3Dseg` offers a utility function `export_bundle_algo_history` to dump the history to hard drive and recall it by `import_bundle_algo_history`. \n",
    "\n",
    "If the files are copied to a remote system, please make sure the alrogirthm templates are also copied there. Some functions require the path to instantiate the algorithm class properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = bundle_generator.get_history()\n",
    "export_bundle_algo_history(history)  # save Algo objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Training\n",
    "\n",
    "### 2.3.1 Add training parameters to cut down the training time in this notebook (Optional)\n",
    "\n",
    "This step is not required, but for demo purposes, we'll set a limit of the epochs to train the algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_iterations': 12, 'num_iterations_per_validation': 6, 'num_images_per_batch': 2, 'num_epochs': 2, 'num_warmup_iterations': 6}\n"
     ]
    }
   ],
   "source": [
    "# This code block is optional - you don't need training params unless you need it\n",
    "max_epochs = 2\n",
    "\n",
    "num_gpus = 1 if \"multigpu\" in data_src_cfg and not data_src_cfg[\"multigpu\"] else torch.cuda.device_count()\n",
    "\n",
    "num_epoch = max_epochs\n",
    "num_images_per_batch = 2\n",
    "files_train_fold0, _ = datafold_read(datalist_file, \"\", 0)\n",
    "n_data = len(files_train_fold0)\n",
    "n_iter = int(num_epoch * n_data / num_images_per_batch / num_gpus)\n",
    "n_iter_val = int(n_iter / 2)\n",
    "\n",
    "train_param = {\n",
    "    \"num_iterations\": n_iter,\n",
    "    \"num_iterations_per_validation\": n_iter_val,\n",
    "    \"num_images_per_batch\": num_images_per_batch,\n",
    "    \"num_epochs\": num_epoch,\n",
    "    \"num_warmup_iterations\": n_iter_val,\n",
    "}\n",
    "\n",
    "print(train_param)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Training the neural network sequentially\n",
    "\n",
    "The algo_gen history contains `Algo` object that has multiple methods such as `train` and `predict`. We can easily use such APIs to trigger neural network training. By default, `AutoRunnner` will start a training on a single node (single or multiple GPUs) in a seqential manner.\n",
    "\n",
    "`algo_to_pickle` is optional and it will update the dumped Algo objects with the accuracies information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-20 09:10:58,727 - INFO - Launching: torchrun --nnodes=1 --nproc_per_node=2 ./auto3dseg_work_dir/dints_4/scripts/search.py run --config_file='./auto3dseg_work_dir/dints_4/configs/transforms_validate.yaml','./auto3dseg_work_dir/dints_4/configs/transforms_train.yaml','./auto3dseg_work_dir/dints_4/configs/transforms_infer.yaml','./auto3dseg_work_dir/dints_4/configs/hyper_parameters_search.yaml','./auto3dseg_work_dir/dints_4/configs/network.yaml','./auto3dseg_work_dir/dints_4/configs/network_search.yaml','./auto3dseg_work_dir/dints_4/configs/hyper_parameters.yaml' --searching#num_iterations=12 --searching#num_iterations_per_validation=6 --searching#num_images_per_batch=2 --searching#num_epochs=2 --searching#num_warmup_iterations=6\n",
      "2022-09-20 09:12:44,544 - INFO - CompletedProcess(args=['torchrun', '--nnodes=1', '--nproc_per_node=2', './auto3dseg_work_dir/dints_4/scripts/search.py', 'run', \"--config_file='./auto3dseg_work_dir/dints_4/configs/transforms_validate.yaml','./auto3dseg_work_dir/dints_4/configs/transforms_train.yaml','./auto3dseg_work_dir/dints_4/configs/transforms_infer.yaml','./auto3dseg_work_dir/dints_4/configs/hyper_parameters_search.yaml','./auto3dseg_work_dir/dints_4/configs/network.yaml','./auto3dseg_work_dir/dints_4/configs/network_search.yaml','./auto3dseg_work_dir/dints_4/configs/hyper_parameters.yaml'\", '--searching#num_iterations=12', '--searching#num_iterations_per_validation=6', '--searching#num_images_per_batch=2', '--searching#num_epochs=2', '--searching#num_warmup_iterations=6'], returncode=0, stdout=b\"[info] number of GPUs: 2\n",
      "2022-09-20 09:11:01,518 - Added key: store_based_barrier_key:1 to store for rank: 1\n",
      "[info] number of GPUs: 2\n",
      "2022-09-20 09:11:01,519 - Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "2022-09-20 09:11:01,519 - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n",
      "[info] world_size: 2\n",
      "train_files_w: 6\n",
      "train_files_a: 6\n",
      "val_files: 3\n",
      "2022-09-20 09:11:01,528 - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n",
      "[info] world_size: 2\n",
      "train_files_w: 6\n",
      "train_files_a: 6\n",
      "val_files: 3\n",
      "num_epochs 4\n",
      "num_epochs_warmup 2\n",
      "num_epochs_per_validation 2\n",
      "[info] amp enabled\n",
      "----------\n",
      "epoch 1/4\n",
      "learning rate is set to 0.025\n",
      "[2022-09-20 09:11:18] 1/3, train_loss: 0.9266\n",
      "[2022-09-20 09:11:20] 2/3, train_loss: 1.0570\n",
      "[2022-09-20 09:11:22] 3/3, train_loss: 0.8528\n",
      "epoch 1 average loss: 0.9205, best mean dice: -1.0000 at epoch -1\n",
      "----------\n",
      "epoch 2/4\n",
      "learning rate is set to 0.025\n",
      "[2022-09-20 09:11:25] 1/3, train_loss: 0.8991\n",
      "[2022-09-20 09:11:27] 2/3, train_loss: 0.9737\n",
      "[2022-09-20 09:11:28] 3/3, train_loss: 0.9019\n",
      "epoch 2 average loss: 0.9094, best mean dice: -1.0000 at epoch -1\n",
      "1 / 3 tensor([[0.0072, 0.0466]], device='cuda:0')\n",
      "2 / 3 tensor([[0.0060, 0.0228]], device='cuda:0')\n",
      "1 / 3 tensor([[0.0102, 0.0227]], device='cuda:1')\n",
      "3 / 3 tensor([[0.0234, 0.1056]], device='cuda:0')\n",
      "2 / 3 tensor([[0.0033, 0.0629]], device='cuda:1')\n",
      "3 / 3 tensor([[0.0078, 0.0659]], device='cuda:1')\n",
      "evaluation metric - class 1: 0.00965491309762001\n",
      "evaluation metric - class 2: 0.054418206214904785\n",
      "avg_metric 0.0320365596562624\n",
      "saved new best metric model\n",
      "current epoch: 2 current mean dice: 0.0320 best mean dice: 0.0320 at epoch 2\n",
      "----------\n",
      "epoch 3/4\n",
      "learning rate is set to 0.025\n",
      "[2022-09-20 09:11:54] 1/3, train_loss: 0.8252\n",
      "[2022-09-20 09:11:58] 1/3, train_loss_arch: 1.0377\n",
      "[2022-09-20 09:12:00] 2/3, train_loss: 0.8528\n",
      "[2022-09-20 09:12:02] 2/3, train_loss_arch: 0.8846\n",
      "[2022-09-20 09:12:03] 3/3, train_loss: 1.0565\n",
      "[2022-09-20 09:12:06] 3/3, train_loss_arch: 0.9387\n",
      "epoch 3 average loss: 0.9380, best mean dice: 0.0320 at epoch 2\n",
      "epoch 3 average arch loss: 0.9537, best mean dice: 0.0320 at epoch 2\n",
      "----------\n",
      "epoch 4/4\n",
      "learning rate is set to 0.0125\n",
      "[2022-09-20 09:12:09] 1/3, train_loss: 0.9641\n",
      "[2022-09-20 09:12:12] 1/3, train_loss_arch: 1.2984\n",
      "[2022-09-20 09:12:14] 2/3, train_loss: 0.8378\n",
      "[2022-09-20 09:12:16] 2/3, train_loss_arch: 1.2495\n",
      "[2022-09-20 09:12:18] 3/3, train_loss: 1.0368\n",
      "[2022-09-20 09:12:20] 3/3, train_loss_arch: 1.2647\n",
      "epoch 4 average loss: 0.9064, best mean dice: 0.0320 at epoch 2\n",
      "epoch 4 average arch loss: 1.2709, best mean dice: 0.0320 at epoch 2\n",
      "1 / 3 tensor([[0.0097, 0.0552]], device='cuda:0')\n",
      "2 / 3 tensor([[0.0064, 0.0254]], device='cuda:0')\n",
      "1 / 3 tensor([[0.0063, 0.0216]], device='cuda:1')\n",
      "3 / 3 tensor([[0.0198, 0.1109]], device='cuda:0')\n",
      "2 / 3 tensor([[0.0061, 0.0534]], device='cuda:1')\n",
      "3 / 3 tensor([[0.0123, 0.0685]], device='cuda:1')\n",
      "evaluation metric - class 1: 0.010102814063429832\n",
      "evaluation metric - class 2: 0.055860052506128945\n",
      "avg_metric 0.032981433284779385\n",
      "saved new best metric model\n",
      "current epoch: 4 current mean dice: 0.0330 best mean dice: 0.0330 at epoch 4\n",
      "train completed, best_metric: -1.0000 at epoch: -1\n",
      "train completed, best_metric: 0.0330 at epoch: 4\n",
      "\", stderr=b'WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "Modifying image pixdim from [0.6249999 0.6249999 3.6       1.       ] to [  0.62499988   0.62499988   3.5999999  152.06272679]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625       0.625       3.5999999 151.7973753]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  170.38896694]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625       0.625       3.5999999 149.7974827]\n",
      "Modifying image pixdim from [0.62499976 0.62499976 3.6        1.        ] to [  0.62499976   0.62499976   3.5999999  164.74616031]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  160.67573396]\n",
      "Modifying image pixdim from [0.62499976 0.62499976 3.6        1.        ] to [  0.62499976   0.62499976   3.5999999  164.74616031]\n",
      "Modifying image pixdim from [0.625      0.62500006 3.6000001  1.        ] to [  0.625        0.62500005   3.60000016 168.35859116]\n",
      "Modifying image pixdim from [0.6       0.5999997 3.999998  1.       ] to [  0.60000002   0.59999975   3.99999799 129.0477496 ]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  150.20609596]\n",
      "Modifying image pixdim from [0.625   0.625   3.59999 1.     ] to [  0.625        0.625        3.59998989 208.35237358]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  202.45334114]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  148.64025265]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  150.52861008]\n",
      "Modifying image pixdim from [0.6249998 0.625     3.5999987 1.       ] to [  0.62499983   0.625        3.59999877 153.34152766]\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 149.1610426 ]\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 173.25173679]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  170.38896694]\n",
      "is_namedtuple is deprecated, please use the python checks instead\n",
      "is_namedtuple is deprecated, please use the python checks instead\n",
      "no available indices of class 1 to crop, set the crop ratio of this class to zero.\n",
      "no available indices of class 2 to crop, set the crop ratio of this class to zero.\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  160.84918933]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  142.87013615]\n",
      "Modifying image pixdim from [0.6249998 0.625     3.5999987 1.       ] to [  0.62499983   0.625        3.59999877 153.34152766]\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 149.1610426 ]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  160.84918933]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  170.38896694]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  142.87013615]\n",
      "no available indices of class 1 to crop, set the crop ratio of this class to zero.\n",
      "no available indices of class 2 to crop, set the crop ratio of this class to zero.\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 173.25173679]\n",
      "no available indices of class 1 to crop, set the crop ratio of this class to zero.\n",
      "no available indices of class 2 to crop, set the crop ratio of this class to zero.\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 151.21210251]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625       0.625       3.5999999 152.3814254]\n",
      "Modifying image pixdim from [0.75      0.7500001 4.0000005 1.       ] to [  0.75         0.75000013   4.00000043 128.6789431 ]\n",
      "Modifying image pixdim from [0.6       0.5999997 3.999998  1.       ] to [  0.60000002   0.59999975   3.99999799 117.82332812]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  170.38896694]\n",
      "Modifying image pixdim from [0.6249998 0.625     3.5999987 1.       ] to [  0.62499983   0.625        3.59999877 153.34152766]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  142.87013615]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  160.84918933]\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 149.1610426 ]\n",
      "no available indices of class 1 to crop, set the crop ratio of this class to zero.\n",
      "no available indices of class 2 to crop, set the crop ratio of this class to zero.\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 173.25173679]\n",
      "Modifying image pixdim from [0.75       0.74999964 2.9999986  1.        ] to [  0.75         0.74999965   2.99999861 157.50724574]\n",
      "Modifying image pixdim from [0.6        0.60000014 4.0000005  1.        ] to [  0.60000002   0.60000017   4.00000043 128.8161199 ]\n",
      "Modifying image pixdim from [0.6249998 0.625     3.5999987 1.       ] to [  0.62499983   0.625        3.59999877 153.34152766]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  160.84918933]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  162.36758282]\n",
      "no available indices of class 1 to crop, set the crop ratio of this class to zero.\n",
      "no available indices of class 2 to crop, set the crop ratio of this class to zero.\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 149.1610426 ]\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 149.1610426 ]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  170.38896694]\n",
      "no available indices of class 1 to crop, set the crop ratio of this class to zero.\n",
      "no available indices of class 2 to crop, set the crop ratio of this class to zero.\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 173.25173679]\n",
      "Modifying image pixdim from [0.6249998 0.625     3.5999987 1.       ] to [  0.62499983   0.625        3.59999877 153.34152766]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  160.84918933]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  142.87013615]\n",
      "Modifying image pixdim from [0.75       0.74999964 2.9999986  1.        ] to [  0.75         0.74999965   2.99999861 157.50724574]\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 149.1610426 ]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  162.36758282]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  160.84918933]\n",
      "Modifying image pixdim from [0.6249998 0.625     3.5999987 1.       ] to [  0.62499983   0.625        3.59999877 153.34152766]\n",
      "Modifying image pixdim from [0.6        0.60000014 4.0000005  1.        ] to [  0.60000002   0.60000017   4.00000043 128.8161199 ]\n",
      "no available indices of class 1 to crop, set the crop ratio of this class to zero.\n",
      "no available indices of class 2 to crop, set the crop ratio of this class to zero.\n",
      "')\n",
      "2022-09-20 09:12:44,545 - INFO - Launching: torchrun --nnodes=1 --nproc_per_node=2 ./auto3dseg_work_dir/dints_4/scripts/train.py run --config_file='./auto3dseg_work_dir/dints_4/configs/transforms_validate.yaml','./auto3dseg_work_dir/dints_4/configs/transforms_train.yaml','./auto3dseg_work_dir/dints_4/configs/transforms_infer.yaml','./auto3dseg_work_dir/dints_4/configs/hyper_parameters_search.yaml','./auto3dseg_work_dir/dints_4/configs/network.yaml','./auto3dseg_work_dir/dints_4/configs/network_search.yaml','./auto3dseg_work_dir/dints_4/configs/hyper_parameters.yaml' --training#num_iterations=12 --training#num_iterations_per_validation=6 --training#num_images_per_batch=2 --training#num_epochs=2 --training#num_warmup_iterations=6\n",
      "2022-09-20 09:17:30,505 - INFO - CompletedProcess(args=['torchrun', '--nnodes=1', '--nproc_per_node=2', './auto3dseg_work_dir/dints_4/scripts/train.py', 'run', \"--config_file='./auto3dseg_work_dir/dints_4/configs/transforms_validate.yaml','./auto3dseg_work_dir/dints_4/configs/transforms_train.yaml','./auto3dseg_work_dir/dints_4/configs/transforms_infer.yaml','./auto3dseg_work_dir/dints_4/configs/hyper_parameters_search.yaml','./auto3dseg_work_dir/dints_4/configs/network.yaml','./auto3dseg_work_dir/dints_4/configs/network_search.yaml','./auto3dseg_work_dir/dints_4/configs/hyper_parameters.yaml'\", '--training#num_iterations=12', '--training#num_iterations_per_validation=6', '--training#num_images_per_batch=2', '--training#num_epochs=2', '--training#num_warmup_iterations=6'], returncode=0, stdout=b\"[info] number of GPUs: 2\n",
      "2022-09-20 09:12:47,399 - Added key: store_based_barrier_key:1 to store for rank: 1\n",
      "[info] number of GPUs: 2\n",
      "2022-09-20 09:12:47,415 - Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "2022-09-20 09:12:47,415 - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n",
      "[info] world_size: 2\n",
      "train_files: 12\n",
      "val_files: 3\n",
      "2022-09-20 09:12:47,419 - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n",
      "[info] world_size: 2\n",
      "train_files: 12\n",
      "val_files: 3\n",
      "num_epochs 2\n",
      "num_epochs_per_validation 1\n",
      "[info] training from scratch\n",
      "[info] amp enabled\n",
      "----------\n",
      "epoch 1/2\n",
      "learning rate is set to 0.2\n",
      "[info] training from scratch\n",
      "[2022-09-20 09:13:03] 1/6, train_loss: 0.9369\n",
      "[2022-09-20 09:13:05] 2/6, train_loss: 0.8486\n",
      "[2022-09-20 09:13:07] 3/6, train_loss: 0.8447\n",
      "[2022-09-20 09:13:09] 4/6, train_loss: 0.8675\n",
      "[2022-09-20 09:13:12] 5/6, train_loss: 0.8604\n",
      "[2022-09-20 09:13:14] 6/6, train_loss: 0.8058\n",
      "epoch 1 average loss: 0.8540, best mean dice: -1.0000 at epoch -1\n",
      "1 / 3 tensor([[0.0221, 0.0545]], device='cuda:0')\n",
      "2 / 3 tensor([[0.0093, 0.0205]], device='cuda:0')\n",
      "3 / 3 tensor([[0.0399, 0.1065]], device='cuda:0')\n",
      "1 / 3 tensor([[0.0120, 0.0241]], device='cuda:1')\n",
      "2 / 3 tensor([[0.0130, 0.0570]], device='cuda:1')\n",
      "3 / 3 tensor([[0.0082, 0.0785]], device='cuda:1')\n",
      "evaluation metric - class 1: 0.017443853120009106\n",
      "evaluation metric - class 2: 0.05683837334314982\n",
      "avg_metric 0.03714111323157946\n",
      "saved new best metric model\n",
      "current epoch: 1 current mean dice: 0.0371 best mean dice: 0.0371 at epoch 1\n",
      "----------\n",
      "epoch 2/2\n",
      "learning rate is set to 0.025\n",
      "[2022-09-20 09:15:18] 1/6, train_loss: 0.8608\n",
      "[2022-09-20 09:15:20] 2/6, train_loss: 0.8269\n",
      "[2022-09-20 09:15:22] 3/6, train_loss: 0.7828\n",
      "[2022-09-20 09:15:24] 4/6, train_loss: 0.7636\n",
      "[2022-09-20 09:15:27] 5/6, train_loss: 0.7769\n",
      "[2022-09-20 09:15:29] 6/6, train_loss: 0.7651\n",
      "epoch 2 average loss: 0.8047, best mean dice: 0.0371 at epoch 1\n",
      "1 / 3 tensor([[0.0216, 0.0611]], device='cuda:0')\n",
      "2 / 3 tensor([[0.0071, 0.0236]], device='cuda:0')\n",
      "3 / 3 tensor([[0.0443, 0.1209]], device='cuda:0')\n",
      "1 / 3 tensor([[0.0124, 0.0260]], device='cuda:1')\n",
      "2 / 3 tensor([[0.0112, 0.0651]], device='cuda:1')\n",
      "3 / 3 tensor([[0.0037, 0.0848]], device='cuda:1')\n",
      "evaluation metric - class 1: 0.0167141060034434\n",
      "evaluation metric - class 2: 0.0635906308889389\n",
      "avg_metric 0.040152368446191154\n",
      "saved new best metric model\n",
      "current epoch: 2 current mean dice: 0.0402 best mean dice: 0.0402 at epoch 2\n",
      "train completed, best_metric: 0.0402 at epoch: 2\n",
      "-1\n",
      "0.040152368446191154\n",
      "\", stderr=b'WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  142.87013615]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  150.20609596]\n",
      "Modifying image pixdim from [0.6       0.6000003 4.0000024 1.       ] to [  0.60000002   0.60000034   4.00000227 149.31681629]\n",
      "Modifying image pixdim from [0.6249999 0.6249999 3.6       1.       ] to [  0.62499988   0.62499988   3.5999999  152.06272679]\n",
      "Modifying image pixdim from [0.6249998 0.625     3.5999987 1.       ] to [  0.62499983   0.625        3.59999877 153.34152766]\n",
      "Modifying image pixdim from [0.6249999 0.6249999 3.6       1.       ] to [  0.62499988   0.62499988   3.5999999  152.06272679]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625       0.625       3.5999999 151.7973753]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  150.20609596]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  180.81811432]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  160.84918933]\n",
      "Modifying image pixdim from [0.6       0.6000003 4.0000024 1.       ] to [  0.60000002   0.60000034   4.00000227 149.31681629]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  142.87013615]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  150.52861008]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  148.64025265]\n",
      "Modifying image pixdim from [0.6       0.5999997 3.999998  1.       ] to [  0.60000002   0.59999975   3.99999799 129.0477496 ]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  160.67573396]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  162.36758282]\n",
      "Modifying image pixdim from [0.75       0.74999964 2.9999986  1.        ] to [  0.75         0.74999965   2.99999861 157.50724574]\n",
      "Modifying image pixdim from [0.6       0.5999997 3.999998  1.       ] to [  0.60000002   0.59999975   3.99999799 129.0477496 ]\n",
      "no available indices of class 1 to crop, set the crop ratio of this class to zero.\n",
      "no available indices of class 2 to crop, set the crop ratio of this class to zero.\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  160.84918933]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  160.67573396]\n",
      "Modifying image pixdim from [0.6        0.60000014 4.0000005  1.        ] to [  0.60000002   0.60000017   4.00000041 174.1516677 ]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625       0.625       3.5999999 149.7974827]\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 149.1610426 ]\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 173.25173679]\n",
      "Modifying image pixdim from [0.62499976 0.62499976 3.6        1.        ] to [  0.62499976   0.62499976   3.5999999  164.74616031]\n",
      "is_namedtuple is deprecated, please use the python checks instead\n",
      "is_namedtuple is deprecated, please use the python checks instead\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 151.21210251]\n",
      "Modifying image pixdim from [0.6       0.5999997 3.999998  1.       ] to [  0.60000002   0.59999975   3.99999799 117.82332812]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625       0.625       3.5999999 152.3814254]\n",
      "Modifying image pixdim from [0.75      0.7500001 4.0000005 1.       ] to [  0.75         0.75000013   4.00000043 128.6789431 ]\n",
      "Modifying image pixdim from [0.6       0.5999997 3.999998  1.       ] to [  0.60000002   0.59999975   3.99999799 129.0477496 ]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  160.84918933]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625       0.625       3.5999999 149.7974827]\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 149.1610426 ]\n",
      "Modifying image pixdim from [0.6        0.60000014 4.0000005  1.        ] to [  0.60000002   0.60000017   4.00000041 174.1516677 ]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  162.36758282]\n",
      "Modifying image pixdim from [0.62499976 0.62499976 3.6        1.        ] to [  0.62499976   0.62499976   3.5999999  164.74616031]\n",
      "Modifying image pixdim from [0.6       0.5999997 3.999998  1.       ] to [  0.60000002   0.59999975   3.99999799 129.0477496 ]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  160.67573396]\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 173.25173679]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  160.67573396]\n",
      "no available indices of class 1 to crop, set the crop ratio of this class to zero.\n",
      "no available indices of class 2 to crop, set the crop ratio of this class to zero.\n",
      "Modifying image pixdim from [0.75       0.74999964 2.9999986  1.        ] to [  0.75         0.74999965   2.99999861 157.50724574]\n",
      "')\n",
      "2022-09-20 09:17:30,515 - INFO - Launching: torchrun --nnodes=1 --nproc_per_node=2 ./auto3dseg_work_dir/segresnet_0/scripts/train.py run --config_file='./auto3dseg_work_dir/segresnet_0/configs/transforms_validate.yaml','./auto3dseg_work_dir/segresnet_0/configs/transforms_train.yaml','./auto3dseg_work_dir/segresnet_0/configs/transforms_infer.yaml','./auto3dseg_work_dir/segresnet_0/configs/network.yaml','./auto3dseg_work_dir/segresnet_0/configs/hyper_parameters.yaml' --num_iterations=12 --num_iterations_per_validation=6 --num_images_per_batch=2 --num_epochs=2 --num_warmup_iterations=6\n",
      "2022-09-20 09:18:06,263 - INFO - CompletedProcess(args=['torchrun', '--nnodes=1', '--nproc_per_node=2', './auto3dseg_work_dir/segresnet_0/scripts/train.py', 'run', \"--config_file='./auto3dseg_work_dir/segresnet_0/configs/transforms_validate.yaml','./auto3dseg_work_dir/segresnet_0/configs/transforms_train.yaml','./auto3dseg_work_dir/segresnet_0/configs/transforms_infer.yaml','./auto3dseg_work_dir/segresnet_0/configs/network.yaml','./auto3dseg_work_dir/segresnet_0/configs/hyper_parameters.yaml'\", '--num_iterations=12', '--num_iterations_per_validation=6', '--num_images_per_batch=2', '--num_epochs=2', '--num_warmup_iterations=6'], returncode=0, stdout=b\"[info] number of GPUs: 2\n",
      "2022-09-20 09:17:33,347 - Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "[info] number of GPUs: 2\n",
      "2022-09-20 09:17:33,351 - Added key: store_based_barrier_key:1 to store for rank: 1\n",
      "2022-09-20 09:17:33,351 - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n",
      "[info] world_size: 2\n",
      "train_files: 12\n",
      "val_files: 3\n",
      "2022-09-20 09:17:33,358 - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n",
      "[info] world_size: 2\n",
      "train_files: 12\n",
      "val_files: 3\n",
      "num_epochs 2\n",
      "num_epochs_per_validation 1\n",
      "[info] training from scratch\n",
      "[info] amp enabled\n",
      "----------\n",
      "epoch 1/2\n",
      "learning rate is set to 2e-05\n",
      "[info] training from scratch\n",
      "[2022-09-20 09:17:44] 1/6, train_loss: 1.9939\n",
      "2022-09-20 09:17:44,658 - Reducer buckets have been rebuilt in this iteration.\n",
      "2022-09-20 09:17:44,660 - Reducer buckets have been rebuilt in this iteration.\n",
      "[2022-09-20 09:17:45] 2/6, train_loss: 2.0258\n",
      "[2022-09-20 09:17:46] 3/6, train_loss: 2.0235\n",
      "[2022-09-20 09:17:47] 4/6, train_loss: 1.9006\n",
      "[2022-09-20 09:17:48] 5/6, train_loss: 1.8539\n",
      "[2022-09-20 09:17:49] 6/6, train_loss: 1.8241\n",
      "epoch 1 average loss: 1.9399, best mean dice: -1.0000 at epoch -1\n",
      "1 / 3 tensor([[0.0180, 0.0896]], device='cuda:0')\n",
      "1 / 3 tensor([[0.0363, 0.1168]], device='cuda:1')\n",
      "2 / 3 tensor([[0.0239, 0.0217]], device='cuda:0')\n",
      "2 / 3 tensor([[0.0569, 0.0091]], device='cuda:1')\n",
      "3 / 3 tensor([[0.0279, 0.0240]], device='cuda:0')\n",
      "3 / 3 tensor([[0.0231, 0.0258]], device='cuda:1')\n",
      "evaluation metric - class 1: 0.031007106105486553\n",
      "evaluation metric - class 2: 0.04782626032829285\n",
      "avg_metric 0.0394166832168897\n",
      "saved new best metric model\n",
      "current epoch: 1 current mean dice: 0.0394 best mean dice: 0.0394 at epoch 1\n",
      "----------\n",
      "epoch 2/2\n",
      "learning rate is set to 0.0\n",
      "[2022-09-20 09:17:55] 1/6, train_loss: 1.7259\n",
      "[2022-09-20 09:17:56] 2/6, train_loss: 1.9185\n",
      "[2022-09-20 09:17:57] 3/6, train_loss: 1.7607\n",
      "[2022-09-20 09:17:58] 4/6, train_loss: 1.7740\n",
      "[2022-09-20 09:17:59] 5/6, train_loss: 1.7419\n",
      "[2022-09-20 09:18:00] 6/6, train_loss: 1.6928\n",
      "epoch 2 average loss: 1.7829, best mean dice: 0.0394 at epoch 1\n",
      "1 / 3 tensor([[0.0035, 0.3549]], device='cuda:0')\n",
      "1 / 3 tensor([[0.0125, 0.2132]], device='cuda:1')\n",
      "2 / 3 tensor([[0.0075, 0.1080]], device='cuda:0')\n",
      "2 / 3 tensor([[0.0289, 0.0532]], device='cuda:1')\n",
      "3 / 3 tensor([[0.0103, 0.0705]], device='cuda:0')\n",
      "3 / 3 tensor([[0.0042, 0.0892]], device='cuda:1')\n",
      "evaluation metric - class 1: 0.011155456304550171\n",
      "evaluation metric - class 2: 0.14814913272857666\n",
      "avg_metric 0.07965229451656342\n",
      "saved new best metric model\n",
      "current epoch: 2 current mean dice: 0.0797 best mean dice: 0.0797 at epoch 2\n",
      "train completed, best_metric: 0.0797 at epoch: 2\n",
      "0.07965229451656342\n",
      "-1\n",
      "\", stderr=b'WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 151.21210251]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  160.84918933]\n",
      "Modifying image pixdim from [0.6       0.5999997 3.999998  1.       ] to [  0.60000002   0.59999975   3.99999799 117.82332812]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  180.81811432]\n",
      "Modifying image pixdim from [0.75       0.74999964 2.9999986  1.        ] to [  0.75         0.74999965   2.99999861 157.50724574]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  202.45334114]\n",
      "Modifying image pixdim from [0.604167  0.6041667 3.999998  1.       ] to [  0.60416698   0.60416671   3.99999799 174.60244975]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  154.70488398]\n",
      "Modifying image pixdim from [0.6        0.60000014 4.0000005  1.        ] to [  0.60000002   0.60000017   4.00000041 174.1516677 ]\n",
      "Modifying image pixdim from [0.625   0.625   3.59999 1.     ] to [  0.625        0.625        3.59998989 208.35237358]\n",
      "Modifying image pixdim from [0.6249999 0.6249999 3.6       1.       ] to [  0.62499988   0.62499988   3.5999999  152.06272679]\n",
      "Modifying image pixdim from [0.6249998 0.625     3.5999987 1.       ] to [  0.62499983   0.625        3.59999877 153.34152766]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  150.20609596]\n",
      "Modifying image pixdim from [0.6        0.60000014 4.0000005  1.        ] to [  0.60000002   0.60000017   4.00000043 128.8161199 ]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  150.52861008]\n",
      "Modifying image pixdim from [0.604167  0.6041667 3.999998  1.       ] to [  0.60416698   0.60416671   3.99999799 174.60244975]\n",
      "Modifying image pixdim from [0.62499976 0.62499976 3.6        1.        ] to [  0.62499976   0.62499976   3.5999999  164.74616031]\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 173.25173679]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  150.52861008]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625       0.625       3.5999999 152.3814254]\n",
      "Modifying image pixdim from [0.625      0.62500006 3.6000001  1.        ] to [  0.625        0.62500005   3.60000016 168.35859116]\n",
      "is_namedtuple is deprecated, please use the python checks instead\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  148.64025265]\n",
      "Modifying image pixdim from [0.6       0.5999997 3.999998  1.       ] to [  0.60000002   0.59999975   3.99999799 129.0477496 ]\n",
      "Modifying image pixdim from [0.6       0.5999997 3.999998  1.       ] to [  0.60000002   0.59999975   3.99999799 129.0477496 ]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  142.87013615]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625       0.625       3.5999999 152.3814254]\n",
      "is_namedtuple is deprecated, please use the python checks instead\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 149.1610426 ]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  170.38896694]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  160.67573396]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625       0.625       3.5999999 151.7973753]\n",
      "Modifying image pixdim from [0.625   0.625   3.60001 1.     ] to [  0.625        0.625        3.60000992 173.25173679]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625       0.625       3.5999999 152.3814254]\n",
      "Modifying image pixdim from [0.6       0.5999997 3.999998  1.       ] to [  0.60000002   0.59999975   3.99999799 129.0477496 ]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625       0.625       3.5999999 152.3814254]\n",
      "Modifying image pixdim from [0.625      0.62500006 3.6000001  1.        ] to [  0.625        0.62500005   3.60000016 168.35859116]\n",
      "Modifying image pixdim from [0.6       0.5999997 3.999998  1.       ] to [  0.60000002   0.59999975   3.99999799 129.0477496 ]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  150.52861008]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  150.52861008]\n",
      "Modifying image pixdim from [0.62499976 0.62499976 3.6        1.        ] to [  0.62499976   0.62499976   3.5999999  164.74616031]\n",
      "Modifying image pixdim from [0.604167  0.6041667 3.999998  1.       ] to [  0.60416698   0.60416671   3.99999799 174.60244975]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  142.87013615]\n",
      "Modifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  148.64025265]\n",
      "')\n",
      "2022-09-20 09:18:06,270 - INFO - Launching: torchrun --nnodes=1 --nproc_per_node=2 ./auto3dseg_work_dir/swinunetr_2/scripts/train.py run --config_file='./auto3dseg_work_dir/swinunetr_2/configs/transforms_validate.yaml','./auto3dseg_work_dir/swinunetr_2/configs/transforms_train.yaml','./auto3dseg_work_dir/swinunetr_2/configs/transforms_infer.yaml','./auto3dseg_work_dir/swinunetr_2/configs/network.yaml','./auto3dseg_work_dir/swinunetr_2/configs/hyper_parameters.yaml' --num_iterations=12 --num_iterations_per_validation=6 --num_images_per_batch=2 --num_epochs=2 --num_warmup_iterations=6\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "subprocess call error 1: b'WARNING:torch.distributed.run:\n*****************************************\nSetting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n*****************************************\nModifying image pixdim from [0.6        0.60000014 4.0000005  1.        ] to [  0.60000002   0.60000017   4.00000041 174.1516677 ]\nModifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625       0.625       3.5999999 151.7973753]\nModifying image pixdim from [0.625   0.625   3.59999 1.     ] to [  0.625        0.625        3.59998989 208.35237358]\nModifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  160.67573396]\nModifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  142.87013615]\nModifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  154.70488398]\nModifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  154.70488398]\nModifying image pixdim from [0.6       0.5999997 3.999998  1.       ] to [  0.60000002   0.59999975   3.99999799 117.82332812]\nModifying image pixdim from [0.6249998 0.625     3.5999987 1.       ] to [  0.62499983   0.625        3.59999877 153.34152766]\nModifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  170.38896694]\nModifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625       0.625       3.5999999 149.7974827]\nModifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625       0.625       3.5999999 152.3814254]\nTraceback (most recent call last):\n  File \"/workspace/monai/monai-in-dev/monai/transforms/croppad/array.py\", line 184, in __call__\n    out = _pad(img_t, pad_width=to_pad_, mode=mode_, **kwargs_)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/croppad/array.py\", line 138, in _pt_pad\n    return pad_pt(img.unsqueeze(0), pt_pad_width, mode=mode, **kwargs).squeeze(0)\n  File \"/workspace/monai/monai-in-dev/monai/data/meta_tensor.py\", line 249, in __torch_function__\n    ret = super().__torch_function__(func, types, args, kwargs)\n  File \"/opt/conda/lib/python3.8/site-packages/torch/_tensor.py\", line 1089, in __torch_function__\n    ret = func(*args, **kwargs)\nRuntimeError: Argument #4: Padding size should be less than the corresponding input dimension, but got: padding (22, 22) at dimension 4 of input [1, 2, 320, 320, 20]\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/workspace/monai/monai-in-dev/monai/transforms/transform.py\", line 91, in apply_transform\n    return _apply_transform(transform, data, unpack_items)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/transform.py\", line 55, in _apply_transform\n    return transform(parameters)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/croppad/dictionary.py\", line 147, in __call__\n    d[key] = self.padder(d[key], mode=m)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/croppad/array.py\", line 189, in __call__\n    raise ValueError(f\"{mode_}, {kwargs_}, {img_t.dtype}, {img_t.device}\") from err\nValueError: reflect, {}, torch.float32, cpu\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"./auto3dseg_work_dir/swinunetr_2/scripts/train.py\", line 409, in <module>\n    fire.Fire()\n  File \"/opt/conda/lib/python3.8/site-packages/fire/core.py\", line 141, in Fire\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n  File \"/opt/conda/lib/python3.8/site-packages/fire/core.py\", line 466, in _Fire\n    component, remaining_args = _CallAndUpdateTrace(\n  File \"/opt/conda/lib/python3.8/site-packages/fire/core.py\", line 681, in _CallAndUpdateTrace\n    component = fn(*varargs, **kwargs)\n  File \"./auto3dseg_work_dir/swinunetr_2/scripts/train.py\", line 141, in run\n    train_ds = monai.data.CacheDataset(\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 794, in __init__\n    self.set_data(data)\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 819, in set_data\n    self._cache = _compute_cache()\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 808, in _compute_cache\n    return self._fill_cache()\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 835, in _fill_cache\n    return list(p.imap(self._load_cache_item, range(self.cache_num)))\n  File \"/opt/conda/lib/python3.8/multiprocessing/pool.py\", line 868, in next\n    raise value\n  File \"/opt/conda/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 848, in _load_cache_item\n    item = apply_transform(_xform, item)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/transform.py\", line 118, in apply_transform\n    raise RuntimeError(f\"applying transform {transform}\") from e\nRuntimeError: applying transform <monai.transforms.croppad.dictionary.SpatialPadd object at 0x7f7e57967d00>\nTraceback (most recent call last):\n  File \"/workspace/monai/monai-in-dev/monai/transforms/croppad/array.py\", line 184, in __call__\n    out = _pad(img_t, pad_width=to_pad_, mode=mode_, **kwargs_)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/croppad/array.py\", line 138, in _pt_pad\n    return pad_pt(img.unsqueeze(0), pt_pad_width, mode=mode, **kwargs).squeeze(0)\n  File \"/workspace/monai/monai-in-dev/monai/data/meta_tensor.py\", line 249, in __torch_function__\n    ret = super().__torch_function__(func, types, args, kwargs)\n  File \"/opt/conda/lib/python3.8/site-packages/torch/_tensor.py\", line 1089, in __torch_function__\n    ret = func(*args, **kwargs)\nRuntimeError: Argument #4: Padding size should be less than the corresponding input dimension, but got: padding (22, 22) at dimension 4 of input [1, 2, 320, 320, 20]\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/workspace/monai/monai-in-dev/monai/transforms/transform.py\", line 91, in apply_transform\n    return _apply_transform(transform, data, unpack_items)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/transform.py\", line 55, in _apply_transform\n    return transform(parameters)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/croppad/dictionary.py\", line 147, in __call__\n    d[key] = self.padder(d[key], mode=m)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/croppad/array.py\", line 189, in __call__\n    raise ValueError(f\"{mode_}, {kwargs_}, {img_t.dtype}, {img_t.device}\") from err\nValueError: reflect, {}, torch.float32, cpu\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"./auto3dseg_work_dir/swinunetr_2/scripts/train.py\", line 409, in <module>\n    fire.Fire()\n  File \"/opt/conda/lib/python3.8/site-packages/fire/core.py\", line 141, in Fire\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n  File \"/opt/conda/lib/python3.8/site-packages/fire/core.py\", line 466, in _Fire\n    component, remaining_args = _CallAndUpdateTrace(\n  File \"/opt/conda/lib/python3.8/site-packages/fire/core.py\", line 681, in _CallAndUpdateTrace\n    component = fn(*varargs, **kwargs)\n  File \"./auto3dseg_work_dir/swinunetr_2/scripts/train.py\", line 141, in run\n    train_ds = monai.data.CacheDataset(\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 794, in __init__\n    self.set_data(data)\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 819, in set_data\n    self._cache = _compute_cache()\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 808, in _compute_cache\n    return self._fill_cache()\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 835, in _fill_cache\n    return list(p.imap(self._load_cache_item, range(self.cache_num)))\n  File \"/opt/conda/lib/python3.8/multiprocessing/pool.py\", line 868, in next\n    raise value\n  File \"/opt/conda/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 848, in _load_cache_item\n    item = apply_transform(_xform, item)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/transform.py\", line 118, in apply_transform\n    raise RuntimeError(f\"applying transform {transform}\") from e\nRuntimeError: applying transform <monai.transforms.croppad.dictionary.SpatialPadd object at 0x7fae56a13700>\nterminate called without an active exception\nterminate called recursively\nterminate called without an active exception\nERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: -6) local_rank: 0 (pid: 430021) of binary: /opt/conda/bin/python\nTraceback (most recent call last):\n  File \"/opt/conda/bin/torchrun\", line 33, in <module>\n    sys.exit(load_entry_point(\\'torch\\', \\'console_scripts\\', \\'torchrun\\')())\n  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/run.py\", line 761, in main\n    run(args)\n  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/run.py\", line 752, in run\n    elastic_launch(\n  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 132, in __call__\n    return launch_agent(self._config, self._entrypoint, list(args))\n  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 246, in launch_agent\n    raise ChildFailedError(\ntorch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n========================================================\n./auto3dseg_work_dir/swinunetr_2/scripts/train.py FAILED\n--------------------------------------------------------\nFailures:\n[1]:\n  time      : 2022-09-20_09:18:11\n  host      : adminn-MS-7D31\n  rank      : 1 (local_rank: 1)\n  exitcode  : -6 (pid: 430022)\n  error_file: <N/A>\n  traceback : Signal 6 (SIGABRT) received by PID 430022\n--------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2022-09-20_09:18:11\n  host      : adminn-MS-7D31\n  rank      : 0 (local_rank: 0)\n  exitcode  : -6 (pid: 430021)\n  error_file: <N/A>\n  traceback : Signal 6 (SIGABRT) received by PID 430021\n========================================================\n', b'[info] number of GPUs: 2\n[info] number of GPUs: 2\n2022-09-20 09:18:09,084 - Added key: store_based_barrier_key:1 to store for rank: 0\n2022-09-20 09:18:09,084 - Added key: store_based_barrier_key:1 to store for rank: 1\n2022-09-20 09:18:09,084 - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n2022-09-20 09:18:09,084 - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n[info] world_size: 2\n[info] world_size: 2\ntrain_files: 12\ntrain_files: 12\nval_files: 3val_files:\n 3\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/workspace/monai/monai-in-dev/monai/apps/auto3dseg/bundle_gen.py:183\u001b[0m, in \u001b[0;36mBundleAlgo._run_cmd\u001b[0;34m(self, cmd, devices_info)\u001b[0m\n\u001b[1;32m    182\u001b[0m     ps_environ[\u001b[39m\"\u001b[39m\u001b[39mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m devices_info\n\u001b[0;32m--> 183\u001b[0m normal_out \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mrun(cmd\u001b[39m.\u001b[39;49msplit(), env\u001b[39m=\u001b[39;49mps_environ, check\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, capture_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    184\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mrepr\u001b[39m(normal_out)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mn\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/subprocess.py:516\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[39mif\u001b[39;00m check \u001b[39mand\u001b[39;00m retcode:\n\u001b[0;32m--> 516\u001b[0m         \u001b[39mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[39m.\u001b[39margs,\n\u001b[1;32m    517\u001b[0m                                  output\u001b[39m=\u001b[39mstdout, stderr\u001b[39m=\u001b[39mstderr)\n\u001b[1;32m    518\u001b[0m \u001b[39mreturn\u001b[39;00m CompletedProcess(process\u001b[39m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['torchrun', '--nnodes=1', '--nproc_per_node=2', './auto3dseg_work_dir/swinunetr_2/scripts/train.py', 'run', \"--config_file='./auto3dseg_work_dir/swinunetr_2/configs/transforms_validate.yaml','./auto3dseg_work_dir/swinunetr_2/configs/transforms_train.yaml','./auto3dseg_work_dir/swinunetr_2/configs/transforms_infer.yaml','./auto3dseg_work_dir/swinunetr_2/configs/network.yaml','./auto3dseg_work_dir/swinunetr_2/configs/hyper_parameters.yaml'\", '--num_iterations=12', '--num_iterations_per_validation=6', '--num_images_per_batch=2', '--num_epochs=2', '--num_warmup_iterations=6']' returned non-zero exit status 1.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/workspace/monai/tutorials-in-dev/auto3dseg/notebooks/auto3dseg_autorunner_ref_api.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636861726d696e675f656469736f6e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f31302e31392e3138332e323231227d7d/workspace/monai/tutorials-in-dev/auto3dseg/notebooks/auto3dseg_autorunner_ref_api.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m task \u001b[39min\u001b[39;00m history:\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636861726d696e675f656469736f6e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f31302e31392e3138332e323231227d7d/workspace/monai/tutorials-in-dev/auto3dseg/notebooks/auto3dseg_autorunner_ref_api.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _, algo \u001b[39min\u001b[39;00m task\u001b[39m.\u001b[39mitems():\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636861726d696e675f656469736f6e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f31302e31392e3138332e323231227d7d/workspace/monai/tutorials-in-dev/auto3dseg/notebooks/auto3dseg_autorunner_ref_api.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m         algo\u001b[39m.\u001b[39;49mtrain(train_param)  \u001b[39m# can use default params by `algo.train()`\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636861726d696e675f656469736f6e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f31302e31392e3138332e323231227d7d/workspace/monai/tutorials-in-dev/auto3dseg/notebooks/auto3dseg_autorunner_ref_api.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m         acc \u001b[39m=\u001b[39m algo\u001b[39m.\u001b[39mget_score()\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636861726d696e675f656469736f6e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f31302e31392e3138332e323231227d7d/workspace/monai/tutorials-in-dev/auto3dseg/notebooks/auto3dseg_autorunner_ref_api.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m         algo_to_pickle(algo, template_path\u001b[39m=\u001b[39malgo\u001b[39m.\u001b[39mtemplate_path, best_metrics\u001b[39m=\u001b[39macc)\n",
      "File \u001b[0;32m/workspace/monai/monai-in-dev/monai/apps/auto3dseg/bundle_gen.py:200\u001b[0m, in \u001b[0;36mBundleAlgo.train\u001b[0;34m(self, train_params)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[39mLoad the run function in the training script of each model. Training parameter is predefined by the\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39malgo_config.yaml file, which is pre-filled by the fill_template_config function in the same instance.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39m    train_params:  to specify the devices using a list of integers: ``{\"CUDA_VISIBLE_DEVICES\": [1,2,3]}``.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    199\u001b[0m cmd, devices_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_cmd(train_params)\n\u001b[0;32m--> 200\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_cmd(cmd, devices_info)\n",
      "File \u001b[0;32m/workspace/monai/monai-in-dev/monai/apps/auto3dseg/bundle_gen.py:188\u001b[0m, in \u001b[0;36mBundleAlgo._run_cmd\u001b[0;34m(self, cmd, devices_info)\u001b[0m\n\u001b[1;32m    186\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mrepr\u001b[39m(e\u001b[39m.\u001b[39mstdout)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mn\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    187\u001b[0m     errors \u001b[39m=\u001b[39m \u001b[39mrepr\u001b[39m(e\u001b[39m.\u001b[39mstderr)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mn\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 188\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msubprocess call error \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m.\u001b[39mreturncode\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00merrors\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00moutput\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[39mreturn\u001b[39;00m normal_out\n",
      "\u001b[0;31mRuntimeError\u001b[0m: subprocess call error 1: b'WARNING:torch.distributed.run:\n*****************************************\nSetting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n*****************************************\nModifying image pixdim from [0.6        0.60000014 4.0000005  1.        ] to [  0.60000002   0.60000017   4.00000041 174.1516677 ]\nModifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625       0.625       3.5999999 151.7973753]\nModifying image pixdim from [0.625   0.625   3.59999 1.     ] to [  0.625        0.625        3.59998989 208.35237358]\nModifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  160.67573396]\nModifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  142.87013615]\nModifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  154.70488398]\nModifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  154.70488398]\nModifying image pixdim from [0.6       0.5999997 3.999998  1.       ] to [  0.60000002   0.59999975   3.99999799 117.82332812]\nModifying image pixdim from [0.6249998 0.625     3.5999987 1.       ] to [  0.62499983   0.625        3.59999877 153.34152766]\nModifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625        0.625        3.5999999  170.38896694]\nModifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625       0.625       3.5999999 149.7974827]\nModifying image pixdim from [0.625 0.625 3.6   1.   ] to [  0.625       0.625       3.5999999 152.3814254]\nTraceback (most recent call last):\n  File \"/workspace/monai/monai-in-dev/monai/transforms/croppad/array.py\", line 184, in __call__\n    out = _pad(img_t, pad_width=to_pad_, mode=mode_, **kwargs_)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/croppad/array.py\", line 138, in _pt_pad\n    return pad_pt(img.unsqueeze(0), pt_pad_width, mode=mode, **kwargs).squeeze(0)\n  File \"/workspace/monai/monai-in-dev/monai/data/meta_tensor.py\", line 249, in __torch_function__\n    ret = super().__torch_function__(func, types, args, kwargs)\n  File \"/opt/conda/lib/python3.8/site-packages/torch/_tensor.py\", line 1089, in __torch_function__\n    ret = func(*args, **kwargs)\nRuntimeError: Argument #4: Padding size should be less than the corresponding input dimension, but got: padding (22, 22) at dimension 4 of input [1, 2, 320, 320, 20]\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/workspace/monai/monai-in-dev/monai/transforms/transform.py\", line 91, in apply_transform\n    return _apply_transform(transform, data, unpack_items)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/transform.py\", line 55, in _apply_transform\n    return transform(parameters)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/croppad/dictionary.py\", line 147, in __call__\n    d[key] = self.padder(d[key], mode=m)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/croppad/array.py\", line 189, in __call__\n    raise ValueError(f\"{mode_}, {kwargs_}, {img_t.dtype}, {img_t.device}\") from err\nValueError: reflect, {}, torch.float32, cpu\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"./auto3dseg_work_dir/swinunetr_2/scripts/train.py\", line 409, in <module>\n    fire.Fire()\n  File \"/opt/conda/lib/python3.8/site-packages/fire/core.py\", line 141, in Fire\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n  File \"/opt/conda/lib/python3.8/site-packages/fire/core.py\", line 466, in _Fire\n    component, remaining_args = _CallAndUpdateTrace(\n  File \"/opt/conda/lib/python3.8/site-packages/fire/core.py\", line 681, in _CallAndUpdateTrace\n    component = fn(*varargs, **kwargs)\n  File \"./auto3dseg_work_dir/swinunetr_2/scripts/train.py\", line 141, in run\n    train_ds = monai.data.CacheDataset(\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 794, in __init__\n    self.set_data(data)\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 819, in set_data\n    self._cache = _compute_cache()\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 808, in _compute_cache\n    return self._fill_cache()\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 835, in _fill_cache\n    return list(p.imap(self._load_cache_item, range(self.cache_num)))\n  File \"/opt/conda/lib/python3.8/multiprocessing/pool.py\", line 868, in next\n    raise value\n  File \"/opt/conda/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 848, in _load_cache_item\n    item = apply_transform(_xform, item)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/transform.py\", line 118, in apply_transform\n    raise RuntimeError(f\"applying transform {transform}\") from e\nRuntimeError: applying transform <monai.transforms.croppad.dictionary.SpatialPadd object at 0x7f7e57967d00>\nTraceback (most recent call last):\n  File \"/workspace/monai/monai-in-dev/monai/transforms/croppad/array.py\", line 184, in __call__\n    out = _pad(img_t, pad_width=to_pad_, mode=mode_, **kwargs_)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/croppad/array.py\", line 138, in _pt_pad\n    return pad_pt(img.unsqueeze(0), pt_pad_width, mode=mode, **kwargs).squeeze(0)\n  File \"/workspace/monai/monai-in-dev/monai/data/meta_tensor.py\", line 249, in __torch_function__\n    ret = super().__torch_function__(func, types, args, kwargs)\n  File \"/opt/conda/lib/python3.8/site-packages/torch/_tensor.py\", line 1089, in __torch_function__\n    ret = func(*args, **kwargs)\nRuntimeError: Argument #4: Padding size should be less than the corresponding input dimension, but got: padding (22, 22) at dimension 4 of input [1, 2, 320, 320, 20]\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/workspace/monai/monai-in-dev/monai/transforms/transform.py\", line 91, in apply_transform\n    return _apply_transform(transform, data, unpack_items)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/transform.py\", line 55, in _apply_transform\n    return transform(parameters)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/croppad/dictionary.py\", line 147, in __call__\n    d[key] = self.padder(d[key], mode=m)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/croppad/array.py\", line 189, in __call__\n    raise ValueError(f\"{mode_}, {kwargs_}, {img_t.dtype}, {img_t.device}\") from err\nValueError: reflect, {}, torch.float32, cpu\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"./auto3dseg_work_dir/swinunetr_2/scripts/train.py\", line 409, in <module>\n    fire.Fire()\n  File \"/opt/conda/lib/python3.8/site-packages/fire/core.py\", line 141, in Fire\n    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n  File \"/opt/conda/lib/python3.8/site-packages/fire/core.py\", line 466, in _Fire\n    component, remaining_args = _CallAndUpdateTrace(\n  File \"/opt/conda/lib/python3.8/site-packages/fire/core.py\", line 681, in _CallAndUpdateTrace\n    component = fn(*varargs, **kwargs)\n  File \"./auto3dseg_work_dir/swinunetr_2/scripts/train.py\", line 141, in run\n    train_ds = monai.data.CacheDataset(\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 794, in __init__\n    self.set_data(data)\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 819, in set_data\n    self._cache = _compute_cache()\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 808, in _compute_cache\n    return self._fill_cache()\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 835, in _fill_cache\n    return list(p.imap(self._load_cache_item, range(self.cache_num)))\n  File \"/opt/conda/lib/python3.8/multiprocessing/pool.py\", line 868, in next\n    raise value\n  File \"/opt/conda/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/workspace/monai/monai-in-dev/monai/data/dataset.py\", line 848, in _load_cache_item\n    item = apply_transform(_xform, item)\n  File \"/workspace/monai/monai-in-dev/monai/transforms/transform.py\", line 118, in apply_transform\n    raise RuntimeError(f\"applying transform {transform}\") from e\nRuntimeError: applying transform <monai.transforms.croppad.dictionary.SpatialPadd object at 0x7fae56a13700>\nterminate called without an active exception\nterminate called recursively\nterminate called without an active exception\nERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: -6) local_rank: 0 (pid: 430021) of binary: /opt/conda/bin/python\nTraceback (most recent call last):\n  File \"/opt/conda/bin/torchrun\", line 33, in <module>\n    sys.exit(load_entry_point(\\'torch\\', \\'console_scripts\\', \\'torchrun\\')())\n  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/run.py\", line 761, in main\n    run(args)\n  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/run.py\", line 752, in run\n    elastic_launch(\n  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 132, in __call__\n    return launch_agent(self._config, self._entrypoint, list(args))\n  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 246, in launch_agent\n    raise ChildFailedError(\ntorch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n========================================================\n./auto3dseg_work_dir/swinunetr_2/scripts/train.py FAILED\n--------------------------------------------------------\nFailures:\n[1]:\n  time      : 2022-09-20_09:18:11\n  host      : adminn-MS-7D31\n  rank      : 1 (local_rank: 1)\n  exitcode  : -6 (pid: 430022)\n  error_file: <N/A>\n  traceback : Signal 6 (SIGABRT) received by PID 430022\n--------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2022-09-20_09:18:11\n  host      : adminn-MS-7D31\n  rank      : 0 (local_rank: 0)\n  exitcode  : -6 (pid: 430021)\n  error_file: <N/A>\n  traceback : Signal 6 (SIGABRT) received by PID 430021\n========================================================\n', b'[info] number of GPUs: 2\n[info] number of GPUs: 2\n2022-09-20 09:18:09,084 - Added key: store_based_barrier_key:1 to store for rank: 0\n2022-09-20 09:18:09,084 - Added key: store_based_barrier_key:1 to store for rank: 1\n2022-09-20 09:18:09,084 - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n2022-09-20 09:18:09,084 - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.\n[info] world_size: 2\n[info] world_size: 2\ntrain_files: 12\ntrain_files: 12\nval_files: 3val_files:\n 3\n'"
     ]
    }
   ],
   "source": [
    "history = import_bundle_algo_history(work_dir, only_trained=False)\n",
    "for task in history:\n",
    "    for _, algo in task.items():\n",
    "        algo.train(train_param)  # can use default params by `algo.train()`\n",
    "        acc = algo.get_score()\n",
    "        algo_to_pickle(algo, template_path=algo.template_path, best_metrics=acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Train with Hyper-parameter Optimization (HPO)\n",
    "\n",
    "Another method to handle the neural network training is to perform HPO (e.g. training & searching). This is made possible by NNI or Optuna packages which are installed in the MONAI development environment. `AutoRunner` uses NNI as backend via the `NNIGen`, but Optuna HPO can also be chosen via the `OptunaGen` method in the Auto3Dseg pipeline\n",
    "\n",
    "To start a NNI, the users need to prepare a config file `nni_config.yaml` and run the command in bash:\n",
    "\n",
    "```bash\n",
    "nnictl create --config nni_config.yaml\n",
    "```\n",
    "\n",
    "Below is an example of the config:\n",
    "```\n",
    "default_nni_config = {\n",
    "    \"experimentName\": name,\n",
    "    \"search_space\": search_space,\n",
    "    \"trialCommand\": cmd,\n",
    "    \"trialCodeDirectory\": \".\",\n",
    "    \"trialGpuNumber\": torch.cuda.device_count(),\n",
    "    \"trialConcurrency\": 1,\n",
    "    \"maxTrialNumber\": 10,\n",
    "    \"maxExperimentDuration\": \"1h\",\n",
    "    \"tuner\": {\"name\": \"GridSearch\"},\n",
    "    \"trainingService\": {\"platform\": \"local\", \"useActiveGpu\": True},\n",
    "}\n",
    "```\n",
    "\n",
    "Example of the search space:\n",
    "```python\n",
    "search_space = {\"_type\": \"choice\", \"_value\": [0.0001, 0.001, 0.01, 0.1]}}\n",
    "```\n",
    "\n",
    "Example of the search command for `segresnet_0`\n",
    "```python\n",
    "cmd = \"python -m monai.apps.auto3dseg NNIGen run_algo \" + \"./auto3dseg/segresnet_0/algo_object.pkl\" + \" ./auto3dseg\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Ensemble\n",
    "\n",
    "Finally, after the neural networks are trained, `AutoRunner` will apply the ensemble methods in Auto3Dseg to improve the overall performance. \n",
    "\n",
    "Here we used a utility function `import_bundle_algo_history` to load the `Algo` that are trained into the ensemble. With the history loaded, we build an ensemble method and use the method to perform the inference on all testing data. By default, `AutoRunner` uses the `AlgoEnsembleBestN` to find the best N models and ensemble the prediction maps by taking the mean of the feature maps.\n",
    "\n",
    "Note: Because we need to get the prediction in Python, there are no CLI command suggestion in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = import_bundle_algo_history(work_dir, only_trained=True)\n",
    "builder = AlgoEnsembleBuilder(history, input)\n",
    "builder.set_ensemble_method(AlgoEnsembleBestN(n_best=5))\n",
    "ensembler = builder.get_ensemble()\n",
    "preds = ensembler()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
