{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use MLflow in MONAI Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MLflow](https://mlflow.org/) is an experiment management tool that can be used for logging experiment details and results in machine learning experiments. The MONAI workflow integrates mlflow as a part of it to make it convenient for users recording their experiments. This tutorial shows how to enable it in MONAI bundle workflow from three aspects.\n",
    "1. Use MLflow in MONAI bundle by default.\n",
    "2. Use MLflow in MONAI bundle with a config file.\n",
    "3. Use MLflow in parsed MONAI bundle with python code.\n",
    "\n",
    "This tutorial takes the [3D spleen segmentation task](https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/spleen_segmentation_3d.ipynb) as an example. In order to quickly verify the MLflow function, each example will only run 5 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MLFlow` comes as part of the `monai[all]` installation. For official documentation on MLFlow's experiment management functionalities, click [here](https://www.mlflow.org/docs/latest/tracking.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[gdown, nibabel, tqdm, ignite]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import monai\n",
    "import tempfile\n",
    "from monai.apps import download_and_extract\n",
    "from monai.bundle import ConfigParser\n",
    "from monai.handlers import MLFlowHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data directory\n",
    "\n",
    "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable. This allows you to save results and reuse downloads. If not specified a temporary directory will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MONAI_DATA_DIRECTORY=/workspace/data/medical\n",
      "/workspace/data/medical\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download spleen dataset\n",
    "Downloads and extracts the dataset. The dataset comes from http://medicaldecathlon.com/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/data/medical/Task09_Spleen\n"
     ]
    }
   ],
   "source": [
    "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task09_Spleen.tar\"\n",
    "md5 = \"410d4a301da4e5b2f6f86ec3ddba524e\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"Task09_Spleen.tar\")\n",
    "data_dir = os.path.join(root_dir, \"Task09_Spleen\")\n",
    "print(data_dir)\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use MLflow in MONAI bundle\n",
    "\n",
    "In this part, we will take the [spleen segmentation bundle](https://github.com/Project-MONAI/model-zoo/tree/dev/models/spleen_ct_segmentation) as an example to show how to enable MLflow in it. Typically there are two ways to enable MLflow in a bundle training process. The easiest way is to add `--tracking \"mlflow\"` at the end of the command line. Some extra parameters like `tracking_uri` and `experiment_name` can also be added this way. The second is to add a config json file as input. In this file, users can define their own setting on MLflow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download spleen segmentation bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-09 03:08:01,304 - INFO - --- input summary of monai.bundle.scripts.download ---\n",
      "2022-12-09 03:08:01,305 - INFO - > name: 'spleen_ct_segmentation'\n",
      "2022-12-09 03:08:01,306 - INFO - > version: '0.3.7'\n",
      "2022-12-09 03:08:01,306 - INFO - > bundle_dir: './'\n",
      "2022-12-09 03:08:01,306 - INFO - > source: 'github'\n",
      "2022-12-09 03:08:01,307 - INFO - > repo: 'Project-MONAI/model-zoo/hosting_storage_v1'\n",
      "2022-12-09 03:08:01,307 - INFO - > progress: True\n",
      "2022-12-09 03:08:01,307 - INFO - ---\n",
      "\n",
      "\n",
      "2022-12-09 03:08:01,308 - INFO - Expected md5 is None, skip md5 check for file spleen_ct_segmentation_v0.3.7.zip.\n",
      "2022-12-09 03:08:01,308 - INFO - File exists: spleen_ct_segmentation_v0.3.7.zip, skipped downloading.\n",
      "2022-12-09 03:08:01,308 - INFO - Writing into directory: ..\n"
     ]
    }
   ],
   "source": [
    "monai.bundle.download(name=\"spleen_ct_segmentation\", version=\"0.3.7\", bundle_dir=\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run spleen bundle with MLflow parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command line in the next cell is the easiest way to run the spleen segementation training  bundle with mlflow. Please modify the `--dataset_dir` with your own path of dataset. The parameter `--tracking \"mlflow\"` at the end of the original command is to enable the mlflow during training. Parameters `--tracking_uri`, `--experiment_name` and `--run_name` can also be added and modified to change the tracking uri, experiment name and run name of mlflow. To enable MLflow in multi-gpu training is as the same with single gpu by adding `--tracking \"mlflow\"` to the end of command line. \n",
    "\n",
    "A `mlruns` folder will be created in the `spleen_ct_segmentation/eval` folder during the running. Running the command `mlflow ui` in this folder can set a webpage UI for tracking. By default, the address will be `http://127.0.0.1:5000`. If there is a confliction of port or host address, `--port` and `--host` parameters can be modified to new one. \n",
    "Here is the tracking result.\n",
    "![image](./extra_pics/mlflow_default_result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-09 03:08:04,152 - INFO - --- input summary of monai.bundle.scripts.run ---\n",
      "2022-12-09 03:08:04,152 - INFO - > runner_id: 'training'\n",
      "2022-12-09 03:08:04,152 - INFO - > meta_file: 'configs/metadata.json'\n",
      "2022-12-09 03:08:04,152 - INFO - > config_file: 'configs/train.json'\n",
      "2022-12-09 03:08:04,152 - INFO - > logging_file: 'configs/logging.conf'\n",
      "2022-12-09 03:08:04,152 - INFO - > tracking: 'mlflow'\n",
      "2022-12-09 03:08:04,152 - INFO - > bundle_root: './'\n",
      "2022-12-09 03:08:04,152 - INFO - > dataset_dir: '/workspace/data/medical/Task09_Spleen'\n",
      "2022-12-09 03:08:04,152 - INFO - > train#trainer#max_epochs: 10\n",
      "2022-12-09 03:08:04,152 - INFO - ---\n",
      "\n",
      "\n",
      "2022-12-09 03:08:04,152 - INFO - set logging properties based on config: configs/logging.conf.\n",
      "Loading dataset: 100%|██████████████████████████| 32/32 [00:21<00:00,  1.49it/s]\n",
      "Loading dataset: 100%|████████████████████████████| 9/9 [00:10<00:00,  1.13s/it]\n",
      "2022-12-09 03:08:37,943 - ignite.engine.engine.SupervisedTrainer - INFO - Engine run resuming from iteration 0, epoch 0 until 10 epochs\n",
      "2022/12/09 03:08:37 INFO mlflow.tracking.fluent: Experiment with name 'monai_experiment' does not exist. Creating a new experiment.\n",
      "2022-12-09 03:08:41,235 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 1/16 -- train_loss: 1.5364 \n",
      "2022-12-09 03:08:41,327 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 2/16 -- train_loss: 1.5299 \n",
      "2022-12-09 03:08:41,420 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 3/16 -- train_loss: 1.4873 \n",
      "2022-12-09 03:08:41,518 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 4/16 -- train_loss: 1.5010 \n",
      "2022-12-09 03:08:41,657 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 5/16 -- train_loss: 1.5109 \n",
      "2022-12-09 03:08:41,753 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 6/16 -- train_loss: 1.5003 \n",
      "2022-12-09 03:08:41,897 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 7/16 -- train_loss: 1.4706 \n",
      "2022-12-09 03:08:41,990 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 8/16 -- train_loss: 1.3903 \n",
      "2022-12-09 03:08:42,104 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 9/16 -- train_loss: 1.4331 \n",
      "2022-12-09 03:08:42,217 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 10/16 -- train_loss: 1.3766 \n",
      "2022-12-09 03:08:42,327 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 11/16 -- train_loss: 1.3845 \n",
      "2022-12-09 03:08:42,436 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 12/16 -- train_loss: 1.3429 \n",
      "2022-12-09 03:08:42,545 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 13/16 -- train_loss: 1.3879 \n",
      "2022-12-09 03:08:42,655 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 14/16 -- train_loss: 1.3377 \n",
      "2022-12-09 03:08:42,784 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 15/16 -- train_loss: 1.3041 \n",
      "2022-12-09 03:08:42,873 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 16/16 -- train_loss: 1.3647 \n",
      "2022-12-09 03:08:42,874 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.4414298004574246\n",
      "2022-12-09 03:08:42,875 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[1] Metrics -- train_accuracy: 0.4414 \n",
      "2022-12-09 03:08:42,875 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.4414298004574246 at epoch: 1\n",
      "2022-12-09 03:08:42,875 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[1] Complete. Time taken: 00:00:04.176\n",
      "2022-12-09 03:08:43,662 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 1/16 -- train_loss: 1.3636 \n",
      "2022-12-09 03:08:43,895 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 2/16 -- train_loss: 1.3071 \n",
      "2022-12-09 03:08:43,995 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 3/16 -- train_loss: 1.3390 \n",
      "2022-12-09 03:08:44,094 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 4/16 -- train_loss: 1.3669 \n",
      "2022-12-09 03:08:44,212 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 5/16 -- train_loss: 1.3734 \n",
      "2022-12-09 03:08:44,332 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 6/16 -- train_loss: 1.3274 \n",
      "2022-12-09 03:08:44,473 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 7/16 -- train_loss: 1.2474 \n",
      "2022-12-09 03:08:44,589 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 8/16 -- train_loss: 1.2438 \n",
      "2022-12-09 03:08:44,727 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 9/16 -- train_loss: 1.2473 \n",
      "2022-12-09 03:08:44,819 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 10/16 -- train_loss: 1.2577 \n",
      "2022-12-09 03:08:44,930 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 11/16 -- train_loss: 1.2939 \n",
      "2022-12-09 03:08:45,040 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 12/16 -- train_loss: 1.3326 \n",
      "2022-12-09 03:08:45,170 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 13/16 -- train_loss: 1.3386 \n",
      "2022-12-09 03:08:45,280 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 14/16 -- train_loss: 1.2417 \n",
      "2022-12-09 03:08:45,370 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 15/16 -- train_loss: 1.2410 \n",
      "2022-12-09 03:08:45,481 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 16/16 -- train_loss: 1.2734 \n",
      "2022-12-09 03:08:45,482 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.45736187475698964\n",
      "2022-12-09 03:08:45,482 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[2] Metrics -- train_accuracy: 0.4574 \n",
      "2022-12-09 03:08:45,482 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.45736187475698964 at epoch: 2\n",
      "2022-12-09 03:08:45,482 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[2] Complete. Time taken: 00:00:02.607\n",
      "2022-12-09 03:08:46,470 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 1/16 -- train_loss: 1.2456 \n",
      "2022-12-09 03:08:46,629 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 2/16 -- train_loss: 1.2104 \n",
      "2022-12-09 03:08:46,726 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 3/16 -- train_loss: 1.1972 \n",
      "2022-12-09 03:08:46,825 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 4/16 -- train_loss: 1.1688 \n",
      "2022-12-09 03:08:47,017 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 5/16 -- train_loss: 1.2475 \n",
      "2022-12-09 03:08:47,144 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 6/16 -- train_loss: 1.2491 \n",
      "2022-12-09 03:08:47,243 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 7/16 -- train_loss: 1.2617 \n",
      "2022-12-09 03:08:47,343 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 8/16 -- train_loss: 1.2395 \n",
      "2022-12-09 03:08:47,529 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 9/16 -- train_loss: 1.2060 \n",
      "2022-12-09 03:08:47,619 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 10/16 -- train_loss: 1.1786 \n",
      "2022-12-09 03:08:47,709 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 11/16 -- train_loss: 1.2018 \n",
      "2022-12-09 03:08:47,798 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 12/16 -- train_loss: 1.2141 \n",
      "2022-12-09 03:08:47,965 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 13/16 -- train_loss: 1.1967 \n",
      "2022-12-09 03:08:48,055 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 14/16 -- train_loss: 1.2033 \n",
      "2022-12-09 03:08:48,144 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 15/16 -- train_loss: 1.1991 \n",
      "2022-12-09 03:08:48,233 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 16/16 -- train_loss: 1.2184 \n",
      "2022-12-09 03:08:48,235 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.5076389312744141\n",
      "2022-12-09 03:08:48,235 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[3] Metrics -- train_accuracy: 0.5076 \n",
      "2022-12-09 03:08:48,235 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.5076389312744141 at epoch: 3\n",
      "2022-12-09 03:08:48,235 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[3] Complete. Time taken: 00:00:02.753\n",
      "2022-12-09 03:08:49,275 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 1/16 -- train_loss: 1.1402 \n",
      "2022-12-09 03:08:49,372 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 2/16 -- train_loss: 1.1186 \n",
      "2022-12-09 03:08:49,468 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 3/16 -- train_loss: 1.1000 \n",
      "2022-12-09 03:08:49,568 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 4/16 -- train_loss: 1.2314 \n",
      "2022-12-09 03:08:49,807 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 5/16 -- train_loss: 1.1512 \n",
      "2022-12-09 03:08:49,902 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 6/16 -- train_loss: 1.1858 \n",
      "2022-12-09 03:08:50,000 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 7/16 -- train_loss: 1.2349 \n",
      "2022-12-09 03:08:50,099 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 8/16 -- train_loss: 1.2411 \n",
      "2022-12-09 03:08:50,248 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 9/16 -- train_loss: 1.1151 \n",
      "2022-12-09 03:08:50,338 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 10/16 -- train_loss: 1.2122 \n",
      "2022-12-09 03:08:50,469 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 11/16 -- train_loss: 1.2287 \n",
      "2022-12-09 03:08:50,559 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 12/16 -- train_loss: 1.2275 \n",
      "2022-12-09 03:08:50,669 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 13/16 -- train_loss: 1.1740 \n",
      "2022-12-09 03:08:50,779 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 14/16 -- train_loss: 1.1569 \n",
      "2022-12-09 03:08:50,888 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 15/16 -- train_loss: 1.1312 \n",
      "2022-12-09 03:08:50,997 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 16/16 -- train_loss: 1.1199 \n",
      "2022-12-09 03:08:50,998 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.5632316183160853\n",
      "2022-12-09 03:08:50,998 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[4] Metrics -- train_accuracy: 0.5632 \n",
      "2022-12-09 03:08:50,998 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.5632316183160853 at epoch: 4\n",
      "2022-12-09 03:08:50,999 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[4] Complete. Time taken: 00:00:02.763\n",
      "2022-12-09 03:08:51,912 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 1/16 -- train_loss: 1.1660 \n",
      "2022-12-09 03:08:52,065 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 2/16 -- train_loss: 1.1599 \n",
      "2022-12-09 03:08:52,206 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 3/16 -- train_loss: 1.1252 \n",
      "2022-12-09 03:08:52,302 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 4/16 -- train_loss: 1.0192 \n",
      "2022-12-09 03:08:52,631 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 5/16 -- train_loss: 1.1297 \n",
      "2022-12-09 03:08:52,725 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 6/16 -- train_loss: 1.1494 \n",
      "2022-12-09 03:08:52,820 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 7/16 -- train_loss: 1.1494 \n",
      "2022-12-09 03:08:52,920 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 8/16 -- train_loss: 1.1959 \n",
      "2022-12-09 03:08:53,129 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 9/16 -- train_loss: 1.2127 \n",
      "2022-12-09 03:08:53,219 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 10/16 -- train_loss: 1.0702 \n",
      "2022-12-09 03:08:53,308 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 11/16 -- train_loss: 1.0966 \n",
      "2022-12-09 03:08:53,398 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 12/16 -- train_loss: 1.1724 \n",
      "2022-12-09 03:08:53,508 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 13/16 -- train_loss: 1.0640 \n",
      "2022-12-09 03:08:53,638 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 14/16 -- train_loss: 1.0819 \n",
      "2022-12-09 03:08:53,729 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 15/16 -- train_loss: 1.0933 \n",
      "2022-12-09 03:08:53,840 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 16/16 -- train_loss: 1.0995 \n",
      "2022-12-09 03:08:53,841 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.626623374444467\n",
      "2022-12-09 03:08:53,842 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run resuming from iteration 0, epoch 4 until 5 epochs\n",
      "2022-12-09 03:08:57,565 - ignite.engine.engine.SupervisedEvaluator - INFO - Got new best metric of val_mean_dice: 0.04803755134344101\n",
      "2022-12-09 03:08:57,565 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[5] Metrics -- val_accuracy: 0.7500 val_mean_dice: 0.0480 \n",
      "2022-12-09 03:08:57,565 - ignite.engine.engine.SupervisedEvaluator - INFO - Key metric: val_mean_dice best value: 0.04803755134344101 at epoch: 5\n",
      "2022-12-09 03:08:57,602 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[5] Complete. Time taken: 00:00:03.463\n",
      "2022-12-09 03:08:57,602 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run complete. Time taken: 00:00:03.761\n",
      "2022-12-09 03:08:57,704 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[5] Metrics -- train_accuracy: 0.6266 \n",
      "2022-12-09 03:08:57,704 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.626623374444467 at epoch: 5\n",
      "2022-12-09 03:08:57,705 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[5] Complete. Time taken: 00:00:06.706\n",
      "2022-12-09 03:08:58,584 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 1/16 -- train_loss: 1.1457 \n",
      "2022-12-09 03:08:58,772 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 2/16 -- train_loss: 1.1030 \n",
      "2022-12-09 03:08:58,868 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 3/16 -- train_loss: 1.0931 \n",
      "2022-12-09 03:08:58,980 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 4/16 -- train_loss: 1.0559 \n",
      "2022-12-09 03:08:59,121 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 5/16 -- train_loss: 1.1182 \n",
      "2022-12-09 03:08:59,259 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 6/16 -- train_loss: 1.1016 \n",
      "2022-12-09 03:08:59,376 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 7/16 -- train_loss: 1.0591 \n",
      "2022-12-09 03:08:59,478 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 8/16 -- train_loss: 1.1271 \n",
      "2022-12-09 03:08:59,719 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 9/16 -- train_loss: 1.0882 \n",
      "2022-12-09 03:08:59,808 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 10/16 -- train_loss: 1.0261 \n",
      "2022-12-09 03:08:59,898 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 11/16 -- train_loss: 1.0374 \n",
      "2022-12-09 03:08:59,988 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 12/16 -- train_loss: 1.0899 \n",
      "2022-12-09 03:09:00,157 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 13/16 -- train_loss: 1.0381 \n",
      "2022-12-09 03:09:00,247 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 14/16 -- train_loss: 0.9745 \n",
      "2022-12-09 03:09:00,337 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 15/16 -- train_loss: 1.0226 \n",
      "2022-12-09 03:09:00,427 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 16/16 -- train_loss: 1.0637 \n",
      "2022-12-09 03:09:00,428 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.7156343283476653\n",
      "2022-12-09 03:09:00,429 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[6] Metrics -- train_accuracy: 0.7156 \n",
      "2022-12-09 03:09:00,429 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.7156343283476653 at epoch: 6\n",
      "2022-12-09 03:09:00,429 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[6] Complete. Time taken: 00:00:02.724\n",
      "2022-12-09 03:09:01,351 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 1/16 -- train_loss: 0.9754 \n",
      "2022-12-09 03:09:01,451 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 2/16 -- train_loss: 1.0061 \n",
      "2022-12-09 03:09:01,639 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 3/16 -- train_loss: 1.0463 \n",
      "2022-12-09 03:09:01,740 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 4/16 -- train_loss: 1.0894 \n",
      "2022-12-09 03:09:01,871 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 5/16 -- train_loss: 1.0334 \n",
      "2022-12-09 03:09:02,053 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 6/16 -- train_loss: 1.0240 \n",
      "2022-12-09 03:09:02,153 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 7/16 -- train_loss: 1.0488 \n",
      "2022-12-09 03:09:02,248 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 8/16 -- train_loss: 1.0326 \n",
      "2022-12-09 03:09:02,438 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 9/16 -- train_loss: 1.0070 \n",
      "2022-12-09 03:09:02,530 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 10/16 -- train_loss: 0.9675 \n",
      "2022-12-09 03:09:02,640 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 11/16 -- train_loss: 0.9813 \n",
      "2022-12-09 03:09:02,749 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 12/16 -- train_loss: 1.0632 \n",
      "2022-12-09 03:09:02,899 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 13/16 -- train_loss: 1.0636 \n",
      "2022-12-09 03:09:02,989 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 14/16 -- train_loss: 1.0622 \n",
      "2022-12-09 03:09:03,079 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 15/16 -- train_loss: 0.9367 \n",
      "2022-12-09 03:09:03,189 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 16/16 -- train_loss: 1.0709 \n",
      "2022-12-09 03:09:03,191 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.812228450068721\n",
      "2022-12-09 03:09:03,191 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[7] Metrics -- train_accuracy: 0.8122 \n",
      "2022-12-09 03:09:03,191 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.812228450068721 at epoch: 7\n",
      "2022-12-09 03:09:03,191 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[7] Complete. Time taken: 00:00:02.762\n",
      "2022-12-09 03:09:04,004 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 1/16 -- train_loss: 1.0404 \n",
      "2022-12-09 03:09:04,104 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 2/16 -- train_loss: 1.0352 \n",
      "2022-12-09 03:09:04,248 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 3/16 -- train_loss: 1.1429 \n",
      "2022-12-09 03:09:04,345 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 4/16 -- train_loss: 1.0167 \n",
      "2022-12-09 03:09:04,508 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 5/16 -- train_loss: 0.9630 \n",
      "2022-12-09 03:09:04,613 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 6/16 -- train_loss: 0.9736 \n",
      "2022-12-09 03:09:04,790 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 7/16 -- train_loss: 1.0373 \n",
      "2022-12-09 03:09:04,886 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 8/16 -- train_loss: 0.9325 \n",
      "2022-12-09 03:09:05,028 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 9/16 -- train_loss: 0.9106 \n",
      "2022-12-09 03:09:05,119 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 10/16 -- train_loss: 0.9815 \n",
      "2022-12-09 03:09:05,304 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 11/16 -- train_loss: 1.0576 \n",
      "2022-12-09 03:09:05,394 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 12/16 -- train_loss: 1.0148 \n",
      "2022-12-09 03:09:05,484 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 13/16 -- train_loss: 0.9699 \n",
      "2022-12-09 03:09:05,575 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 14/16 -- train_loss: 0.8975 \n",
      "2022-12-09 03:09:05,705 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 15/16 -- train_loss: 0.9198 \n",
      "2022-12-09 03:09:05,795 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 16/16 -- train_loss: 1.0270 \n",
      "2022-12-09 03:09:05,797 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.8783524831136068\n",
      "2022-12-09 03:09:05,797 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[8] Metrics -- train_accuracy: 0.8784 \n",
      "2022-12-09 03:09:05,797 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.8783524831136068 at epoch: 8\n",
      "2022-12-09 03:09:05,798 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[8] Complete. Time taken: 00:00:02.606\n",
      "2022-12-09 03:09:06,649 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 1/16 -- train_loss: 0.9984 \n",
      "2022-12-09 03:09:06,794 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 2/16 -- train_loss: 1.0076 \n",
      "2022-12-09 03:09:06,895 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 3/16 -- train_loss: 0.9211 \n",
      "2022-12-09 03:09:07,069 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 4/16 -- train_loss: 0.9744 \n",
      "2022-12-09 03:09:07,222 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 5/16 -- train_loss: 0.9681 \n",
      "2022-12-09 03:09:07,319 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 6/16 -- train_loss: 0.9730 \n",
      "2022-12-09 03:09:07,415 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 7/16 -- train_loss: 0.9156 \n",
      "2022-12-09 03:09:07,533 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 8/16 -- train_loss: 0.9250 \n",
      "2022-12-09 03:09:07,720 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 9/16 -- train_loss: 0.9513 \n",
      "2022-12-09 03:09:07,815 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 10/16 -- train_loss: 0.8712 \n",
      "2022-12-09 03:09:07,905 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 11/16 -- train_loss: 0.9633 \n",
      "2022-12-09 03:09:07,995 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 12/16 -- train_loss: 1.0261 \n",
      "2022-12-09 03:09:08,125 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 13/16 -- train_loss: 0.9133 \n",
      "2022-12-09 03:09:08,214 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 14/16 -- train_loss: 0.9038 \n",
      "2022-12-09 03:09:08,344 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 15/16 -- train_loss: 0.9243 \n",
      "2022-12-09 03:09:08,434 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 16/16 -- train_loss: 1.0317 \n",
      "2022-12-09 03:09:08,435 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.9313665231068929\n",
      "2022-12-09 03:09:08,435 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[9] Metrics -- train_accuracy: 0.9314 \n",
      "2022-12-09 03:09:08,435 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.9313665231068929 at epoch: 9\n",
      "2022-12-09 03:09:08,436 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[9] Complete. Time taken: 00:00:02.638\n",
      "2022-12-09 03:09:09,302 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 1/16 -- train_loss: 0.8986 \n",
      "2022-12-09 03:09:09,439 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 2/16 -- train_loss: 0.8643 \n",
      "2022-12-09 03:09:09,538 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 3/16 -- train_loss: 0.9163 \n",
      "2022-12-09 03:09:09,639 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 4/16 -- train_loss: 0.8585 \n",
      "2022-12-09 03:09:09,814 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 5/16 -- train_loss: 0.8224 \n",
      "2022-12-09 03:09:09,932 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 6/16 -- train_loss: 1.0684 \n",
      "2022-12-09 03:09:10,032 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 7/16 -- train_loss: 0.9831 \n",
      "2022-12-09 03:09:10,130 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 8/16 -- train_loss: 0.9391 \n",
      "2022-12-09 03:09:10,303 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 9/16 -- train_loss: 0.9966 \n",
      "2022-12-09 03:09:10,417 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 10/16 -- train_loss: 0.8755 \n",
      "2022-12-09 03:09:10,510 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 11/16 -- train_loss: 1.0204 \n",
      "2022-12-09 03:09:10,624 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 12/16 -- train_loss: 0.9428 \n",
      "2022-12-09 03:09:10,756 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 13/16 -- train_loss: 0.9101 \n",
      "2022-12-09 03:09:10,847 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 14/16 -- train_loss: 0.8826 \n",
      "2022-12-09 03:09:10,957 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 15/16 -- train_loss: 0.9348 \n",
      "2022-12-09 03:09:11,068 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 16/16 -- train_loss: 0.9190 \n",
      "2022-12-09 03:09:11,069 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.9522470809795238\n",
      "2022-12-09 03:09:11,069 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run resuming from iteration 0, epoch 9 until 10 epochs\n",
      "2022-12-09 03:09:14,153 - ignite.engine.engine.SupervisedEvaluator - INFO - Got new best metric of val_mean_dice: 0.41805189847946167\n",
      "2022-12-09 03:09:14,153 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[10] Metrics -- val_accuracy: 0.9894 val_mean_dice: 0.4181 \n",
      "2022-12-09 03:09:14,153 - ignite.engine.engine.SupervisedEvaluator - INFO - Key metric: val_mean_dice best value: 0.41805189847946167 at epoch: 10\n",
      "2022-12-09 03:09:14,178 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[10] Complete. Time taken: 00:00:02.812\n",
      "2022-12-09 03:09:14,178 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run complete. Time taken: 00:00:03.109\n",
      "2022-12-09 03:09:14,281 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[10] Metrics -- train_accuracy: 0.9522 \n",
      "2022-12-09 03:09:14,281 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.9522470809795238 at epoch: 10\n",
      "2022-12-09 03:09:14,282 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[10] Complete. Time taken: 00:00:05.846\n",
      "2022-12-09 03:09:14,285 - ignite.engine.engine.SupervisedTrainer - INFO - Engine run complete. Time taken: 00:00:36.342\n",
      "[null, null, null]\n"
     ]
    }
   ],
   "source": [
    "!cd spleen_ct_segmentation;python -m monai.bundle run training \\\n",
    "    --meta_file configs/metadata.json \\\n",
    "    --config_file configs/train.json \\\n",
    "    --logging_file configs/logging.conf \\\n",
    "    --bundle_root ./ \\\n",
    "    --dataset_dir /workspace/data/medical/Task09_Spleen \\\n",
    "    --train#trainer#max_epochs 10 \\\n",
    "    --tracking \"mlflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run spleen bundle with a MLflow config file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other way to run MLflow with bundle is to pass a JSON config file to `--tracking` parameter. In this file, a `mlflow_hander`, which is a handler to leverage MLflow in MONAI bundle, should be defined to enable tracking. More parameters and details can be added through this way. There is an example JSON named `mlflow_example.json` in this folder for reference. When writting the config JSON in multi-gpu environment, please note to use `_disabled_` parameter as shown in the example JSON to only use MLflow in the first gpu.\n",
    "\n",
    "The next cell contains a command line to run spleen segmentation training with the given config JSON. As the experiment finished, it will be logged as shown below. And it is different from the defualt one by `run_name` and `parameters`, since we changed these in the config file.\n",
    "\n",
    "![image](./extra_pics/mlflow_config_result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-09 03:09:18,211 - INFO - --- input summary of monai.bundle.scripts.run ---\n",
      "2022-12-09 03:09:18,211 - INFO - > runner_id: 'training'\n",
      "2022-12-09 03:09:18,211 - INFO - > meta_file: 'configs/metadata.json'\n",
      "2022-12-09 03:09:18,211 - INFO - > config_file: 'configs/train.json'\n",
      "2022-12-09 03:09:18,211 - INFO - > logging_file: 'configs/logging.conf'\n",
      "2022-12-09 03:09:18,211 - INFO - > tracking: '../mlflow_example.json'\n",
      "2022-12-09 03:09:18,211 - INFO - > bundle_root: './'\n",
      "2022-12-09 03:09:18,211 - INFO - > dataset_dir: '/workspace/data/medical/Task09_Spleen'\n",
      "2022-12-09 03:09:18,211 - INFO - > train#trainer#max_epochs: 10\n",
      "2022-12-09 03:09:18,211 - INFO - ---\n",
      "\n",
      "\n",
      "2022-12-09 03:09:18,211 - INFO - set logging properties based on config: configs/logging.conf.\n",
      "Loading dataset: 100%|██████████████████████████| 32/32 [00:21<00:00,  1.49it/s]\n",
      "Loading dataset: 100%|████████████████████████████| 9/9 [00:10<00:00,  1.11s/it]\n",
      "2022-12-09 03:09:51,801 - ignite.engine.engine.SupervisedTrainer - INFO - Engine run resuming from iteration 0, epoch 0 until 10 epochs\n",
      "2022-12-09 03:09:55,066 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 1/16 -- train_loss: 1.5364 \n",
      "2022-12-09 03:09:55,158 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 2/16 -- train_loss: 1.5299 \n",
      "2022-12-09 03:09:55,252 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 3/16 -- train_loss: 1.4873 \n",
      "2022-12-09 03:09:55,347 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 4/16 -- train_loss: 1.5010 \n",
      "2022-12-09 03:09:55,487 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 5/16 -- train_loss: 1.5109 \n",
      "2022-12-09 03:09:55,581 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 6/16 -- train_loss: 1.5003 \n",
      "2022-12-09 03:09:55,698 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 7/16 -- train_loss: 1.4706 \n",
      "2022-12-09 03:09:55,815 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 8/16 -- train_loss: 1.3903 \n",
      "2022-12-09 03:09:55,928 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 9/16 -- train_loss: 1.4331 \n",
      "2022-12-09 03:09:56,038 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 10/16 -- train_loss: 1.3766 \n",
      "2022-12-09 03:09:56,147 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 11/16 -- train_loss: 1.3845 \n",
      "2022-12-09 03:09:56,256 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 12/16 -- train_loss: 1.3429 \n",
      "2022-12-09 03:09:56,364 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 13/16 -- train_loss: 1.3879 \n",
      "2022-12-09 03:09:56,473 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 14/16 -- train_loss: 1.3377 \n",
      "2022-12-09 03:09:56,602 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 15/16 -- train_loss: 1.3041 \n",
      "2022-12-09 03:09:56,692 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 1/10, Iter: 16/16 -- train_loss: 1.3647 \n",
      "2022-12-09 03:09:56,693 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.4414298004574246\n",
      "2022-12-09 03:09:56,693 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[1] Metrics -- train_accuracy: 0.4414 \n",
      "2022-12-09 03:09:56,693 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.4414298004574246 at epoch: 1\n",
      "2022-12-09 03:09:56,694 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[1] Complete. Time taken: 00:00:04.115\n",
      "2022-12-09 03:09:57,460 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 1/16 -- train_loss: 1.3636 \n",
      "2022-12-09 03:09:57,731 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 2/16 -- train_loss: 1.3071 \n",
      "2022-12-09 03:09:57,829 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 3/16 -- train_loss: 1.3390 \n",
      "2022-12-09 03:09:57,925 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 4/16 -- train_loss: 1.3669 \n",
      "2022-12-09 03:09:58,051 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 5/16 -- train_loss: 1.3734 \n",
      "2022-12-09 03:09:58,172 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 6/16 -- train_loss: 1.3274 \n",
      "2022-12-09 03:09:58,290 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 7/16 -- train_loss: 1.2474 \n",
      "2022-12-09 03:09:58,409 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 8/16 -- train_loss: 1.2438 \n",
      "2022-12-09 03:09:58,521 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 9/16 -- train_loss: 1.2473 \n",
      "2022-12-09 03:09:58,633 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 10/16 -- train_loss: 1.2577 \n",
      "2022-12-09 03:09:58,744 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 11/16 -- train_loss: 1.2939 \n",
      "2022-12-09 03:09:58,853 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 12/16 -- train_loss: 1.3326 \n",
      "2022-12-09 03:09:58,983 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 13/16 -- train_loss: 1.3386 \n",
      "2022-12-09 03:09:59,091 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 14/16 -- train_loss: 1.2417 \n",
      "2022-12-09 03:09:59,181 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 15/16 -- train_loss: 1.2410 \n",
      "2022-12-09 03:09:59,291 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 2/10, Iter: 16/16 -- train_loss: 1.2734 \n",
      "2022-12-09 03:09:59,293 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.45736187475698964\n",
      "2022-12-09 03:09:59,293 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[2] Metrics -- train_accuracy: 0.4574 \n",
      "2022-12-09 03:09:59,293 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.45736187475698964 at epoch: 2\n",
      "2022-12-09 03:09:59,293 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[2] Complete. Time taken: 00:00:02.599\n",
      "2022-12-09 03:10:00,274 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 1/16 -- train_loss: 1.2456 \n",
      "2022-12-09 03:10:00,412 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 2/16 -- train_loss: 1.2104 \n",
      "2022-12-09 03:10:00,530 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 3/16 -- train_loss: 1.1972 \n",
      "2022-12-09 03:10:00,629 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 4/16 -- train_loss: 1.1688 \n",
      "2022-12-09 03:10:00,841 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 5/16 -- train_loss: 1.2475 \n",
      "2022-12-09 03:10:00,934 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 6/16 -- train_loss: 1.2491 \n",
      "2022-12-09 03:10:01,054 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 7/16 -- train_loss: 1.2617 \n",
      "2022-12-09 03:10:01,153 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 8/16 -- train_loss: 1.2395 \n",
      "2022-12-09 03:10:01,369 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 9/16 -- train_loss: 1.2060 \n",
      "2022-12-09 03:10:01,459 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 10/16 -- train_loss: 1.1786 \n",
      "2022-12-09 03:10:01,549 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 11/16 -- train_loss: 1.2018 \n",
      "2022-12-09 03:10:01,639 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 12/16 -- train_loss: 1.2141 \n",
      "2022-12-09 03:10:01,807 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 13/16 -- train_loss: 1.1967 \n",
      "2022-12-09 03:10:01,897 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 14/16 -- train_loss: 1.2033 \n",
      "2022-12-09 03:10:01,987 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 15/16 -- train_loss: 1.1991 \n",
      "2022-12-09 03:10:02,077 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 3/10, Iter: 16/16 -- train_loss: 1.2184 \n",
      "2022-12-09 03:10:02,078 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.5076389312744141\n",
      "2022-12-09 03:10:02,078 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[3] Metrics -- train_accuracy: 0.5076 \n",
      "2022-12-09 03:10:02,078 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.5076389312744141 at epoch: 3\n",
      "2022-12-09 03:10:02,079 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[3] Complete. Time taken: 00:00:02.785\n",
      "2022-12-09 03:10:03,127 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 1/16 -- train_loss: 1.1402 \n",
      "2022-12-09 03:10:03,229 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 2/16 -- train_loss: 1.1186 \n",
      "2022-12-09 03:10:03,328 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 3/16 -- train_loss: 1.1000 \n",
      "2022-12-09 03:10:03,430 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 4/16 -- train_loss: 1.2314 \n",
      "2022-12-09 03:10:03,665 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 5/16 -- train_loss: 1.1512 \n",
      "2022-12-09 03:10:03,759 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 6/16 -- train_loss: 1.1858 \n",
      "2022-12-09 03:10:03,854 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 7/16 -- train_loss: 1.2349 \n",
      "2022-12-09 03:10:03,950 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 8/16 -- train_loss: 1.2411 \n",
      "2022-12-09 03:10:04,093 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 9/16 -- train_loss: 1.1151 \n",
      "2022-12-09 03:10:04,185 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 10/16 -- train_loss: 1.2122 \n",
      "2022-12-09 03:10:04,295 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 11/16 -- train_loss: 1.2287 \n",
      "2022-12-09 03:10:04,405 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 12/16 -- train_loss: 1.2275 \n",
      "2022-12-09 03:10:04,516 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 13/16 -- train_loss: 1.1740 \n",
      "2022-12-09 03:10:04,645 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 14/16 -- train_loss: 1.1569 \n",
      "2022-12-09 03:10:04,734 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 15/16 -- train_loss: 1.1312 \n",
      "2022-12-09 03:10:04,844 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 4/10, Iter: 16/16 -- train_loss: 1.1199 \n",
      "2022-12-09 03:10:04,845 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.5632316183160853\n",
      "2022-12-09 03:10:04,845 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[4] Metrics -- train_accuracy: 0.5632 \n",
      "2022-12-09 03:10:04,845 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.5632316183160853 at epoch: 4\n",
      "2022-12-09 03:10:04,846 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[4] Complete. Time taken: 00:00:02.767\n",
      "2022-12-09 03:10:05,759 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 1/16 -- train_loss: 1.1660 \n",
      "2022-12-09 03:10:05,883 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 2/16 -- train_loss: 1.1599 \n",
      "2022-12-09 03:10:06,161 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 3/16 -- train_loss: 1.1252 \n",
      "2022-12-09 03:10:06,262 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 4/16 -- train_loss: 1.0192 \n",
      "2022-12-09 03:10:06,432 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 5/16 -- train_loss: 1.1297 \n",
      "2022-12-09 03:10:06,528 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 6/16 -- train_loss: 1.1494 \n",
      "2022-12-09 03:10:06,624 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 7/16 -- train_loss: 1.1494 \n",
      "2022-12-09 03:10:06,744 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 8/16 -- train_loss: 1.1959 \n",
      "2022-12-09 03:10:07,043 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 9/16 -- train_loss: 1.2127 \n",
      "2022-12-09 03:10:07,133 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 10/16 -- train_loss: 1.0702 \n",
      "2022-12-09 03:10:07,222 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 11/16 -- train_loss: 1.0966 \n",
      "2022-12-09 03:10:07,332 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 12/16 -- train_loss: 1.1724 \n",
      "2022-12-09 03:10:07,441 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 13/16 -- train_loss: 1.0640 \n",
      "2022-12-09 03:10:07,571 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 14/16 -- train_loss: 1.0819 \n",
      "2022-12-09 03:10:07,660 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 15/16 -- train_loss: 1.0933 \n",
      "2022-12-09 03:10:07,769 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 5/10, Iter: 16/16 -- train_loss: 1.0995 \n",
      "2022-12-09 03:10:07,771 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.626623374444467\n",
      "2022-12-09 03:10:07,771 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run resuming from iteration 0, epoch 4 until 5 epochs\n",
      "2022-12-09 03:10:11,479 - ignite.engine.engine.SupervisedEvaluator - INFO - Got new best metric of val_mean_dice: 0.04803894832730293\n",
      "2022-12-09 03:10:11,479 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[5] Metrics -- val_accuracy: 0.7500 val_mean_dice: 0.0480 \n",
      "2022-12-09 03:10:11,479 - ignite.engine.engine.SupervisedEvaluator - INFO - Key metric: val_mean_dice best value: 0.04803894832730293 at epoch: 5\n",
      "2022-12-09 03:10:11,508 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[5] Complete. Time taken: 00:00:03.441\n",
      "2022-12-09 03:10:11,509 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run complete. Time taken: 00:00:03.738\n",
      "2022-12-09 03:10:11,611 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[5] Metrics -- train_accuracy: 0.6266 \n",
      "2022-12-09 03:10:11,611 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.626623374444467 at epoch: 5\n",
      "2022-12-09 03:10:11,612 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[5] Complete. Time taken: 00:00:06.766\n",
      "2022-12-09 03:10:12,495 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 1/16 -- train_loss: 1.1457 \n",
      "2022-12-09 03:10:12,636 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 2/16 -- train_loss: 1.1030 \n",
      "2022-12-09 03:10:12,733 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 3/16 -- train_loss: 1.0931 \n",
      "2022-12-09 03:10:12,831 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 4/16 -- train_loss: 1.0559 \n",
      "2022-12-09 03:10:13,042 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 5/16 -- train_loss: 1.1182 \n",
      "2022-12-09 03:10:13,178 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 6/16 -- train_loss: 1.1016 \n",
      "2022-12-09 03:10:13,274 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 7/16 -- train_loss: 1.0591 \n",
      "2022-12-09 03:10:13,374 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 8/16 -- train_loss: 1.1271 \n",
      "2022-12-09 03:10:13,586 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 9/16 -- train_loss: 1.0882 \n",
      "2022-12-09 03:10:13,677 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 10/16 -- train_loss: 1.0261 \n",
      "2022-12-09 03:10:13,767 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 11/16 -- train_loss: 1.0374 \n",
      "2022-12-09 03:10:13,856 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 12/16 -- train_loss: 1.0899 \n",
      "2022-12-09 03:10:14,027 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 13/16 -- train_loss: 1.0381 \n",
      "2022-12-09 03:10:14,118 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 14/16 -- train_loss: 0.9745 \n",
      "2022-12-09 03:10:14,207 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 15/16 -- train_loss: 1.0226 \n",
      "2022-12-09 03:10:14,301 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 6/10, Iter: 16/16 -- train_loss: 1.0637 \n",
      "2022-12-09 03:10:14,302 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.7156343283476653\n",
      "2022-12-09 03:10:14,302 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[6] Metrics -- train_accuracy: 0.7156 \n",
      "2022-12-09 03:10:14,302 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.7156343283476653 at epoch: 6\n",
      "2022-12-09 03:10:14,303 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[6] Complete. Time taken: 00:00:02.691\n",
      "2022-12-09 03:10:15,247 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 1/16 -- train_loss: 0.9754 \n",
      "2022-12-09 03:10:15,347 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 2/16 -- train_loss: 1.0061 \n",
      "2022-12-09 03:10:15,482 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 3/16 -- train_loss: 1.0463 \n",
      "2022-12-09 03:10:15,580 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 4/16 -- train_loss: 1.0894 \n",
      "2022-12-09 03:10:15,728 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 5/16 -- train_loss: 1.0334 \n",
      "2022-12-09 03:10:15,910 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 6/16 -- train_loss: 1.0240 \n",
      "2022-12-09 03:10:16,009 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 7/16 -- train_loss: 1.0488 \n",
      "2022-12-09 03:10:16,105 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 8/16 -- train_loss: 1.0326 \n",
      "2022-12-09 03:10:16,224 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 9/16 -- train_loss: 1.0070 \n",
      "2022-12-09 03:10:16,358 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 10/16 -- train_loss: 0.9675 \n",
      "2022-12-09 03:10:16,447 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 11/16 -- train_loss: 0.9813 \n",
      "2022-12-09 03:10:16,567 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 12/16 -- train_loss: 1.0632 \n",
      "2022-12-09 03:10:16,716 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 13/16 -- train_loss: 1.0636 \n",
      "2022-12-09 03:10:16,805 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 14/16 -- train_loss: 1.0622 \n",
      "2022-12-09 03:10:16,895 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 15/16 -- train_loss: 0.9367 \n",
      "2022-12-09 03:10:17,005 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 7/10, Iter: 16/16 -- train_loss: 1.0709 \n",
      "2022-12-09 03:10:17,006 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.812228450068721\n",
      "2022-12-09 03:10:17,006 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[7] Metrics -- train_accuracy: 0.8122 \n",
      "2022-12-09 03:10:17,006 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.812228450068721 at epoch: 7\n",
      "2022-12-09 03:10:17,006 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[7] Complete. Time taken: 00:00:02.704\n",
      "2022-12-09 03:10:17,839 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 1/16 -- train_loss: 1.0404 \n",
      "2022-12-09 03:10:17,937 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 2/16 -- train_loss: 1.0352 \n",
      "2022-12-09 03:10:18,087 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 3/16 -- train_loss: 1.1429 \n",
      "2022-12-09 03:10:18,185 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 4/16 -- train_loss: 1.0167 \n",
      "2022-12-09 03:10:18,361 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 5/16 -- train_loss: 0.9630 \n",
      "2022-12-09 03:10:18,460 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 6/16 -- train_loss: 0.9736 \n",
      "2022-12-09 03:10:18,648 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 7/16 -- train_loss: 1.0373 \n",
      "2022-12-09 03:10:18,747 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 8/16 -- train_loss: 0.9325 \n",
      "2022-12-09 03:10:18,863 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 9/16 -- train_loss: 0.9106 \n",
      "2022-12-09 03:10:18,957 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 10/16 -- train_loss: 0.9815 \n",
      "2022-12-09 03:10:19,112 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 11/16 -- train_loss: 1.0576 \n",
      "2022-12-09 03:10:19,202 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 12/16 -- train_loss: 1.0148 \n",
      "2022-12-09 03:10:19,312 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 13/16 -- train_loss: 0.9699 \n",
      "2022-12-09 03:10:19,402 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 14/16 -- train_loss: 0.8975 \n",
      "2022-12-09 03:10:19,513 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 15/16 -- train_loss: 0.9198 \n",
      "2022-12-09 03:10:19,623 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 8/10, Iter: 16/16 -- train_loss: 1.0270 \n",
      "2022-12-09 03:10:19,625 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.8783524831136068\n",
      "2022-12-09 03:10:19,625 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[8] Metrics -- train_accuracy: 0.8784 \n",
      "2022-12-09 03:10:19,625 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.8783524831136068 at epoch: 8\n",
      "2022-12-09 03:10:19,625 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[8] Complete. Time taken: 00:00:02.619\n",
      "2022-12-09 03:10:20,525 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 1/16 -- train_loss: 0.9984 \n",
      "2022-12-09 03:10:20,647 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 2/16 -- train_loss: 1.0076 \n",
      "2022-12-09 03:10:20,747 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 3/16 -- train_loss: 0.9211 \n",
      "2022-12-09 03:10:20,902 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 4/16 -- train_loss: 0.9744 \n",
      "2022-12-09 03:10:21,075 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 5/16 -- train_loss: 0.9681 \n",
      "2022-12-09 03:10:21,171 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 6/16 -- train_loss: 0.9730 \n",
      "2022-12-09 03:10:21,266 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 7/16 -- train_loss: 0.9156 \n",
      "2022-12-09 03:10:21,387 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 8/16 -- train_loss: 0.9250 \n",
      "2022-12-09 03:10:21,570 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 9/16 -- train_loss: 0.9513 \n",
      "2022-12-09 03:10:21,672 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 10/16 -- train_loss: 0.8712 \n",
      "2022-12-09 03:10:21,761 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 11/16 -- train_loss: 0.9633 \n",
      "2022-12-09 03:10:21,850 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 12/16 -- train_loss: 1.0261 \n",
      "2022-12-09 03:10:21,980 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 13/16 -- train_loss: 0.9133 \n",
      "2022-12-09 03:10:22,069 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 14/16 -- train_loss: 0.9038 \n",
      "2022-12-09 03:10:22,199 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 15/16 -- train_loss: 0.9243 \n",
      "2022-12-09 03:10:22,290 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 9/10, Iter: 16/16 -- train_loss: 1.0317 \n",
      "2022-12-09 03:10:22,291 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.9313665231068929\n",
      "2022-12-09 03:10:22,291 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[9] Metrics -- train_accuracy: 0.9314 \n",
      "2022-12-09 03:10:22,291 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.9313665231068929 at epoch: 9\n",
      "2022-12-09 03:10:22,292 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[9] Complete. Time taken: 00:00:02.667\n",
      "2022-12-09 03:10:23,162 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 1/16 -- train_loss: 0.8986 \n",
      "2022-12-09 03:10:23,306 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 2/16 -- train_loss: 0.8643 \n",
      "2022-12-09 03:10:23,404 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 3/16 -- train_loss: 0.9163 \n",
      "2022-12-09 03:10:23,503 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 4/16 -- train_loss: 0.8585 \n",
      "2022-12-09 03:10:23,664 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 5/16 -- train_loss: 0.8224 \n",
      "2022-12-09 03:10:23,783 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 6/16 -- train_loss: 1.0684 \n",
      "2022-12-09 03:10:23,881 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 7/16 -- train_loss: 0.9831 \n",
      "2022-12-09 03:10:23,981 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 8/16 -- train_loss: 0.9391 \n",
      "2022-12-09 03:10:24,174 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 9/16 -- train_loss: 0.9966 \n",
      "2022-12-09 03:10:24,286 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 10/16 -- train_loss: 0.8755 \n",
      "2022-12-09 03:10:24,375 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 11/16 -- train_loss: 1.0204 \n",
      "2022-12-09 03:10:24,504 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 12/16 -- train_loss: 0.9428 \n",
      "2022-12-09 03:10:24,614 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 13/16 -- train_loss: 0.9101 \n",
      "2022-12-09 03:10:24,704 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 14/16 -- train_loss: 0.8826 \n",
      "2022-12-09 03:10:24,813 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 15/16 -- train_loss: 0.9348 \n",
      "2022-12-09 03:10:24,925 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch: 10/10, Iter: 16/16 -- train_loss: 0.9190 \n",
      "2022-12-09 03:10:24,926 - ignite.engine.engine.SupervisedTrainer - INFO - Got new best metric of train_accuracy: 0.9522470809795238\n",
      "2022-12-09 03:10:24,926 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run resuming from iteration 0, epoch 9 until 10 epochs\n",
      "2022-12-09 03:10:28,036 - ignite.engine.engine.SupervisedEvaluator - INFO - Got new best metric of val_mean_dice: 0.4180336594581604\n",
      "2022-12-09 03:10:28,036 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[10] Metrics -- val_accuracy: 0.9894 val_mean_dice: 0.4180 \n",
      "2022-12-09 03:10:28,036 - ignite.engine.engine.SupervisedEvaluator - INFO - Key metric: val_mean_dice best value: 0.4180336594581604 at epoch: 10\n",
      "2022-12-09 03:10:28,057 - ignite.engine.engine.SupervisedEvaluator - INFO - Epoch[10] Complete. Time taken: 00:00:02.827\n",
      "2022-12-09 03:10:28,057 - ignite.engine.engine.SupervisedEvaluator - INFO - Engine run complete. Time taken: 00:00:03.131\n",
      "2022-12-09 03:10:28,161 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[10] Metrics -- train_accuracy: 0.9522 \n",
      "2022-12-09 03:10:28,161 - ignite.engine.engine.SupervisedTrainer - INFO - Key metric: train_accuracy best value: 0.9522470809795238 at epoch: 10\n",
      "2022-12-09 03:10:28,162 - ignite.engine.engine.SupervisedTrainer - INFO - Epoch[10] Complete. Time taken: 00:00:05.870\n",
      "2022-12-09 03:10:28,162 - ignite.engine.engine.SupervisedTrainer - INFO - Engine run complete. Time taken: 00:00:36.361\n",
      "[null, null, null]\n"
     ]
    }
   ],
   "source": [
    "!cd spleen_ct_segmentation;python -m monai.bundle run training \\\n",
    "    --meta_file configs/metadata.json \\\n",
    "    --config_file configs/train.json \\\n",
    "    --logging_file configs/logging.conf \\\n",
    "    --bundle_root ./ \\\n",
    "    --dataset_dir /workspace/data/medical/Task09_Spleen \\\n",
    "    --train#trainer#max_epochs 10 \\\n",
    "    --tracking ../mlflow_example.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run parsed spleen segmentation bundle with mlflow_handler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we use the parsed trainer from spleen bundle to show how to add mlflow_handler to a monai engine in python code. However, users can also write their own workflow in python code from beginning and reference to this part to add mlflow_handler. \n",
    "The recorded results are shown below:\n",
    "![image](./extra_pics/mlflow_python_result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 32/32 [00:21<00:00,  1.46it/s]\n",
      "Loading dataset: 100%|██████████| 9/9 [00:10<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-09 03:11:03,853 - Engine run resuming from iteration 0, epoch 0 until 10 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2022/12/09 03:11:03 INFO mlflow.tracking.fluent: Experiment with name 'ParsedExperiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-09 03:11:06,452 - Epoch: 1/10, Iter: 1/16 -- train_loss: 1.2814 \n",
      "2022-12-09 03:11:06,553 - Epoch: 1/10, Iter: 2/16 -- train_loss: 1.2986 \n",
      "2022-12-09 03:11:06,634 - Epoch: 1/10, Iter: 3/16 -- train_loss: 1.2531 \n",
      "2022-12-09 03:11:06,739 - Epoch: 1/10, Iter: 4/16 -- train_loss: 1.2530 \n",
      "2022-12-09 03:11:06,843 - Epoch: 1/10, Iter: 5/16 -- train_loss: 1.2678 \n",
      "2022-12-09 03:11:07,036 - Epoch: 1/10, Iter: 6/16 -- train_loss: 1.2561 \n",
      "2022-12-09 03:11:07,121 - Epoch: 1/10, Iter: 7/16 -- train_loss: 1.2565 \n",
      "2022-12-09 03:11:07,203 - Epoch: 1/10, Iter: 8/16 -- train_loss: 1.2506 \n",
      "2022-12-09 03:11:07,304 - Epoch: 1/10, Iter: 9/16 -- train_loss: 1.2100 \n",
      "2022-12-09 03:11:07,401 - Epoch: 1/10, Iter: 10/16 -- train_loss: 1.2038 \n",
      "2022-12-09 03:11:07,496 - Epoch: 1/10, Iter: 11/16 -- train_loss: 1.1974 \n",
      "2022-12-09 03:11:07,591 - Epoch: 1/10, Iter: 12/16 -- train_loss: 1.1782 \n",
      "2022-12-09 03:11:07,686 - Epoch: 1/10, Iter: 13/16 -- train_loss: 1.1557 \n",
      "2022-12-09 03:11:07,781 - Epoch: 1/10, Iter: 14/16 -- train_loss: 1.1301 \n",
      "2022-12-09 03:11:07,876 - Epoch: 1/10, Iter: 15/16 -- train_loss: 1.0833 \n",
      "2022-12-09 03:11:07,971 - Epoch: 1/10, Iter: 16/16 -- train_loss: 1.2007 \n",
      "2022-12-09 03:11:07,972 - Got new best metric of train_accuracy: 0.6459033754136827\n",
      "2022-12-09 03:11:07,973 - Epoch[1] Metrics -- train_accuracy: 0.6459 \n",
      "2022-12-09 03:11:07,973 - Key metric: train_accuracy best value: 0.6459033754136827 at epoch: 1\n",
      "2022-12-09 03:11:07,974 - Epoch[1] Complete. Time taken: 00:00:03.252\n",
      "2022-12-09 03:11:08,876 - Epoch: 2/10, Iter: 1/16 -- train_loss: 1.1597 \n",
      "2022-12-09 03:11:08,962 - Epoch: 2/10, Iter: 2/16 -- train_loss: 1.0955 \n",
      "2022-12-09 03:11:09,071 - Epoch: 2/10, Iter: 3/16 -- train_loss: 1.0970 \n",
      "2022-12-09 03:11:09,158 - Epoch: 2/10, Iter: 4/16 -- train_loss: 1.1395 \n",
      "2022-12-09 03:11:09,262 - Epoch: 2/10, Iter: 5/16 -- train_loss: 1.1166 \n",
      "2022-12-09 03:11:09,368 - Epoch: 2/10, Iter: 6/16 -- train_loss: 1.0752 \n",
      "2022-12-09 03:11:09,476 - Epoch: 2/10, Iter: 7/16 -- train_loss: 1.1295 \n",
      "2022-12-09 03:11:09,630 - Epoch: 2/10, Iter: 8/16 -- train_loss: 1.0652 \n",
      "2022-12-09 03:11:09,806 - Epoch: 2/10, Iter: 9/16 -- train_loss: 1.1810 \n",
      "2022-12-09 03:11:09,933 - Epoch: 2/10, Iter: 10/16 -- train_loss: 1.0860 \n",
      "2022-12-09 03:11:10,009 - Epoch: 2/10, Iter: 11/16 -- train_loss: 1.0351 \n",
      "2022-12-09 03:11:10,104 - Epoch: 2/10, Iter: 12/16 -- train_loss: 1.0970 \n",
      "2022-12-09 03:11:10,261 - Epoch: 2/10, Iter: 13/16 -- train_loss: 1.0640 \n",
      "2022-12-09 03:11:10,337 - Epoch: 2/10, Iter: 14/16 -- train_loss: 1.0411 \n",
      "2022-12-09 03:11:10,412 - Epoch: 2/10, Iter: 15/16 -- train_loss: 1.0479 \n",
      "2022-12-09 03:11:10,487 - Epoch: 2/10, Iter: 16/16 -- train_loss: 1.1375 \n",
      "2022-12-09 03:11:10,489 - Got new best metric of train_accuracy: 0.7331078229127107\n",
      "2022-12-09 03:11:10,489 - Epoch[2] Metrics -- train_accuracy: 0.7331 \n",
      "2022-12-09 03:11:10,489 - Key metric: train_accuracy best value: 0.7331078229127107 at epoch: 2\n",
      "2022-12-09 03:11:10,490 - Epoch[2] Complete. Time taken: 00:00:02.516\n",
      "2022-12-09 03:11:11,339 - Epoch: 3/10, Iter: 1/16 -- train_loss: 0.9894 \n",
      "2022-12-09 03:11:11,609 - Epoch: 3/10, Iter: 2/16 -- train_loss: 1.0495 \n",
      "2022-12-09 03:11:11,692 - Epoch: 3/10, Iter: 3/16 -- train_loss: 1.0770 \n",
      "2022-12-09 03:11:11,775 - Epoch: 3/10, Iter: 4/16 -- train_loss: 1.0642 \n",
      "2022-12-09 03:11:11,894 - Epoch: 3/10, Iter: 5/16 -- train_loss: 0.9982 \n",
      "2022-12-09 03:11:12,073 - Epoch: 3/10, Iter: 6/16 -- train_loss: 1.0222 \n",
      "2022-12-09 03:11:12,154 - Epoch: 3/10, Iter: 7/16 -- train_loss: 0.9975 \n",
      "2022-12-09 03:11:12,235 - Epoch: 3/10, Iter: 8/16 -- train_loss: 1.0623 \n",
      "2022-12-09 03:11:12,316 - Epoch: 3/10, Iter: 9/16 -- train_loss: 1.0122 \n",
      "2022-12-09 03:11:12,540 - Epoch: 3/10, Iter: 10/16 -- train_loss: 1.0436 \n",
      "2022-12-09 03:11:12,619 - Epoch: 3/10, Iter: 11/16 -- train_loss: 0.9649 \n",
      "2022-12-09 03:11:12,694 - Epoch: 3/10, Iter: 12/16 -- train_loss: 0.9710 \n",
      "2022-12-09 03:11:12,769 - Epoch: 3/10, Iter: 13/16 -- train_loss: 0.9914 \n",
      "2022-12-09 03:11:12,864 - Epoch: 3/10, Iter: 14/16 -- train_loss: 1.0657 \n",
      "2022-12-09 03:11:12,978 - Epoch: 3/10, Iter: 15/16 -- train_loss: 1.0709 \n",
      "2022-12-09 03:11:13,054 - Epoch: 3/10, Iter: 16/16 -- train_loss: 1.0317 \n",
      "2022-12-09 03:11:13,056 - Got new best metric of train_accuracy: 0.8075258113719799\n",
      "2022-12-09 03:11:13,056 - Epoch[3] Metrics -- train_accuracy: 0.8075 \n",
      "2022-12-09 03:11:13,056 - Key metric: train_accuracy best value: 0.8075258113719799 at epoch: 3\n",
      "2022-12-09 03:11:13,057 - Epoch[3] Complete. Time taken: 00:00:02.567\n",
      "2022-12-09 03:11:13,966 - Epoch: 4/10, Iter: 1/16 -- train_loss: 0.9247 \n",
      "2022-12-09 03:11:14,209 - Epoch: 4/10, Iter: 2/16 -- train_loss: 0.9931 \n",
      "2022-12-09 03:11:14,289 - Epoch: 4/10, Iter: 3/16 -- train_loss: 1.0579 \n",
      "2022-12-09 03:11:14,372 - Epoch: 4/10, Iter: 4/16 -- train_loss: 0.9277 \n",
      "2022-12-09 03:11:14,557 - Epoch: 4/10, Iter: 5/16 -- train_loss: 0.9577 \n",
      "2022-12-09 03:11:14,740 - Epoch: 4/10, Iter: 6/16 -- train_loss: 1.0045 \n",
      "2022-12-09 03:11:14,823 - Epoch: 4/10, Iter: 7/16 -- train_loss: 0.9044 \n",
      "2022-12-09 03:11:14,904 - Epoch: 4/10, Iter: 8/16 -- train_loss: 0.9042 \n",
      "2022-12-09 03:11:15,005 - Epoch: 4/10, Iter: 9/16 -- train_loss: 1.0128 \n",
      "2022-12-09 03:11:15,190 - Epoch: 4/10, Iter: 10/16 -- train_loss: 0.8797 \n",
      "2022-12-09 03:11:15,268 - Epoch: 4/10, Iter: 11/16 -- train_loss: 1.0114 \n",
      "2022-12-09 03:11:15,344 - Epoch: 4/10, Iter: 12/16 -- train_loss: 0.9098 \n",
      "2022-12-09 03:11:15,419 - Epoch: 4/10, Iter: 13/16 -- train_loss: 0.9561 \n",
      "2022-12-09 03:11:15,534 - Epoch: 4/10, Iter: 14/16 -- train_loss: 0.9780 \n",
      "2022-12-09 03:11:15,609 - Epoch: 4/10, Iter: 15/16 -- train_loss: 1.0190 \n",
      "2022-12-09 03:11:15,705 - Epoch: 4/10, Iter: 16/16 -- train_loss: 0.9469 \n",
      "2022-12-09 03:11:15,706 - Got new best metric of train_accuracy: 0.8578813605838351\n",
      "2022-12-09 03:11:15,707 - Epoch[4] Metrics -- train_accuracy: 0.8579 \n",
      "2022-12-09 03:11:15,707 - Key metric: train_accuracy best value: 0.8578813605838351 at epoch: 4\n",
      "2022-12-09 03:11:15,708 - Epoch[4] Complete. Time taken: 00:00:02.650\n",
      "2022-12-09 03:11:16,788 - Epoch: 5/10, Iter: 1/16 -- train_loss: 1.0125 \n",
      "2022-12-09 03:11:16,874 - Epoch: 5/10, Iter: 2/16 -- train_loss: 0.9519 \n",
      "2022-12-09 03:11:16,956 - Epoch: 5/10, Iter: 3/16 -- train_loss: 0.9675 \n",
      "2022-12-09 03:11:17,043 - Epoch: 5/10, Iter: 4/16 -- train_loss: 0.8677 \n",
      "2022-12-09 03:11:17,267 - Epoch: 5/10, Iter: 5/16 -- train_loss: 0.8705 \n",
      "2022-12-09 03:11:17,369 - Epoch: 5/10, Iter: 6/16 -- train_loss: 0.8659 \n",
      "2022-12-09 03:11:17,449 - Epoch: 5/10, Iter: 7/16 -- train_loss: 0.9184 \n",
      "2022-12-09 03:11:17,531 - Epoch: 5/10, Iter: 8/16 -- train_loss: 0.8756 \n",
      "2022-12-09 03:11:17,653 - Epoch: 5/10, Iter: 9/16 -- train_loss: 0.8637 \n",
      "2022-12-09 03:11:17,753 - Epoch: 5/10, Iter: 10/16 -- train_loss: 0.8593 \n",
      "2022-12-09 03:11:17,830 - Epoch: 5/10, Iter: 11/16 -- train_loss: 0.9401 \n",
      "2022-12-09 03:11:17,906 - Epoch: 5/10, Iter: 12/16 -- train_loss: 0.8875 \n",
      "2022-12-09 03:11:18,002 - Epoch: 5/10, Iter: 13/16 -- train_loss: 0.9937 \n",
      "2022-12-09 03:11:18,097 - Epoch: 5/10, Iter: 14/16 -- train_loss: 0.9315 \n",
      "2022-12-09 03:11:18,192 - Epoch: 5/10, Iter: 15/16 -- train_loss: 0.9903 \n",
      "2022-12-09 03:11:18,287 - Epoch: 5/10, Iter: 16/16 -- train_loss: 0.8864 \n",
      "2022-12-09 03:11:18,289 - Got new best metric of train_accuracy: 0.8963277693148013\n",
      "2022-12-09 03:11:18,289 - Engine run resuming from iteration 0, epoch 4 until 5 epochs\n",
      "2022-12-09 03:11:20,242 - Got new best metric of val_mean_dice: 0.20106561481952667\n",
      "2022-12-09 03:11:20,243 - Epoch[5] Metrics -- val_accuracy: 0.9759 val_mean_dice: 0.2011 \n",
      "2022-12-09 03:11:20,243 - Key metric: val_mean_dice best value: 0.20106561481952667 at epoch: 5\n",
      "2022-12-09 03:11:20,280 - Epoch[5] Complete. Time taken: 00:00:01.639\n",
      "2022-12-09 03:11:20,281 - Engine run complete. Time taken: 00:00:01.991\n",
      "2022-12-09 03:11:20,388 - Epoch[5] Metrics -- train_accuracy: 0.8963 \n",
      "2022-12-09 03:11:20,389 - Key metric: train_accuracy best value: 0.8963277693148013 at epoch: 5\n",
      "2022-12-09 03:11:20,390 - Epoch[5] Complete. Time taken: 00:00:04.682\n",
      "2022-12-09 03:11:21,636 - Epoch: 6/10, Iter: 1/16 -- train_loss: 0.9581 \n",
      "2022-12-09 03:11:21,722 - Epoch: 6/10, Iter: 2/16 -- train_loss: 0.9456 \n",
      "2022-12-09 03:11:21,892 - Epoch: 6/10, Iter: 3/16 -- train_loss: 0.9142 \n",
      "2022-12-09 03:11:21,978 - Epoch: 6/10, Iter: 4/16 -- train_loss: 0.8945 \n",
      "2022-12-09 03:11:22,162 - Epoch: 6/10, Iter: 5/16 -- train_loss: 0.9048 \n",
      "2022-12-09 03:11:22,245 - Epoch: 6/10, Iter: 6/16 -- train_loss: 0.8638 \n",
      "2022-12-09 03:11:22,329 - Epoch: 6/10, Iter: 7/16 -- train_loss: 0.8825 \n",
      "2022-12-09 03:11:22,410 - Epoch: 6/10, Iter: 8/16 -- train_loss: 0.9144 \n",
      "2022-12-09 03:11:22,590 - Epoch: 6/10, Iter: 9/16 -- train_loss: 0.8032 \n",
      "2022-12-09 03:11:22,667 - Epoch: 6/10, Iter: 10/16 -- train_loss: 0.8993 \n",
      "2022-12-09 03:11:22,744 - Epoch: 6/10, Iter: 11/16 -- train_loss: 0.8742 \n",
      "2022-12-09 03:11:22,883 - Epoch: 6/10, Iter: 12/16 -- train_loss: 0.9562 \n",
      "2022-12-09 03:11:22,958 - Epoch: 6/10, Iter: 13/16 -- train_loss: 0.9235 \n",
      "2022-12-09 03:11:23,033 - Epoch: 6/10, Iter: 14/16 -- train_loss: 0.7959 \n",
      "2022-12-09 03:11:23,129 - Epoch: 6/10, Iter: 15/16 -- train_loss: 0.8283 \n",
      "2022-12-09 03:11:23,225 - Epoch: 6/10, Iter: 16/16 -- train_loss: 0.9926 \n",
      "2022-12-09 03:11:23,227 - Got new best metric of train_accuracy: 0.9166286433184588\n",
      "2022-12-09 03:11:23,227 - Epoch[6] Metrics -- train_accuracy: 0.9166 \n",
      "2022-12-09 03:11:23,227 - Key metric: train_accuracy best value: 0.9166286433184588 at epoch: 6\n",
      "2022-12-09 03:11:23,228 - Epoch[6] Complete. Time taken: 00:00:02.838\n",
      "2022-12-09 03:11:24,085 - Epoch: 7/10, Iter: 1/16 -- train_loss: 0.8646 \n",
      "2022-12-09 03:11:24,192 - Epoch: 7/10, Iter: 2/16 -- train_loss: 0.8672 \n",
      "2022-12-09 03:11:24,310 - Epoch: 7/10, Iter: 3/16 -- train_loss: 0.8279 \n",
      "2022-12-09 03:11:24,427 - Epoch: 7/10, Iter: 4/16 -- train_loss: 0.8489 \n",
      "2022-12-09 03:11:24,534 - Epoch: 7/10, Iter: 5/16 -- train_loss: 0.8728 \n",
      "2022-12-09 03:11:24,651 - Epoch: 7/10, Iter: 6/16 -- train_loss: 0.8718 \n",
      "2022-12-09 03:11:24,758 - Epoch: 7/10, Iter: 7/16 -- train_loss: 0.8930 \n",
      "2022-12-09 03:11:24,871 - Epoch: 7/10, Iter: 8/16 -- train_loss: 0.8825 \n",
      "2022-12-09 03:11:24,978 - Epoch: 7/10, Iter: 9/16 -- train_loss: 0.7795 \n",
      "2022-12-09 03:11:25,135 - Epoch: 7/10, Iter: 10/16 -- train_loss: 0.8614 \n",
      "2022-12-09 03:11:25,231 - Epoch: 7/10, Iter: 11/16 -- train_loss: 0.8281 \n",
      "2022-12-09 03:11:25,326 - Epoch: 7/10, Iter: 12/16 -- train_loss: 0.7355 \n",
      "2022-12-09 03:11:25,422 - Epoch: 7/10, Iter: 13/16 -- train_loss: 0.7688 \n",
      "2022-12-09 03:11:25,518 - Epoch: 7/10, Iter: 14/16 -- train_loss: 0.7359 \n",
      "2022-12-09 03:11:25,614 - Epoch: 7/10, Iter: 15/16 -- train_loss: 0.8304 \n",
      "2022-12-09 03:11:25,711 - Epoch: 7/10, Iter: 16/16 -- train_loss: 0.7975 \n",
      "2022-12-09 03:11:25,713 - Got new best metric of train_accuracy: 0.9416072103712294\n",
      "2022-12-09 03:11:25,713 - Epoch[7] Metrics -- train_accuracy: 0.9416 \n",
      "2022-12-09 03:11:25,714 - Key metric: train_accuracy best value: 0.9416072103712294 at epoch: 7\n",
      "2022-12-09 03:11:25,715 - Epoch[7] Complete. Time taken: 00:00:02.486\n",
      "2022-12-09 03:11:26,599 - Epoch: 8/10, Iter: 1/16 -- train_loss: 0.8725 \n",
      "2022-12-09 03:11:26,825 - Epoch: 8/10, Iter: 2/16 -- train_loss: 0.8704 \n",
      "2022-12-09 03:11:26,909 - Epoch: 8/10, Iter: 3/16 -- train_loss: 0.8727 \n",
      "2022-12-09 03:11:27,013 - Epoch: 8/10, Iter: 4/16 -- train_loss: 0.9155 \n",
      "2022-12-09 03:11:27,140 - Epoch: 8/10, Iter: 5/16 -- train_loss: 0.7325 \n",
      "2022-12-09 03:11:27,265 - Epoch: 8/10, Iter: 6/16 -- train_loss: 0.8865 \n",
      "2022-12-09 03:11:27,348 - Epoch: 8/10, Iter: 7/16 -- train_loss: 0.7199 \n",
      "2022-12-09 03:11:27,452 - Epoch: 8/10, Iter: 8/16 -- train_loss: 0.8549 \n",
      "2022-12-09 03:11:27,559 - Epoch: 8/10, Iter: 9/16 -- train_loss: 0.8507 \n",
      "2022-12-09 03:11:27,684 - Epoch: 8/10, Iter: 10/16 -- train_loss: 0.8287 \n",
      "2022-12-09 03:11:27,762 - Epoch: 8/10, Iter: 11/16 -- train_loss: 0.7405 \n",
      "2022-12-09 03:11:27,858 - Epoch: 8/10, Iter: 12/16 -- train_loss: 0.8485 \n",
      "2022-12-09 03:11:27,933 - Epoch: 8/10, Iter: 13/16 -- train_loss: 0.8552 \n",
      "2022-12-09 03:11:28,069 - Epoch: 8/10, Iter: 14/16 -- train_loss: 0.6832 \n",
      "2022-12-09 03:11:28,145 - Epoch: 8/10, Iter: 15/16 -- train_loss: 0.7843 \n",
      "2022-12-09 03:11:28,222 - Epoch: 8/10, Iter: 16/16 -- train_loss: 0.8392 \n",
      "2022-12-09 03:11:28,224 - Got new best metric of train_accuracy: 0.9490710276144522\n",
      "2022-12-09 03:11:28,224 - Epoch[8] Metrics -- train_accuracy: 0.9491 \n",
      "2022-12-09 03:11:28,224 - Key metric: train_accuracy best value: 0.9490710276144522 at epoch: 8\n",
      "2022-12-09 03:11:28,226 - Epoch[8] Complete. Time taken: 00:00:02.511\n",
      "2022-12-09 03:11:29,093 - Epoch: 9/10, Iter: 1/16 -- train_loss: 0.7847 \n",
      "2022-12-09 03:11:29,320 - Epoch: 9/10, Iter: 2/16 -- train_loss: 0.9362 \n",
      "2022-12-09 03:11:29,407 - Epoch: 9/10, Iter: 3/16 -- train_loss: 0.8009 \n",
      "2022-12-09 03:11:29,492 - Epoch: 9/10, Iter: 4/16 -- train_loss: 0.7633 \n",
      "2022-12-09 03:11:29,603 - Epoch: 9/10, Iter: 5/16 -- train_loss: 0.7909 \n",
      "2022-12-09 03:11:29,763 - Epoch: 9/10, Iter: 6/16 -- train_loss: 0.8263 \n",
      "2022-12-09 03:11:29,849 - Epoch: 9/10, Iter: 7/16 -- train_loss: 0.7695 \n",
      "2022-12-09 03:11:29,978 - Epoch: 9/10, Iter: 8/16 -- train_loss: 0.7830 \n",
      "2022-12-09 03:11:30,136 - Epoch: 9/10, Iter: 9/16 -- train_loss: 0.7219 \n",
      "2022-12-09 03:11:30,234 - Epoch: 9/10, Iter: 10/16 -- train_loss: 0.8410 \n",
      "2022-12-09 03:11:30,310 - Epoch: 9/10, Iter: 11/16 -- train_loss: 0.7155 \n",
      "2022-12-09 03:11:30,406 - Epoch: 9/10, Iter: 12/16 -- train_loss: 0.7542 \n",
      "2022-12-09 03:11:30,502 - Epoch: 9/10, Iter: 13/16 -- train_loss: 0.7186 \n",
      "2022-12-09 03:11:30,639 - Epoch: 9/10, Iter: 14/16 -- train_loss: 0.9042 \n",
      "2022-12-09 03:11:30,715 - Epoch: 9/10, Iter: 15/16 -- train_loss: 0.7793 \n",
      "2022-12-09 03:11:30,792 - Epoch: 9/10, Iter: 16/16 -- train_loss: 0.6968 \n",
      "2022-12-09 03:11:30,793 - Got new best metric of train_accuracy: 0.9602406996267813\n",
      "2022-12-09 03:11:30,794 - Epoch[9] Metrics -- train_accuracy: 0.9602 \n",
      "2022-12-09 03:11:30,794 - Key metric: train_accuracy best value: 0.9602406996267813 at epoch: 9\n",
      "2022-12-09 03:11:30,795 - Epoch[9] Complete. Time taken: 00:00:02.569\n",
      "2022-12-09 03:11:31,821 - Epoch: 10/10, Iter: 1/16 -- train_loss: 0.8388 \n",
      "2022-12-09 03:11:31,927 - Epoch: 10/10, Iter: 2/16 -- train_loss: 0.8046 \n",
      "2022-12-09 03:11:32,009 - Epoch: 10/10, Iter: 3/16 -- train_loss: 0.7012 \n",
      "2022-12-09 03:11:32,095 - Epoch: 10/10, Iter: 4/16 -- train_loss: 0.8168 \n",
      "2022-12-09 03:11:32,279 - Epoch: 10/10, Iter: 5/16 -- train_loss: 0.8513 \n",
      "2022-12-09 03:11:32,362 - Epoch: 10/10, Iter: 6/16 -- train_loss: 0.7660 \n",
      "2022-12-09 03:11:32,446 - Epoch: 10/10, Iter: 7/16 -- train_loss: 0.7036 \n",
      "2022-12-09 03:11:32,528 - Epoch: 10/10, Iter: 8/16 -- train_loss: 0.6789 \n",
      "2022-12-09 03:11:32,682 - Epoch: 10/10, Iter: 9/16 -- train_loss: 0.7039 \n",
      "2022-12-09 03:11:32,761 - Epoch: 10/10, Iter: 10/16 -- train_loss: 0.7184 \n",
      "2022-12-09 03:11:32,840 - Epoch: 10/10, Iter: 11/16 -- train_loss: 0.7484 \n",
      "2022-12-09 03:11:32,935 - Epoch: 10/10, Iter: 12/16 -- train_loss: 0.6916 \n",
      "2022-12-09 03:11:33,072 - Epoch: 10/10, Iter: 13/16 -- train_loss: 0.7466 \n",
      "2022-12-09 03:11:33,148 - Epoch: 10/10, Iter: 14/16 -- train_loss: 0.8005 \n",
      "2022-12-09 03:11:33,244 - Epoch: 10/10, Iter: 15/16 -- train_loss: 0.7790 \n",
      "2022-12-09 03:11:33,321 - Epoch: 10/10, Iter: 16/16 -- train_loss: 0.6723 \n",
      "2022-12-09 03:11:33,323 - Got new best metric of train_accuracy: 0.9672698886306198\n",
      "2022-12-09 03:11:33,324 - Engine run resuming from iteration 0, epoch 9 until 10 epochs\n",
      "2022-12-09 03:11:35,295 - Got new best metric of val_mean_dice: 0.6302940845489502\n",
      "2022-12-09 03:11:35,296 - Epoch[10] Metrics -- val_accuracy: 0.9943 val_mean_dice: 0.6303 \n",
      "2022-12-09 03:11:35,296 - Key metric: val_mean_dice best value: 0.6302940845489502 at epoch: 10\n",
      "2022-12-09 03:11:35,319 - Epoch[10] Complete. Time taken: 00:00:01.640\n",
      "2022-12-09 03:11:35,319 - Engine run complete. Time taken: 00:00:01.995\n",
      "2022-12-09 03:11:35,426 - Epoch[10] Metrics -- train_accuracy: 0.9673 \n",
      "2022-12-09 03:11:35,427 - Key metric: train_accuracy best value: 0.9672698886306198 at epoch: 10\n",
      "2022-12-09 03:11:35,428 - Epoch[10] Complete. Time taken: 00:00:04.633\n",
      "2022-12-09 03:11:35,428 - Engine run complete. Time taken: 00:00:31.575\n"
     ]
    }
   ],
   "source": [
    "tracking_uri = \"./spleen_ct_segmentation/eval/mlruns\"\n",
    "ml_tracking = MLFlowHandler(\n",
    "    tracking_uri=tracking_uri,\n",
    "    experiment_name=\"ParsedExperiment\",\n",
    "    run_name=\"Parsed1\",\n",
    "    tag_name=\"train_loss\",\n",
    "    iteration_log=True,\n",
    "    epoch_log=True,\n",
    "    output_transform=monai.handlers.from_engine([\"loss\"], first=True),\n",
    ")\n",
    "parser = ConfigParser()\n",
    "parser.read_config(f=\"./spleen_ct_segmentation/configs/train.json\")\n",
    "parser.read_meta(f=\"./spleen_ct_segmentation/configs/metadata.json\")\n",
    "parser.update({\"train#trainer#max_epochs\": 10, \"dataset_dir\": data_dir})\n",
    "\n",
    "trainer = parser.get_parsed_content(\"train#trainer\")\n",
    "ml_tracking.attach(trainer)\n",
    "trainer.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
