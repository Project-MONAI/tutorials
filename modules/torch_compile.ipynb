{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) MONAI Consortium  \n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  \n",
    "you may not use this file except in compliance with the License.  \n",
    "You may obtain a copy of the License at  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;http://www.apache.org/licenses/LICENSE-2.0  \n",
    "Unless required by applicable law or agreed to in writing, software  \n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,  \n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \n",
    "See the License for the specific language governing permissions and  \n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 2.0 Integration\n",
    "\n",
    "This notebook introduces how to use `torch.compile` in MONAI pipeline. It mainly includes several parts as shown below.\n",
    "- What is torch.compile?\n",
    "\n",
    "    `torch.compile` is the main API for PyTorch 2.0, which wraps your model and returns a compiled model. It is a fully additive (and optional) feature and hence 2.0 is 100% backward compatible by definition.\n",
    "\n",
    "- A simple demo to show how to use the `torch.compile`.\n",
    "\n",
    "- Use the `torch.compile` in the bundle.\n",
    "\n",
    "- Compared results\n",
    "\n",
    "    We run an end-to-end pipeline based on [\"fast_training_tutorial.ipynb\"](https://github.com/Project-MONAI/tutorials/blob/main/acceleration/fast_training_tutorial.ipynb), and we can see a 10% speed up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, matplotlib]\"\n",
    "!pip install -q torch>=2.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import tempfile\n",
    "\n",
    "import monai\n",
    "import monai.transforms as mt\n",
    "from monai.config import print_config\n",
    "from monai.utils import set_determinism\n",
    "from monai.bundle import download, create_workflow\n",
    "from monai.engines import SupervisedTrainer\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data directory\n",
    "\n",
    "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.  \n",
    "This allows you to save results and reuse downloads.  \n",
    "If not specified, a temporary directory will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/data\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple demo to show how to use the `torch.compile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 09:01:27,769 - INFO - Expected md5 is None, skip md5 check for file samples.zip.\n",
      "2024-01-09 09:01:27,769 - INFO - File exists: samples.zip, skipped downloading.\n",
      "2024-01-09 09:01:27,771 - INFO - Writing into directory: /workspace/data.\n"
     ]
    }
   ],
   "source": [
    "sample_url = \"https://github.com/Project-MONAI/MONAI-extra-test-data/releases\"\n",
    "sample_url += \"/download/0.8.1/totalSegmentator_mergedLabel_samples.zip\"\n",
    "monai.apps.download_and_extract(sample_url, output_dir=root_dir, filepath=\"samples.zip\")\n",
    "\n",
    "base_name = os.path.join(root_dir, \"totalSegmentator_mergedLabel_samples\")\n",
    "input_data = []\n",
    "for filename in os.listdir(os.path.join(base_name, \"imagesTr\")):\n",
    "    input_data.append(\n",
    "        {\n",
    "            \"image\": os.path.join(base_name, \"imagesTr\", filename),\n",
    "            \"label\": os.path.join(base_name, \"labelsTr\", filename),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set deterministic for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "transform = mt.Compose(\n",
    "    [\n",
    "        mt.LoadImageD(keys=(\"image\", \"label\"), image_only=True, ensure_channel_first=True),\n",
    "        mt.SpacingD(keys=(\"image\", \"label\"), pixdim=1.5),\n",
    "        mt.EnsureTypeD(keys=(\"image\", \"label\"), device=device),\n",
    "        mt.RandRotateD(\n",
    "            keys=(\"image\", \"label\"),\n",
    "            prob=1.0,\n",
    "            range_x=0.1,\n",
    "            range_y=0.1,\n",
    "            range_z=0.3,\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        mt.RandZoomD(keys=(\"image\", \"label\"), prob=1.0, min_zoom=0.8, max_zoom=1.2, mode=(\"trilinear\", \"nearest\")),\n",
    "        mt.ResizeWithPadOrCropD(keys=(\"image\", \"label\"), spatial_size=(96, 96, 96)),\n",
    "        # add `FromMetaTensorD` to convert `MetaTensor` to `torch.Tensor`\n",
    "        mt.FromMetaTensorD(keys=(\"image\", \"label\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model\n",
    "\n",
    "Here we used `create_workflow` to get the network instance from the bundle. You can also initialize your own network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-09 09:01:30,861 - INFO - --- input summary of monai.bundle.scripts.download ---\n",
      "2024-01-09 09:01:30,863 - INFO - > name: 'wholeBody_ct_segmentation'\n",
      "2024-01-09 09:01:30,864 - INFO - > bundle_dir: './bundle'\n",
      "2024-01-09 09:01:30,865 - INFO - > source: 'monaihosting'\n",
      "2024-01-09 09:01:30,865 - INFO - > remove_prefix: 'monai_'\n",
      "2024-01-09 09:01:30,866 - INFO - > progress: True\n",
      "2024-01-09 09:01:30,867 - INFO - ---\n",
      "\n",
      "\n",
      "2024-01-09 09:01:31,054 - INFO - Expected md5 is None, skip md5 check for file bundle/wholeBody_ct_segmentation_v0.2.1.zip.\n",
      "2024-01-09 09:01:31,055 - INFO - File exists: bundle/wholeBody_ct_segmentation_v0.2.1.zip, skipped downloading.\n",
      "2024-01-09 09:01:31,056 - INFO - Writing into directory: bundle.\n",
      "2024-01-09 09:01:31,968 - INFO - --- input summary of monai.bundle.scripts.run ---\n",
      "2024-01-09 09:01:31,969 - INFO - > config_file: './bundle/wholeBody_ct_segmentation/configs/train.json'\n",
      "2024-01-09 09:01:31,970 - INFO - > workflow_type: 'train'\n",
      "2024-01-09 09:01:31,971 - INFO - ---\n",
      "\n",
      "\n",
      "2024-01-09 09:01:31,972 - INFO - Setting logging properties based on config: bundle/wholeBody_ct_segmentation/configs/logging.conf.\n"
     ]
    }
   ],
   "source": [
    "bundle_dir = \"./bundle\"\n",
    "os.makedirs(bundle_dir, exist_ok=True)\n",
    "\n",
    "bundle = download(\"wholeBody_ct_segmentation\", bundle_dir=bundle_dir)\n",
    "config_file = os.path.join(bundle_dir, \"wholeBody_ct_segmentation/configs/train.json\")\n",
    "train_workflow = create_workflow(config_file=str(config_file), workflow_type=\"train\")\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    return train_workflow.network_def.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 20/20 [00:05<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 time 2.3300938606262207\n",
      "epoch1 time 1.0478227138519287\n",
      "epoch2 time 1.0480997562408447\n",
      "epoch3 time 1.0515162944793701\n",
      "epoch4 time 1.0385167598724365\n",
      "epoch5 time 1.0458405017852783\n",
      "total time 105.7378671169281\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 100\n",
    "dataset = monai.data.CacheDataset(data=input_data, transform=transform, cache_rate=1.0, num_workers=4)\n",
    "data_loader = monai.data.DataLoader(dataset, batch_size=1)\n",
    "\n",
    "model = create_model()\n",
    "s = time.time()\n",
    "for i in range(epoch_num):\n",
    "    e = time.time()\n",
    "    for batch_data in data_loader:\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        out = model(inputs)\n",
    "    if i <= 5:\n",
    "        print(f\"epoch{i} time\", time.time() - e)\n",
    "print(\"total time\", time.time() - s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With compile\n",
    "\n",
    "The only difference is that we wrap the model with `torch.compile`. As [torch](https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html) mentioned, we can see that `torch.compile`` takes longer in the first epoch, as it must compile the model, but in subsequent iterations, we can see a significant improvement compared to eager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 20/20 [00:04<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 time 15.756214141845703\n",
      "epoch1 time 0.528465986251831\n",
      "epoch2 time 0.5261788368225098\n",
      "epoch3 time 0.5370438098907471\n",
      "epoch4 time 0.532045841217041\n",
      "epoch5 time 0.5341622829437256\n",
      "total time 67.98181772232056\n"
     ]
    }
   ],
   "source": [
    "dataset = monai.data.CacheDataset(data=input_data, transform=transform, cache_rate=1.0, num_workers=4)\n",
    "data_loader = monai.data.DataLoader(dataset, batch_size=1)\n",
    "\n",
    "model = torch.compile(create_model())\n",
    "s = time.time()\n",
    "for i in range(epoch_num):\n",
    "    e = time.time()\n",
    "    for batch_data in data_loader:\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        out = model(inputs)\n",
    "    if i <= 5:\n",
    "        print(f\"epoch{i} time\", time.time() - e)\n",
    "print(\"total time\", time.time() - s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the `torch.compile` in the bundle\n",
    "\n",
    "We can simply set `compile=True` in the `SupervisedTrainer` and `SupervisedEvaluator`. Here we convert data to `torch.Tensor` internally if set `compile=True`. Here is the [ticket](https://github.com/pytorch/pytorch/issues/117026) we can track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SupervisedTrainer(\n",
    "    device=device,\n",
    "    max_epochs=epoch_num,\n",
    "    train_data_loader=data_loader,\n",
    "    network=model,\n",
    "    # optimizer=optimizer,\n",
    "    # loss_function=loss_function,\n",
    "    # inferer=SimpleInferer(),\n",
    "    # postprocessing=post_transform,\n",
    "    # amp=args.amp,\n",
    "    # key_train_metric={\n",
    "    #     \"train_dice\": MeanDice(\n",
    "    #         include_background=False,\n",
    "    #         output_transform=from_engine([\"pred\", \"label\"]),\n",
    "    #     )\n",
    "    # },\n",
    "    compile=True,\n",
    "    # you can also add `compile_kwargs` dict of the args for `torch.compile()` API\n",
    "    compile_kwargs={},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compared results\n",
    "\n",
    "We used `torch.compile` in fast_training_tutorial.ipynb and see a 10% speed up.\n",
    "\n",
    "![compile_benchmark_total_epoch_time_comparison](../figures/total_epoch_time_comparison-compile.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
