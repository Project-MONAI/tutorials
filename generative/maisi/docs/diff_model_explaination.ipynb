{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fbc25b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "from monai.transforms import Compose\n",
    "from monai.data import ThreadDataLoader\n",
    "from monai.utils import set_determinism\n",
    "import json\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbe1d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function placeholders (definitions provided earlier)\n",
    "def diff_model_create_training_data(dataroot, filenames_filepath, output_root_embedding, autoencoder_root, list_filepath, output_dir, pl_root):\n",
    "    pass  # Function definition here\n",
    "\n",
    "def diff_model_train(ckpt_folder, ckpt_prefix, data_root, data_list, data_list_order, ignore_prev_loss, output_size, pretrained_ckpt_filepath, lr, num_epochs, num_training_data, num_train_timesteps, scheduler_method):\n",
    "    pass  # Function definition here\n",
    "\n",
    "def diff_model_infer(ckpt_filepath, random_seed, output_prefix, output_size, amp, a_min, a_max, b_min, b_max):\n",
    "    pass  # Function definition here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f15719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "dataroot = \"./data\"\n",
    "filenames_filepath = \"./filenames.txt\"\n",
    "output_root_embedding = \"./embeddings\"\n",
    "autoencoder_root = \"./autoencoder\"\n",
    "list_filepath = \"./list.txt\"\n",
    "output_dir = \"./output\"\n",
    "pl_root = \"./pl_root\"\n",
    "ckpt_folder = \"./models\"\n",
    "ckpt_prefix = \"unet3d\"\n",
    "data_list = \"./dataset_image.json\"\n",
    "data_list_order = \"sorted\"\n",
    "pretrained_ckpt_filepath = \"scratch\"\n",
    "ckpt_filepath = \"./models/unet3d_best.pt\"\n",
    "output_prefix = \"unet_3d\"\n",
    "output_size = 512\n",
    "amp = True\n",
    "a_min = -1000\n",
    "a_max = 1000\n",
    "b_min = 0\n",
    "b_max = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bff1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pseudo data\n",
    "os.makedirs(dataroot, exist_ok=True)\n",
    "os.makedirs(output_root_embedding, exist_ok=True)\n",
    "os.makedirs(autoencoder_root, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(pl_root, exist_ok=True)\n",
    "os.makedirs(ckpt_folder, exist_ok=True)\n",
    "os.makedirs(\"./predictions\", exist_ok=True)\n",
    "\n",
    "# Create pseudo filenames.txt\n",
    "filenames = [f\"image_{i:03d}_image.nii.gz\" for i in range(10)]\n",
    "with open(filenames_filepath, \"w\") as f:\n",
    "    f.write(\"\\n\".join(filenames))\n",
    "\n",
    "print(\"Created pseudo filenames.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f98e2db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create Training Data\n",
    "print(\"Creating training data...\")\n",
    "diff_model_create_training_data(dataroot, filenames_filepath, output_root_embedding, autoencoder_root, list_filepath, output_dir, pl_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0dbbdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train the Model\n",
    "print(\"Training the model...\")\n",
    "diff_model_train(\n",
    "    ckpt_folder=ckpt_folder,\n",
    "    ckpt_prefix=ckpt_prefix,\n",
    "    data_root=dataroot,\n",
    "    data_list=data_list,\n",
    "    data_list_order=data_list_order,\n",
    "    ignore_prev_loss=False,\n",
    "    output_size=output_size,\n",
    "    pretrained_ckpt_filepath=pretrained_ckpt_filepath,\n",
    "    lr=1e-4,\n",
    "    num_epochs=10,  # Reduced for testing purposes\n",
    "    num_training_data=1024,\n",
    "    num_train_timesteps=1000,\n",
    "    scheduler_method=\"ddpm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85b17df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Infer using the Trained Model\n",
    "print(\"Running inference...\")\n",
    "diff_model_infer(\n",
    "    ckpt_filepath=ckpt_filepath,\n",
    "    random_seed=random.randint(0, 99999),\n",
    "    output_prefix=output_prefix,\n",
    "    output_size=output_size,\n",
    "    amp=amp,\n",
    "    a_min=a_min,\n",
    "    a_max=a_max,\n",
    "    b_min=b_min,\n",
    "    b_max=b_max\n",
    ")\n",
    "\n",
    "print(\"Completed all steps.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
