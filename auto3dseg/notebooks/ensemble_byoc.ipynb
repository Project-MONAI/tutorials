{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customize Algorithm Ensemble in Auto3DSeg\n",
    "\n",
    "In this notebook, we will provide a brief example of how to to customize your ensemble pipeline by defining new ensemble class\n",
    "\n",
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import random\n",
    "\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "from monai.apps.auto3dseg import (\n",
    "    AlgoEnsemble,\n",
    "    AlgoEnsembleBuilder,\n",
    "    DataAnalyzer,\n",
    "    BundleGen,\n",
    ")\n",
    "\n",
    "from monai.bundle.config_parser import ConfigParser\n",
    "from monai.data import create_test_image_3d\n",
    "from monai.utils.enums import AlgoEnsembleKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate a dataset and Auto3D datalist using MONAI functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_datalist = {\n",
    "    \"testing\": [{\"image\": \"val_001.fake.nii.gz\"}, {\"image\": \"val_002.fake.nii.gz\"}],\n",
    "    \"training\": [\n",
    "        {\"fold\": 0, \"image\": \"tr_image_001.fake.nii.gz\", \"label\": \"tr_label_001.fake.nii.gz\"},\n",
    "        {\"fold\": 0, \"image\": \"tr_image_002.fake.nii.gz\", \"label\": \"tr_label_002.fake.nii.gz\"},\n",
    "        {\"fold\": 0, \"image\": \"tr_image_003.fake.nii.gz\", \"label\": \"tr_label_003.fake.nii.gz\"},\n",
    "        {\"fold\": 0, \"image\": \"tr_image_004.fake.nii.gz\", \"label\": \"tr_label_004.fake.nii.gz\"},\n",
    "        {\"fold\": 1, \"image\": \"tr_image_005.fake.nii.gz\", \"label\": \"tr_label_005.fake.nii.gz\"},\n",
    "        {\"fold\": 1, \"image\": \"tr_image_006.fake.nii.gz\", \"label\": \"tr_label_006.fake.nii.gz\"},\n",
    "        {\"fold\": 1, \"image\": \"tr_image_007.fake.nii.gz\", \"label\": \"tr_label_007.fake.nii.gz\"},\n",
    "        {\"fold\": 1, \"image\": \"tr_image_008.fake.nii.gz\", \"label\": \"tr_label_008.fake.nii.gz\"},\n",
    "        {\"fold\": 2, \"image\": \"tr_image_009.fake.nii.gz\", \"label\": \"tr_label_009.fake.nii.gz\"},\n",
    "        {\"fold\": 2, \"image\": \"tr_image_010.fake.nii.gz\", \"label\": \"tr_label_010.fake.nii.gz\"},\n",
    "        {\"fold\": 2, \"image\": \"tr_image_011.fake.nii.gz\", \"label\": \"tr_label_011.fake.nii.gz\"},\n",
    "        {\"fold\": 2, \"image\": \"tr_image_012.fake.nii.gz\", \"label\": \"tr_label_012.fake.nii.gz\"},\n",
    "    ],\n",
    "}\n",
    "\n",
    "dataroot = str(Path(\"./data\"))\n",
    "work_dir = str(Path(\"./ensemble_byoc_work_dir\"))\n",
    "\n",
    "da_output_yaml = os.path.join(work_dir, \"datastats.yaml\")\n",
    "data_src_cfg = os.path.join(work_dir, \"data_src_cfg.yaml\")\n",
    "\n",
    "if not os.path.isdir(dataroot):\n",
    "    os.makedirs(dataroot)\n",
    "\n",
    "if not os.path.isdir(work_dir):\n",
    "    os.makedirs(work_dir)\n",
    "\n",
    "# Generate a fake dataset\n",
    "for d in sim_datalist[\"testing\"] + sim_datalist[\"training\"]:\n",
    "    im, seg = create_test_image_3d(64, 64, 64, rad_max=10, num_seg_classes=1, random_state=np.random.RandomState(42))\n",
    "    nib_image = nib.Nifti1Image(im, affine=np.eye(4))\n",
    "    image_fpath = os.path.join(dataroot, d[\"image\"])\n",
    "    nib.save(nib_image, image_fpath)\n",
    "\n",
    "    if \"label\" in d:\n",
    "        nib_image = nib.Nifti1Image(seg, affine=np.eye(4))\n",
    "        label_fpath = os.path.join(dataroot, d[\"label\"])\n",
    "        nib.save(nib_image, label_fpath)\n",
    "\n",
    "# write to a json file\n",
    "sim_datalist_filename = os.path.join(dataroot, \"sim_datalist.json\")\n",
    "ConfigParser.export_config_file(sim_datalist, sim_datalist_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a new class that inherit the AlgoEnsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAlgoEnsemble(AlgoEnsemble):\n",
    "    \"\"\"\n",
    "    Randomly select N models to do ensemble\n",
    "    \"\"\"\n",
    "    def __init__(self, n_models=3):\n",
    "\n",
    "        super().__init__()\n",
    "        self.n_models = n_models\n",
    "\n",
    "    def collect_algos(self):\n",
    "        \"\"\"\n",
    "        collect_algos defines the method to collect the target algos from the self.algos list\n",
    "        \"\"\"\n",
    "        n = len(self.algos)\n",
    "        if self.n_models > n:\n",
    "            raise ValueError(f\"Number of loaded Algo is {n}, but {self.n_models} algos are requested.\")\n",
    "\n",
    "        indexes = list(range(n))\n",
    "        random.shuffle(indexes)\n",
    "        indexes = indexes[0:self.n_models]\n",
    "        self.algo_ensemble = []\n",
    "        for idx in indexes:\n",
    "            self.algo_ensemble.append(deepcopy(self.algos[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Auto3DSeg data analyzer, algo generation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = DataAnalyzer(sim_datalist_filename, dataroot, output_path=da_output_yaml)\n",
    "da.get_all_case_stats()\n",
    "\n",
    "data_src = {\n",
    "    \"modality\": \"MRI\",\n",
    "    \"datalist\": sim_datalist_filename,\n",
    "    \"dataroot\": dataroot,\n",
    "}\n",
    "\n",
    "ConfigParser.export_config_file(data_src, data_src_cfg)\n",
    "\n",
    "bundle_generator = BundleGen(\n",
    "    algo_path=work_dir, data_stats_filename=da_output_yaml, data_src_cfg_name=data_src_cfg\n",
    ")\n",
    "bundle_generator.generate(work_dir, num_fold=2)\n",
    "history = bundle_generator.get_history()\n",
    "\n",
    "\n",
    "max_epochs = 2\n",
    "\n",
    "# safeguard to ensure max_epochs is greater or equal to 2\n",
    "max_epochs = max(max_epochs, 2)\n",
    "\n",
    "train_param = {\n",
    "    \"CUDA_VISIBLE_DEVICES\": [0],  # use only 1 gpu\n",
    "    \"num_iterations\": 4 * max_epochs,\n",
    "    \"num_iterations_per_validation\": 2 * max_epochs,\n",
    "    \"num_images_per_batch\": 2,\n",
    "    \"num_epochs\": max_epochs,\n",
    "    \"num_warmup_iterations\": 2 * max_epochs,\n",
    "}\n",
    "\n",
    "for h in history:\n",
    "    for _, algo in h.items():\n",
    "        algo.train(train_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply MyAlgoEnsemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = AlgoEnsembleBuilder(history, data_src_cfg)\n",
    "builder.set_ensemble_method(MyAlgoEnsemble())\n",
    "ensemble = builder.get_ensemble()\n",
    "preds = ensemble()\n",
    "\n",
    "print('The ensemble randomly picks the following models:')\n",
    "for algo in ensemble.get_algo_ensemble():\n",
    "    print(algo[AlgoEnsembleKeys.ID])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
