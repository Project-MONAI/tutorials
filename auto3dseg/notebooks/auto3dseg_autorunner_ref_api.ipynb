{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MONAI Auto3DSeg Reference Python APIs\n",
    "\n",
    "In this notebook, we will break down the Auto3DSeg by the modules in the pipeline and introduce the API calls in Python and CLI commands. Particularly, if you have used the AutoRunner class, we will map the AutoRunner commands and configurations to each of the Auto3DSeg module APIs\n",
    "\n",
    "![workflow](../figures/workflow.png)\n",
    "\n",
    "## 1 Set up environment, imports and datasets\n",
    "\n",
    "If you have set up MONAI and run the AutoRunner notebooks in simulated and real-world datasets, you may skip this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Set up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Set up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.apps.auto3dseg import (\n",
    "    DataAnalyzer,\n",
    "    BundleGen,\n",
    "    AlgoEnsembleBestN,\n",
    "    AlgoEnsembleBuilder,\n",
    "    export_bundle_algo_history,\n",
    "    import_bundle_algo_history,\n",
    ")\n",
    "from monai.auto3dseg import algo_to_pickle, datafold_read\n",
    "from monai.bundle.config_parser import ConfigParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Download public datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task09_Spleen.tar: 1.50GB [00:43, 36.7MB/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-29 03:49:02,357 - INFO - Downloaded: Task09_Spleen.tar\n",
      "2022-09-29 03:49:02,359 - INFO - Expected md5 is None, skip md5 check for file Task09_Spleen.tar.\n",
      "2022-09-29 03:49:02,359 - INFO - Writing into directory: ./.\n"
     ]
    }
   ],
   "source": [
    "root = \"./\"\n",
    "work_dir = os.path.join(root, 'ref_api_work_dir')\n",
    "if not os.path.isdir(work_dir):\n",
    "    os.makedirs(work_dir)\n",
    "\n",
    "msd_task = \"Task09_Spleen\"\n",
    "dataroot = os.path.join(root, msd_task)\n",
    "datalist_file = os.path.join(\"..\", \"tasks\", \"msd\", msd_task, \"msd_\" + msd_task.lower() + \"_folds.json\")\n",
    "\n",
    "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/\" + msd_task + \".tar\"\n",
    "compressed_file = os.path.join(root, msd_task + \".tar\")\n",
    "if os.path.exists(root):\n",
    "    download_and_extract(resource, compressed_file, root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Prepare a input YAML configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_src_cfg = {\n",
    "    \"name\": msd_task,  # optional\n",
    "    \"task\": \"segmentation\",  # optional\n",
    "    \"modality\": \"MRI\",  # required\n",
    "    \"datalist\": datalist_file,  # required\n",
    "    \"dataroot\": dataroot,  # required\n",
    "}\n",
    "input = os.path.join(work_dir, 'input.yaml')\n",
    "ConfigParser.export_config_file(data_src_cfg, input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Breaking down the AutoRunner\n",
    "\n",
    "Below is the typical usage of AutoRunner\n",
    "```python\n",
    "runner = AutoRunner(input=input)\n",
    "runner.run() \n",
    "```\n",
    "\n",
    "The two lines cover the typical settings in Auto3DSeg and now we are going through the internal APIs calls inside these two lines\n",
    "\n",
    "### 2.1 Data Analysis\n",
    "\n",
    "When the `analyze` flag is set to `True`, `AutoRunner` will call `DataAnalyzer` to analyze the datasets and generate a statisical report in YAML. Below is the equivalent Python API calls of `DataAnalyzer`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:34<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-29 01:43:36,891 - WARNING - Data is not completely uniform. MONAI transforms may provide unexpected result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datastats_file = os.path.join(work_dir, 'data_stats.yaml')\n",
    "analyser = DataAnalyzer(datalist_file, dataroot, output_path=datastats_file, device=\"cpu\")\n",
    "datastat = analyser.get_all_case_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the Python API call, user can also use command line interface (CLI) provided by the user's OS. One example is the following bash commands:\n",
    "\n",
    "```bash\n",
    "python -m monai.apps.auto3dseg DataAnalyzer get_all_case_stats --datalist=\"../tasks/msd/Task09_Spleen/msd_task09_spleen_folds.json\" --dataroot=\"./Task09_Spleen\" --output_path=\"./ref_api_work_dir/data_stats.yaml\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Algorithm Generation (algo_gen)\n",
    "\n",
    "When the `algo_gen` flag is set to `True`, `AutoRunner` will use `BundleGen` to generate monai bundles from templated algorithms in the working directory. \n",
    "\n",
    "The templated algorithms are customized for the datasets when the `generate` method is called. In detail, the `generate` method will fill the templates using information from the data_stats report. Also, it will copy the necessary scripts (train.py/infer.py) to the algorithm folder. Finally, it will create an algo_object.pkl to save the `Algo` so that it can be instantiated in the local or remote machine. Cross validation is used by default, and `num_fold` can be set to 1 if the users do not want cross validation.\n",
    "\n",
    "Below is the equivalent Python API calls of `BundleGen`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "algo_templates.tar.gz: 100%|██████████| 280k/280k [00:00<00:00, 607kB/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-29 01:43:37,829 - INFO - Downloaded: /tmp/tmpodiia3qq/algo_templates.tar.gz\n",
      "2022-09-29 01:43:37,830 - INFO - Expected md5 is None, skip md5 check for file /tmp/tmpodiia3qq/algo_templates.tar.gz.\n",
      "2022-09-29 01:43:37,830 - INFO - Writing into directory: ./ref_api_work_dir.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-29 01:43:38,651 - INFO - ./ref_api_work_dir/segresnet2d_0\n",
      "2022-09-29 01:43:39,029 - INFO - ./ref_api_work_dir/segresnet2d_1\n",
      "2022-09-29 01:43:39,411 - INFO - ./ref_api_work_dir/segresnet2d_2\n",
      "2022-09-29 01:43:39,916 - INFO - ./ref_api_work_dir/segresnet2d_3\n",
      "2022-09-29 01:43:40,373 - INFO - ./ref_api_work_dir/segresnet2d_4\n",
      "2022-09-29 01:43:41,656 - INFO - ./ref_api_work_dir/dints_0\n",
      "2022-09-29 01:43:42,284 - INFO - ./ref_api_work_dir/dints_1\n",
      "2022-09-29 01:43:42,678 - INFO - ./ref_api_work_dir/dints_2\n",
      "2022-09-29 01:43:43,172 - INFO - ./ref_api_work_dir/dints_3\n",
      "2022-09-29 01:43:43,681 - INFO - ./ref_api_work_dir/dints_4\n",
      "2022-09-29 01:43:44,448 - INFO - ./ref_api_work_dir/swinunetr_0\n",
      "2022-09-29 01:43:44,807 - INFO - ./ref_api_work_dir/swinunetr_1\n",
      "2022-09-29 01:43:45,177 - INFO - ./ref_api_work_dir/swinunetr_2\n",
      "2022-09-29 01:43:45,687 - INFO - ./ref_api_work_dir/swinunetr_3\n",
      "2022-09-29 01:43:48,313 - INFO - ./ref_api_work_dir/swinunetr_4\n",
      "2022-09-29 01:43:48,983 - INFO - ./ref_api_work_dir/segresnet_0\n",
      "2022-09-29 01:43:49,597 - INFO - ./ref_api_work_dir/segresnet_1\n",
      "2022-09-29 01:43:50,008 - INFO - ./ref_api_work_dir/segresnet_2\n",
      "2022-09-29 01:43:50,393 - INFO - ./ref_api_work_dir/segresnet_3\n",
      "2022-09-29 01:43:51,990 - INFO - ./ref_api_work_dir/segresnet_4\n"
     ]
    }
   ],
   "source": [
    "bundle_generator = BundleGen(\n",
    "    algo_path=work_dir,\n",
    "    data_stats_filename=datastats_file,\n",
    "    data_src_cfg_name=input,\n",
    ")\n",
    "\n",
    "bundle_generator.generate(work_dir, num_fold=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the Python API call, user can also use command line interface (CLI) provided by the user's OS. One example is the following bash commands:\n",
    "\n",
    "```bash\n",
    "python -m monai.apps.auto3dseg BundleGen generate \n",
    "--algo_path=\"./auto3dseg_work_dir/\" --data_stats_filename=\"./auto3dseg_work_dir/data_stats.yaml\" --data_src_cfg_name=\"./auto3dseg_work_dir/input.yaml\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Getting and Saving the history to hard drive\n",
    "\n",
    "If the users continue to train the algorithms on local system, The history of the algorithm generation can be fetched via `get_history` method of the `BundleGen` object. There also are scenarios that users need to stop the Python process after the `algo_gen`. For example, the users may need to transfer the files to a remote cluster to start the training. `Auto3DSeg` offers a utility function `export_bundle_algo_history` to dump the history to hard drive and recall it by `import_bundle_algo_history`. \n",
    "\n",
    "If the files are copied to a remote system, please make sure the alrogirthm templates are also copied there. Some functions require the path to instantiate the algorithm class properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = bundle_generator.get_history()\n",
    "export_bundle_algo_history(history)  # save Algo objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Training\n",
    "\n",
    "### 2.3.1 Add training parameters to cut down the training time in this notebook (Optional)\n",
    "\n",
    "This step is not required, but for demo purposes, we'll set a limit of the epochs to train the algorithms. \n",
    "\n",
    "Note: **Auto3DSeg** uses bundle templates to perform training, validation, and inference. The number of epochs/iterations of training is specified by the config files in each template. While we can override them, it is also noted that some bundle templates may use \"num_iterations\" and other may use \"num_epochs\" to iterate. Below is code-block to convert num_epoch to iteration style and override all algorithms with the same training parameters for 1-GPU/2-GPU machine. Again, it is not required to do so. You can either not specify this training params, or specify a train param for each algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_iterations': 32000, 'num_iterations_per_validation': 16000, 'num_images_per_batch': 2, 'num_epochs': 2000, 'num_warmup_iterations': 16000}\n"
     ]
    }
   ],
   "source": [
    "# The training params are optional. If you don't want to change the default settings, you can use either `train()` or `train({})` in 2.3.2 \n",
    "\n",
    "max_epochs = 2000\n",
    "\n",
    "# safeguard to ensure max_epochs is greater or equal to 2\n",
    "max_epochs = max(max_epochs, 2)\n",
    "\n",
    "num_gpus = 1 if \"multigpu\" in data_src_cfg and not data_src_cfg[\"multigpu\"] else torch.cuda.device_count()\n",
    "\n",
    "num_epoch = max_epochs\n",
    "num_images_per_batch = 2\n",
    "files_train_fold0, _ = datafold_read(datalist_file, \"\", 0)\n",
    "n_data = len(files_train_fold0)\n",
    "n_iter = int(num_epoch * n_data / num_images_per_batch / num_gpus)\n",
    "n_iter_val = int(n_iter / 2)\n",
    "\n",
    "train_param = {\n",
    "    \"num_iterations\": n_iter,\n",
    "    \"num_iterations_per_validation\": n_iter_val,\n",
    "    \"num_images_per_batch\": num_images_per_batch,\n",
    "    \"num_epochs\": num_epoch,\n",
    "    \"num_warmup_iterations\": n_iter_val,\n",
    "}\n",
    "\n",
    "print(train_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Training the neural networks sequentially\n",
    "\n",
    "The algo_gen history contains `Algo` object that has multiple methods such as `train` and `predict`. We can easily use such APIs to trigger neural network training. By default, `AutoRunnner` will start a training on a single node (single or multiple GPUs) in a seqential manner.\n",
    "\n",
    "`algo_to_pickle` is optional and it will update the dumped Algo objects with the accuracies information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = import_bundle_algo_history(work_dir, only_trained=False)\n",
    "for task in history:\n",
    "    for _, algo in task.items():\n",
    "        algo.train(train_param)  # can use default params by `algo.train()`\n",
    "        acc = algo.get_score()\n",
    "        algo_to_pickle(algo, template_path=algo.template_path, best_metrics=acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Train with Hyper-parameter Optimization (HPO)\n",
    "\n",
    "Another method to handle the neural network training is to perform HPO (e.g. training & searching). This is made possible by NNI or Optuna packages which are installed in the MONAI development environment. `AutoRunner` uses NNI as backend via the `NNIGen`, but Optuna HPO can also be chosen via the `OptunaGen` method in the Auto3DSeg pipeline\n",
    "\n",
    "To start a NNI, the users need to prepare a config file `nni_config.yaml` and run the command in bash:\n",
    "\n",
    "```bash\n",
    "nnictl create --config nni_config.yaml\n",
    "```\n",
    "\n",
    "Below is an example of the config:\n",
    "```\n",
    "default_nni_config = {\n",
    "    \"experimentName\": name,\n",
    "    \"search_space\": search_space,\n",
    "    \"trialCommand\": cmd,\n",
    "    \"trialCodeDirectory\": \".\",\n",
    "    \"trialGpuNumber\": torch.cuda.device_count(),\n",
    "    \"trialConcurrency\": 1,\n",
    "    \"maxTrialNumber\": 10,\n",
    "    \"maxExperimentDuration\": \"1h\",\n",
    "    \"tuner\": {\"name\": \"GridSearch\"},\n",
    "    \"trainingService\": {\"platform\": \"local\", \"useActiveGpu\": True},\n",
    "}\n",
    "```\n",
    "\n",
    "Example of the search space:\n",
    "```python\n",
    "search_space = {\"_type\": \"choice\", \"_value\": [0.0001, 0.001, 0.01, 0.1]}}\n",
    "```\n",
    "\n",
    "Example of the search command for `segresnet_0`\n",
    "```python\n",
    "cmd = \"python -m monai.apps.auto3dseg NNIGen run_algo \" + \"./auto3dseg/segresnet_0/algo_object.pkl\" + \" ./auto3dseg\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Ensemble\n",
    "\n",
    "Finally, after the neural networks are trained, `AutoRunner` will apply the ensemble methods in Auto3DSeg to improve the overall performance. \n",
    "\n",
    "Here we used a utility function `import_bundle_algo_history` to load the `Algo` that are trained into the ensemble. With the history loaded, we build an ensemble method and use the method to perform the inference on all testing data. By default, `AutoRunner` uses the `AlgoEnsembleBestN` to find the best N models and ensemble the prediction maps by taking the mean of the feature maps.\n",
    "\n",
    "Note: Because we need to get the prediction in Python, there are no CLI command suggestion in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = import_bundle_algo_history(work_dir, only_trained=True)\n",
    "builder = AlgoEnsembleBuilder(history, input)\n",
    "builder.set_ensemble_method(AlgoEnsembleBestN(n_best=5))\n",
    "ensembler = builder.get_ensemble()\n",
    "preds = ensembler()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
