{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import jit\n",
    "\n",
    "from monai.apps.deepgrow.transforms import (\n",
    "    AddGuidanceFromPointsd,\n",
    "    AddGuidanceSignald,\n",
    "    Fetch2DSliced,\n",
    "    ResizeGuidanced,\n",
    "    RestoreLabeld,\n",
    "    SpatialCropGuidanced,\n",
    ")\n",
    "from monai.transforms import (\n",
    "    AsChannelFirstd,\n",
    "    Spacingd,\n",
    "    LoadImaged,\n",
    "    AddChanneld,\n",
    "    NormalizeIntensityd,\n",
    "    ToTensord,\n",
    "    ToNumpyd,\n",
    "    Activationsd,\n",
    "    AsDiscreted,\n",
    "    Resized\n",
    ")\n",
    "\n",
    "max_epochs = 1\n",
    "\n",
    "\n",
    "def draw_points(guidance):\n",
    "    if guidance is None:\n",
    "        return\n",
    "    colors = ['r+', 'b+']\n",
    "    for color, points in zip(colors, guidance):\n",
    "        for p in points:\n",
    "            p1 = p[-1]\n",
    "            p2 = p[-2]\n",
    "            plt.plot(p1, p2, color, 'MarkerSize', 30)\n",
    "\n",
    "\n",
    "def show_image(image, label, guidance=None):\n",
    "    plt.figure(\"check\", (12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"image\")\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "\n",
    "    if label is not None:\n",
    "        masked = np.ma.masked_where(label == 0, label)\n",
    "        plt.imshow(masked, 'jet', interpolation='none', alpha=0.7)\n",
    "\n",
    "    draw_points(guidance)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if label is not None:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(\"label\")\n",
    "        plt.imshow(label)\n",
    "        plt.colorbar()\n",
    "        # draw_points(guidance)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_data(data):\n",
    "    for k in data:\n",
    "        v = data[k]\n",
    "\n",
    "        d = type(v)\n",
    "        if type(v) in (int, float, bool, str, dict, tuple):\n",
    "            d = v\n",
    "        elif hasattr(v, 'shape'):\n",
    "            d = v.shape\n",
    "\n",
    "        if k in ('image_meta_dict', 'label_meta_dict'):\n",
    "            for m in data[k]:\n",
    "                print('{} Meta:: {} => {}'.format(k, m, data[k][m]))\n",
    "        else:\n",
    "            print('Data key: {} = {}'.format(k, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Processing\n",
    "roi_size = [256, 256]\n",
    "model_size = [128, 192, 192]\n",
    "pixdim = (1.0, 1.0)\n",
    "dimensions = 2\n",
    "\n",
    "data = {\n",
    "    'image': '_image.nii.gz',\n",
    "    'foreground': [[66, 180, 105]],\n",
    "    'background': []\n",
    "}\n",
    "slice_idx = original_slice_idx = data['foreground'][0][2]\n",
    "\n",
    "pre_transforms = [\n",
    "    LoadImaged(keys='image'),\n",
    "    AsChannelFirstd(keys='image'),\n",
    "    Spacingd(keys='image', pixdim=pixdim, mode='bilinear'),\n",
    "\n",
    "    AddGuidanceFromPointsd(ref_image='image', guidance='guidance', foreground='foreground', background='background',\n",
    "                           dimensions=dimensions),\n",
    "    Fetch2DSliced(keys='image', guidance='guidance'),\n",
    "    AddChanneld(keys='image'),\n",
    "\n",
    "    SpatialCropGuidanced(keys='image', guidance='guidance', spatial_size=roi_size),\n",
    "    Resized(keys='image', spatial_size=roi_size, mode='area'),\n",
    "    ResizeGuidanced(guidance='guidance', ref_image='image'),\n",
    "    NormalizeIntensityd(keys='image', subtrahend=208.0, divisor=388.0),\n",
    "    AddGuidanceSignald(image='image', guidance='guidance'),\n",
    "    ToTensord(keys='image')\n",
    "]\n",
    "\n",
    "original_image = None\n",
    "original_image_slice = None\n",
    "for t in pre_transforms:\n",
    "    tname = type(t).__name__\n",
    "\n",
    "    data = t(data)\n",
    "    image = data['image']\n",
    "    label = data.get('label')\n",
    "    guidance = data.get('guidance')\n",
    "\n",
    "    print(\"{} => image shape: {}, label shape: {}\".format(\n",
    "        tname, image.shape, label.shape if label is not None else None))\n",
    "\n",
    "    image = image if tname == 'Fetch2DSliced' else image[:, :, slice_idx] if tname in (\n",
    "        'LoadImaged') else image[slice_idx, :, :]\n",
    "    label = None\n",
    "\n",
    "    guidance = guidance if guidance else [np.roll(data['foreground'], 1).tolist(), []]\n",
    "    print('Guidance: {}'.format(guidance))\n",
    "\n",
    "    show_image(image, label, guidance)\n",
    "    if tname == 'Fetch2DSliced':\n",
    "        slice_idx = 0\n",
    "    if tname == 'LoadImaged':\n",
    "        original_image = data['image']\n",
    "    if tname == 'AddChanneld':\n",
    "        original_image_slice = data['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model_path = '/workspace/Data/models/deepgrow_2d.ts'\n",
    "model = jit.load(model_path)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "inputs = data['image'][None].cuda()\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "outputs = outputs[0]\n",
    "data['pred'] = outputs\n",
    "\n",
    "post_transforms = [\n",
    "    Activationsd(keys='pred', sigmoid=True),\n",
    "    AsDiscreted(keys='pred', threshold_values=True, logit_thresh=0.5),\n",
    "    ToNumpyd(keys='pred'),\n",
    "    RestoreLabeld(keys='pred', ref_image='image', mode='nearest'),\n",
    "]\n",
    "\n",
    "for t in post_transforms:\n",
    "    tname = type(t).__name__\n",
    "\n",
    "    data = t(data)\n",
    "    image = original_image if tname == 'RestoreLabeld' else data['image']\n",
    "    label = data['pred']\n",
    "    print(\"{} => image shape: {}, pred shape: {}\".format(tname, image.shape, label.shape))\n",
    "\n",
    "    if tname in 'RestoreLabeld':\n",
    "        image = image[:, :, original_slice_idx]\n",
    "        label = label[0, :, :].detach().cpu().numpy() if torch.is_tensor(label) else label[original_slice_idx]\n",
    "        print(\"PLOT:: {} => image shape: {}, pred shape: {}; min: {}, max: {}, sum: {}\".format(\n",
    "            tname, image.shape, label.shape, np.min(label), np.max(label), np.sum(label)))\n",
    "        show_image(image, label)\n",
    "    else:\n",
    "        image = image[0, :, :].detach().cpu().numpy() if torch.is_tensor(image) else image[0]\n",
    "        label = label[0, :, :].detach().cpu().numpy() if torch.is_tensor(label) else label[0]\n",
    "        print(\"PLOT:: {} => image shape: {}, pred shape: {}; min: {}, max: {}, sum: {}\".format(\n",
    "            tname, image.shape, label.shape, np.min(label), np.max(label), np.sum(label)))\n",
    "        show_image(image, label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}