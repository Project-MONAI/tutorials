{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwesh/anaconda3/envs/nuclick_tutorial/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from skimage.measure import regionprops\n",
    "from monai.engines import SupervisedTrainer, SupervisedEvaluator\n",
    "from monai.handlers import (\n",
    "    CheckpointSaver,\n",
    "    MeanDice,\n",
    "    StatsHandler,\n",
    "    TensorBoardImageHandler,\n",
    "    TensorBoardStatsHandler,\n",
    "    ValidationHandler,\n",
    "    from_engine\n",
    ")\n",
    "from monai.inferers import SimpleInferer\n",
    "from monai.losses import DiceLoss\n",
    "from monai.networks.nets import BasicUNet\n",
    "from monai.data import (\n",
    "    Dataset,\n",
    "    DataLoader,\n",
    ")\n",
    "from monai.transforms import (\n",
    "    Activationsd,\n",
    "    AddChanneld,\n",
    "    AsChannelFirstd,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    EnsureTyped,\n",
    "    LoadImaged,\n",
    "    LoadImage,\n",
    "    RandRotate90d,\n",
    "    ScaleIntensityRangeD,\n",
    "    ToNumpyd,\n",
    "    TorchVisiond,\n",
    "    ToTensord,\n",
    ")\n",
    "\n",
    "from monai.apps.nuclick.transforms import (\n",
    "    FlattenLabeld,\n",
    "    ExtractPatchd,\n",
    "    SplitLabeld,\n",
    "    AddPointGuidanceSignald,\n",
    "    FilterImaged\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_nuclei_dataset(d, centroid_key=\"centroid\", mask_value_key=\"mask_value\", min_area=5):\n",
    "    dataset_json = []\n",
    "\n",
    "    mask = LoadImage(image_only=True, dtype=np.uint8)(d[\"label\"])\n",
    "    _, labels, _, _ = cv2.connectedComponentsWithStats(mask, 4, cv2.CV_32S)\n",
    "\n",
    "    stats = regionprops(labels)\n",
    "    for stat in stats:\n",
    "        if stat.area < min_area:\n",
    "            print(f\"++++ Ignored label with smaller area => ( {stat.area} < {min_area})\")\n",
    "            continue\n",
    "\n",
    "        x, y = stat.centroid\n",
    "        x = int(math.floor(x))\n",
    "        y = int(math.floor(y))\n",
    "\n",
    "        item = copy.deepcopy(d)\n",
    "        item[centroid_key] = (x, y)\n",
    "        item[mask_value_key] = stat.label\n",
    "\n",
    "        dataset_json.append(item)\n",
    "    return dataset_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Path for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the code paths here\n",
    "img_data_path = os.path.normpath('/scratch/pan_nuke_data/fold_1/Fold_1/images/fold1/images.npy')\n",
    "label_data_path = os.path.normpath('/scratch/pan_nuke_data/fold_1/Fold_1/masks/fold1/masks.npy')\n",
    "dataset_path = os.path.normpath('/home/vishwesh/nuclick_experiments/try_1/data')\n",
    "json_path = os.path.normpath('/home/vishwesh/nuclick_experiments/try_1/data_list.json')\n",
    "logging_dir = os.path.normpath('/home/vishwesh/nuclick_experiments/try_6/')\n",
    "model_weights_path = os.path.join(logging_dir, 'network_key_metric=0.8494.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "    patch_size = 128\n",
    "    min_area = 5\n",
    "    val_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=(\"image\", \"label\"), dtype=np.uint8),\n",
    "            FilterImaged(keys=\"image\", min_size=5),\n",
    "            FlattenLabeld(keys=\"label\"),\n",
    "            AsChannelFirstd(keys=\"image\"),\n",
    "            AddChanneld(keys=\"label\"),\n",
    "            ExtractPatchd(keys=(\"image\", \"label\"), patch_size=patch_size),\n",
    "            SplitLabeld(keys=\"label\", others=\"others\", mask_value=\"mask_value\", min_area=min_area),\n",
    "            ToTensord(keys=\"image\"),\n",
    "            TorchVisiond(\n",
    "                keys=\"image\", name=\"ColorJitter\", brightness=64.0 / 255.0, contrast=0.75, saturation=0.25, hue=0.04\n",
    "            ),\n",
    "            ToNumpyd(keys=\"image\"),\n",
    "            RandRotate90d(keys=(\"image\", \"label\", \"others\"), prob=0.5, spatial_axes=(0, 1)),\n",
    "            ScaleIntensityRangeD(keys=\"image\", a_min=0.0, a_max=255.0, b_min=-1.0, b_max=1.0),\n",
    "            AddPointGuidanceSignald(image=\"image\", label=\"label\", others=\"others\", drop_rate=1.0),\n",
    "            EnsureTyped(keys=(\"image\", \"label\"))\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (32, 64, 128, 256, 512, 32).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BasicUNet(\n",
       "  (conv_0): TwoConv(\n",
       "    (conv_0): Convolution(\n",
       "      (conv): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (adn): ADN(\n",
       "        (N): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (D): Dropout(p=0.0, inplace=False)\n",
       "        (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_1): Convolution(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (adn): ADN(\n",
       "        (N): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (D): Dropout(p=0.0, inplace=False)\n",
       "        (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_1): Down(\n",
       "    (max_pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_2): Down(\n",
       "    (max_pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_3): Down(\n",
       "    (max_pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_4): Down(\n",
       "    (max_pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upcat_4): UpCat(\n",
       "    (upsample): UpSample(\n",
       "      (deconv): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upcat_3): UpCat(\n",
       "    (upsample): UpSample(\n",
       "      (deconv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upcat_2): UpCat(\n",
       "    (upsample): UpSample(\n",
       "      (deconv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upcat_1): UpCat(\n",
       "    (upsample): UpSample(\n",
       "      (deconv): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    network = BasicUNet(\n",
    "        spatial_dims=2,\n",
    "        in_channels=5,\n",
    "        out_channels=1,\n",
    "        features=(32, 64, 128, 256, 512, 32),\n",
    "    )\n",
    "    \n",
    "    # The saved weights is a state_dict already\n",
    "    model_weights = torch.load(model_weights_path)\n",
    "    #print(model_weights)\n",
    "    network.load_state_dict(model_weights)\n",
    "    network.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 247.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the json file and get a couple of samples for inferencing\n",
    "with open(json_path, 'rb') as j_file:\n",
    "    json_data = json.load(j_file)\n",
    "j_file.close()\n",
    "\n",
    "test_data = json_data[0:1]\n",
    "\n",
    "test_data_new = []\n",
    "for d in tqdm(test_data):\n",
    "    test_data_new.extend(split_nuclei_dataset(d, min_area=min_area))\n",
    "\n",
    "test_ds = Dataset(data=test_data_new, \n",
    "                  transform=val_transforms,\n",
    "                  )\n",
    "\n",
    "test_loader = DataLoader(test_ds, \n",
    "                         batch_size=1, \n",
    "                         shuffle=False, \n",
    "                         num_workers=1, \n",
    "                         pin_memory=True\n",
    "                        )\n",
    "\n",
    "#print(json_data[0:10])\n",
    "#test_sample = json_data[0]\n",
    "#print(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 128, 128])\n",
      "torch.Size([1, 1, 128, 128])\n",
      "torch.Size([1, 5, 128, 128])\n",
      "torch.Size([1, 1, 128, 128])\n",
      "torch.Size([1, 5, 128, 128])\n",
      "torch.Size([1, 1, 128, 128])\n",
      "torch.Size([1, 5, 128, 128])\n",
      "torch.Size([1, 1, 128, 128])\n",
      "torch.Size([1, 5, 128, 128])\n",
      "torch.Size([1, 1, 128, 128])\n",
      "torch.Size([1, 5, 128, 128])\n",
      "torch.Size([1, 1, 128, 128])\n",
      "torch.Size([1, 5, 128, 128])\n",
      "torch.Size([1, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "network.eval()\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(test_loader):\n",
    "        batch['image'] = batch['image'].to(device)\n",
    "        print(batch['image'].shape)\n",
    "        pred = network(batch['image'])\n",
    "        print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuclick_tutorial",
   "language": "python",
   "name": "nuclick_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
