{".class": "MypyFile", "_fullname": "torch.optim._multi_tensor.adagrad", "future_import_flags": [], "is_partial_stub_package": false, "is_stub": false, "names": {".class": "SymbolTable", "Adagrad": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": null, "abstract_attributes": [], "bases": ["torch.optim.optimizer.Optimizer"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "torch.optim._multi_tensor.adagrad.Adagrad", "name": "Adagrad", "type_vars": []}, "deletable_attributes": [], "flags": [], "fullname": "torch.optim._multi_tensor.adagrad.Adagrad", "has_param_spec_type": false, "metaclass_type": null, "metadata": {}, "module_name": "torch.optim._multi_tensor.adagrad", "mro": ["torch.optim._multi_tensor.adagrad.Adagrad", "torch.optim.optimizer.Optimizer", "builtins.object"], "names": {".class": "SymbolTable", "__init__": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "arg_kinds": [0, 0, 1, 1, 1, 1, 1], "arg_names": ["self", "params", "lr", "lr_decay", "weight_decay", "initial_accumulator_value", "eps"], "flags": [], "fullname": "torch.optim._multi_tensor.adagrad.Adagrad.__init__", "name": "__init__", "type": null}}, "share_memory": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "arg_kinds": [0], "arg_names": ["self"], "flags": [], "fullname": "torch.optim._multi_tensor.adagrad.Adagrad.share_memory", "name": "share_memory", "type": null}}, "step": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Decorator", "func": {".class": "FuncDef", "arg_kinds": [0, 1], "arg_names": ["self", "closure"], "flags": ["is_decorated"], "fullname": "torch.optim._multi_tensor.adagrad.Adagrad.step", "name": "step", "type": null}, "is_overload": false, "var": {".class": "Var", "flags": ["is_initialized_in_class", "is_ready"], "fullname": null, "name": "step", "type": {".class": "CallableType", "arg_kinds": [0, 1], "arg_names": ["self", "closure"], "arg_types": ["torch.optim._multi_tensor.adagrad.Adagrad", {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "from_concatenate": false, "implicit": true, "is_ellipsis_args": false, "name": "step of Adagrad", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "variables": []}}}}}, "slots": null, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "F": {".class": "SymbolTableNode", "cross_ref": "torch.optim._multi_tensor._functional", "kind": "Gdef"}, "Optimizer": {".class": "SymbolTableNode", "cross_ref": "torch.optim.optimizer.Optimizer", "kind": "Gdef"}, "__annotations__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "torch.optim._multi_tensor.adagrad.__annotations__", "name": "__annotations__", "type": {".class": "Instance", "args": ["builtins.str", {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 6}], "type_ref": "builtins.dict"}}}, "__doc__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "torch.optim._multi_tensor.adagrad.__doc__", "name": "__doc__", "type": "builtins.str"}}, "__file__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "torch.optim._multi_tensor.adagrad.__file__", "name": "__file__", "type": "builtins.str"}}, "__name__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "torch.optim._multi_tensor.adagrad.__name__", "name": "__name__", "type": "builtins.str"}}, "__package__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "torch.optim._multi_tensor.adagrad.__package__", "name": "__package__", "type": "builtins.str"}}, "torch": {".class": "SymbolTableNode", "cross_ref": "torch", "kind": "Gdef"}}, "path": "/home/canz/.local/lib/python3.8/site-packages/torch/optim/_multi_tensor/adagrad.py"}