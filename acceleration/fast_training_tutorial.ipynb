{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast training with MONAI features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows a regular PyTorch training program and a MONAI optimized training program, and compared the performance.  \n",
    "Mainly includes:\n",
    "1. AMP (Auto mixed precision).\n",
    "2. CacheDataset for deterministic transforms.\n",
    "3. Move data to GPU and cache, then execute random transforms on GPU.\n",
    "4. multi-threads `ThreadDataLoader` is faster than PyTorch DataLoader in light-weight task.\n",
    "5. Use MONAI `DiceCE` loss instead of regular `Dice` loss.\n",
    "6. Analyzed training curve and tuned algorithm: Use `SGD` optimizer, different network parameters, etc.\n",
    "\n",
    "With a V100 GPU and the target validation `mean dice = 0.94` of the `forground` channel only,  it's more than `100x` speedup compared with the Pytorch regular implementation when achieving the same metric. And every epoch is `20x` faster than regular training.\n",
    "\n",
    "It's modified from the Spleen 3D segmentation tutorial notebook, the Spleen dataset can be downloaded from http://medicaldecathlon.com/.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Project-MONAI/tutorials/blob/main/acceleration/fast_training_tutorial.ipynb)(* please note that the free GPU resource in Colab may be not as powerful as the V100 test results in this notebook: it may not support AMP and the GPU computation of transforms may be not faster than the CPU computation.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: if you are unsure if you have monai and/or matplotlib installed, uncomment to check/install\n",
    "# these are commented out to ensure the converted python script runs smoothly\n",
    "# !python3 -c \"import monai\" || pip install -q \"monai-weekly[nibabel, tqdm]\"\n",
    "# !python3 -c \"import matplotlib\" || pip install -q matplotlib\n",
    "# !python3 -c \"import nvtx\" || pip install -q nvtx\n",
    "\n",
    "# NOTE: uncomment when running as Jupyter notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.9.0rc2\n",
      "Numpy version: 1.22.3\n",
      "Pytorch version: 1.12.0a0+bd13bc6\n",
      "MONAI flags: HAS_EXT = True, USE_COMPILED = False\n",
      "MONAI rev id: d8d24eed0ee7705afd55050af0709613fddacb96\n",
      "MONAI __file__: /opt/monai/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.8\n",
      "Nibabel version: 3.2.2\n",
      "scikit-image version: 0.19.2\n",
      "Pillow version: 9.0.1\n",
      "Tensorboard version: 2.8.0\n",
      "gdown version: 4.4.0\n",
      "TorchVision version: 0.13.0a0\n",
      "tqdm version: 4.64.0\n",
      "lmdb version: 1.3.0\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.3.5\n",
      "einops version: 0.4.1\n",
      "transformers version: 4.19.2\n",
      "mlflow version: 1.26.1\n",
      "pynrrd version: 0.4.3\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import (\n",
    "    CacheDataset,\n",
    "    DataLoader,\n",
    "    ThreadDataLoader,\n",
    "    Dataset,\n",
    "    decollate_batch,\n",
    ")\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.losses import DiceLoss, DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.layers import Act, Norm\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    FgBgToIndicesd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    ToDeviced,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "# for profiling\n",
    "import nvtx\n",
    "from monai.utils.nvtx import Range\n",
    "import contextlib  # to improve code readability (combining training/validation loop with and without profiling)\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: set preferred parameters\n",
    "\n",
    "# overwrite and create a new output directory, True by default\n",
    "output_overwrite = True\n",
    "\n",
    "# set profiling = True to obtain results\n",
    "# to use profiling, make sure Nsight systems is installed, and use the following command to run in TERMINAL ONLY:\n",
    "# jupyter nbconvert fast_training_tutorial.ipynb --to python && nsys profile --output ./outputs/output_base --force-overwrite true --trace-fork-before-exec true python3 fast_training_tutorial.py && rm fast_training_tutorial.py\n",
    "# output will be generated in the current directory (you can change --output)\n",
    "profiling = True\n",
    "\n",
    "# if profiling = True, it is recommended to set max_epochs = 6 for faster prototyping\n",
    "# to see the trend in training curve and dice results, set max_epochs to be larger (600)\n",
    "# note that before optimization, training can be quite a bit slower\n",
    "max_epochs = 6\n",
    "\n",
    "no_profiling = contextlib.nullcontext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data directory\n",
    "\n",
    "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.  \n",
    "This allows you to save results and reuse downloads.  \n",
    "If not specified a temporary directory will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root dir is: /tmp/tmp7wd9gqnn\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(f\"root dir is: {root_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs\n",
    "\n",
    "out_dir = \"outputs/\"\n",
    "\n",
    "if os.path.exists(out_dir) and output_overwrite:\n",
    "    shutil.rmtree(out_dir)\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset\n",
    "\n",
    "Downloads and extracts the Decathlon Spleen dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task09_Spleen.tar: 1.50GB [01:05, 24.5MB/s]                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-16 22:39:46,307 - INFO - Downloaded: /tmp/tmp7wd9gqnn/Task09_Spleen.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-16 22:39:49,673 - INFO - Verified 'Task09_Spleen.tar', md5: 410d4a301da4e5b2f6f86ec3ddba524e.\n",
      "2022-06-16 22:39:49,674 - INFO - Writing into directory: /tmp/tmp7wd9gqnn.\n"
     ]
    }
   ],
   "source": [
    "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task09_Spleen.tar\"\n",
    "md5 = \"410d4a301da4e5b2f6f86ec3ddba524e\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"Task09_Spleen.tar\")\n",
    "data_root = os.path.join(root_dir, \"Task09_Spleen\")\n",
    "if not os.path.exists(data_root):\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set MSD Spleen dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = sorted(\n",
    "    glob.glob(os.path.join(data_root, \"imagesTr\", \"*.nii.gz\"))\n",
    ")\n",
    "train_labels = sorted(\n",
    "    glob.glob(os.path.join(data_root, \"labelsTr\", \"*.nii.gz\"))\n",
    ")\n",
    "data_dicts = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(train_images, train_labels)\n",
    "]\n",
    "train_files, val_files = data_dicts[:-9], data_dicts[-9:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup transforms for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformations(fast=False):\n",
    "    train_transforms = [\n",
    "        Range(\"LoadImage\")(LoadImaged(keys=[\"image\", \"label\"])) if profiling else LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        Range()(AddChanneld(keys=[\"image\", \"label\"])) if profiling else AddChanneld(keys=[\"image\", \"label\"]),\n",
    "        Range()(Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\")) if profiling else\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Range(\"Spacing\")(\n",
    "            Spacingd(\n",
    "                keys=[\"image\", \"label\"],\n",
    "                pixdim=(1.5, 1.5, 2.0),\n",
    "                mode=(\"bilinear\", \"nearest\"),\n",
    "            )) if profiling else\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        Range()(\n",
    "            ScaleIntensityRanged(\n",
    "                keys=[\"image\"],\n",
    "                a_min=-57,\n",
    "                a_max=164,\n",
    "                b_min=0.0,\n",
    "                b_max=1.0,\n",
    "                clip=True,\n",
    "            )) if profiling else\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-57,\n",
    "            a_max=164,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        Range()(CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\")\n",
    "                ) if profiling else CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        # pre-compute foreground and background indexes\n",
    "        # and cache them to accelerate training\n",
    "        Range(\"Indexing\")(\n",
    "            FgBgToIndicesd(\n",
    "                keys=\"label\",\n",
    "                fg_postfix=\"_fg\",\n",
    "                bg_postfix=\"_bg\",\n",
    "                image_key=\"image\",\n",
    "            )) if profiling else\n",
    "        FgBgToIndicesd(\n",
    "            keys=\"label\",\n",
    "            fg_postfix=\"_fg\",\n",
    "            bg_postfix=\"_bg\",\n",
    "            image_key=\"image\",\n",
    "        ),\n",
    "        # change to execute transforms with Tensor data\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    "\n",
    "    if fast:\n",
    "        # move the data to GPU and cache to avoid CPU -> GPU sync in every epoch\n",
    "        train_transforms.append(\n",
    "            ToDeviced(keys=[\"image\", \"label\"], device=\"cuda:0\")\n",
    "        )\n",
    "\n",
    "    train_transforms.append(\n",
    "        # randomly crop out patch samples from big\n",
    "        # image based on pos / neg ratio\n",
    "        # the image centers of negative samples\n",
    "        # must be in valid image area\n",
    "        Range(\"RandCrop\")(\n",
    "            RandCropByPosNegLabeld(\n",
    "                keys=[\"image\", \"label\"],\n",
    "                label_key=\"label\",\n",
    "                spatial_size=(96, 96, 96),\n",
    "                pos=1,\n",
    "                neg=1,\n",
    "                num_samples=4,\n",
    "                fg_indices_key=\"label_fg\",\n",
    "                bg_indices_key=\"label_bg\",\n",
    "            )) if profiling else\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            fg_indices_key=\"label_fg\",\n",
    "            bg_indices_key=\"label_bg\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    val_transforms = [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-57,\n",
    "            a_max=164,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    "    if fast:\n",
    "        # move the data to GPU and cache to avoid CPU -> GPU sync in every epoch\n",
    "        val_transforms.append(\n",
    "            ToDeviced(keys=[\"image\", \"label\"], device=\"cuda:0\")\n",
    "        )\n",
    "\n",
    "    return Compose(train_transforms), Compose(val_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the training progress\n",
    "For a typical PyTorch regular training procedure, use regular `Dataset`, `DataLoader`, `Adam` optimizer and `Dice` loss to train the model.\n",
    "\n",
    "For MONAI fast training progress, we mainly introduce the following features:\n",
    "1. `AMP` (auto mixed precision): AMP is an important feature released in PyTorch v1.6, NVIDIA CUDA 11 added strong support for AMP and significantly improved training speed.\n",
    "2. `CacheDataset`: Dataset with the cache mechanism that can load data and cache deterministic transforms' result during training.\n",
    "3. `ToDeviced` transform: to move data to GPU and cache with `CacheDataset`, then execute random transforms on GPU directly, avoid CPU -> GPU sync in every epoch. Please note that not all the MONAI transforms support GPU operation so far, still working in progress.\n",
    "4. `ThreadDataLoader`: uses multi-threads instead of multi-processing, faster than `DataLoader` in light-weight task as we already cached the results of most computation.\n",
    "5. `DiceCE` loss function: computes Dice loss and Cross Entropy Loss, returns the weighted sum of these two losses.\n",
    "6. Analyzed the training curve and tuned algorithm: Use `SGD` optimizer, different network parameters, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference used from https://stackoverflow.com/questions/27803059/conditional-with-statement-in-python/53088625#53088625\n",
    "# accessed June 14, 2022\n",
    "\n",
    "def train_process(fast=False):\n",
    "    learning_rate = 2e-4\n",
    "    val_interval = 5  # do validation for every epoch\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        raise RuntimeError('this tutorial is intended for GPU, but no CUDA device is available')\n",
    "\n",
    "    train_trans, val_trans = transformations(fast=fast)\n",
    "    # set CacheDataset, ThreadDataLoader and DiceCE loss for MONAI fast training\n",
    "    if fast:\n",
    "        # as `RandCropByPosNegLabeld` crops from the cached content and `deepcopy`\n",
    "        # the crop area instead of modifying the cached value, we can set `copy_cache=False`\n",
    "        # to avoid unnecessary deepcopy of cached content in `CacheDataset`\n",
    "        train_ds = CacheDataset(\n",
    "            data=train_files,\n",
    "            transform=train_trans,\n",
    "            cache_rate=1.0,\n",
    "            num_workers=8,\n",
    "            copy_cache=False,\n",
    "        )\n",
    "        val_ds = CacheDataset(\n",
    "            data=val_files, transform=val_trans, cache_rate=1.0, num_workers=5, copy_cache=False\n",
    "        )\n",
    "        # disable multi-workers because `ThreadDataLoader` works with multi-threads\n",
    "        train_loader = ThreadDataLoader(train_ds, num_workers=0, batch_size=4, shuffle=True)\n",
    "        val_loader = ThreadDataLoader(val_ds, num_workers=0, batch_size=1)\n",
    "        loss_function = DiceCELoss(\n",
    "            include_background=False,\n",
    "            to_onehot_y=True,\n",
    "            softmax=True,\n",
    "            squared_pred=True,\n",
    "            batch=True,\n",
    "            smooth_nr=0.00001,\n",
    "            smooth_dr=0.00001,\n",
    "            lambda_dice=0.5,\n",
    "            lambda_ce=0.5,\n",
    "        )\n",
    "        model = UNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=2,\n",
    "            channels=(32, 64, 128, 256, 512),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,\n",
    "            norm=Norm.BATCH,\n",
    "            kernel_size=3,\n",
    "            up_kernel_size=3,\n",
    "            act=Act.PRELU,\n",
    "            dropout=0.2,\n",
    "            bias=True,\n",
    "            dimensions=None,\n",
    "        ).to(device)\n",
    "    else:\n",
    "        train_ds = Dataset(data=train_files, transform=train_trans)\n",
    "        val_ds = Dataset(data=val_files, transform=val_trans)\n",
    "        # num_worker=4 is the best parameter according to the test\n",
    "        train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4)\n",
    "        val_loader = DataLoader(val_ds, batch_size=1, num_workers=4)\n",
    "        loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "        model = UNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=2,\n",
    "            channels=(16, 32, 64, 128, 256),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,\n",
    "            norm=Norm.BATCH,\n",
    "        ).to(device)\n",
    "\n",
    "    post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=2)])\n",
    "    post_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])\n",
    "\n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "\n",
    "    if fast:\n",
    "        # SGD prefer to much bigger learning rate\n",
    "        optimizer = SGD(\n",
    "            model.parameters(),\n",
    "            lr=learning_rate * 1000,\n",
    "            momentum=0.9,\n",
    "            weight_decay=0.00004,\n",
    "        )\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "    else:\n",
    "        optimizer = Adam(model.parameters(), learning_rate)\n",
    "\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    best_metrics_epochs_and_time = [[], [], []]\n",
    "    epoch_loss_values = []\n",
    "    metric_values = []\n",
    "    epoch_times = []\n",
    "    total_start = time.time()\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "\n",
    "        # profiling: full epoch\n",
    "        with nvtx.annotate(\"epoch\", color=\"red\") if profiling else no_profiling:\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            train_loader_iterator = iter(train_loader)\n",
    "\n",
    "            # using step instead of iterate through train_loader directly to track data loading time\n",
    "            # steps are 1-indexed for printing and calculation purposes\n",
    "            for step in range(1, len(train_loader) + 1):\n",
    "                step_start = time.time()\n",
    "\n",
    "                # profiling: train dataload\n",
    "                with nvtx.annotate(\"dataload\", color=\"red\") if profiling else no_profiling:\n",
    "                    # rng_train_dataload = nvtx.start_range(message=\"dataload\", color=\"red\")\n",
    "                    batch_data = next(train_loader_iterator)\n",
    "                    inputs, labels = (\n",
    "                        batch_data[\"image\"].to(device),\n",
    "                        batch_data[\"label\"].to(device),\n",
    "                    )\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                # set AMP for MONAI training\n",
    "                if fast:\n",
    "                    # profiling: forward\n",
    "                    with nvtx.annotate(\"forward\", color=\"green\") if profiling else no_profiling:\n",
    "                        with torch.cuda.amp.autocast():\n",
    "                            outputs = model(inputs)\n",
    "                            loss = loss_function(outputs, labels)\n",
    "\n",
    "                    # profiling: backward\n",
    "                    with nvtx.annotate(\"backward\", color=\"blue\") if profiling else no_profiling:\n",
    "                        scaler.scale(loss).backward()\n",
    "\n",
    "                    # profiling: update\n",
    "                    with nvtx.annotate(\"update\", color=\"yellow\") if profiling else no_profiling:\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                else:\n",
    "                    # profiling: forward\n",
    "                    with nvtx.annotate(\"forward\", color=\"green\") if profiling else no_profiling:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = loss_function(outputs, labels)\n",
    "\n",
    "                    # profiling: backward\n",
    "                    with nvtx.annotate(\"backward\", color=\"blue\") if profiling else no_profiling:\n",
    "                        loss.backward()\n",
    "\n",
    "                    # profiling: update\n",
    "                    with nvtx.annotate(\"update\", color=\"yellow\") if profiling else no_profiling:\n",
    "                        optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_len = math.ceil(len(train_ds) / train_loader.batch_size)\n",
    "                print(\n",
    "                    f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\"\n",
    "                    f\" step time: {(time.time() - step_start):.4f}\"\n",
    "                )\n",
    "            epoch_loss /= step\n",
    "            epoch_loss_values.append(epoch_loss)\n",
    "            print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "            if (epoch + 1) % val_interval == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_loader_iterator = iter(val_loader)\n",
    "\n",
    "                    for val_step in range(len(val_loader)):\n",
    "                        # profiling: val dataload\n",
    "                        with nvtx.annotate(\"dataload\", color=\"red\") if profiling else no_profiling:\n",
    "                            val_data = next(val_loader_iterator)\n",
    "                            val_inputs, val_labels = (\n",
    "                                val_data[\"image\"].to(device),\n",
    "                                val_data[\"label\"].to(device),\n",
    "                            )\n",
    "\n",
    "                        roi_size = (160, 160, 160)\n",
    "                        sw_batch_size = 4\n",
    "\n",
    "                        # profiling: sliding window\n",
    "                        with nvtx.annotate(\"sliding window\", color=\"green\") if profiling else no_profiling:\n",
    "                            # set AMP for MONAI validation\n",
    "                            if fast:\n",
    "                                with torch.cuda.amp.autocast():\n",
    "                                    val_outputs = sliding_window_inference(\n",
    "                                        val_inputs, roi_size, sw_batch_size, model\n",
    "                                    )\n",
    "                            else:\n",
    "                                val_outputs = sliding_window_inference(\n",
    "                                    val_inputs, roi_size, sw_batch_size, model\n",
    "                                )\n",
    "\n",
    "                        # profiling: decollate batch\n",
    "                        with nvtx.annotate(\"decollate batch\", color=\"blue\") if profiling else no_profiling:\n",
    "                            val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                            val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "\n",
    "                        # profiling: compute metric\n",
    "                        with nvtx.annotate(\"compute metric\", color=\"yellow\") if profiling else no_profiling:\n",
    "                            dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "                    metric = dice_metric.aggregate().item()\n",
    "                    dice_metric.reset()\n",
    "                    metric_values.append(metric)\n",
    "                    if metric > best_metric:\n",
    "                        best_metric = metric\n",
    "                        best_metric_epoch = epoch + 1\n",
    "                        best_metrics_epochs_and_time[0].append(best_metric)\n",
    "                        best_metrics_epochs_and_time[1].append(best_metric_epoch)\n",
    "                        best_metrics_epochs_and_time[2].append(\n",
    "                            time.time() - total_start\n",
    "                        )\n",
    "                        torch.save(model.state_dict(), os.path.join(root_dir, \"best_metric_model.pt\"))\n",
    "                        print(\"saved new best metric model\")\n",
    "                    print(\n",
    "                        f\"current epoch: {epoch + 1} current\"\n",
    "                        f\" mean dice: {metric:.4f}\"\n",
    "                        f\" best mean dice: {best_metric:.4f}\"\n",
    "                        f\" at epoch: {best_metric_epoch}\"\n",
    "                    )\n",
    "\n",
    "        print(\n",
    "            f\"time consuming of epoch {epoch + 1} is:\"\n",
    "            f\" {(time.time() - epoch_start):.4f}\"\n",
    "        )\n",
    "        epoch_times.append(time.time() - epoch_start)\n",
    "\n",
    "    total_time = time.time() - total_start\n",
    "    print(\n",
    "        f\"train completed, best_metric: {best_metric:.4f}\"\n",
    "        f\" at epoch: {best_metric_epoch}\"\n",
    "        f\" total time: {total_time:.4f}\"\n",
    "    )\n",
    "    return (\n",
    "        max_epochs,\n",
    "        epoch_loss_values,\n",
    "        metric_values,\n",
    "        epoch_times,\n",
    "        best_metrics_epochs_and_time,\n",
    "        total_time,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable determinism and execute regular PyTorch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/600\n",
      "1/8, train_loss: 0.6697 step time: 17.1989\n",
      "2/8, train_loss: 0.6850 step time: 0.5307\n",
      "3/8, train_loss: 0.6906 step time: 0.6115\n",
      "4/8, train_loss: 0.6771 step time: 0.6116\n",
      "5/8, train_loss: 0.6635 step time: 14.3529\n",
      "6/8, train_loss: 0.6723 step time: 0.5333\n",
      "7/8, train_loss: 0.6568 step time: 0.5963\n",
      "8/8, train_loss: 0.6648 step time: 0.6781\n",
      "epoch 1 average loss: 0.6725\n",
      "time consuming of epoch 1 is: 35.2439\n",
      "----------\n",
      "epoch 2/600\n",
      "1/8, train_loss: 0.6596 step time: 17.1786\n",
      "2/8, train_loss: 0.6672 step time: 0.5336\n",
      "3/8, train_loss: 0.6405 step time: 2.1023\n",
      "4/8, train_loss: 0.6333 step time: 0.5300\n",
      "5/8, train_loss: 0.6444 step time: 14.7795\n",
      "6/8, train_loss: 0.6272 step time: 0.5311\n",
      "7/8, train_loss: 0.6257 step time: 2.4035\n",
      "8/8, train_loss: 0.6351 step time: 0.5317\n",
      "epoch 2 average loss: 0.6416\n",
      "time consuming of epoch 2 is: 38.8903\n",
      "----------\n",
      "epoch 3/600\n",
      "1/8, train_loss: 0.6546 step time: 14.9130\n",
      "2/8, train_loss: 0.6126 step time: 0.8331\n",
      "3/8, train_loss: 0.6392 step time: 3.5149\n",
      "4/8, train_loss: 0.6240 step time: 0.5408\n",
      "5/8, train_loss: 0.6224 step time: 6.8608\n",
      "6/8, train_loss: 0.6048 step time: 6.7214\n",
      "7/8, train_loss: 0.6162 step time: 2.6038\n",
      "8/8, train_loss: 0.6155 step time: 2.0409\n",
      "epoch 3 average loss: 0.6237\n",
      "time consuming of epoch 3 is: 38.3689\n",
      "----------\n",
      "epoch 4/600\n",
      "1/8, train_loss: 0.5985 step time: 15.5692\n",
      "2/8, train_loss: 0.5991 step time: 4.0304\n",
      "3/8, train_loss: 0.5989 step time: 0.5350\n",
      "4/8, train_loss: 0.6410 step time: 0.5364\n",
      "5/8, train_loss: 0.6391 step time: 10.7004\n",
      "6/8, train_loss: 0.5883 step time: 5.4216\n",
      "7/8, train_loss: 0.6105 step time: 0.5272\n",
      "8/8, train_loss: 0.6171 step time: 0.5292\n",
      "epoch 4 average loss: 0.6116\n",
      "time consuming of epoch 4 is: 38.1987\n",
      "----------\n",
      "epoch 5/600\n",
      "1/8, train_loss: 0.6162 step time: 12.5617\n",
      "2/8, train_loss: 0.5857 step time: 6.3806\n",
      "3/8, train_loss: 0.6034 step time: 0.5551\n",
      "4/8, train_loss: 0.5965 step time: 0.5431\n",
      "5/8, train_loss: 0.6278 step time: 6.4910\n",
      "6/8, train_loss: 0.6098 step time: 8.7140\n",
      "7/8, train_loss: 0.5912 step time: 0.8915\n",
      "8/8, train_loss: 0.6127 step time: 3.9683\n",
      "epoch 5 average loss: 0.6054\n",
      "saved new best metric model\n",
      "current epoch: 5 current mean dice: 0.0557 best mean dice: 0.0557 at epoch: 5\n",
      "time consuming of epoch 5 is: 49.6878\n",
      "----------\n",
      "epoch 6/600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8, train_loss: 0.6376 step time: 21.4406\n",
      "2/8, train_loss: 0.6001 step time: 0.5391\n",
      "3/8, train_loss: 0.5945 step time: 0.5352\n",
      "4/8, train_loss: 0.5741 step time: 0.5328\n",
      "5/8, train_loss: 0.5921 step time: 15.2412\n",
      "6/8, train_loss: 0.5781 step time: 0.5316\n",
      "7/8, train_loss: 0.5985 step time: 0.5329\n",
      "8/8, train_loss: 0.5880 step time: 0.5338\n",
      "epoch 6 average loss: 0.5954\n",
      "time consuming of epoch 6 is: 40.2421\n",
      "----------\n",
      "epoch 7/600\n",
      "1/8, train_loss: 0.5818 step time: 17.3160\n",
      "2/8, train_loss: 0.5802 step time: 0.7001\n",
      "3/8, train_loss: 0.5856 step time: 0.5309\n",
      "4/8, train_loss: 0.5847 step time: 0.5294\n",
      "5/8, train_loss: 0.5955 step time: 14.5025\n",
      "6/8, train_loss: 0.5791 step time: 0.5279\n",
      "7/8, train_loss: 0.5697 step time: 0.9032\n",
      "8/8, train_loss: 0.5984 step time: 0.5315\n",
      "epoch 7 average loss: 0.5844\n",
      "time consuming of epoch 7 is: 35.8987\n",
      "----------\n",
      "epoch 8/600\n",
      "1/8, train_loss: 0.5269 step time: 19.6493\n",
      "2/8, train_loss: 0.5973 step time: 0.5280\n",
      "3/8, train_loss: 0.5655 step time: 0.5366\n",
      "4/8, train_loss: 0.5506 step time: 0.5332\n",
      "5/8, train_loss: 0.5897 step time: 16.4449\n",
      "6/8, train_loss: 0.5974 step time: 0.5314\n",
      "7/8, train_loss: 0.5880 step time: 0.5313\n",
      "8/8, train_loss: 0.5854 step time: 0.5317\n",
      "epoch 8 average loss: 0.5751\n",
      "time consuming of epoch 8 is: 39.6344\n",
      "----------\n",
      "epoch 9/600\n",
      "1/8, train_loss: 0.5801 step time: 17.1434\n",
      "2/8, train_loss: 0.5771 step time: 2.3748\n",
      "3/8, train_loss: 0.5979 step time: 0.5221\n",
      "4/8, train_loss: 0.5484 step time: 0.5908\n",
      "5/8, train_loss: 0.5557 step time: 14.9387\n",
      "6/8, train_loss: 0.5978 step time: 0.5339\n",
      "7/8, train_loss: 0.5727 step time: 0.5332\n",
      "8/8, train_loss: 0.5846 step time: 0.5344\n",
      "epoch 9 average loss: 0.5768\n",
      "time consuming of epoch 9 is: 37.5275\n",
      "----------\n",
      "epoch 10/600\n",
      "1/8, train_loss: 0.5683 step time: 21.5493\n",
      "2/8, train_loss: 0.5436 step time: 0.5359\n",
      "3/8, train_loss: 0.5819 step time: 0.5328\n",
      "4/8, train_loss: 0.5825 step time: 0.5401\n",
      "5/8, train_loss: 0.5347 step time: 13.0271\n",
      "6/8, train_loss: 0.5402 step time: 0.5289\n",
      "7/8, train_loss: 0.5912 step time: 0.5301\n",
      "8/8, train_loss: 0.5952 step time: 0.5317\n",
      "epoch 10 average loss: 0.5672\n",
      "saved new best metric model\n",
      "current epoch: 10 current mean dice: 0.0645 best mean dice: 0.0645 at epoch: 10\n",
      "time consuming of epoch 10 is: 47.3924\n",
      "----------\n",
      "epoch 11/600\n",
      "1/8, train_loss: 0.5565 step time: 19.8168\n",
      "2/8, train_loss: 0.5777 step time: 0.5435\n",
      "3/8, train_loss: 0.5736 step time: 0.5426\n",
      "4/8, train_loss: 0.5809 step time: 0.5388\n"
     ]
    }
   ],
   "source": [
    "set_determinism(seed=0)\n",
    "regular_start = time.time()\n",
    "(\n",
    "    epoch_num,\n",
    "    epoch_loss_values,\n",
    "    metric_values,\n",
    "    epoch_times,\n",
    "    best,\n",
    "    train_time,\n",
    ") = train_process(fast=False)\n",
    "total_time = time.time() - regular_start\n",
    "print(\n",
    "    f\"total time of {epoch_num} epochs with regular PyTorch training: {total_time:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable determinism and execute MONAI optimized training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=0)\n",
    "monai_start = time.time()\n",
    "(\n",
    "    epoch_num,\n",
    "    m_epoch_loss_values,\n",
    "    m_metric_values,\n",
    "    m_epoch_times,\n",
    "    m_best,\n",
    "    m_train_time,\n",
    ") = train_process(fast=True)\n",
    "m_total_time = time.time() - monai_start\n",
    "print(\n",
    "    f\"total time of {epoch_num} epochs with MONAI fast training: {m_train_time:.4f},\"\n",
    "    f\" time of preparing cache: {(m_total_time - m_train_time):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training loss and validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 12))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Regular Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.plot(x, y, color=\"red\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"Regular Val Mean Dice\")\n",
    "x = [i + 1 for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.plot(x, y, color=\"red\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"Fast Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(m_epoch_loss_values))]\n",
    "y = m_epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.plot(x, y, color=\"green\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"Fast Val Mean Dice\")\n",
    "x = [i + 1 for i in range(len(m_metric_values))]\n",
    "y = m_metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.plot(x, y, color=\"green\")\n",
    "plt.savefig(\"outputs/loss_dice_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot total time and every epoch time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Total Train Time(600 epochs)\")\n",
    "plt.bar(\n",
    "    \"regular PyTorch\", total_time, 1, label=\"Regular training\", color=\"red\"\n",
    ")\n",
    "plt.bar(\"Fast\", m_total_time, 1, label=\"Fast training\", color=\"green\")\n",
    "plt.ylabel(\"secs\")\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Epoch Time\")\n",
    "x = [i + 1 for i in range(len(epoch_times))]\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"secs\")\n",
    "plt.plot(x, epoch_times, label=\"Regular training\", color=\"red\")\n",
    "plt.plot(x, m_epoch_times, label=\"Fast training\", color=\"green\")\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(\"outputs/total_epoch_time_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot total time to achieve metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_metric_time(threshold, best_values):\n",
    "    for i, v in enumerate(best_values[0]):\n",
    "        if round(v, 4) >= threshold:\n",
    "            return best_values[2][i]\n",
    "    return -1\n",
    "\n",
    "\n",
    "def get_best_metric_epochs(threshold, best_values):\n",
    "    for i, v in enumerate(best_values[0]):\n",
    "        if round(v, 4) >= threshold:\n",
    "            return best_values[1][i]\n",
    "    return -1\n",
    "\n",
    "\n",
    "def get_label(index):\n",
    "    if index == 0:\n",
    "        return \"Regular training\"\n",
    "    elif index == 1:\n",
    "        return \"Fast training\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "plt.figure(\"train\", (18, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Metrics Time\")\n",
    "plt.xlabel(\"secs\")\n",
    "plt.ylabel(\"best mean_dice\")\n",
    "plt.plot(best[2], best[0], label=\"Regular training\", color=\"red\")\n",
    "plt.plot(m_best[2], m_best[0], label=\"Fast training\", color=\"green\")\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Typical Metrics Time\")\n",
    "plt.xlabel(\"best mean_dice\")\n",
    "plt.ylabel(\"secs\")\n",
    "labels = [\"0.80\", \"0.80 \", \"0.90\", \"0.90 \", \"0.92\", \"0.92 \", \"0.94\", \"0.94 \"]\n",
    "x_values = [0.8, 0.8, 0.9, 0.9, 0.92, 0.92, 0.94, 0.94]\n",
    "for i, (l, x) in enumerate(zip(labels, x_values)):\n",
    "    value = int(get_best_metric_time(x, best if i % 2 == 0 else m_best))\n",
    "    color = \"red\" if i % 2 == 0 else \"green\"\n",
    "    plt.bar(l, value, 0.5, label=get_label(i), color=color)\n",
    "    plt.text(l, value, \"%s\" % value, ha=\"center\", va=\"bottom\")\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Typical Metrics Epochs\")\n",
    "plt.xlabel(\"best mean_dice\")\n",
    "plt.ylabel(\"epochs\")\n",
    "for i, (l, x) in enumerate(zip(labels, x_values)):\n",
    "    value = int(get_best_metric_epochs(x, best if i % 2 == 0 else m_best))\n",
    "    color = \"red\" if i % 2 == 0 else \"green\"\n",
    "    plt.bar(l, value, 0.5, label=get_label(i), color=color)\n",
    "    plt.text(l, value, \"%s\" % value, ha=\"center\", va=\"bottom\")\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(\"outputs/metric_time_epochs.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup data directory\n",
    "\n",
    "Remove directory if a temporary was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if directory is None:\n",
    "    shutil.rmtree(root_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
