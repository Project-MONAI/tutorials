{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yxvh7SsKbvv_"
   },
   "source": [
    "Copyright (c) MONAI Consortium  \n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  \n",
    "you may not use this file except in compliance with the License.  \n",
    "You may obtain a copy of the License at  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;http://www.apache.org/licenses/LICENSE-2.0  \n",
    "Unless required by applicable law or agreed to in writing, software  \n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,  \n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \n",
    "See the License for the specific language governing permissions and  \n",
    "limitations under the License.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M565w1lqtd4M"
   },
   "source": [
    "You can download and run this notebook locally, or you can run it for free in a cloud environment using Colab or Sagemaker Studio Lab:\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kirbyju/TCIA_Notebooks/blob/main/TCIA_MONAI_Model_Zoo.ipynb)\n",
    "\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github.com/kirbyju/TCIA_Notebooks/blob/main/TCIA_MONAI_Model_Zoo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HNREyvabvwD",
    "incorrectly_encoded_metadata": "id=\"N92pMd7ig0ZS\" jp-MarkdownHeadingCollapsed=true",
    "tags": []
   },
   "source": [
    "# Summary\n",
    "This notebook demonstrates downloading the [Prostate mri anatomy](https://github.com/Project-MONAI/model-zoo/releases/download/hosting_storage_v1/prostate_mri_anatomy_v0.3.1.zip) model from MONAI's Model Zoo and applying it to segment a subset of data from the [SPIE-AAPM-NCI PROSTATEx Challenges (PROSTATEx) collection](https://doi.org/10.7937/K9TCIA.2017.MURS5CL10.7937/TCIA.X0H0-1706) on [The Cancer Imaging Archive (TCIA)](https://www.cancerimagingarchive.net/).  The resulting data are then visualized using [itkWidgets].(https://github.com/InsightSoftwareConsortium/itkwidgets)\n",
    "\n",
    "Features demonstrated include:\n",
    "* Using a python script to download and load a model from MONAI's Model Zoo into python.\n",
    "* Downloading and preparing data from TCIA for processing using that model.\n",
    "* Applying the model to the TCIA data.\n",
    "* Visually comparing model results with expert segmentation results available on TCIA.\n",
    "\n",
    "# Background\n",
    "[MONAI's Model Zoo](https://monai.io/model-zoo.html) provides pre-trained AI deep learning models that can be downloaded and used to process new data or as a starting point for transfer learning.  The [Prostate mri anatomy](https://github.com/Project-MONAI/model-zoo/releases/download/hosting_storage_v1/prostate_mri_anatomy_v0.3.1.zip) model was trained with the UNet architecture and is used for 3D volumetric segmentation of the anatomical prostate zones on T2w MRI images. The segmentation of the anatomical regions is formulated as a voxel-wise classification. Each voxel is classified as either central gland (1), peripheral zone (2), or background (0). The model is optimized using a gradient descent method that minimizes the focal soft-dice loss between the predicted mask and the actual segmentation. The model was trained in the prostate158 training data, which is available at https://doi.org/10.5281/zenodo.6481141. Only T2w images were used for this task.\n",
    "\n",
    "[The Cancer Imaging Archive (TCIA)](https://www.cancerimagingarchive.net/) is a public service funded by the National Cancer Institute that addresses this challenge by providing hosting and de-identification services to take major burdens of data sharing off researchers. Its rich collection of clinical data and annotations is particularly powerful as a community resource when it is paired with interactive code systems, such as Jupyter systems.\n",
    "\n",
    "[itkWidgets](https://github.com/InsightSoftwareConsortium/itkwidgets) allows researchers to visualize images, point sets, and 3D geometry in Jupyter systems (Jupyer Notebooks, JupyterLab, AWS SageMaker, and Google Colab). Despite its name, itkWidgets does not require the use of ITK. It can directly visualize numpy arrays, torch tensors, DASK arrays, VTK polydata, and a multitude of other python data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nj6P7YCmll4S",
    "tags": []
   },
   "source": [
    "# Outline\n",
    "\n",
    "1. Setup\n",
    "2. Download data from TCIA\n",
    "3. Prepare the data with ITK\n",
    "4. Setup itkWidgets\n",
    "5. MONAI Zoo Basics\n",
    "6. MONAI Model Inference\n",
    "7. Visualizing and Comparing Model and Expert Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FgizAMWemJM"
   },
   "source": [
    "# 1. Setup\n",
    "\n",
    "These are the initial steps for running notebooks within various Jupyter environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "As3EplXrbvwF"
   },
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K3DOvHnXsf-I",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install itk for DICOM I/O and for reading DICOM into an itkImage \n",
    "#   that manages all DICOM field values, include acquistion details \n",
    "#   such as voxel image, image orientation, and image directions,\n",
    "#   which are critical to image processing and display.\n",
    "\n",
    "# Upgrade pip, just in case.\n",
    "!python -m pip install --upgrade -q pip\n",
    "\n",
    "# installations required for monai\n",
    "!python -c \"import monai\" || pip install -q \"monai[nibabel,itk,tqdm,pandas,skimage]\"\n",
    "\n",
    "# These are the libraries used to read DICOM Seg objects.\n",
    "!python -m pip install -q pydicom pydicom-seg\n",
    "\n",
    "# Install tcia_utils to download the datasets.\n",
    "!python -m pip install --upgrade -q tcia_utils\n",
    "\n",
    "# This is the installation required for itkWidgets.\n",
    "!python -m pip install --upgrade --pre -q \"itkwidgets[all]==1.0a20\" imjoy_elfinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BctRdoEcsf-G"
   },
   "source": [
    "## Setup the im-joy-jupyter-extension for itkWidgets\n",
    "On many systems you must manually install the imjoy-jupyter-extension for itkWidgets! If you do not see a blue 'ImJoy' icon on the menu bar in this notebook:\n",
    "\n",
    "* Google CoLab: The following does not apply to Google CoLab - it will not show an ImJoy and all should work without modification.\n",
    "* Enable Extensions: Many Jupyter Lab systems disable jupyter extensions by default, and they must be enabled for this notebook to work. Typically this is accomplished using the Jupyter interface to select the extension manager (left-hand side, icon that looks like a piece of a puzzle) and select the Enable button if it appears.\n",
    "* Install imjoy extension: In the extension manager, search for 'imjoy' and install the 'imjoy-jupyter-extension'. The installation can take several minutes. It may also prompt you to rebuild, save, and reload your jupyter environment as part of this process. In the end, you should see a blue 'ImJoy' icon on the left side of the menu bar in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYxvN-rebvwG"
   },
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tF8-MqoN6YT5"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Numpy for numpy.arrays\n",
    "import numpy as np\n",
    "\n",
    "# Include ITK for DICOM reading.\n",
    "import itk\n",
    "\n",
    "# Include pydicom_seg for DICOM SEG objects\n",
    "import pydicom\n",
    "import pydicom_seg\n",
    "\n",
    "# for downloading data from TCIA\n",
    "from tcia_utils import nbia\n",
    "\n",
    "# This is the most common import command for itkWidgets.\n",
    "#   The view() function opens an interactive viewer for 2D and 3D\n",
    "#   data in a variety of formats.\n",
    "from itkwidgets import view\n",
    "\n",
    "# imports for monai\n",
    "import torch\n",
    "from monai.data import decollate_batch\n",
    "from monai.bundle import ConfigParser, download\n",
    "\n",
    "from monai.config import print_config\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ub0GzFRXemJN"
   },
   "outputs": [],
   "source": [
    "# If running on SageMaker or Studio Lab, install essential packages and extensions.\n",
    "if \"studio-lab-user\" in os.getcwd():\n",
    "    print(\"Upgrading dependencies\")\n",
    "    !conda install --yes -q --prefix {sys.prefix} -c conda-forge opencv nodejs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "di4lxyikemJN",
    "outputId": "408c7a4d-492f-43cf-cb38-afa92d1f53d3"
   },
   "source": [
    "# 2. Download the data from TCIA\n",
    "\n",
    "[Browsing Collections](https://www.cancerimagingarchive.net/collections) and viewing [Analysis Results](https://www.cancerimagingarchive.net/tcia-analysis-results/) of datasets on TCIA are the easiest ways to become familiar with what is available. These pages will help you quickly identify datasets of interest, find valuable, supporting data that are not available via TCIA's APIs (e.g. clinical spreadsheets, non-DICOM segmentation data), and answer the most common questions you might have about the datasets.  In this tutorial we'll be working with the [SPIE-AAPM-NCI PROSTATEx Challenges (PROSTATEx) collection](https://doi.org/10.7937/K9TCIA.2017.MURS5CL), but if you browse the previously mentioned links you will find that TCIA has many other prostate datasets which could be used with the [Prostate mri anatomy](https://github.com/Project-MONAI/model-zoo/releases/download/hosting_storage_v1/prostate_mri_anatomy_v0.3.1.zip) model. \n",
    "\n",
    "We will utilize the [tcia_utils](https://pypi.org/project/tcia-utils/) package to simplify downloading the data from TCIA.  If you are new to accessing TCIA via notebooks, you can find additional tutorials on querying and downloading data at https://github.com/kirbyju/TCIA_Notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urhgDgvb39pS"
   },
   "outputs": [],
   "source": [
    "# Download a \"Shared Cart\" containing 6 scans from PROSTATEx\n",
    "#    that has been previously created via the TCIA website \n",
    "#    (https://nbia.cancerimagingarchive.net).\n",
    "cart_name = \"nbia-17571668146714049\"\n",
    "\n",
    "# retrieve cart metadata\n",
    "cart_data = nbia.getSharedCart(cart_name)\n",
    "\n",
    "# download the series_uids list and return dataframe of metadata\n",
    "df = nbia.downloadSeries(cart_data)\n",
    "\n",
    "# display dataframe\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGPw6j3hbvwI"
   },
   "source": [
    "# 3. Prepare the data with itk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wR4HJu-emJP"
   },
   "outputs": [],
   "source": [
    "dicom_data_dir = \"tciaDownload\"\n",
    "\n",
    "# The series_uid defines their directory where the MR data was stored on disk.\n",
    "mr_series_uid = df.at[df.Modality.eq('MR').idxmax(), 'Series UID']\n",
    "mr_dir = os.path.join(dicom_data_dir, mr_series_uid)\n",
    "\n",
    "# Read the DICOM MR series' objects and reconstruct them into a 3D ITK image.\n",
    "#   The itk.F option is added to store the image in memory using floating-point precision pixels (useful if you will filter the image or use it with MONAI).\n",
    "#   For more info on imread, see https://itkpythonpackage.readthedocs.io/en/master/Quick_start_guide.html.\n",
    "mr_image = itk.imread(mr_dir, itk.F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JdT44AzPemJP"
   },
   "outputs": [],
   "source": [
    "# The series_uid defines where the RTSTRUCT was stored on disk.  It is stored in a single file.\n",
    "seg_series_uid = df.at[df.Modality.eq('SEG').idxmax(), 'Series UID']\n",
    "seg_dir = os.path.join(dicom_data_dir, seg_series_uid)\n",
    "seg_file = glob.glob(os.path.join(seg_dir, \"*.dcm\"))[0]\n",
    "\n",
    "# Read the DICOM SEG object using pydicom and pydicom_seg.\n",
    "seg_dicom = pydicom.dcmread(seg_file)\n",
    "seg_reader = pydicom_seg.MultiClassReader()\n",
    "seg_obj = seg_reader.read(seg_dicom)\n",
    "\n",
    "# Convert the DICOM SEG object into an itk image, with correct voxel origin, spacing, and directions in physical space.\n",
    "seg_image = itk.GetImageFromArray(seg_obj.data.astype(np.float32))\n",
    "seg_image.CopyInformation(mr_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGV9j8TbemJP",
    "tags": []
   },
   "source": [
    "# 4. MONAI Zoo Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "diJ1EeQQemJQ"
   },
   "outputs": [],
   "source": [
    "model_name = \"prostate_mri_anatomy\"\n",
    "model_version = \"0.3.1\"\n",
    "zoo_dir = os.path.abspath(\"./models\")\n",
    "\n",
    "download(name=model_name, version=model_version, bundle_dir=zoo_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xcj8cA_ZemJQ"
   },
   "outputs": [],
   "source": [
    "# This model includes scripts that must be run on new data.\n",
    "#    We could import those scripts into this python notebook, but they\n",
    "#    bring in additional dependencies.   Instead, we provide the following\n",
    "#    more compact and compatible implementation.  Otherwise, you can\n",
    "#    include the model's script directory by uncommenting these lines and\n",
    "#    installing their dependencies and doing appropriate data conversions.\n",
    "# scripts_dir = os.path.join(zoo_dir, model_name, \"scripts\")\n",
    "# sys.path.insert(1, scripts_dir)\n",
    "\n",
    "# Compact alternative implementation of this model's specific cropping step.\n",
    "#   Ideally this would have been accomplished using MONAI's transforms\n",
    "#   for data pre-processing / augmentation instead of using a separate\n",
    "#   function.\n",
    "def prostate_crop(img):\n",
    "    boundary = [int(crop_size * 0.2) for crop_size in img.GetLargestPossibleRegion().GetSize()]\n",
    "    new_image = itk.CropImageFilter(Input=img, BoundaryCropSize=boundary)\n",
    "    return new_image\n",
    "\n",
    "\n",
    "mr_image_prep = prostate_crop(mr_image)\n",
    "seg_image_prep = prostate_crop(seg_image)\n",
    "\n",
    "# Running a MONAI model on new data requires that data to be saved on\n",
    "#   local disk.\n",
    "itk.imwrite(mr_image_prep, mr_dir + \".nii.gz\")\n",
    "itk.imwrite(seg_image_prep, seg_dir + \".nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YhDJqRkHemJQ"
   },
   "outputs": [],
   "source": [
    "# The model's config file dynamically generates the functions needed to process new data.\n",
    "\n",
    "# Define our local system and filesystem.\n",
    "output_dir = os.path.abspath(\"./monai_results\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Parse the variables in the config file.\n",
    "model_config_file = os.path.join(zoo_dir, model_name, \"configs\", \"inference.json\")\n",
    "model_config = ConfigParser()\n",
    "model_config.read_config(model_config_file)\n",
    "\n",
    "# Update the confir variables to match our filesystem.\n",
    "model_config[\"bundle_root\"] = zoo_dir\n",
    "model_config[\"output_dir\"] = output_dir\n",
    "\n",
    "# Identify which version of the model we want to load (each version is a\n",
    "#    \"checkpoint\").  For most models, the \"best\" checkpoint is called \"model.pt\"\n",
    "#    and it is stored in the models subdir.\n",
    "checkpoint = os.path.join(zoo_dir, model_name, \"models\", \"model.pt\")\n",
    "\n",
    "# Ask the config file to generate the functions needed to process new data.\n",
    "#    These functions are adapted to our system by the config variables we\n",
    "#    modified above.  The order of first defining variables and then creating the\n",
    "#    functions is critical.\n",
    "preprocessing = model_config.get_parsed_content(\"preprocessing\")\n",
    "\n",
    "model = model_config.get_parsed_content(\"network\").to(device)\n",
    "\n",
    "inferer = model_config.get_parsed_content(\"inferer\")\n",
    "\n",
    "postprocessing = model_config.get_parsed_content(\"postprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CqoHulOhemJR"
   },
   "outputs": [],
   "source": [
    "# Point the dataloader to the downloaded and converted TCIA data.\n",
    "datalist = [mr_dir + \".nii.gz\"]\n",
    "model_config[\"datalist\"] = datalist\n",
    "dataloader = model_config.get_parsed_content(\"dataloader\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zX0UIVt9bvwJ"
   },
   "source": [
    "# 5. Visualize the data with itkWidgets\n",
    "\n",
    "[itkWidgets documentation](https://itkwidgets.readthedocs.io/en/latest/?badge=latest) provides a summary and illustrations of itkWidgets for a wide variety of scientific data visualization use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RF4LqDs-emJR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "view(image=mr_image_prep, label_image=seg_image_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FmGXwzXemJR",
    "tags": []
   },
   "source": [
    "# 6. MONAI Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kbGZrHfWemJR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(checkpoint, map_location=device))\n",
    "model.eval()\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for d in dataloader:\n",
    "        images = d[\"image\"].to(device)\n",
    "        d[\"pred\"] = inferer(images, network=model)\n",
    "        results.append([postprocessing(i) for i in decollate_batch(d)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrMqViotemJS"
   },
   "source": [
    "# 7. Visualizing and Comparing Model and Expert Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cjLs9PjDemJS"
   },
   "outputs": [],
   "source": [
    "# Read the result image that was written into the output_dir.\n",
    "result_image = itk.imread(os.path.join(output_dir, os.path.split(mr_dir)[\n",
    "                          1], os.path.split(mr_dir)[1] + \"_trans.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xkh3TtD9emJS"
   },
   "outputs": [],
   "source": [
    "# Various manipulations were done to the input image before it is fed to the model\n",
    "#    for inference.   As a result, the result image may not be in the same\n",
    "#    spacing, orientation, etc as the original input data.  So, we resample the results\n",
    "#    image to match the physical properties of the original input data.\n",
    "interpolator = itk.NearestNeighborInterpolateImageFunction.New(seg_image)\n",
    "result_image_resampled = itk.resample_image_filter(Input=result_image,\n",
    "                                                   Interpolator=interpolator,\n",
    "                                                   reference_image=seg_image_prep,\n",
    "                                                   use_reference_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9bmgCBL9emJS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# View the image with results overlaid in an interactive 2D slice viewer.\n",
    "viewer_b = view(image=mr_image_prep, label_image=result_image_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mYRlAbKusf-L",
    "tags": []
   },
   "outputs": [],
   "source": [
    "viewer_b.set_image_color_map(\"Grayscale\")\n",
    "viewer_b.set_label_image_blend(0.5)\n",
    "viewer_b.set_image_color_range([100, 500])\n",
    "viewer_b.set_view_mode('ZPlane')\n",
    "viewer_b.set_ui_collapsed(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2wHOPVkWemJS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_array = itk.GetArrayViewFromImage(result_image_resampled)\n",
    "expert_array = itk.GetArrayViewFromImage(seg_image_prep)\n",
    "\n",
    "# Note that the data in the ProstateX repo uses different labels than the data used to\n",
    "#    build the model.  For example, the prostate is label 1 in the model and label 2\n",
    "#    in the ProstateX data.\n",
    "# The following creates a label image where \n",
    "#    1 = ideal prostate, but model called non-prostate (red)\n",
    "#    2 = model called prostate, but ideal called non-prostate (purple)\n",
    "#    3 = modeal and ideal agreed (green)\n",
    "compare_model_expert = np.where(result_array != 1, 0, 2) + np.where(expert_array != 2, 0, 1)\n",
    "compare_image = itk.GetImageFromArray(compare_model_expert.astype(np.float32))\n",
    "compare_image.CopyInformation(seg_image_prep)\n",
    "\n",
    "viewer_c = view(image=mr_image_prep, label_image=compare_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "diqDQW4PemJS"
   },
   "outputs": [],
   "source": [
    "# Switch to an interactive slice view so that labels are more easily seen.\n",
    "viewer_c.set_label_image_blend(0.6)\n",
    "viewer_c.set_image_color_map(\"Grayscale\")\n",
    "viewer_c.set_view_mode(\"ZPlane\")\n",
    "viewer_c.set_image_color_range([100, 500])\n",
    "viewer_c.set_ui_collapsed(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYXsNGcY93B8",
    "tags": []
   },
   "source": [
    "# Acknowledgements\n",
    "\n",
    "TCIA is funded by the [Cancer Imaging Program (CIP)](https://imaging.cancer.gov/), a part of the United States [National Cancer Institute (NCI)](https://www.cancer.gov/), and is managed by the [Frederick National Laboratory for Cancer Research (FNLCR)](https://frederick.cancer.gov/).\n",
    "\n",
    "If you leverage this notebook or any TCIA datasets in your work, please be sure to comply with the [TCIA Data Usage Policy](https://wiki.cancerimagingarchive.net/x/c4hF). In particular, make sure to cite the DOI(s) for the specific TCIA datasets you used in addition to TCIA citation provided below!\n",
    "\n",
    "This notebook was created by [Stephen Aylward (Kitware)](https://www.kitware.com/stephen-aylward/), [Justin Kirby (Frederick National Laboratory for Cancer Research)](https://www.linkedin.com/in/justinkirby82/), [Brianna Major (Kitware)](https://www.kitware.com/brianna-major/), and [Matt McCormick (Kitware)](https://www.kitware.com/matt-mccormick/).   The creation of this notebook was funded, in part, by NIBIB and NIGMS R01EB021396,\n",
    "NIBIB R01EB014955, NCI R01CA220681, and NINDS R42NS086295.\n",
    "\n",
    "If you have any questions, suggestions, or issues with itkWidgets, please post them on the [itkwidget issue tracker](https://github.com/InsightSoftwareConsortium/itkwidgets/issues) or feel free to email us at kitware@kitware.com.\n",
    "\n",
    "## Dataset Citation\n",
    "The data used in this notebook was part of the SPIE-AAPM-NCI PROSTATEx Challenges (PROSTATEx) collection:\n",
    "\n",
    "Geert Litjens, Oscar Debats, Jelle Barentsz, Nico Karssemeijer, and Henkjan Huisman. \"ProstateX Challenge data\", The Cancer Imaging Archive (2017). DOI: [10.7937/K9TCIA.2017.MURS5CL](https://doi.org/10.7937/K9TCIA.2017.MURS5CL)\n",
    "\n",
    "## Publication Citation\n",
    "The data used in this notebook was part of the SPIE-AAPM-NCI PROSTATEx Challenges (PROSTATEx) collection:\n",
    "\n",
    "Litjens G, Debats O, Barentsz J, Karssemeijer N, Huisman H. \"Computer-aided detection of prostate cancer in MRI\", IEEE Transactions on Medical Imaging 2014;33:1083-1092. DOI: [10.1109/TMI.2014.2303821](https://doi.org/10.1109/TMI.2014.2303821)\n",
    "\n",
    "## TCIA Citation\n",
    "\n",
    "Clark, K., Vendt, B., Smith, K., Freymann, J., Kirby, J., Koppel, P., Moore, S., Phillips, S., Maffitt, D., Pringle, M., Tarbox, L., & Prior, F. (2013). The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository. Journal of Digital Imaging, 26(6), 1045â€“1057. https://doi.org/10.1007/s10278-013-9622-7"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
